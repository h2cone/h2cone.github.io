<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Huangh&#39;s blog</title>
    <link>https://h2cone.github.io/</link>
    <description>Recent content on Huangh&#39;s blog</description>
    <generator>Hugo 0.125.0</generator>
    <language>en-us</language>
    <copyright>© Huangh&#39;s blog</copyright>
    <lastBuildDate>Sat, 28 Dec 2024 14:42:59 +0800</lastBuildDate>
    <atom:link href="https://h2cone.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>造你自己的桌面应用</title>
      <link>https://h2cone.github.io/2024/12/28/your-own-desktop-app/</link>
      <pubDate>Sat, 28 Dec 2024 14:42:59 +0800</pubDate>
      <guid>https://h2cone.github.io/2024/12/28/your-own-desktop-app/</guid>
      <description>Node 本来想用 jdx/mise 丝滑安装和管理 Node.js 版本，可似乎没搭配 npm，于是参考了 Install Node.js on Windows 推荐的 nvm-windows ，在 Windows 上安装长期支持的 Node 版本。&#xA;&amp;gt; nvm install 20 Downloading node.js version 20.18.1 (64-bit)... Extracting node and npm... Complete npm v10.8.2 installed successfully. Installation complete. If you want to use this version, type nvm use 20.18.1 &amp;gt; nvm use 20.18.1 Now using node v20.18.1 (64-bit) &amp;gt; npm --version 10.8.2 遇到问题直接 nvm debug 很有帮助。&#xA;Solution 1: Electron + Vue + daisyUI 在 Web 开发中，我们通常使用 HTML 和 CSS 以及 JavaScript 来开发网站前端，这些技术也可以用来开发桌面应用程序。例如 Electron 是最流行的跨平台桌面应用框架之一，Visual Studio Code、Postman、Discord 等知名桌面应用都在展示柜的前列。</description>
    </item>
    <item>
      <title>流式处理 gzip</title>
      <link>https://h2cone.github.io/2024/09/03/gzip-streaming/</link>
      <pubDate>Tue, 03 Sep 2024 14:16:35 +0800</pubDate>
      <guid>https://h2cone.github.io/2024/09/03/gzip-streaming/</guid>
      <description>需求背景 不同的客户从服务端获取相同对象时返回不同的文件视图。待处理的文件是 gzip 压缩的文本文件，既不希望在处理过程中产生文件存储开销，也不希望 TTFB 过长影响客户体验。刚好 gzip 压缩算法基于 Deflate，允许在处理数据时逐块进行解压或压缩，而不需要一次性将整个数据加载到内存中。如果是在 Amazon S3 存储压缩文件，那么 Amazon S3 Object Lambda 是配套的解决方案。面向 Serverless 计算，我们的函数在运行时受到云厂商配额的限制：内存、时间、空间、并发等。因此，我们需要在处理文件时，尽可能减少内存占用，同时提高执行效率。&#xA;心路历程 解压 刚开始学习使用 reqwest 来获取文本文件，结合各种异步库来流式读取文件内容。&#xA;use futures::TryStreamExt; use tokio::io::AsyncBufReadExt; use tokio_util::io::StreamReader; let url = &amp;#34;...&amp;#34; let resp = reqwest::get(url).await?; let stream = resp.bytes_stream(); let stream_reader = StreamReader::new(stream.map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))); let reader = tokio::io::BufReader::new(stream_reader); let mut lines = reader.lines(); while let Some(line) = lines.next_line().await? { // ... } 紧接着，注意到 Rust 团队维护的 flate2-rs 可以用来流式压缩/解压 *.</description>
    </item>
    <item>
      <title>造你自己的 HTTP 代理</title>
      <link>https://h2cone.github.io/2024/05/29/your-own-http-proxy/</link>
      <pubDate>Wed, 29 May 2024 20:35:53 +0800</pubDate>
      <guid>https://h2cone.github.io/2024/05/29/your-own-http-proxy/</guid>
      <description>前面的话 最近在亲近 Rust 生态，注意到 Cloudflare 开源了用于构建快速和可靠以及可演进的网络服务库 Pingora，了解了“最少必要知识”后，决定尝试基于 Pingora 构建 HTTP 代理服务来代替私有服务器上的 Caddy。&#xA;老弟我的服务器配置文件 Caddyfile 类似于：&#xA;:8008 route /json { reverse_proxy node1:8090 node2:8090 } 简言之，Caddy 会监听端口 8008 的 HTTP 请求，若请求 URI 为 /json，则将请求转发到上游 node1 或 node2 的后端服务。&#xA;upstream backend { server node1:8090; server node2:8090; } server { listen 8008; location /json { proxy_pass http://backend; } } 准备工作 使用 Cargo 新建项目：&#xA;. ├── Cargo.toml ├── .gitignore ├── README.md └── src 编辑 Cargo.toml 配置项：</description>
    </item>
    <item>
      <title>本站是如何构建的</title>
      <link>https://h2cone.github.io/2024/05/21/build_this_site/</link>
      <pubDate>Tue, 21 May 2024 20:04:12 +0800</pubDate>
      <guid>https://h2cone.github.io/2024/05/21/build_this_site/</guid>
      <description>碎碎念 这个博客是我在很久以前就是开始维护了，最初使用的是 Hugo 生成的静态内容并托管在 GitHub Pages 上，长期使用过两个大而全的主题，可见多了容易审美疲劳，于是就准备走向“大道至简”；由于近期在学习 Rust，被系统推荐到另一个静态站点生成器 Zola，于是就尝试了一下从 Hugo 迁移到 Zola，但是令我沮丧的不仅是 Zola 的主题生态不如 Hugo，而是 Zola 作者没有计划支持自定义 URL 模板或者添加一个选项以将日期集成到路径中没那么快实现；显然本站的博文 URL 是包含日期的，暂无精力处理这个迁移问题，于是就又回到了 Hugo。&#xA;工作流 好的工作流可以确保博客开发和部署的高效和可维护性，使得开发者可以专注于内容创作而不是复杂的部署过程。&#xA;🟢 localhost 表示本地开发环境。 在本地计算机上，使用 Hugo 生成和预览博客内容。 通过 Hugo 的本地服务器查看和调试博客，确保所有内容和样式都正确显示。 🟡 https://github.com/&amp;lt;username&amp;gt;/&amp;lt;username&amp;gt;.github.io 表示 GitHub Pages 仓库。 这是用于 GitHub Pages 部署的仓库。通常它的名字为 &amp;lt;username&amp;gt;.github.io，其中 &amp;lt;username&amp;gt; 是 GitHub 用户名，例如 https://github.com/h2cone/h2cone.github.io 从博客主仓库部署（deploying）生成的静态文件到这个仓库。可以通过 git submodule 或 gh-pages 分支来支持。 部署后，GitHub Pages 服务会自动从这个仓库中提取内容，并在 URL https://&amp;lt;username&amp;gt;.github.io 上提供服务（serving）。 🟣 https://github.com/&amp;lt;username&amp;gt;/&amp;lt;blog&amp;gt; 表示博客主仓库。 博客的主要源代码托管在 GitHub 仓库中。这个仓库包含所有博客文章、配置文件和 Hugo 所需的其他资源。若无权访问则可能是因为作者将其设置为私有仓库，例如 https://github.com/h2cone/blog 本地开发完成后，将修改内容同步（syncing）到这个仓库。通过 git push 命令将本地更改推送到 GitHub 仓库。 🔵 https://github.</description>
    </item>
    <item>
      <title>造你自己的 Chrome 扩展</title>
      <link>https://h2cone.github.io/2024/01/31/your-own-chrome-extension/</link>
      <pubDate>Wed, 31 Jan 2024 23:57:13 +0800</pubDate>
      <guid>https://h2cone.github.io/2024/01/31/your-own-chrome-extension/</guid>
      <description>背景 除了纸质书，有时也会从 Z-Library 下载不同版本的电子书，但是它的域名经常由于查封而改变，因此想造一个 Chrome 扩展来快捷访问 Z-Library 的最新正规站点。&#xA;AI 生成 . ├── README.md ├── images │ └── favicon.png ├── manifest.json └── popup ├── popup.html └── popup.js 配置文件 { &amp;#34;name&amp;#34;: &amp;#34;openzlib&amp;#34;, &amp;#34;description&amp;#34;: &amp;#34;Open Z-Library&amp;#34;, &amp;#34;version&amp;#34;: &amp;#34;1.0&amp;#34;, &amp;#34;manifest_version&amp;#34;: 3, &amp;#34;action&amp;#34;: { &amp;#34;default_icon&amp;#34;: &amp;#34;images/favicon.png&amp;#34;, &amp;#34;default_popup&amp;#34;: &amp;#34;popup/popup.html&amp;#34; }, &amp;#34;host_permissions&amp;#34;: [ &amp;#34;&amp;lt;all_urls&amp;gt;&amp;#34; ] } 这段代码是一个 manifest.json 文件，它是 Chrome 扩展的关键组成部分。这个文件向 Chrome 浏览器提供了关于扩展的重要信息。&#xA;&amp;quot;name&amp;quot;: &amp;quot;openzlib&amp;quot;：这是扩展的名称，用户会看到这个名称。 &amp;quot;description&amp;quot;: &amp;quot;Open Z-Library&amp;quot;：这是对扩展功能的简短描述。 &amp;quot;version&amp;quot;: &amp;quot;1.0&amp;quot;：这是扩展的当前版本。每次发布扩展的新版本时，都需要更新这个值。 &amp;quot;manifest_version&amp;quot;: 3：这表示 manifest.json 文件格式的版本。 &amp;quot;action&amp;quot;：这个对象定义了扩展的默认图标和弹出窗口。&amp;quot;default_icon&amp;quot; 属性指向图标文件的位置，&amp;quot;default_popup&amp;quot; 属性指向用户点击 Chrome 工具栏中的扩展图标时应显示的 HTML 文件。 &amp;quot;host_permissions&amp;quot;: \[&amp;quot;&amp;lt;all_urls&amp;gt;&amp;quot;\]：这个数组定义了扩展可以访问的 URL。在这个例子中，扩展有权限访问所有的 URL。 主要代码 &amp;lt;!</description>
    </item>
    <item>
      <title>造你自己的 GraalVM Native Image 命令行应用</title>
      <link>https://h2cone.github.io/2023/11/18/your-own-graalvm-native-image-cli-app/</link>
      <pubDate>Sat, 18 Nov 2023 23:39:26 +0800</pubDate>
      <guid>https://h2cone.github.io/2023/11/18/your-own-graalvm-native-image-cli-app/</guid>
      <description>写在前面 云原生声量最大的一段时间里 Java 时常被人诟病应用启动速度太慢了，而且占用内存也很大，由于云原生应用目标包括快速启动、快速响应、快速扩容、快速收缩，因此 Java 一直被认为不适合云原生应用。但是，随着 GraalVM 的曝光，这个问题得到了部分解决，GraalVM 可以将 Java 应用编译成本地可执行文件，它被称为 Native Image，这样就不需要安装 Java 运行时（JRE）了，直接运行即可。&#xA;最早体验到 Native Image 是通过 Quarkus 与 Picocli 开发一些命令行应用（CLI App），个人感觉针对不同的平台打包出不同的二进制文件的编译和部署成本比 Go/Rust/Node.js 语言都高，Native Image 的限制也比较多，比如反射、动态代理、动态类加载等，不得不以声明式告诉 GraalVM 哪些类有哪些动态行为。后来 Spring Boot 也支持了 Native Image，那些老毛病健在，只不过生态规模更大罢了。&#xA;GraalVM 能显著提升 Java 应用程序的性能还是挺可信的，比如 GraalVM for JDK 21 is here! 和 Migrating 10MinuteMail from Java to GraalVM Native，尤其相较于传统 JVM 应用的这两个指标：&#xA;启动时间 startup time 单位时间与内存的吞吐量 requests/GB-s 先决条件 安装 Java 21 或更高版本，现在挺流行使用 SDKMAN! 安装和管理多版本 JDK，我习惯在 Download Azul JDKs 下载 OpenJDK。 在 Windows 平台，在 WSL 之外，也可以只通过类似于 alias 的别名动态切换 JDK 版本，比如编辑 PowerShell 的 $profile 指向的文件： # reload env path Function Refresh { $env:Path = [System.</description>
    </item>
    <item>
      <title>虚拟线程速览</title>
      <link>https://h2cone.github.io/2023/09/26/a-quick-look-at-virtual-threads/</link>
      <pubDate>Tue, 26 Sep 2023 22:32:39 +0800</pubDate>
      <guid>https://h2cone.github.io/2023/09/26/a-quick-look-at-virtual-threads/</guid>
      <description>为了解决什么问题？ 围绕 I/O 为核心的单机任务，难点之一是权衡应对负载增加的能力和开发的难易程度，从 网络·NIO 中我们可以看到，Blocking I/O 优点是概念简单，缺点是在 I/O 操作完成之前，线程将无法执行任何其他操作，另外一点容易忽视的是它经过 Java 堆复制数据；Java NIO 劣势是概念较复杂（考虑异步容易出错），优势是支持非阻塞 I/O 和分配直接内存。一般情况下，基于 NIO 的服务比基于 BIO 的服务性能表现更好，但阻塞式 I/O 对广大开发者的心智负担更低。&#xA;使用非阻塞 I/O 模型难以避免引入异步编程或响应式编程，而这些范式对于开发者来说是一种挑战，因此许多主流语言都提供了将单线程阻塞式代码转化为异步、非阻塞式代码的语法糖，比如 C#/JavaScript 的 async/await：&#xA;让出（yield）控制权给调用者线程。 尝试隐藏异步调用与同步调用的差异，使其看起来像同步代码那样简单。 是通过编译器自动将 async 方法转换为状态机来实现的。 详情参考 Task asynchronous programming model，随着越来越多的异步“传染”程序代码，性能提高代价可能是越来越难以推理代码。由于各种各样的原因，Java 官方没走 async/await 的道路，而是选择了类似于 Go/Kotlin 协程 的“绿色线程”。所谓“绿色”是相对于 OS 线程而言，其中 Java 的线程瓶颈尤为严重，已知 1 线程需要大小 1MB 的栈，那么 10000 线程大约消费 10 GB 内存，这类来自 OS 的瓶颈促使开发人员考虑线程池技术。随着负载的增加，Java 线程池的扩展又是一大挑战，官方正式推出的挑战者是虚拟线程。&#xA;“每线程一请求”的崛起？ ExecutorService executor = Executors.newThreadPerTaskExecutor(Thread.ofVirtual().name(&amp;#34;my-thread&amp;#34;, 0).factory()); @Override public void run() { try (ServerSocket serverSocket = new ServerSocket(port)) { while (!</description>
    </item>
    <item>
      <title>通过 Azure OpenAI API 接入 ChatGPT</title>
      <link>https://h2cone.github.io/2023/04/26/azure_openai_api_0/</link>
      <pubDate>Wed, 26 Apr 2023 13:54:13 +0800</pubDate>
      <guid>https://h2cone.github.io/2023/04/26/azure_openai_api_0/</guid>
      <description>写在前面 上个月参与公司将 LLM 应用到基于 Spring Boot 的业务系统差事：接入 ChatGPT。&#xA;Azure OpenAI Service Azure OpenAI 服务允许通过 REST API 访问 OpenAI 的强大语言模型，包括 GPT-3、Codex 和 Embeddings 模型系列。 这些模型可以轻松适应特定的任务，包括但不限于内容生成、汇总、语义搜索和自然语言到代码的转换。用户可以通过 REST API、Python SDK 或 Azure OpenAI Studio 中基于 Web 的界面访问该服务。&#xA;使用 Azure OpenAI 服务在大部分情况下不需要代理，无严格网络封锁。&#xA;依赖库 后端 TheoKanning/openai-java。Java 中的 OpenAI GPT-3 API 客户端。 knuddelsgmbh/jtokkit。JTokkit 是一个 Java 分词器库，设计用于 OpenAI 模型。 前端 mpetazzoni/sse.js。一个灵活的 JavaScript SSE 库。 认证 与 OpenAI API 的 header 要求包含 Authorization: Bearer $OPENAI_API_KEY 不同的是，Azure OpenAI API 的 header 要求包含 api-key: $OPENAI_API_KEY，详情参考 Azure OpenAI Service REST API reference。</description>
    </item>
    <item>
      <title>V2Ray &#43; Cloudflare WARP</title>
      <link>https://h2cone.github.io/2023/04/05/proxy_with_warp/</link>
      <pubDate>Wed, 05 Apr 2023 16:22:44 +0800</pubDate>
      <guid>https://h2cone.github.io/2023/04/05/proxy_with_warp/</guid>
      <description>🧱 有一阵子访问 OpenAI（现在更像 CloseAI） 的一些域名经常遇到 Cloudflare 的 Access Denied，一开始尝试更换机房 IP 来代理，可几乎没有一个不在黑名单。侥幸通过先走代理，在登录最后一步切换为直连绕过了数次，直到国内终于彻底被墙了。&#xA;❓ 打不过就加入它：流量出站转向 Cloudflare 网络。&#xA;在 VPS 上安装 WARP，以 Debian/Ubuntu 为例： sudo apt install cloudflare-warp 以本地代理模式运行 WARP warp-cli register warp-cli set-mode proxy warp-cli connect warp-cli enable-always-on 测试代理模式 curl ifconfig.me 留意前后标准输出的区别。&#xA;export ALL_PROXY=socks5://127.0.0.1:40000 curl ifconfig.me 配置 V2Ray 设置路由规则，非国内域名走 WARP 代理。&#xA;{ &amp;#34;routing&amp;#34;: { &amp;#34;domainStrategy&amp;#34;: &amp;#34;IPIfNonMatch&amp;#34;, &amp;#34;rules&amp;#34;: [ { &amp;#34;type&amp;#34;: &amp;#34;field&amp;#34;, &amp;#34;outboundTag&amp;#34;: &amp;#34;reject&amp;#34;, &amp;#34;ip&amp;#34;: [ &amp;#34;geoip:private&amp;#34; ] }, { &amp;#34;type&amp;#34;: &amp;#34;field&amp;#34;, &amp;#34;outboundTag&amp;#34;: &amp;#34;proxy&amp;#34;, &amp;#34;domain&amp;#34;: [ &amp;#34;geosite:geolocation-!</description>
    </item>
    <item>
      <title>Rust 八股</title>
      <link>https://h2cone.github.io/2022/12/04/rust_rookie_qa/</link>
      <pubDate>Sun, 04 Dec 2022 21:17:41 +0800</pubDate>
      <guid>https://h2cone.github.io/2022/12/04/rust_rookie_qa/</guid>
      <description>设问 先有 Rust 还是先有 Rust 编译器？ 第一个 Rust 编译器一定是用非 Rust 实现的，假设它叫引导编译器，巨佬用引导编译器来编译用 Rust 编写的 Rust 编译器源代码得到 Rust 实现的 Rust 编译器，从此以后的迭代开发无需引导编译器，而是基于 Rust 实现的 Rust 编译器。&#xA;第一次看到 rust-lang/rust 就有这样的疑问，后来才想起来这种解决方案被称为自举。&#xA;语句与表达式的区别？ 语句（statement）是执行某些动作的指令，无返回值；表达式（expression）被估算（evaluate）输出返回值。&#xA;当在语句行尾处遇到 ; 时，其左邻的片段将被估算出返回值，该返回值又被 = 赋予某个变量，它们通常成对出现，若该片段不含分号，则它被看作是表达式。&#xA;内存分配在哪里？ 基于堆的内存分配（heap-based memory allocation）或基于栈的内存分配（stack-based memory allocation）。赋值语句、函数调用等场景离不开给变量（的值）分配内存，很喜欢书中的餐厅隐喻，在栈上分配内存就像叠碟子，而堆上分配内存就像进入餐厅找空位。&#xA;标量类型（scalar type）数值仅在堆上分配内存，比如整数、浮点数、布尔、字符，它们的长度固定的含义是在运行时比特序列长度不可变，换言之，在编译时就已经知道它们的大小。复合类型（Compound Types）中的元组和数组的长度固定，因此在栈上分配内存；相反，在编译时未知大小的数据或可能改变大小的数据必须被存储在堆上，而找到堆上数据的方法是通过栈上的指针的值——虚拟地址，地址为标量。总而言之，要么仅在栈上分配内存，要么既在栈上，又在堆上分配内存。&#xA;每个小矩形内：栈在左，堆在右。 scalar 标量。 ptr 指针。 箭头：地址指向的位置。 len 长度。 cap 容量。 蓝色：len。 绿色：cap - len。 赋值语句或函数调用传参本质上是纯栈的数据拷贝? 如果在堆上的数据很大，那么堆的数据拷贝在运行时开销非常昂贵，一般情况下都是隐式 Copy，除非显式 Clone。&#xA;什么是所有权？ 所有权（ownership）使 Rust 能够无需垃圾收集器的情况下保证内存安全。默认情况下，违反所有权规则会导致编译错误，所有权规则如下所述：&#xA;每个值（value）都有一个所有者（owner）。 一个所有者是一个变量。 隐式只有一个所有者，显式支持多个所有者。 当所有者超出作用域（variable scope）时，该值将被销毁（drop）。 范围开始于左大括号 {, 结束于右大括号 }。 通过实现 Drop 来销毁值。 在规则之上，所有权可以在变量之间转移（move），用官方的例子来说，被其它变量夺走所有权的变量已无效。</description>
    </item>
    <item>
      <title>正则表达式用例</title>
      <link>https://h2cone.github.io/2022/07/15/regex_use_cases/</link>
      <pubDate>Fri, 15 Jul 2022 10:31:49 +0800</pubDate>
      <guid>https://h2cone.github.io/2022/07/15/regex_use_cases/</guid>
      <description>前言 正则表达式是指定文本中搜索模式的字符序列，这种模式被字符串搜索算法用于对字符串进行查找、替换、校验等。&#xA;拆分 在日志解析领域，时常遇到满足特定模式的日志条目，比如“头部”是时间信息，“身体”是详细信息的日志条目：&#xA;% cat a0.log &amp;lt;30&amp;gt;May 21 21:33:47 localhost alert: {category=漏洞扫描事件} {type=WebShell} {priority=提示} {typeCN=Web后门} {level=6} {id=974609} {time=2018-05-21 21:33:04} {sip=101.206.169.180} {sport=49187} {dip=10.1.186.7} {dport=9084} {host=m.****.com.cn:9084} {code=200} {sysurl=https://h2cone.github.io/sys/web_session.php?level=6&amp;amp;sid=974609} {attach=/sys/web_session.php?act=download&amp;amp;level=6&amp;amp;sid=974609} {intent=上传可执行脚本或WebShell文件} {detail=在Post数据包中发现含有JSP/ASP/ASP.NET代码特征的字符：&amp;lt;%request/QueryString/Form/[&amp;#39;...&amp;#39;]%&amp;gt;} {dev=zonghang01} {url=http://m.****.com.cn:9084/pmobile/MCPerEAccountSignTrs.do} 人脑能够从少量日志条目归纳出日志的格式，也能从程序开发者的角度看见日志的结构，但是计算机只有在人类的指导（声明字符串满足的模式）下才能区分日志条目的各个组成部分。&#xA;% cat a0.log | sd &amp;#39;(&amp;lt;\d+&amp;gt;\w+\s+\d{1,2}\s+\d{2}:\d{2}:\d{2}\s+\w+\s+\w+:\s+)(.+)&amp;#39; &amp;#39;$1\n$2&amp;#39; &amp;lt;30&amp;gt;May 21 21:33:47 localhost alert: {category=漏洞扫描事件} {type=WebShell} {priority=提示} {typeCN=Web后门} {level=6} {id=974609} {time=2018-05-21 21:33:04} {sip=101.206.169.180} {sport=49187} {dip=10.1.186.7} {dport=9084} {host=m.****.com.cn:9084} {code=200} {sysurl=https://h2cone.github.io/sys/web_session.php?level=6&amp;amp;sid=974609} {attach=/sys/web_session.php?act=download&amp;amp;level=6&amp;amp;sid=974609} {intent=上传可执行脚本或WebShell文件} {detail=在Post数据包中发现含有JSP/ASP/ASP.NET代码特征的字符：&amp;lt;%request/QueryString/Form/[&amp;#39;...&amp;#39;]%&amp;gt;} {dev=zonghang01} {url=http://m.****.com.cn:9084/pmobile/MCPerEAccountSignTrs.do} 命令行工具 sd 用于在文本中查找与替换，它既支持基于字面量的查找，也支持基于正则表达式的查找。上文整条命令表示将文件 a1.log 输入到 sd，它第一个参数是替换前字符串满足的模式（正则表达式），第二个参数是替换后的字符串格式，从输出结果可以看到日志条目的“头部”和“身体”之间已通过行分隔符 \n 分隔，相当于拆分成两个部分。</description>
    </item>
    <item>
      <title>高吞吐 Kafka 客户端配置</title>
      <link>https://h2cone.github.io/2022/06/20/high_throughput_kafka_client_config/</link>
      <pubDate>Mon, 20 Jun 2022 10:16:16 +0800</pubDate>
      <guid>https://h2cone.github.io/2022/06/20/high_throughput_kafka_client_config/</guid>
      <description>写在前面的话 团队围绕着 Kafka 一系列服务的压力测试的核心指标之一是 Eevents per second，排除其它因素，它与吞吐量正相关。&#xA;什么是吞吐量 吞吐量是指通过通信通道成功传递消息的速率。从 Kafka 生产者（Producer）的角度来看，可以用单位时间内交付成功的记录条数或大小来描述吞吐量；从 Kafka 消费者（Consumer）的角度来看，可以用单位时间内读取的记录条数或大小来描述。&#xA;生产者准备记录包含业务逻辑，此处只关注单位时间内接收到回执（ack）的记录条数或大小。默认情况下，生产者使用异步发送，且它将尝试在内存中累积记录并在单个请求中发送批量记录。&#xA;for (long i = 0; i &amp;lt; numRecords; i++) { producer.send(record, callback); } 调用方法 KafkaProducer.send(ProducerRecord, Callback) 不阻塞在该方法，既传递记录（record）的引用，也传递回调（callback）的引用。&#xA;class MyCallback implements Callback { @Override public void onCompletion(RecordMetadata metadata, Exception e) { // handling } } 生产者接受到发送记录的回执时，将有线程执行方法 onCompletion 的代码，我们可以在回调方法体内实现记录条数或大小的累计。&#xA;注意：“提交偏移量”不一定发生在“处理记录”之后。&#xA;while (conditions) { ConsumerRecords records = consumer.poll(timeout); processRetrievedRecords(records); } 消费者处理记录包含业务逻辑，此处只关注单位时间内接受到的记录条数或大小。默认情况下，消费者通过轮询拉取（poll）批量的记录，每次调用方法 KafkaConsumer.poll(Duration) 阻塞在该方法，直到超时（timeout）返回，且会有线程定期透明地提交前一批的最后一条记录的偏移量（auto commit）。&#xA;测试吞吐量 生产者工具 在 Kafka 安装目录，有助于测试生产者性能的命令行工具是 kafka-producer-perf-test.</description>
    </item>
    <item>
      <title>Java 8 到 Java 17 的特性</title>
      <link>https://h2cone.github.io/2022/05/30/java8-java17/</link>
      <pubDate>Mon, 30 May 2022 10:37:32 +0800</pubDate>
      <guid>https://h2cone.github.io/2022/05/30/java8-java17/</guid>
      <description>个人选择 公司中的遗留项目基于 Java 8，也有部署使用 Java 11 的开源软件；对于 Side Project，甚至是新项目，可以毫不犹豫使用 Java 11/17。个人嫌在 Oracle 官方下载 JDK 过于麻烦，也非 100% 开源，加上本地操作系统指令集架构从 x86 转到了 ARM，因此决定下载 Azul Zulu Builds of OpenJDK。&#xA;市面上各家厂商构建的 JDK 不可能毫无差异，比如 OpenJDK 与 Oracle JDK – 比较表。&#xA;向后兼容 Java 8 有时被称为 Java 1.8，在这之后的版本号不再以 1. 开头，随着发布时间的增加而增加，上图中只有 8、11、17 是 LTS 版本。&#xA;% java -version openjdk version &amp;#34;17.0.3&amp;#34; 2022-04-19 LTS OpenJDK Runtime Environment Zulu17.34+19-CA (build 17.0.3+7-LTS) OpenJDK 64-Bit Server VM Zulu17.34+19-CA (build 17.0.3+7-LTS, mixed mode, sharing) Java 版本之间破坏性变更较小，JVM 高度向后兼容，新版通常兼容旧版，例如基于 Java 5 或 Java 8 的程序，一般情况下，不更改代码也可以在 Java 8 到 Java 17 的 JVM 上运行正常；反过来说，不能向前兼容，例如使用 Java 17 编译输出的 Class 或 Jar 文件无法在 17 之前的 JVM 上加载通过：UnsupportedClassVersionError。</description>
    </item>
    <item>
      <title>重新认识 MySQL（一）</title>
      <link>https://h2cone.github.io/2022/03/15/mysql-index/</link>
      <pubDate>Tue, 15 Mar 2022 15:48:42 +0800</pubDate>
      <guid>https://h2cone.github.io/2022/03/15/mysql-index/</guid>
      <description>概述 MySQL 无疑是“八股文”的重灾区之一，默认存储引擎是 InnoDB 的 MySQL 实际上是什么样子？&#xA;MySQL 架构 这是 MySQL 架构图，结合应用程序开发经验，不难看出：&#xA;客户端/服务端模型。 MySQL 的守护进程是 mysqld。 MySQL 服务端向客户端提供了 SQL 接口（包括 DDL、DML、DQL、DCL）。 MySQL 可插拔存储引擎，MySQL 8.0 默认存储引擎是 InnoDB（除非创建表时指定其它引擎）。 MySQL 服务端从上到下可分为三层次：服务层（SQL、解析、优化、缓存）、存储引擎、文件。 存储引擎隐藏了数据库文件与内存缓冲池的复杂性，向服务层提供了统一的文件读写接口？ InnoDB 架构 InnoDB 至少有以下优势：&#xA;遵循 ACID 模型，事务具有提交、回滚、崩溃恢复的功能以保护用户数据。 行级锁与一致性读提高了多用户并发访问的性能。 每张 InnoDB 表都有一个聚簇索引，能够最小化主键查询的 I/O 次数。 支持外键约束来保持数据完整性。 这是 InnoDB 架构图，二分为在内存中的结构与在磁盘上的结构，&#xA;SQL 执行路径 一条普通的 SELECT 语句的旅程如下所示：&#xA;客户端输入语句。&#xA;消息通过 TCP/IP 线路。&#xA;服务端判定是否命中缓存，未命中则解析语句与生成执行计划。&#xA;服务端调用下层函数。&#xA;存储引擎读写文件。&#xA;索引篇 数据结构 索引是以额外的写入与空间为代价来加速数据查找的一类数据结构的统称。索引就像图书开头名为“目录”的书页或结尾名为“索引”的书页，读者想要查看某一内容，与其从第一页开始翻阅直到遇见目标书页为止，不如先在“索引”或“目录”查找关键词得到页码，有了页码就能快速定位关键词所在的书页。虽然隐喻便于理解索引的加速作用，但说服力有限，至少定性描述解决查找问题的数据结构与算法性能：&#xA;上图是著名的红皮书对所讲述的数据结构与算法时间复杂度的总结，顺序查找最慢，二叉树查找最坏的情况下退化成顺序查询，而有序数组的插入操作很慢，对于查找与插入较好的权衡是 2-3 树查找（红黑树）。散列表或哈希表表现如何？取决于哈希函数的实现，一般情况下，Hash Table 时间复杂度是 O(1)，几乎与 N 无关。&#xA;数据库系统（DBMS）不仅管理内存缓冲池（Buffer Pool），而且管理数据库文件（Database File）。由于计算机系统主存（Memory）与磁盘（Disk）的速度高度不对等，开发者选择数据结构不仅考虑发生在内存的查找与插入，而且高度注意磁盘 I/O 次数或页（Page）访问次数。</description>
    </item>
    <item>
      <title>连接池的意义</title>
      <link>https://h2cone.github.io/2022/01/16/connection-pool-0/</link>
      <pubDate>Sun, 16 Jan 2022 23:30:47 +0800</pubDate>
      <guid>https://h2cone.github.io/2022/01/16/connection-pool-0/</guid>
      <description>前言 不久前参与了基于编排引擎的应用程序开发，在并发执行大量的短时任务时发现工作流当中任务之间的延迟可能远大于任务执行耗时。翻阅官方文档时发现此编排引擎以“数据库连接饥渴”著称，警告道：对于 MySQL 来说通常不是问题，因为它处理连接的模型是基于线程的，但这对于 PostgreSQL 可能是个问题，因为它的连接处理是基于进程的。&#xA;曾经误以为编排引擎或数据库持有连接池，一方面由于对连接池的初印象来自于客户端 JDBC 连接池，另一方面是由于对于 MySQL 连接器的误解。&#xA;将连接池加入到系统，随后测试发现并发执行任务的性能显著提高，很难不对连接池刮目相看。&#xA;进程，还是线程 The Internals of PostgreSQL 展示了 PostgreSQL/Postgres 多进程架构：&#xA;一个客户端（client）的连接请求由服务进程（server process）分派给一个后台进程（backend process）处理，后台进程从服务进程衍生（fork）而来。&#xA;系统调用 fork 用于创建进程，此处引用 The fork() System Call 的图来简单认识一下：&#xA;众所周知，创建进程的开销通常大于创建线程。Postgres 为什么使用多进程架构？在遥远的过去，线程模型在 Unix 上并不成熟，第一个 Postgres 开发者可能认为进程是比线程更安全、健壮、稳定的选择。&#xA;进程之间的隔离性强于线程之间的隔离性，一个进程的崩溃通常不会影响其它进程。 在现代操作系统上，创建进程与创建线程之间的开销差异比以前小得多。 当事务非常短的时候，创建进程的成本是否真的可以忽略不计？What is the point of bouncing 的作者测量了建立连接的耗时：&#xA;这意味着用“信任”连接到 localhost 平均需要 0.045ms，用 MD5 认证则需要 0.063ms。在网络上，它需要 0.532ms（信任）和 0.745ms（md5）。这听起来可能不多，但考虑到从相对较宽的表中获取单行（宽度，如解释所示：750 字节），使用主键需要 0.03ms，我们突然可以看到连接的开销比从磁盘获取数据要多 20 倍。&#xA;连接池是否可以减少频繁创建进程的成本？Scaling PostgreSQL with PgBouncer: You May Need a Connection Pooler 的测试结果一目了然：</description>
    </item>
    <item>
      <title>浅谈 Raft</title>
      <link>https://h2cone.github.io/2021/10/17/raft-0/</link>
      <pubDate>Sun, 17 Oct 2021 19:00:17 +0800</pubDate>
      <guid>https://h2cone.github.io/2021/10/17/raft-0/</guid>
      <description>重要的事情 不是对论文的阅读理解，而是受到了动画的启发。&#xA;启发式问题 共识是什么？共识算法的应用场景？&#xA;共识是分布式系统最重要的抽象之一，著名的《Designing Data-Intensive Applications》展示了全景式的分布式系统，其中有一大章探讨一致性与共识的内容。&#xA;共识问题通常形式化描述如下：一个或多个结点可以提议某些值，由共识算法来决定最终值。&#xA;“通俗理解，共识是让几个结点就某项提议达成一致。例如，多个人同时尝试预订飞机的最后一个座位或剧院中的同一座位，或者尝试使用相同的用户名注册账户，此时可以用共识算法来决定这些不相容的操作之中谁是获胜者。”&#xA;对于本地或共享内存的唯一性问题，直截了当的解决方案是使用锁，但到了分布式系统，复杂度骤然上升，共识可能是唯一可靠的方法。不止于此，共识算法可以应用于分布式系统的一系列问题：&#xA;可线性化的比较－设置寄存器。寄存器需要根据当前值是否等于输入的参数，来自动决定接下来是否应该设置新值。 原子事务提交。数据库需要决定是否提交或中止分布式事务。 全序广播。消息系统要决定以何种顺序发送消息。 锁与租约。当多个客户端争抢锁或租约时，要决定其中哪一个成功。 成员/协调服务。对于失败检测器（例如超时机制），系统要决定结点的存活状态（例如基于会话超时）。 唯一性约束。当多个事务在相同的主键上试图井发创建冲突资源时，约束条件要决定哪一个被允许，哪些违反约束因而必须失败。 Raft 可能是最易于理解的共识算法，标杆式的实现是 etcd/raft，其它的实现可以在这里找到。&#xA;为什么需要 Leader 或 Primary 或 Master 这类角色的选举？&#xA;向客户端制造了单一服务端点的假象，客户端与系统的通信简化为与单一服务端的通信。&#xA;有一种无主结点数据复制（leaderless replication）声称，如果 w + r &amp;gt; n，则读写的结点中一定包含最新值（n 是副本数，写入需要 w 个结点确认，读取必须至少查询 r 个结点）。如果写入了 w 个结点，则需要读取多于 n - w 个结点保证包含最新值（想象一下 w 个结点与 r 个结点有重叠），因此 r &amp;gt; n - w -&amp;gt; r + w &amp;gt; n，这被称为 Quorum，但现实情况往往更加复杂，不保证一定能读取到最新值。&#xA;为单一 Leader 编写程序可能比采用 Quorum 等其它方法更容易，但是劣势也很明显，例如单点失效发生在唯一的 Leader 身上，那恢复期间服务不可用？客户端可以重试，直到一名新的 Leader 被选举出来；更严重的缺陷是唯一的 Leader 负载过高时，会成为了系统的性能瓶颈。早有耳闻 TiKV 是基于 Raft 的分布式键值对数据库，其扩展方式是通过数据分区与 Raft 组（raft group）。</description>
    </item>
    <item>
      <title>优化过长的“分支代码”</title>
      <link>https://h2cone.github.io/2021/08/05/loop_or_strategy/</link>
      <pubDate>Thu, 05 Aug 2021 14:37:16 +0800</pubDate>
      <guid>https://h2cone.github.io/2021/08/05/loop_or_strategy/</guid>
      <description>基于多态 假设有一段“分支代码”（片段 1）：&#xA;// 可能的 Case CaseEnum caseEnum = getRandomCase(); if (CaseEnum.AA.equals(caseEnum)) { // ... } else if (CaseEnum.BB.equals(caseEnum)) { // ... } else if (CaseEnum.CC.equals(caseEnum)) { // ... } 其等效代码类似于（片段 2）：&#xA;// 可能的 Case CaseEnum caseEnum = getRandomCase(); for (CaseHandler handler : caseHandlerFactory.getHandlers()) { if (handler.match(caseEnum)) { handler.handle(); break; } } 当增加分支的时候，片段 1 需要在尾部追加代码，而片段 2 无需变更，前提是片段 2 依赖更多的类。&#xA;注意：片段 2 在最坏情况下的运行时间的增长数量级是 N。&#xA;如何实现？&#xA;（一）CaseHandler。&#xA;public interface CaseHandler { /** * 匹配 Case。 * * @param caseEnum Case 枚举 * @return 是否 */ boolean match(CaseEnum caseEnum); /** * 业务处理。 */ void handle(); } （二）CaseHandler 实现之一。</description>
    </item>
    <item>
      <title>ElasticsearchRestTemplate 的一些坑</title>
      <link>https://h2cone.github.io/2021/07/26/elasticsearch_rest_template_pitfall/</link>
      <pubDate>Mon, 26 Jul 2021 11:05:02 +0800</pubDate>
      <guid>https://h2cone.github.io/2021/07/26/elasticsearch_rest_template_pitfall/</guid>
      <description>基于日期的索引 预期单一索引增长速率较快，最终决定创建基于日期的索引（time-based indices），例如按月份分索引：&#xA;@Document(indexName = &amp;#34;my_index-#{@timeBasedIndexNameProvider.toMonth()}&amp;#34;, shards = 3) public class Entity { // ... } 其中 indexName 的值可包含 SpEL，引用了 TimeBasedIndexNameProvider 的 toMonth。&#xA;@Component(&amp;#34;timeBasedIndexNameProvider&amp;#34;) public class TimeBasedIndexNameProvider { public String toMonth() { return LocalDateTime.now().format(DateTimeFormatter.ofPattern(&amp;#34;yyyy-MM&amp;#34;)); } } 生成的一系列索引名形式如下：&#xA;my_index-2021-07 my_index-2021-08 &amp;hellip;&amp;hellip; 保存实体时，当前月份的索引可能还未创建，如果直接使用 ElasticsearchRestTemplate 的 save 方法，当前版本并不会解析实体类的实例字段上标注的 Elasticsearch 相关注解，例如有一个字段（batchId）：&#xA;@Field(type = FieldType.Keyword) private String batchId; 这种情况下，自动创建的 my_index-* 的 Mapping 所包含的 batchId 类型是 Text，而不是预期的 Keyword。一般来说，在保存实体之前，先检测当前月份的索引是否存在，若不存在，则创建索引（包括 Mapping），否则直接保存实体。&#xA;void createIndexAndPutMapping(Class&amp;lt;T&amp;gt; entityClass) { IndexOperations ops = elasticsearchRestTemplate.</description>
    </item>
    <item>
      <title>Airflow 杂技</title>
      <link>https://h2cone.github.io/2021/05/01/airflow_trick/</link>
      <pubDate>Sat, 01 May 2021 18:12:03 +0800</pubDate>
      <guid>https://h2cone.github.io/2021/05/01/airflow_trick/</guid>
      <description>背景 近期，从零开始搭建 SOAR 平台，其中工作流引擎或任务编排组件是核心组件之一。&#xA;Airflow Airflow 是用于描述、执行、监控工作流的平台。目前为止，启动 Airflow 最快的方式是——在 Docker 中运行 Airflow，这种安装方式也有利于可扩展性。&#xA;有一些组件需要说明一下（此处省略 Flower）：&#xA;Webserver：提供访问 DAG、任务、变量、连接等等的状态信息的 Airflow REST API。 Scheduler：负责 DAG 解析与任务调度。 Worker：执行由 Scheduler 分配的任务。 Redis：Scheduler 与 Worker 之间的消息代理。 Postgres：存储有关 DAG、任务、变量、连接等等的状态信息。 上述组件是进程级组件，需要注意的是 DAGs 并不是进程，而是指多个 Python 源文件。DAG 是有向无环图（Directed Acyclic Graph）的缩写，从 Airflow 的角度来看，DAG 用于描述工作流，有向无环图中的结点被称为任务（Task），而 Task 是通过 Operator 来实现。DAGs 的位置在 Airflow 配置文件中指定，重要的事情是 Webserver 和 Scheduler 以及 Worker 都需要读取 DAGs。&#xA;生成 DAG 编写 DAG 需要一定的 Python 知识，甚至 Airflow 并不提供创建 DAG 的 UI 或 REST API。情理之中，Airflow 创建工作流并不包含“无代码”或“低代码”特性，从官方首页可以看到其定位：</description>
    </item>
    <item>
      <title>忙等</title>
      <link>https://h2cone.github.io/2021/03/08/busy_waiting/</link>
      <pubDate>Mon, 08 Mar 2021 23:05:33 +0800</pubDate>
      <guid>https://h2cone.github.io/2021/03/08/busy_waiting/</guid>
      <description>反面 上课期间看到一段模拟投票的程序，其中主协程（main goroutine）产生的若干子协程并发请求票与计票，主协程重复检查票数是否已达到预期。&#xA;package main import ( &amp;#34;fmt&amp;#34; &amp;#34;math/rand&amp;#34; &amp;#34;os&amp;#34; &amp;#34;strconv&amp;#34; &amp;#34;sync&amp;#34; &amp;#34;time&amp;#34; ) func main() { rand.Seed(time.Now().UnixNano()) total, err := strconv.Atoi(os.Args[1]) if err != nil { panic(err) } overHalf := total/2 + 1 count := 0 finished := 0 var mu sync.Mutex for i := 0; i &amp;lt; total; i++ { go func() { vote := requestVote() mu.Lock() defer mu.Unlock() if vote { count++ } finished++ }() } for count &amp;lt; overHalf &amp;amp;&amp;amp; finished &amp;lt; total { // .</description>
    </item>
    <item>
      <title>编译的一些事</title>
      <link>https://h2cone.github.io/2021/01/22/some_things_about_compilation/</link>
      <pubDate>Fri, 22 Jan 2021 10:20:35 +0800</pubDate>
      <guid>https://h2cone.github.io/2021/01/22/some_things_about_compilation/</guid>
      <description>一次交叉编译体验 有一个项目使用高级编程语言创建原生进程（native process）来执行 Shell 脚本，其中有一段用于编辑特定配置文件的代码片段。&#xA;for name in $names; do eval expr=&amp;#39;$&amp;#39;&amp;#34;$name&amp;#34; sed -i -e &amp;#34;s/&amp;lt;@${name}@&amp;gt;/${expr}/g&amp;#34; ${file%.*}.${component_instance} done sed（stream editor）是一个用于过滤和转换文本的 Unix 程序。&#xA;# 将 file.txt 中的 before 就地替换为 after sed -i -e &amp;#39;s/before/after/g&amp;#39; file.txt 用法还算简单，但是，如果 after 包含特殊字符，比如传递包含正则表达式的多行代码（想象一下 Logstash 配置），运行时将极有可能发生类似错误：unknown option to s&#39;。如果要对特殊字符进行转义，这种方案不仅复杂还易错，甚至可能会更改“间接调用” Shell 脚本的应用程序代码。换个角度，sed 是否有更好的替代品？&#xA;感谢使用 Rust 重写一切的开源软件作者们，sd 完全可以代替 sed，而且能识别特殊字符。&#xA;sd -s before after file.txt 兴致勃勃从 releases 下载可执行文件，却遇到因为开发/测试环境的 glibc 版本不符合 sd 的要求从而导致无法正常执行。&#xA;$ ./sd-v0.7.6-x86_64-unknown-linux-musl --help ./sd-v0.7.6-x86_64-unknown-linux-musl: /lib64/libc.so.6: version `GLIBC_2.18&amp;#39; not found (required by .</description>
    </item>
    <item>
      <title>Vert.x 与 Hazelcast</title>
      <link>https://h2cone.github.io/2020/12/14/vertx-hazelcast-exp/</link>
      <pubDate>Mon, 14 Dec 2020 14:50:54 +0800</pubDate>
      <guid>https://h2cone.github.io/2020/12/14/vertx-hazelcast-exp/</guid>
      <description>前面的话 有一个项目使用了 Vert.x 3，没想到 v4.0.0 已经发布。&#xA;什么是 Vert.x Vert.x 是用于在 JVM 上构建 Reactive 应用程序的工具包。&#xA;早在 2014 年反应式宣言就提出反应式（Reactive）应用程序/软件系统应具有反应灵敏（Responsive）、回弹性（Resilient）、弹性（Elastic）、消息驱动（Message Driven）等特征，这些莫名其妙的要求可以归属于前文常常提到的软件系统三大目标。&#xA;Vert.x 受到了 Node.js 启发，推荐的编程范式是事件驱动，事件可以由软件、用户、系统产生或触发，处理事件的函数通常被称为 Event Handler。&#xA;import io.vertx.core.AbstractVerticle; public class Server extends AbstractVerticle { public void start() { vertx.createHttpServer().requestHandler(req -&amp;gt; { req.response() .putHeader(&amp;#34;content-type&amp;#34;, &amp;#34;text/plain&amp;#34;) .end(&amp;#34;Hello from Vert.x!&amp;#34;); }).listen(8080); } } 如上所示，使用 Vert.x 编写一个简单的 HTTP Server，其中 requestHandler 方法传入了用于处理请求事件的 Handler，Handler 表现为回调函数，即 Call­back；其中 listen 方法是非阻塞方法，线程调用非阻塞方法不会被阻塞在该方法，而是继续执行其它代码；非阻塞函数有时被称为异步函数，返回值可以被称为异步结果，仅使用 Callback 处理异步结果可能导致嵌套和凌乱的代码，被称为回调地狱。Vert.x 支持 Fu­tures/Promises 和 RxJava，前者用于优雅地链式异步操作，后者用于高级反应式编程。&#xA;Vert.x 的非阻塞 I/O 基于 Netty，在此之上构建 Vert.</description>
    </item>
    <item>
      <title>Kafka 之于 Elastic Stack</title>
      <link>https://h2cone.github.io/2020/11/22/kafka_in_the_elk/</link>
      <pubDate>Sun, 22 Nov 2020 11:32:08 +0800</pubDate>
      <guid>https://h2cone.github.io/2020/11/22/kafka_in_the_elk/</guid>
      <description>背景 刚入行那会，公司产品研发部正如火如荼建设微服务基础设施，其中就包括日志中心。试想一下，包含众多容器化应用程序的系统，一个服务可能会有多个实例，每个实例输出各自的日志记录；假如在客户端收到了来自服务器端的异常响应，例如 500 Internal Server Error，相应的负责人不可避免地会遇到需要通过查看容器日志来查明哪里发生故障或则什么原因导致性能下降的情景。&#xA;负责人也许走了弯路。登录哪些服务器或跳板机？有没有访问权？需不需要通过“中介”才能获得许可或相关日志文件？查看哪些结点上的哪些服务的日志？&#xA;负责人也以可以走已经铺好的路。直接在日志中心 Web 版搜索所需的一切日志记录；系统中所有服务的日志记录都可以被索引与检索，不仅仅可以用于故障排除，还可以用于监控、告警、数据分析等等。&#xA;集中式日志管理 上图来自运维咖啡吧，这是一类典型的日志处理架构。&#xA;Filebeat，轻量级日志采集器。 考虑到基于 Docker 开发服务，应用程序的父镜像应包含 Filebeat，例如 FROM 父镜像 之后执行一系列下载、安装、设置 Filebeat 的指令。 Filebeat 作为应用程序的 agent 可以将日志作为输入源（从日志文件读取行），再将 kafka 作为输出目的地（发送日志记录或事件到 Kafka）。 Logstash，传输和处理日志、事件等数据。 因为 Logstash 有许多输入插件，包括读取来自 Kafka Topic 的事件，可以作为 Kafka 的消费者。 ELK 中的 Logstash 当然支持将 Elasticsearch 作为输出目的地。 Elasticsearch，分布式 RESTful 搜索引擎。 Kibana，可视化 Elasticsearch 数据的用户界面。 有趣的是，Elastic Stack 并不包含 Kafka，但两者在日志/事件处理领域却是经典组合。&#xA;何时组合使用 Kafka 与 Elastic Stack 应对突发流量 在大数据领域，Kafka 以单位时间内吞吐量极高著称，所谓吞吐量是指代可处理的记录条数，Kafka 非常适用于流量削峰。早在 2014 年，Kafka 已经能达到每秒 200 万次写入（在三台廉价的机器上）。为什么 Kafka 如此之快？至少有如下原因：</description>
    </item>
    <item>
      <title>日志游记</title>
      <link>https://h2cone.github.io/2020/08/30/log-notes/</link>
      <pubDate>Sun, 30 Aug 2020 15:21:41 +0800</pubDate>
      <guid>https://h2cone.github.io/2020/08/30/log-notes/</guid>
      <description>什么是日志 日志是追加式的，按时间排序的记录（条目）序列。&#xA;无关记录的格式，日志文件记录操作系统或其它软件运行时发生的事件及其时间。&#xA;&amp;lt;34&amp;gt;1 2003-10-11T22:14:15.003Z mymachine.example.com su - ID47 - BOM&amp;#39;su root&amp;#39; failed for lonvick on /dev/pts/8 “应用程序日志”是人类可读的文本，比如 Syslog 和 SLF4J 等；如上所示，这是一个来自 RFC5424 的 syslog 日志消息例子，从中不难看出主机（mymachine.example.com）上的一个应用程序（su）在 2003-10-11T22:14:15.003Z 发生了 “&amp;lsquo;su root&amp;rsquo; failed for lonvick&amp;hellip;”。&#xA;现代最流行的分布式版本控制系统中的日志记录着所有贡献者的提交历史：&#xA;% git log ... commit 130560a769fe6da64c87f695e4665225de1faec3 Author: Daniel Smith &amp;lt;dbsmith@google.com&amp;gt; Date: Fri Jun 6 17:31:45 2014 -0700 Proofread guestbook.md commit 2c4b3a562ce34cddc3f8218a2c4d11c7310e6d56 Author: Joe Beda &amp;lt;joe.github@bedafamily.com&amp;gt; Date: Fri Jun 6 16:40:48 2014 -0700 First commit 然而，日志并非全都是人类可读的，它可能是二进制格式而只能被程序读取，作为关键抽象普遍存在于数据库系统和分布式系统之中。&#xA;数据库日志 关系数据库系统中的日志通常用于崩溃恢复、提供一定程度的原子性与持久性、数据复制。</description>
    </item>
    <item>
      <title>从 MySQL 到 TiDB</title>
      <link>https://h2cone.github.io/2020/07/11/from-mysql-to-tidb/</link>
      <pubDate>Sat, 11 Jul 2020 11:21:03 +0800</pubDate>
      <guid>https://h2cone.github.io/2020/07/11/from-mysql-to-tidb/</guid>
      <description>MySQL 窘境 扩展 数据以前所未有的速度增长，例如从 GB 到 TB，甚至到 PB；负载增加，例如单位时间请求数、I/O 次数、活跃用户数激增；这可能引起单机 MySQL server 性能下降，甚至不可用。我们想尽办法扩展 MySQL，通常，要么采购更强大的机器作为数据库服务器，这是一种纵向扩展（scale up）；要么对 MySQL 的库或表进行分片（MySQL Sharding），即将数据集分离得到多个子数据集，任意两个子数据集可能存储在同一台机器上，也可能存储在不同机器上，这是一种横向扩展（scale out）。&#xA;纵向扩展需要应对一些问题：&#xA;成本增长过快。如果把一台机器的 CPU 核数增加一倍，主存和磁盘各扩容一倍，则最终总成本增加不止一倍。 预见性能瓶颈。一台机器尽管拥有两倍的硬件指标但却不一定能处理两倍的负载。 有限容错能力。显然无法提供异地容错能力。 横向扩展一般不需要高端的硬件或机器，但需要多台一般的机器和应对分布式系统的许多挑战：&#xA;故障与部分失效。 不可靠的网络。 不可靠的时钟。 因为关心系统应对负载增加的能力（可扩展性），所以关心系统容错能力（可用性与一致性）。&#xA;达成以上目标至少需要分区，对于 Elasticsearch 和 SolrCloud 以及 MongoDB 来说是 shard；对于 Cassandra 和 HBase 分别是 vnode 和 region。&#xA;为什么分区 增强可扩展性。海量数据分布在更多磁盘上，查询负载分布到更多处理器上。 分区容错。数据分区与数据复制通常结合使用，即每个分区在多个结点上存有副本（replica）。 副本的优势：&#xA;容错。容忍结点失效，支持故障转移。 横向扩展。采用多结点来处理更多的请求。 就近访问。将副本部署到距离用户更近的地方。 Partitioning 项目开始初期，什么情况下适合对 MySQL 分库分表？阿里巴巴 Java 开发手册在“MySQL 数据库“章节中有一则推荐，仅供参考：&#xA;【推荐】单表行数超过 500 万行或者单表容量超过 2 GB，才推荐进行分库分表。 说明：如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。&#xA;我们通常使用垂直分区（vertical partitioning）和水平分区（horizontal partitioning），如下图所示：&#xA;VP1 和 VP2 表现得像两张可通过 ID 关联起来的表，HP1 和 HP2 的 scheme 和列（columns）相同，但行（rows）不同。行的增长速度通常快于列的增长速度，我们更关注水平分区，数据库分片是数据库或搜索引擎的水平分区；但新问题随之而来：假设 HP1、HP2、HP3、HP4&amp;hellip;&amp;hellip; 包含了多张表的数据，且由多个 MySQL server 维护，如果客户端要查找满足给定条件的一行或多行记录，那么它应该向哪个或哪些 MySQL server 发起请求？如何合并多个结点返回的结果集？如何执行跨分区 JOIN、排序、分页、分组等操作？如何保证分布式事务？</description>
    </item>
    <item>
      <title>Go 指针要点</title>
      <link>https://h2cone.github.io/2020/06/21/go-pointer/</link>
      <pubDate>Sun, 21 Jun 2020 11:11:59 +0800</pubDate>
      <guid>https://h2cone.github.io/2020/06/21/go-pointer/</guid>
      <description>关键 变量是包含值的存储。 指针的值是变量的地址。 Go 语言的变量都拥有地址，而指针是一个变量，它的值是另外一个变量的地址。当我们说整型指针时，我们指的是一类型的指针。考虑下面的代码片段：&#xA;x := 1 p := &amp;amp;x // p, 类型 *int, 指向 x fmt.Println(*p) // &amp;#34;1&amp;#34; *p = 2 // 相当于 x = 2 fmt.Println(x) // &amp;#34;2&amp;#34; 操作符 &amp;amp; 作用于变量 x，产生了指针 p，p 的类型是 *int，可以发现其中 int 就是 x 的类型；操作符 * 作用于 p，检索了 p 指向的变量 x，能够读写 x 的值，但是这到底是什么意思？下图是一个很好的类比：&#xA;左边为变量，中间为地址 （试着打印一下 p），右边为值。当执行了 p := &amp;amp;x 后，*p 是 x 的别名，故赋新值给 *p 也就更改了 x 的值。为什么指针还需要绑定类型？出于类型安全考虑，如果把上面代码的 *p = 2 替换成 *p = &amp;quot;two&amp;quot;，那么编译不通过。</description>
    </item>
    <item>
      <title>Goodbye Spring</title>
      <link>https://h2cone.github.io/2020/06/04/goodbye-spring/</link>
      <pubDate>Thu, 04 Jun 2020 00:00:24 +0800</pubDate>
      <guid>https://h2cone.github.io/2020/06/04/goodbye-spring/</guid>
      <description>Spring + Hibernate Web 调用栈 本文首发于 https://h2cone.github.io/&#xA;查找图片来源 Java call stack – from HTTP upto JDBC as a picture </description>
    </item>
    <item>
      <title>RabbitMQ 的可靠性</title>
      <link>https://h2cone.github.io/2020/05/04/rabbitmq-reliability/</link>
      <pubDate>Mon, 04 May 2020 11:54:46 +0800</pubDate>
      <guid>https://h2cone.github.io/2020/05/04/rabbitmq-reliability/</guid>
      <description>高级消息队列协议 众所周知，RabbitMQ 实现了 AMQP（Advanced Message Queuing Protocol），准确来说是 AMQP 0-9-1；AMQP 是一种使符合要求的客户端可以与符合要求的消息代理（message broker）进行通信的一种消息传递协议，它的概念如下图所示：&#xA;生产者（producer）发布消息，消费者（consumer）消耗消息。生产者或发布者（publisher）通常无需关心以下几点：&#xA;消息将发送到哪些队列（queue）。 消息（message）被哪些消费者消费。 Exchange 接收生产者发布的消息并路由到队列，exchange 根据什么转发消息到队列？人类可以使用绑定（binding）来定义 queue 和 exchange 的关系以及提供消息路由规则。生产者只面向 exchange 发布消息，而消费者只面向 queue 消耗消息，因此常说 RabbitMQ 解耦生产者和消费者。&#xA;值得一提的是，单独的 MySQL server 可以创建多个数据库；与此类似，单独的 RabbitMQ server 可以创建多个虚拟主机（virtual host）。虚拟主机包含 queues 和 exchanges 以及 bindings，虚拟主机之间可相互隔离。&#xA;Exchange 当成功安装了 RabbitMQ 并正常启动后，可以通过后台管理界面去直观认识这种消息代理，不难发现 RabbitMQ 提供了 4 种 exchange 类型：&#xA;Exchange 使用的路由算法取决于 exchange 类型和 binding 规则。&#xA;Direct exchange 如果一个 exchange 的类型是 direct，将一个 queue 绑定到该 exchange 时，要求附加一个名为 routing key 的参数；当一个携带 routing key 的消息到达该 exchange 时，该 exchange 将转发消息到相应的 queue（精确匹配 routing key）。</description>
    </item>
    <item>
      <title>初识 BitArray</title>
      <link>https://h2cone.github.io/2020/04/23/bit-array-0/</link>
      <pubDate>Thu, 23 Apr 2020 17:40:57 +0800</pubDate>
      <guid>https://h2cone.github.io/2020/04/23/bit-array-0/</guid>
      <description>纸上谈兵 有两个 1GB 的文本文件，文件内容是无序数组（一行一个整数，一个文件中大概有一亿个非负整数，同一个文件中不重复），请在内存使用尽可能少的情况下将只在其中一个文件出现过的数字找出来。&#xA;应用 BitArray。逐行读取 2 个文件的整数并分别映射到 2 个 BitArray，其中每个 BitArray 的长度为 1 亿，即 100000000 bit = 11.92093 MB，求这两个 BitArray 的对称差。&#xA;映射。将文件中的非负整数映射为下标（索引），比如给定 {1, 5} 和 {1, 2} 这两个整数集，则相应的 BitArray 分别形如：&#xA;00&amp;hellip;100010&#xA;00&amp;hellip;000110&#xA;Bit array 每位初始值位 0，设置为 1 则表示该位的下标（index）为相应的整数，右边第一位下标为 0，从右到左单调递增，增量为 1。&#xA;对称差。两个集合的对称差是属于一个集合而不属于另一个集合的元素组成的集合。比如 {1, 5} 与 {1, 2} 的对称差为 {2, 5}，相应的 BitArray 运算形如：&#xA;00&amp;hellip;100010 ^ 00&amp;hellip;000110 -&amp;gt; 00&amp;hellip;100100&#xA;本文首发于 https://h2cone.github.io/&#xA;参考资料 BitArray - Wikipedia Bitwise operation - Wikipedia </description>
    </item>
    <item>
      <title>使用 Lua 拓展 Nginx</title>
      <link>https://h2cone.github.io/2020/03/31/openresty-exp/</link>
      <pubDate>Tue, 31 Mar 2020 14:44:18 +0800</pubDate>
      <guid>https://h2cone.github.io/2020/03/31/openresty-exp/</guid>
      <description>Nginx Nginx 是高性能的负载均衡器、Web 服务器、反向代理服务器。它是我们既熟悉又陌生的老朋友，经常依靠它水平扩展应用程序、部署前端应用程序、代理应用程序、构建 API 网关等，Nginx 由纯 C 语言实现，但却非常易于使用。&#xA;早在 2005 年，官方博客用一篇标题为 Inside NGINX: How We Designed for Performance &amp;amp; Scale 的文章描述了 Nginx 的架构：&#xA;Nginx 如何创建进程以有效利用资源。 使用状态机来管理流量（traffic）。 非阻塞和事件驱动的架构使 Nginx 可以同时调度多个状态机。 进程架构如何支持不间断的优雅更新和二进制升级。 OpenResty 不妨先看看 OpenResty 官方的宣传语。&#xA;OpenResty® 是一个基于 Nginx 与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。&#xA;比起使用 C 语言，使用 Lua 门槛要稍低一些，而且有 LuaJIT 的性能优化。&#xA;OpenResty® 通过汇聚各种设计精良的 Nginx 模块（主要由 OpenResty 团队自主开发），从而将 Nginx 有效地变成一个强大的通用 Web 应用平台。这样，Web 开发人员和系统工程师可以使用 Lua 脚本语言调动 Nginx 支持的各种 C 以及 Lua 模块，快速构造出足以胜任 10K 乃至 1000K 以上单机并发连接的高性能 Web 应用系统。</description>
    </item>
    <item>
      <title>分布式缓存</title>
      <link>https://h2cone.github.io/2020/03/24/distributed-cache/</link>
      <pubDate>Tue, 24 Mar 2020 17:40:48 +0800</pubDate>
      <guid>https://h2cone.github.io/2020/03/24/distributed-cache/</guid>
      <description>铺垫 存储层次结构 自下而上，更小更快。 自顶向下，更大更慢。 上层是下层的（高速）缓存。 软件系统三大目标 目标 解释 期望 战术 可靠性 容错能力 硬件故障、软件错误、人为失误发生时继续正常运作 熔断、降级、自动恢复、容灾、高可用、强一致性&amp;hellip;&amp;hellip; 可扩展性 应对负载增加的能力 负载增加时保持良好性能或高性能 低延迟、高吞吐、弹性伸缩&amp;hellip;&amp;hellip; 可维护性 运维和开发的难易程度 既简单又好拓展 DRY、SoC、DevOps&amp;hellip;&amp;hellip; Redis cluster 单一独立的 Redis 结点，虽然它真的很快（未来将开新篇章解释），但是也有上限，性能提升总将遇到天花板，而且单点故障将导致一段时间服务不可用。&#xA;Redis 集群如何解决可靠性问题和扩展性问题？&#xA;数据在多个 Redis 结点之间自动分片（shard）。 Redis 集群可以在分区期间提供一定程度的可用性（availability）。 水平扩展 Redis（scalability）。 数据分片 Redis 集群不使用一致性哈希，而是使用哈希槽（hash slot）。&#xA;如上图所示，Redis 集群中的结点（node）负责各自的哈希槽。向集群插入一个键（key）时，只是计算给定键的 CRC16 并取 16384 的模来将给定键映射到哈希槽。&#xA;使用哈希槽可以“轻松”在集群中添加结点到删除结点。若增加一个结点 D，则从 A、B、C 移动一些哈希槽到 D，同理，若删除一个结点 A，则从 A 移动哈希槽到结点 B、C、D，当 A 为空可被完全从集群移除；而且，添加结点、删除结点、更改结点的哈希槽的百分比都不要求集群暂停运作，不需要任何停机时间。&#xA;值得注意的是，Redis 集群支持多个键的操作，前提是单个命令执行或整个事务或 Lua 脚本执行中涉及的所有键属于同一个哈希槽。我们可以使用称为 hash tags 的概念来强制多个 key 映射到同一个哈希槽。&#xA;可用性与一致性 Redis 集群使用主从模型（master-slave model） 实现故障转移。</description>
    </item>
    <item>
      <title>网络·NIO</title>
      <link>https://h2cone.github.io/2020/03/08/network_nio/</link>
      <pubDate>Sun, 08 Mar 2020 11:07:41 +0800</pubDate>
      <guid>https://h2cone.github.io/2020/03/08/network_nio/</guid>
      <description>I/O 本文以多线程·并发编程中的第一张图作为开篇：&#xA;I/O 设备包括鼠标、键盘、显示器、磁盘、网卡等。 I/O（输入/输出），输入是从 I/O 设备复制数据到主存，输出是从主存复制数据到 I/O 设备。 从一个计算机角度来看，网络（适配器）是它的一个 I/O 设备。当计算机系统从主存复制字节序列到网络适配器时，数据流经过网络到达另一台机器，同理，计算机系统可以从网络适配器复制字节序列到主存。&#xA;Socket 从人类的角度来看，计算机网络由一台或多台机器组成。网络中，数据从一台机器传输到另一个机器的方式通常是分组交换，即数据被切分成适合传输的小块数据，小块数据都有各自的编号；它们从一个端点分道扬镳，但殊途同归，到另一个端点时，重新排列组合成完整数据。分组交换的好处之一是充分利用网络带宽，而当 TCP 连接空闲时，通常不占用任何带宽。&#xA;分组交换有可能出现数据的丢失、乱序、重复，如何检测、重传、缓存，实现可靠性传输是 TCP 的目标。别问，问就是三次握手、四次挥手、滑动窗口协议、拥塞控制算法&amp;hellip;&amp;hellip;&#xA;TCP/IP 协议族对普通程序员来说足够复杂，但是，David Wheeler 曾经说过：&#xA;All problems in computer science can be solved by another level of indirection.&#xA;Socket 是进程与传输层的中间层。 Socket 包含五元组 (client ip, client port, server ip, server port, protocol)。 同在传输层的 UDP 不如 TCP 可靠，但是轻量级，因为它没有确认、超时、重传的概念，也没有拥塞控制，而且无连接，从而能广播。&#xA;Socket 隐藏了下层具体实现的复杂性，并给上层提供了简单或统一的 API。下图是 TCP Socket 基本流程，使用 伯克利 Sockets 描述。&#xA;Unix 的主题是“一切都是文件”。当进程申请访问 Socket 时，内核则提供相应的文件描述符（int 变量），进程发起系统调用并传递相应的文件描述符来读写 Socket。&#xA;Java 网络编程 BIO Java 的 BIO 是指 blocking I/O，通常指 java.</description>
    </item>
    <item>
      <title>多线程·并发编程</title>
      <link>https://h2cone.github.io/2020/02/21/thread_concurrent/</link>
      <pubDate>Fri, 21 Feb 2020 17:47:30 +0800</pubDate>
      <guid>https://h2cone.github.io/2020/02/21/thread_concurrent/</guid>
      <description>进程与线程 现代的计算机系统提供了许多漂亮的抽象，如下图所示：&#xA;其中，进程是对处理器、主存和 I/O 设备的抽象，换言之，进程是操作系统对一个正在运行的程序的一种抽象。操作系统上可以“同时”运行多个进程，已经对一边听歌一边写代码和接收消息的流畅不足为奇，之所以用双引号，因为这可能是一种假象。&#xA;大多数计算机系统中，需要运行的进程数是多于可以运行它们的 CPU 个数的，那么所谓的”同时“运行，很有可能是模拟并发的假象；也就是说一个进程的指令和另一个进程的指令是被 CPU 交错执行的，而且 CPU 在进程间切换足够快，进程“暂停”和“恢复”的间隔也足够短，每个进程看上去像是连续运行。除非有多个 CPU 或多处理器的计算机系统，才能支持多进程并行，即处理器同时执行多个程序的指令。&#xA;一个进程用完了操作系统分配给它的时间片，操作系统决定把控制权转移给新的进程，就会进行上下文切换（context switch），即保存当前进程的状态，恢复目标进程的状态，交接控制权。这种状态被称为上下文（context），比如程序计数器和寄存器的当前值以及主存的内容。&#xA;一个进程可以存在多个控制流（control flow），它们被称为线程。如来自维基百科线程词条的插图所示：&#xA;因为只有单处理器，所以这个进程的两个线程轮番运行在进程的上下文中（模拟并发）。操作系统不仅调度进程，教科书常说，线程是操作系统调度的最小单位。大多数计算机系统中，需要运行的线程数大于可以运行它们的 CPU 核数，从单线程进程推广到多线程进程的线程，一个线程时间到了，上下文切换，它被“暂停”了，轮到了另一个线程运行，稍后轮到它时又“恢复”了。&#xA;多线程程序十分普遍。电脑和手机应用程序在用户界面渲染动画，同时在后台执行计算和网络请求。一个 Web 服务器一次处理数千个客户端的请求。多线程下载、多线程爬虫、多线程遍历文件树&amp;hellip;&amp;hellip;多线程成为越来越重要的模型，因为多线程程序有不少优点。&#xA;多线程之间比多进程之间更容易共享数据和通信。同一个进程的多个线程共享进程的资源，比如进程的虚拟地址空间中的程序代码和程序处理的数据以及文件，对于同一进程的线程们来说，可执行代码只有一套，它们可以访问存储在堆 (Heap) 中的共享变量或全局变量，但是，栈（Stack）、包括程序计数器（Program Counter）在内的寄存器（Register）副本、线程本地存储（Thread Local Storage）都是线程私有的（如果有的话）。不仅如此，线程之间可以通过共享的代码、数据、文件进行通信，绝大部分情况下比进程间的通信更高效。&#xA;多线程执行任务更多或更快。如果主线程阻塞在耗时任务，整个程序可能会卡顿或长时间无响应，解决办法之一便是新建一个工作线程专门执行这个耗时任务，而主线程则继续执行其它任务。例如，前面提到的手机 APP（特别是 Android APP），UI 线程被阻塞后很有可能无法正常人机交互了，用户体验极差。更进一步，单进程的多线程之间的协作有可能提高 client-server 系统的性能，譬如异步调用缩短了请求响应时间（也许总延迟几乎没变）。最重要的是，虽然一个传统的 CPU 只能交错执行一个进程的多个线程，但随着多核处理器和超线程（hyperthreading）的普及，面对多任务或大任务的执行，多线程程序的性能上限具有更高的天花板，因为减少了执行多个任务需要模拟并发的开销，还因为处理器可以并行运行多个线程。&#xA;并发与并行 并发（Concurrency）和并行（Parallelism）这两个术语经常混淆，语义应当结合语境。&#xA;如上图所示，假设有两个任务和两个线程，每个任务只能由一线程执行且用时分别是 t1 和 t2（t1 &amp;lt; t2），且线程都是同时启动，那么各个方式总执行时间可能如下表所示：&#xA;方式 总执行时间 串行 t1 + t2 并行 t2 单处理器并发 t1 + t2 + 上下文切换总时间 由此可见，如果上下文切换的耗时可以忽略不计，单处理器并发不仅执行总时间近似于串行执行总时间，还有一个优点是同时执行两个任务的假象。并行的方式非常快，但也取决于最耗时的任务。&#xA;在多处理器计算机系统中，多线程交错执行或并行执行都有可能出现，下文将”交错或并行“统称为”并发“。&#xA;Java 多线程 Java 进程 任何 Java 应用程序都跑在操作系统之上，操作系统作为硬件和应用程序的中间层，隐藏了下层具体实现的复杂性，并给上层提供了简单或统一的接口。</description>
    </item>
    <item>
      <title>造你自己的 MyBatis 插件</title>
      <link>https://h2cone.github.io/2020/02/08/your-own-mybatis-interceptor/</link>
      <pubDate>Sat, 08 Feb 2020 18:28:19 +0800</pubDate>
      <guid>https://h2cone.github.io/2020/02/08/your-own-mybatis-interceptor/</guid>
      <description>插件 我们早已知道 MyBatis 自身支持客户端分页（RowBounds）, 即从数据库获取全部目标数据，在内存中对结果集进行分页，虽然适用于不同数据库，但是数据量足够大时 Java 程序可能发生内存溢出；若采用数据库服务器端分页，即从数据库获取部分目标数据，例如向 MySQL 数据库发送使用了 LIMIT 或 OFFSET关键词的 SQL，还挺简单，可是直接使用 MyBatis 做数据库分页仍然有一些痛点：&#xA;重复编写分页、求总记录数、排序语句。 语法不同，不适用于其它数据库。 那不如改用 Hibernate ？还真不一定，国人偏爱 MyBatis，以至于使用插件来增强 MyBatis，比如 Mybatis-PageHelper，一个通用的 MyBatis 分页插件。想不到 MyBatis 还挺灵活，支持插件机制。仔细翻阅官方文档可以确定 MyBatis 允许你在 Mapper 执行过程中的某些点拦截调用，已经知晓动态代理的朋友们（参见切面和动态代理以及字节码），彷佛看透了 MyBatis 插件。&#xA;默认情况下，MyBatis 允许插件拦截以下方法的调用：&#xA;Classes Methods Executor update, query, flushStatements, commit, rollback, getTransaction, close, isClosed ParameterHandler getParameterObject, setParameters ResultSetHandler handleResultSets, handleOutputParameters StatementHandler prepare, parameterize, batch, update, query 顾名思义，MyBatis 不愧为 SQL 映射框架。这些重要的组件共同参与了 MyBatis 一般的工作流程：&#xA;示例插件 编写一个插件，只需要实现 org.apache.ibatis.plugin.Interceptor 接口，指定你要拦截的方法签名。&#xA;@Intercepts({ @Signature( type = Executor.</description>
    </item>
    <item>
      <title>造你自己的 Spring Boot Starter 组件</title>
      <link>https://h2cone.github.io/2020/01/23/your-own-spring-boot-starter/</link>
      <pubDate>Thu, 23 Jan 2020 20:16:58 +0800</pubDate>
      <guid>https://h2cone.github.io/2020/01/23/your-own-spring-boot-starter/</guid>
      <description>自动配置 遥想以前，Spring 集成其它模块往往需要大量的 XML 配置和 Java 配置，经历过 SSM（Spring、Spring MVC、MyBatis）或者 SSH（Struts、Spring、Hibernate）框架搭建和填空的人们应该深有体会，特别费时费力，直到 Spring Boot 的流行才有所改善。&#xA;Spring Boot 简化配置，开箱即用，得益于自动配置（auto-configuration）。开启了自动配置的 Spring Boot 程序会尝试猜测和配置我们可能需要的 Bean。如果我们给一般的 Spring Boot Web 程序（添加了 spring-boot-starter-web 依赖的 Spring Boot 程序）关联的 application.yml 文件增加一行：&#xA;debug: true 程序启动成功后，可以在控制台观察到一段叫做 CONDITIONS EVALUATION REPORT 的冗长日志，下面截取若干部分：&#xA;============================ CONDITIONS EVALUATION REPORT ============================ Positive matches: ----------------- ... EmbeddedWebServerFactoryCustomizerAutoConfiguration.TomcatWebServerFactoryCustomizerConfiguration matched: - @ConditionalOnClass found required classes &amp;#39;org.apache.catalina.startup.Tomcat&amp;#39;, &amp;#39;org.apache.coyote.UpgradeProtocol&amp;#39; (OnClassCondition) ... Negative matches: ----------------- ... EmbeddedWebServerFactoryCustomizerAutoConfiguration.JettyWebServerFactoryCustomizerConfiguration: Did not match: - @ConditionalOnClass did not find required classes &amp;#39;org.</description>
    </item>
    <item>
      <title>注解处理器</title>
      <link>https://h2cone.github.io/2019/11/30/annotation-processor/</link>
      <pubDate>Sat, 30 Nov 2019 23:43:35 +0800</pubDate>
      <guid>https://h2cone.github.io/2019/11/30/annotation-processor/</guid>
      <description>为什么使用 Getter/Setter Java 的啰嗦和冗余是闻名于世的，特别在开发基于 Java 的业务系统的时候，继续不断地编写普通的 Java 类（数据类型），不假思索地用 private 修饰成员变量，熟练运用编辑器或集成开发环境不停地生成 Getter、Setter、ToString、Constructor 等方法。&#xA;public class Member { public static final Logger log = LoggerFactory.getLogger(Member.class); private Long id; private String name; public Long getId() { return id; } public void setId(Long id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } @Override public String toString() { return new StringJoiner(&amp;#34;, &amp;#34;, Member.</description>
    </item>
    <item>
      <title>Java 程序探测或追踪</title>
      <link>https://h2cone.github.io/2019/10/30/instrument_attach/</link>
      <pubDate>Wed, 30 Oct 2019 15:27:01 +0800</pubDate>
      <guid>https://h2cone.github.io/2019/10/30/instrument_attach/</guid>
      <description>序言 什么情况下应该探测或追踪程序？应用程序无不例外可能存在运行时才暴露的 bug，生产环境的故障排除，不得不依靠读日志和 Review 代码，运气好的话也许只看异常栈和关键代码就能快速提出假设，在本地验证通过，修复后发布上线，最后还可能对先前测试不充分感到羞愧。很不幸，如果是底层或性能的疑难杂症，CPU、内存、I/O、进程、线程、堆、栈等都可能提供线索，它们在程序运行过程中动态变化，只有探测或追踪它们才能超越表面的代码观察，从而搜集下层行为数据以供分析，参与 debug 的程序员则如虎添翼。在 Java 平台，BTrace 非常适合动态追踪正在运行的程序，它的基础正是 Java Instrumention 和 Java Attach API。&#xA;Instrument 简介 Oracle JDK 里有一个名为 java.lang.instrument 的包：&#xA;Provides services that allow Java programming language agents to instrument programs running on the JVM. The mechanism for instrumentation is modification of the byte-codes of methods. [0]&#xA;从它的简介，我们可以确认的是 instrumentation 的机制是更改 Java 字节码，而且我们已经知道类文件包含字节码。不过等等，instrumentation 和 instrument 都是什么意思？在这里的 instrument，我暂时还找不到恰到好处的汉译，作动词时意为“给&amp;hellip;&amp;hellip;装测量仪器”或者“仪器化”，结合简介，此包允许 Java agent 给运行在 JVM 上的程序装测量仪器。Java agent 又是什么？它可以作为 Java 程序的探针，它本质上是一个 Jar 文件，它利用 Instrumentation 来更改已加载到 JVM 的类，例如往原类插入用于探测或追踪的代码，即所谓的埋点，它的底层实现依赖于 JVMTI (Java Virtual Machine Tool Interface)。</description>
    </item>
    <item>
      <title>切面和动态代理以及字节码</title>
      <link>https://h2cone.github.io/2019/09/17/aop_proxy_bytecode/</link>
      <pubDate>Tue, 17 Sep 2019 11:29:21 +0800</pubDate>
      <guid>https://h2cone.github.io/2019/09/17/aop_proxy_bytecode/</guid>
      <description>楔子 想象一下，我们编写的代码块重复了两次或两次以上，理智的程序员可能会考虑重构，提取公共的部分抽象成函数或方法，通过重用函数或方法以此减少冗余，简化代码，甚至预防了“牵一发而动全身”的噩梦，这已经算得上是对 DRY 和 SoC 原则的践行。DRY（Don&amp;rsquo;t repeat yourself）教导我们尽量减少重复代码，而 SoC（Separation of Concerns）指的是关注点分离，因为关注点混杂会极大地增强复杂性，好比把什么都混为一谈，堆积而成的祖传代码，这又是程序员们的另一个噩梦，所以才把复杂的问题分解成若干独立的小问题，模块化，极力追求“高内聚，低耦合”。&#xA;AOP（Aspect-oriented programming）是对横向的重用，非常符合 DRY 和 SoC 的原则。直观上，代码总是从上往下执行，不妨称之为纵向，OOP（Object-oriented Programming）的继承也可看作是纵向；相对则是横向，从横跨多个类的角度来看，横向有着许许多多的统一逻辑可以切入，比如安全检查、异常处理、日志输出、事务管理、追踪、监控等等，这些统一逻辑能够被抽象成模块，重用它们甚至不需要显式使用或只需要编写简单的元数据进行声明，一次编写，到处执行，Java 程序员们已经体验过不少 Spring AOP 的魔术。&#xA;AOP 能够使前文所述的统一逻辑模块化，这些统一逻辑可称之为横切关注点（crosscutting concerns），切面（Aspect）则作为模块，因此译为切面导向编程。切面的作用效果彷佛是往程序的执行点注入了新的代码，这些执行点被称之为接入点（Join Point），比如方法调用的前后；接入点的集合称之为切入点 （Pointcut），比如满足条件的一组方法；注入的代码称之为建议（Advice），比如在方法调用前后输出日志；其中代码注入的术语是编织（Weaving），既然把编织工作交给库或框架，那么可能是在编译时编织（Compile-time weaving）或运行时编织（Run-Time weaving），还可能在编译后编织（Post-compile weaving） 或加载时编织（Load-time weaving）。&#xA;虽说如此，那属于 Spring 核心的 Spring AOP 的魔术是怎么做到的呢？&#xA;喧闹中，听见了一句悄悄话：&#xA;Spring AOP is implemented by using runtime proxies.&#xA;另一句悄悄话：&#xA;In the Spring Framework, an AOP proxy is a JDK dynamic proxy or a CGLIB proxy.&#xA;原来 Spring AOP 是使用运行时代理实现的，代理则是由 JDK 动态代理或 CGLIB 生成。据传闻所说，利用 JDK 动态代理能够在运行时生成代理，一番打听之后也了解到 CGLIB 是一个字节码生成和转换库，也可用于动态生成代理。</description>
    </item>
  </channel>
</rss>
