<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>log on Huangh&#39;s blog</title>
        <link>https://h2cone.github.io/tags/log/</link>
        <description>Recent content in log on Huangh&#39;s blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Sun, 22 Nov 2020 11:32:08 +0800</lastBuildDate><atom:link href="https://h2cone.github.io/tags/log/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Kafka 之于 Elastic Stack</title>
        <link>https://h2cone.github.io/2020/11/22/kafka_in_the_elk/</link>
        <pubDate>Sun, 22 Nov 2020 11:32:08 +0800</pubDate>
        
        <guid>https://h2cone.github.io/2020/11/22/kafka_in_the_elk/</guid>
        <description>&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;刚入行那会，公司产品研发部正如火如荼建设微服务基础设施，其中就包括&lt;strong&gt;日志中心&lt;/strong&gt;。试想一下，包含众多&lt;strong&gt;容器化&lt;/strong&gt;应用程序的系统，一个服务可能会有多个实例，每个实例输出各自的日志记录；假如在客户端收到了来自服务器端的异常响应，例如 &lt;code&gt;500 Internal Server Error&lt;/code&gt;，相应的负责人不可避免地会遇到需要通过查看容器日志来查明哪里发生故障或则什么原因导致性能下降的情景。&lt;/p&gt;
&lt;p&gt;负责人也许走了弯路。登录哪些服务器或跳板机？有没有访问权？需不需要通过“中介”才能获得许可或相关日志文件？查看哪些结点上的哪些服务的日志？&lt;/p&gt;
&lt;p&gt;负责人也以可以走已经铺好的路。直接在日志中心 Web 版搜索所需的一切日志记录；系统中所有服务的日志记录都可以被索引与检索，不仅仅可以用于故障排除，还可以用于监控、告警、数据分析等等。&lt;/p&gt;
&lt;h2 id=&#34;集中式日志管理&#34;&gt;集中式日志管理&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/elastic-stack/centralized_log_management.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;centralized_log_management&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上图来自&lt;a class=&#34;link&#34; href=&#34;https://ops-coffee.cn/elk&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;运维咖啡吧&lt;/a&gt;，这是一类典型的日志处理架构。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/products/beats/filebeat&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Filebeat&lt;/a&gt;，轻量级日志采集器。&lt;/p&gt;
&lt;p&gt;考虑到基于 &lt;a class=&#34;link&#34; href=&#34;https://docs.docker.com/develop/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Docker 开发&lt;/a&gt;服务，应用程序的父镜像应包含 Filebeat，例如 &lt;code&gt;FROM 父镜像&lt;/code&gt; 之后执行一系列下载、安装、设置 Filebeat 的指令。&lt;/p&gt;
&lt;p&gt;Filebeat 作为应用程序的 agent 可以&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-input-log.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;将日志作为输入源（从日志文件读取行）&lt;/a&gt;，再&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/guide/en/beats/filebeat/master/kafka-output.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;将 kafka 作为输出目的地（发送日志记录或事件到 Kafka）&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/products/logstash&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Logstash&lt;/a&gt;，传输和处理日志、事件等数据。&lt;/p&gt;
&lt;p&gt;因为 Logstash 有许多&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/guide/en/logstash/current/input-plugins.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;输入插件&lt;/a&gt;，包括&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/guide/en/logstash/current/input-plugins.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;读取来自 Kafka Topic 的事件&lt;/a&gt;，可以作为 Kafka 的消费者。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/what-is/elk-stack&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ELK&lt;/a&gt; 中的 Logstash 当然支持&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;将 Elasticsearch 作为输出目的地&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/products/elasticsearch&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Elasticsearch&lt;/a&gt;，分布式 RESTful 搜索引擎。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/kibana&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kibana&lt;/a&gt;，可视化 Elasticsearch 数据的用户界面。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有趣的是，&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/cn/elastic-stack&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Elastic Stack&lt;/a&gt; 并不包含 &lt;a class=&#34;link&#34; href=&#34;https://kafka.apache.org&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kafka&lt;/a&gt;，但两者在日志/事件处理领域却是经典组合。&lt;/p&gt;
&lt;h3 id=&#34;何时组合使用-kafka-与-elastic-stack&#34;&gt;何时组合使用 Kafka 与 Elastic Stack&lt;/h3&gt;
&lt;h4 id=&#34;应对突发流量&#34;&gt;应对突发流量&lt;/h4&gt;
&lt;p&gt;在大数据领域，Kafka 以单位时间内&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Throughput&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;吞吐量&lt;/a&gt;极高著称，所谓吞吐量是指代可处理的记录条数，Kafka 非常适用于&lt;strong&gt;流量削峰&lt;/strong&gt;。早在 2014 年，Kafka 已经能达到&lt;a class=&#34;link&#34; href=&#34;https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;每秒 200 万次写入（在三台廉价的机器上）&lt;/a&gt;。为什么 Kafka 如此之快？至少有如下原因：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;基于追加式&lt;a class=&#34;link&#34; href=&#34;https://h2cone.github.io/2020/08/30/log-notes/#%E6%8F%90%E4%BA%A4%E6%97%A5%E5%BF%97&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;提交日志&lt;/a&gt;，顺序 I/O 飞快。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重度使用文件系统缓存。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;复杂性从生产者转移到了消费者。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;高度可水平/横向扩展。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kafka 应对峰值或突发数据的能力远强于 Logstash，可防止单位时间输入过多日志数据导致 Logstash 成为系统的瓶颈；值得注意的是，完成本篇之时，官方的 &lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/guide/en/logstash/current/deploying-and-scaling.html#_scalability&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Logstash 扩展建议&lt;/a&gt;也仅有一小段。&lt;/p&gt;
&lt;h4 id=&#34;当-es-不可访问&#34;&gt;当 ES 不可访问&lt;/h4&gt;
&lt;p&gt;当 Elasticsearch 集群不可访问时（例如升级版本或者其他理由需要暂时下线），Kafka 能够暂时保存 Filebeat 采集的日志数据，直到 Elasticsearch 和 Logstash 再次上线。&lt;/p&gt;
&lt;h3 id=&#34;扩展和容错&#34;&gt;扩展和容错&lt;/h3&gt;
&lt;p&gt;引用一张来自 &lt;a class=&#34;link&#34; href=&#34;https://www.confluent.io/resources/kafka-the-definitive-guide/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kafka: The Definitive Guide&lt;/a&gt; 的插图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/kafka/A_consumer_group_reading_from_a_topic.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;A_consumer_group_reading_from_a _topic&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;消费者群组（Consumer Group）保证同一个主题（Topic）的任意分区（Partition）最多只能被组内的一个消费者使用。增加 Logstash 实例来组成一个消费者群组，它们将并发读取 Kafka Topic 中的日志消息，而不会交叠，因此能够提升单位时间内从 Kafka 到 Logstash 再到 Elasticsearch 的吞吐量；使用多个 Logstash 实例的另外一个好处是是增强系统的容错能力。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/kafka/consumer-groups.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;consumer-groups&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;默认情况下，当消费者加入或离开消费者群组将触发&lt;strong&gt;再平衡（rebalancing）&lt;/strong&gt;，Logstash 消费者的 Kafka Client 库将参与重新分配分区给消费者的过程。当群组中有若干 Logstash 实例失效时，根据再平衡协议，失去消费者的分区将被分配给现有的消费者。&lt;/p&gt;
&lt;h3 id=&#34;一点建议&#34;&gt;一点建议&lt;/h3&gt;
&lt;p&gt;假设 Logstash 实例组成的消费者群组 ID 为 &lt;code&gt;logstash&lt;/code&gt;，存储应用程序日志记录的话题 ID 为 &lt;code&gt;app_logs&lt;/code&gt;，下面是 &lt;code&gt;logstash-*.conf&lt;/code&gt; 的输入源配置：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;input {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    kafka {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        bootstrap_servers =&amp;gt; &amp;#34;kafka_host_1:9092,kafka_host_2:9092&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        group_id =&amp;gt; &amp;#34;logstash&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        topics =&amp;gt; [&amp;#34;app_logs&amp;#34;]
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        consumer_threads =&amp;gt; 8
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        ...
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;其中 &lt;code&gt;consumer_threads&lt;/code&gt; 是消费者线程数（默认值是 1），理想情况下，消费者线程数之和应与分区数相等，以实现完美平衡。如果消费者线程数之和多于分区数，那么某些线程将处于空闲状态；如果消费者线程数之和少于分区数，那么某些线程将消费多个分区。举例来说，&lt;code&gt;app_logs&lt;/code&gt; 话题的分区数为 16，最佳的部署方式很可能是将消费者线程数为 8 的 2 个 Logstash 实例部署到 2 台 CPU 核数为 8 的机器上。&lt;/p&gt;
&lt;p&gt;虽说 Kafka 应对突发数据或流量高峰的能力很强，但是在无法估算日志记录/事件的量级与流速之前应备不时之需。例如，使用一些“突发”主题，当单位时间内应用程序产生过多日志数据时，可以在运行时将其移动到“突发”主题，使其它主题避免不必要的流量。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;本文首发于 &lt;a class=&#34;link&#34; href=&#34;https://h2cone.github.io&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://h2cone.github.io&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/cn/blog/just-enough-kafka-for-the-elastic-stack-part1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Just Enough Kafka for the Elastic Stack, Part 1&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ops-coffee.cn/s/7bygznor_mdcwpf9przcfg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ELK日志系统之通用应用程序日志接入方案&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/swlh/why-kafka-is-so-fast-bde0d987cd03&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Why Kafka Is so Fast&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ops-coffee.cn/s/zlslsqrrlom-8sfwnwcksg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ELK架构下利用Kafka Group实现Logstash的高可用&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/streamthoughts/apache-kafka-rebalance-protocol-or-the-magic-behind-your-streams-applications-e94baf68e4f2&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Apache Kafka Rebalance Protocol, or the magic behind your streams applications&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>日志游记</title>
        <link>https://h2cone.github.io/2020/08/30/log-notes/</link>
        <pubDate>Sun, 30 Aug 2020 15:21:41 +0800</pubDate>
        
        <guid>https://h2cone.github.io/2020/08/30/log-notes/</guid>
        <description>&lt;h2 id=&#34;什么是日志&#34;&gt;什么是日志&lt;/h2&gt;
&lt;p&gt;日志是&lt;strong&gt;追加式&lt;/strong&gt;的，&lt;strong&gt;按时间排序&lt;/strong&gt;的记录（条目）序列。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/log/log%28file%29.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;log(file).png&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;无关记录的格式，日志文件记录操作系统或其它软件运行时发生的&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Event_%28computing%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;事件&lt;/a&gt;及其时间。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;lt;34&amp;gt;1 2003-10-11T22:14:15.003Z mymachine.example.com su - ID47 - BOM&amp;#39;su root&amp;#39; failed for lonvick on /dev/pts/8
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;“应用程序日志”是人类可读的文本，比如 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Syslog&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Syslog&lt;/a&gt; 和 &lt;a class=&#34;link&#34; href=&#34;http://www.slf4j.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SLF4J&lt;/a&gt; 等；如上所示，这是一个来自 &lt;a class=&#34;link&#34; href=&#34;https://tools.ietf.org/html/rfc5424&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;RFC5424&lt;/a&gt; 的 syslog 日志消息例子，从中不难看出主机（mymachine.example.com）上的一个应用程序（su）在 2003-10-11T22:14:15.003Z 发生了 “&amp;lsquo;su root&amp;rsquo; failed for lonvick&amp;hellip;”。&lt;/p&gt;
&lt;p&gt;现代最流行的分布式版本控制系统中的日志记录着所有贡献者的提交&lt;strong&gt;历史&lt;/strong&gt;：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% git log
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;commit 130560a769fe6da64c87f695e4665225de1faec3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Author: Daniel Smith &amp;lt;dbsmith@google.com&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Date:   Fri Jun &lt;span class=&#34;m&#34;&gt;6&lt;/span&gt; 17:31:45 &lt;span class=&#34;m&#34;&gt;2014&lt;/span&gt; -0700
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Proofread guestbook.md
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;commit 2c4b3a562ce34cddc3f8218a2c4d11c7310e6d56
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Author: Joe Beda &amp;lt;joe.github@bedafamily.com&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Date:   Fri Jun &lt;span class=&#34;m&#34;&gt;6&lt;/span&gt; 16:40:48 &lt;span class=&#34;m&#34;&gt;2014&lt;/span&gt; -0700
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    First commit
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;然而，日志并非全都是人类可读的，它可能是二进制格式而只能被程序读取，作为关键抽象普遍存在于数据库系统和分布式系统之中。&lt;/p&gt;
&lt;h2 id=&#34;数据库日志&#34;&gt;数据库日志&lt;/h2&gt;
&lt;p&gt;关系数据库系统中的日志通常用于&lt;a class=&#34;link&#34; href=&#34;http://mlwiki.org/index.php/Crash_Recovery&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;崩溃恢复&lt;/a&gt;、提供一定程度的&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Atomicity_%28database_systems%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;原子性&lt;/a&gt;与&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Durability_%28database_systems%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;持久性&lt;/a&gt;、&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Replication_%28computing%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数据复制&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;预写日志&#34;&gt;预写日志&lt;/h3&gt;
&lt;p&gt;根据经验，我们确信入库数据终将会被写入磁盘。磁盘是一种 I/O 设备（参考&lt;a class=&#34;link&#34; href=&#34;https://h2cone.github.io/2020/03/08/network_nio/#i-o&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;网络·NIO # I/O&lt;/a&gt;），从主存复制数据到 I/O 设备并不是一个原子操作，如果客户端发送请求后，数据库服务端处理请求中，系统&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Crash_%28computing%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;崩溃&lt;/a&gt;或宕机抑或重启，服务端·如何保证不丢失变更或者恢复到正确的数据？&lt;/p&gt;
&lt;p&gt;很久以前，存在着无原子性的非分布式数据库事务。张三账户有 1000 元，李四账户有 2000 元，张三向李四转账 200 元，数据库系统先将张三账户减少 200 元，然后将 800 元写回张三账户，接着将李四账户增加 200 元并且将 2200 元写回李四账户时，服务器突然发生故障；系统重启后，只有一个账户是对的，张三账户是 800 元，但是李四账户还是 2000 元，200 元不翼而飞。&lt;/p&gt;
&lt;p&gt;计算机界明显的坑早已被前人填满。&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Write-ahead_logging&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Write-ahead logging&lt;/a&gt; 是数据库系统中提供原子性与持久性的技术（日志先行技术），简称 &lt;strong&gt;WAL&lt;/strong&gt;，一言蔽之，数据库系统首先将数据变更记录到日志中，然后将日志写入稳定存储（如磁盘），之后才将变更写入数据库。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://mlwiki.org/index.php/Redo_Logging&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Redo log&lt;/a&gt; 和 &lt;a class=&#34;link&#34; href=&#34;http://mlwiki.org/index.php/Undo_Logging&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Undo log&lt;/a&gt; 是运用了 WAL 的磁盘数据结构：&lt;/p&gt;
&lt;p&gt;&lt;del&gt;- Undo log 在崩溃恢复期间用于撤消或回滚未提交的事务。&lt;/del&gt;&lt;/p&gt;
&lt;p&gt;&lt;del&gt;- Redo log 在崩溃恢复期间用于重做已提交但未将数据库对象从缓冲区刷入磁盘的事务。&lt;/del&gt;&lt;/p&gt;
&lt;p&gt;撤消和重做的前提是记录了数据库对象变更前的值和变更后的值。&lt;/p&gt;
&lt;p&gt;假设事务 T[i] 所操作的数据库对象是 X，X 的值从 V[old] 更改为 V[new]，&lt;del&gt;将数据从缓冲区刷入磁盘的操作被称为 flush&lt;/del&gt;，那么 undo/redo log 日志记录形式如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;begin T[i]        //（1）
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;(T[i], X, V)      //（2）
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;commit T[i]       //（3）
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;（1）记录事务开始。&lt;/p&gt;
&lt;p&gt;（2）记录数据库对象的值。Undo log 记录 (T[i], X, V[old]) ，而 Redo log 记录 (T[i], X, V[new])，两者都要求 flush X 之前 flush (T[i], X, V)。&lt;/p&gt;
&lt;p&gt;（3）记录事务提交。Undo log 要求 flush X 之后 flush (commit T[i])，而 Redo log 要求 flush X 之前 flush (commit T[i])。&lt;/p&gt;
&lt;p&gt;在崩溃恢复期间，从数据库系统角度来看：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;若发现 undo log 缺少（3），则无法确定 flush X 是否完成。决定将 X 的值设为 V[old] 后 flush X，因为 X 变更前的值是 V[old]，即使恢复过程中又发生崩溃，重复将 X 的值设为 V[old] 仍然&lt;strong&gt;幂等&lt;/strong&gt;，直到恢复完成后，可以在（3）位置写一条记录：rollback T[i]，下次恢复期间忽略。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;若发现 redo log 缺少（3），则确定 flush X 未执行。决定将 X 的值设为 V[new]，重试 flush X。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;若发现缺少（2），则忽略此事务（无计可施）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;若没有（1），则无此事务。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;逻辑日志&#34;&gt;逻辑日志&lt;/h3&gt;
&lt;p&gt;前文&lt;a class=&#34;link&#34; href=&#34;https://h2cone.github.io/2020/07/11/from-mysql-to-tidb/#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MySQL 窘境 # 主从复制&lt;/a&gt;中提到其数据复制需要数据变更日志，或则数据变更日志记录（事件）。MySQL Server 有&lt;a class=&#34;link&#34; href=&#34;https://dev.mysql.com/doc/refman/5.7/en/server-logs.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;若干种日志&lt;/a&gt;，其中二进制日志（Binary log，简称 binlog）包含描述数据变更的“事件”，例如创建表或对表数据的更改，&lt;strong&gt;MySQL binlog 与存储引擎解耦&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在服务化架构中，组合使用 MySQL 和 &lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/products/elasticsearch&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Elasticsearch&lt;/a&gt; 时常常要求将 MySQL 数据同步到 Elasticsearch；Elastic Stack 的解决方案是使用 &lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/logstash&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Logstash&lt;/a&gt; 的插件：&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Jdbc input plugin&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/elastic-stack/logstash-plugin.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;logstash-plugin&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;Logstash 的 Jdbc input plugin 会根据配置文件定时/定期对 MySQL 进行轮询，可获取上一次询问之后插入或更改的记录。有人误以为 Jdbc input plugin 最快只能每分钟查询一次，实际上也能设置&lt;a class=&#34;link&#34; href=&#34;https://github.com/logstash-plugins/logstash-input-jdbc/issues/265&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;秒级&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;监听 binlog 事件可以实现将 MySQL 数据同步到各种数据源，这种方案非常适合各种消息传递、数据流、实时数据处理。假设有一个中间件，根据 &lt;a class=&#34;link&#34; href=&#34;https://dev.mysql.com/doc/internals/en/client-server-protocol.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MySQL 协议&lt;/a&gt;，它只要向 MySQL master 注册为 MySQL slave，持续接收并解析 binlog 事件，经过处理后又能作为消息传递给各种服务或组件以满足数据同步需求；比如 &lt;a class=&#34;link&#34; href=&#34;https://github.com/alibaba/canal&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;alibaba/canal&lt;/a&gt;，它是一个关于 MySQL binlog 增量订阅&amp;amp;消费的组件。&lt;/p&gt;
&lt;p&gt;诸如此类的设计模式被称为 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Change_data_capture&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CDC（change data capture）&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;分布式系统日志&#34;&gt;分布式系统日志&lt;/h2&gt;
&lt;p&gt;这要从&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/State_machine_replication&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;状态机复制&lt;/a&gt;说起。如下图所示，每个 Server 存储了一个它的&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Finite-state_machine&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;状态机（State Machine）&lt;/a&gt;按顺序执行的一系列命令的日志（Log）；每个日志包含相同顺序的命令集，因此每个状态机将执行相同的命令序列；因为讨论的状态机具有&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Deterministic_algorithm&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;确定性&lt;/a&gt;，所以它们将产生相同的输出并以相同的状态结束。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/distributed-system/replicated-state-machine-architecture.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;replicated-state-machine-architecture&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;什么是确定性？给定特定的输入，将始终产生相同的输出。作为反面，执行类似以下命令的若干状态机（进程）将产生不同的输出并以不同的状态（磁盘和主存中的数据）结束。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;INSERT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;INTO&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;VALUES&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;NOW&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;());&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;状态机复制通常使用 &lt;strong&gt;replicated log&lt;/strong&gt; 实现，保持 replicated log 的一致性是&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Consensus_%28computer_science%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;共识&lt;/a&gt;算法的工作。&lt;/p&gt;
&lt;h2 id=&#34;提交日志&#34;&gt;提交日志&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://kafka.apache.org&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Apache Kafka&lt;/a&gt; 分区（partition）的本质是&lt;strong&gt;提交日志（commit log）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;如果把 Kafka 与&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Relational_database&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;关系型数据库&lt;/a&gt;作类比，那么消息（message）类比行（row），主题（topic）类比表（table）；一个主题分成多个分区，分区是追加式的消息序列，同一个主题的多个分区可以分布在不同机器上。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/kafka/Representation_of_a_topic_with_multiple_partitions.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Representation_of_a_topic_with_multiple_partitions&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;从 Kafka 的角度来看，将消息写入分区就像将日志记录写入提交日志（追加式更新日志文件）。&lt;/p&gt;
&lt;p&gt;在 Kafka 的 &lt;code&gt;server.properties&lt;/code&gt; 中，有一个 &lt;code&gt;log.dirs&lt;/code&gt; 用于指定日志文件目录列表。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# A comma separated list of directories under which to store log files
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;log.dirs=/usr/local/var/lib/kafka-logs
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在磁盘上，一个分区是一个目录，例如主题名为 quickstart-events 的一个分区：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% tree /usr/local/var/lib/kafka-logs/quickstart-events-0/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;/usr/local/var/lib/kafka-logs/quickstart-events-0/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── 00000000000000000000.index
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── 00000000000000000000.log
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── 00000000000000000000.timeindex
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;└── leader-epoch-checkpoint
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;其中 index 文件与 log 文件合称为一个 &lt;strong&gt;segment&lt;/strong&gt;，以人类可读的方式查看 log 文件：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% kafka-run-class kafka.tools.DumpLogSegments --deep-iteration --print-data-log --files /usr/local/var/lib/kafka-logs/quickstart-events-0/00000000000000000000.log
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Dumping /usr/local/var/lib/kafka-logs/quickstart-events-0/00000000000000000000.log
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Starting offset: &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;baseOffset: &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; lastOffset: &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; count: &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; isTransactional: &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt; isControl: &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt; position: &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; CreateTime: &lt;span class=&#34;m&#34;&gt;1604900950169&lt;/span&gt; size: &lt;span class=&#34;m&#34;&gt;90&lt;/span&gt; magic: &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; compresscodec: NONE crc: &lt;span class=&#34;m&#34;&gt;3202290031&lt;/span&gt; isvalid: &lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; offset: &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; CreateTime: &lt;span class=&#34;m&#34;&gt;1604900950169&lt;/span&gt; keysize: -1 valuesize: &lt;span class=&#34;m&#34;&gt;22&lt;/span&gt; sequence: -1 headerKeys: &lt;span class=&#34;o&#34;&gt;[]&lt;/span&gt; payload: This is my first event
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;baseOffset: &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; lastOffset: &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; count: &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; isTransactional: &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt; isControl: &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt; position: &lt;span class=&#34;m&#34;&gt;90&lt;/span&gt; CreateTime: &lt;span class=&#34;m&#34;&gt;1604900955215&lt;/span&gt; size: &lt;span class=&#34;m&#34;&gt;91&lt;/span&gt; magic: &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; compresscodec: NONE crc: &lt;span class=&#34;m&#34;&gt;3852839661&lt;/span&gt; isvalid: &lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; offset: &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; CreateTime: &lt;span class=&#34;m&#34;&gt;1604900955215&lt;/span&gt; keysize: -1 valuesize: &lt;span class=&#34;m&#34;&gt;23&lt;/span&gt; sequence: -1 headerKeys: &lt;span class=&#34;o&#34;&gt;[]&lt;/span&gt; payload: This is my second event
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;从中可以发现，消息编码在 log 文件中；index 文件则包含了偏移量（offset）与消息在 log 文件中的位置（position）的映射，用于查找消息。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/kafka/A_consumer_group_reading_from_a_topic.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;A_consumer_group_reading_from_a _topic&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;对于消息消费者（consumer）来说，从分区读取消息就像从提交日志读取记录；消费者通过分区的偏移量（offset）区分已读消息和未读消息，偏移量作为元数据存储在 &lt;a class=&#34;link&#34; href=&#34;https://elang2.github.io/myblog/posts/2017-09-20-Kafak-And-Zookeeper-Offsets.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Zookeeper 树或 Kafka 内置主题&lt;/a&gt;中。&lt;/p&gt;
&lt;p&gt;毫不夸张地说，Kafka 是一个分布式提交日志系统，只不过官方更愿意称之为分布式事件&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Streaming_data&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;流&lt;/a&gt;平台。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;本文首发于 &lt;a class=&#34;link&#34; href=&#34;https://h2cone.github.io&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://h2cone.github.io&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;The Log: What every software engineer should know about real-time data&amp;rsquo;s unifying abstraction&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Log_file&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Wikipedia # Log file&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Write-ahead_logging&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Wikipedia # Write-ahead logging&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://mlwiki.org/index.php/Undo/Redo_Logging&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML Wiki # Undo/Redo Logging&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://www.mathcs.emory.edu/~cheung/Courses/554/Syllabus/6-logging/overview.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Intro to undo/redo logging&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://www.mathcs.emory.edu/~cheung/Courses/554/Syllabus/6-logging/undo-redo2.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Recovering from a system crash using undo/redo-log&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/35574452&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;undo log 与 redo log 原理分析&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://dev.mysql.com/doc/refman/5.7/en/binary-log.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MySQL 5.7 Reference Manual # The Binary Log&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://dev.mysql.com/doc/refman/5.7/en/mysqlbinlog.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MySQL 5.7 Reference Manual # mysqlbinlog — Utility for Processing Binary Log Files&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://dev.mysql.com/doc/refman/5.7/en/replication-formats.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MySQL 5.7 Reference Manual # Replication Formats&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/blog/how-to-keep-elasticsearch-synchronized-with-a-relational-database-using-logstash&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;How to keep Elasticsearch synchronized with a relational database using Logstash and JDBC&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@siddontang/how-to-sync-your-mysql-data-to-elasticsearch-ddae009243c1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;How to sync your MySQL data to Elasticsearch&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://raft.github.io&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;The Raft Consensus Algorithm&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://thehoard.blog/how-kafkas-storage-internals-work-3a29b02e026&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;How Kafka’s Storage Internals Work&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://presos.jamesward.com/distributed_commit_logs_with_apache_kafka/#/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Distributed Commit Logs with Apache Kafka&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        
    </channel>
</rss>
