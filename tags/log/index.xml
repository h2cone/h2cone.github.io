<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Log on Huangh&#39;s blog</title>
    <link>https://h2cone.github.io/tags/log/</link>
    <description>Recent content in Log on Huangh&#39;s blog</description>
    <generator>Hugo 0.125.0</generator>
    <language>en-us</language>
    <copyright>© Huangh&#39;s blog</copyright>
    <lastBuildDate>Sun, 22 Nov 2020 11:32:08 +0800</lastBuildDate>
    <atom:link href="https://h2cone.github.io/tags/log/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kafka 之于 Elastic Stack</title>
      <link>https://h2cone.github.io/2020/11/22/kafka_in_the_elk/</link>
      <pubDate>Sun, 22 Nov 2020 11:32:08 +0800</pubDate>
      <guid>https://h2cone.github.io/2020/11/22/kafka_in_the_elk/</guid>
      <description>背景 刚入行那会，公司产品研发部正如火如荼建设微服务基础设施，其中就包括日志中心。试想一下，包含众多容器化应用程序的系统，一个服务可能会有多个实例，每个实例输出各自的日志记录；假如在客户端收到了来自服务器端的异常响应，例如 500 Internal Server Error，相应的负责人不可避免地会遇到需要通过查看容器日志来查明哪里发生故障或则什么原因导致性能下降的情景。&#xA;负责人也许走了弯路。登录哪些服务器或跳板机？有没有访问权？需不需要通过“中介”才能获得许可或相关日志文件？查看哪些结点上的哪些服务的日志？&#xA;负责人也以可以走已经铺好的路。直接在日志中心 Web 版搜索所需的一切日志记录；系统中所有服务的日志记录都可以被索引与检索，不仅仅可以用于故障排除，还可以用于监控、告警、数据分析等等。&#xA;集中式日志管理 上图来自运维咖啡吧，这是一类典型的日志处理架构。&#xA;Filebeat，轻量级日志采集器。 考虑到基于 Docker 开发服务，应用程序的父镜像应包含 Filebeat，例如 FROM 父镜像 之后执行一系列下载、安装、设置 Filebeat 的指令。 Filebeat 作为应用程序的 agent 可以将日志作为输入源（从日志文件读取行），再将 kafka 作为输出目的地（发送日志记录或事件到 Kafka）。 Logstash，传输和处理日志、事件等数据。 因为 Logstash 有许多输入插件，包括读取来自 Kafka Topic 的事件，可以作为 Kafka 的消费者。 ELK 中的 Logstash 当然支持将 Elasticsearch 作为输出目的地。 Elasticsearch，分布式 RESTful 搜索引擎。 Kibana，可视化 Elasticsearch 数据的用户界面。 有趣的是，Elastic Stack 并不包含 Kafka，但两者在日志/事件处理领域却是经典组合。&#xA;何时组合使用 Kafka 与 Elastic Stack 应对突发流量 在大数据领域，Kafka 以单位时间内吞吐量极高著称，所谓吞吐量是指代可处理的记录条数，Kafka 非常适用于流量削峰。早在 2014 年，Kafka 已经能达到每秒 200 万次写入（在三台廉价的机器上）。为什么 Kafka 如此之快？至少有如下原因：</description>
    </item>
    <item>
      <title>日志游记</title>
      <link>https://h2cone.github.io/2020/08/30/log-notes/</link>
      <pubDate>Sun, 30 Aug 2020 15:21:41 +0800</pubDate>
      <guid>https://h2cone.github.io/2020/08/30/log-notes/</guid>
      <description>什么是日志 日志是追加式的，按时间排序的记录（条目）序列。&#xA;无关记录的格式，日志文件记录操作系统或其它软件运行时发生的事件及其时间。&#xA;&amp;lt;34&amp;gt;1 2003-10-11T22:14:15.003Z mymachine.example.com su - ID47 - BOM&amp;#39;su root&amp;#39; failed for lonvick on /dev/pts/8 “应用程序日志”是人类可读的文本，比如 Syslog 和 SLF4J 等；如上所示，这是一个来自 RFC5424 的 syslog 日志消息例子，从中不难看出主机（mymachine.example.com）上的一个应用程序（su）在 2003-10-11T22:14:15.003Z 发生了 “&amp;lsquo;su root&amp;rsquo; failed for lonvick&amp;hellip;”。&#xA;现代最流行的分布式版本控制系统中的日志记录着所有贡献者的提交历史：&#xA;% git log ... commit 130560a769fe6da64c87f695e4665225de1faec3 Author: Daniel Smith &amp;lt;dbsmith@google.com&amp;gt; Date: Fri Jun 6 17:31:45 2014 -0700 Proofread guestbook.md commit 2c4b3a562ce34cddc3f8218a2c4d11c7310e6d56 Author: Joe Beda &amp;lt;joe.github@bedafamily.com&amp;gt; Date: Fri Jun 6 16:40:48 2014 -0700 First commit 然而，日志并非全都是人类可读的，它可能是二进制格式而只能被程序读取，作为关键抽象普遍存在于数据库系统和分布式系统之中。&#xA;数据库日志 关系数据库系统中的日志通常用于崩溃恢复、提供一定程度的原子性与持久性、数据复制。</description>
    </item>
  </channel>
</rss>
