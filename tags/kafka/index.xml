<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>kafka on Huangh&#39;s blog</title>
        <link>https://h2cone.github.io/tags/kafka/</link>
        <description>Recent content in kafka on Huangh&#39;s blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Mon, 20 Jun 2022 10:16:16 +0800</lastBuildDate><atom:link href="https://h2cone.github.io/tags/kafka/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>高吞吐 Kafka 客户端配置</title>
        <link>https://h2cone.github.io/2022/06/20/high_throughput_kafka_client_config/</link>
        <pubDate>Mon, 20 Jun 2022 10:16:16 +0800</pubDate>
        
        <guid>https://h2cone.github.io/2022/06/20/high_throughput_kafka_client_config/</guid>
        <description>&lt;h2 id=&#34;写在前面的话&#34;&gt;写在前面的话&lt;/h2&gt;
&lt;p&gt;团队围绕着 Kafka 一系列服务的压力测试的核心指标之一是 &lt;strong&gt;Eevents per second&lt;/strong&gt;，排除其它因素，它与&lt;strong&gt;吞吐量&lt;/strong&gt;正相关。&lt;/p&gt;
&lt;h2 id=&#34;什么是吞吐量&#34;&gt;什么是吞吐量&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Network_throughput&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;吞吐量&lt;/a&gt;是指通过通信通道成功传递消息的&lt;strong&gt;速率&lt;/strong&gt;。从 Kafka 生产者（Producer）的角度来看，可以用单位时间内交付成功的记录条数或大小来描述吞吐量；从 Kafka 消费者（Consumer）的角度来看，可以用单位时间内读取的记录条数或大小来描述。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/kafka/producer-broker.svg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;producer-broker&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;生产者准备记录包含业务逻辑，此处只关注单位时间内接收到回执（ack）的记录条数或大小。默认情况下，生产者使用&lt;strong&gt;异步&lt;/strong&gt;发送，且它将尝试在内存中累积记录并在单个请求中发送批量记录。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;long&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;numRecords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;producer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;send&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;record&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;callback&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;调用方法 &lt;a class=&#34;link&#34; href=&#34;https://javadoc.io/static/org.apache.kafka/kafka-clients/3.2.0/org/apache/kafka/clients/producer/KafkaProducer.html#send-org.apache.kafka.clients.producer.ProducerRecord-org.apache.kafka.clients.producer.Callback-&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;KafkaProducer.send(ProducerRecord, Callback)&lt;/a&gt; &lt;strong&gt;不阻塞&lt;/strong&gt;在该方法，既传递记录（record）的引用，也传递回调（callback）的引用。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;MyCallback&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;implements&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Callback&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;onCompletion&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RecordMetadata&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Exception&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;// handling
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;生产者接受到发送记录的回执时，将有线程执行方法 onCompletion 的代码，我们可以在回调方法体内实现记录条数或大小的累计。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/kafka/consumer-broker.svg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;consumer-broker&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;注意：“提交偏移量”不一定发生在“处理记录”之后。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;conditions&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;ConsumerRecords&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;records&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;consumer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;poll&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;timeout&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;processRetrievedRecords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;records&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;消费者处理记录包含业务逻辑，此处只关注单位时间内接受到的记录条数或大小。默认情况下，消费者通过轮询拉取（poll）批量的记录，每次调用方法 &lt;a class=&#34;link&#34; href=&#34;https://javadoc.io/static/org.apache.kafka/kafka-clients/3.2.0/org/apache/kafka/clients/consumer/KafkaConsumer.html#poll-java.time.Duration-&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;KafkaConsumer.poll(Duration)&lt;/a&gt; &lt;strong&gt;阻塞&lt;/strong&gt;在该方法，直到超时（timeout）返回，且会有线程定期透明地提交前一批的最后一条记录的偏移量（auto commit）。&lt;/p&gt;
&lt;h2 id=&#34;测试吞吐量&#34;&gt;测试吞吐量&lt;/h2&gt;
&lt;h3 id=&#34;生产者工具&#34;&gt;生产者工具&lt;/h3&gt;
&lt;p&gt;在 Kafka 安装目录，有助于测试生产者性能的命令行工具是 kafka-producer-perf-test.sh。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% ./bin/kafka-producer-perf-test.sh --help
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;usage: producer-performance &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;-h&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; --topic TOPIC --num-records NUM-RECORDS &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;--payload-delimiter PAYLOAD-DELIMITER&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; --throughput THROUGHPUT &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;--producer-props PROP-NAME&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;PROP-VALUE &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;PROP-NAME&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;PROP-VALUE ...&lt;span class=&#34;o&#34;&gt;]]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;--producer.config CONFIG-FILE&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                            &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;--print-metrics&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;--transactional-id TRANSACTIONAL-ID&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;--transaction-duration-ms TRANSACTION-DURATION&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;--record-size RECORD-SIZE &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; --payload-file PAYLOAD-FILE&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;This tool is used to verify the producer performance.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;optional arguments:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  -h, --help             show this &lt;span class=&#34;nb&#34;&gt;help&lt;/span&gt; message and &lt;span class=&#34;nb&#34;&gt;exit&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  --topic TOPIC          produce messages to this topic
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  --num-records NUM-RECORDS
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                         number of messages to produce
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  --payload-delimiter PAYLOAD-DELIMITER
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                         provides delimiter to be used when --payload-file is provided. Defaults to new line. Note that this parameter will be ignored &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; --payload-file is not provided. &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;default: &lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  --throughput THROUGHPUT
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                         throttle maximum message throughput to *approximately* THROUGHPUT messages/sec. Set this to -1 to disable throttling.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  --producer-props PROP-NAME&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;PROP-VALUE &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;PROP-NAME&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;PROP-VALUE ...&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                         kafka producer related configuration properties like bootstrap.servers,client.id etc. These configs take precedence over those passed via --producer.config.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  --producer.config CONFIG-FILE
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                         producer config properties file.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  --print-metrics        print out metrics at the end of the test. &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;default: &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  --transactional-id TRANSACTIONAL-ID
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                         The transactionalId to use &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; transaction-duration-ms is &amp;gt; 0. Useful when testing the performance of concurrent transactions. &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;default: performance-producer-default-transactional-id&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  --transaction-duration-ms TRANSACTION-DURATION
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                         The max age of each transaction. The commitTransaction will be called after this &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; has elapsed. Transactions are only enabled &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; this value is positive. &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;default: 0&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  either --record-size or --payload-file must be specified but not both.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  --record-size RECORD-SIZE
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                         message size in bytes. Note that you must provide exactly one of --record-size or --payload-file.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  --payload-file PAYLOAD-FILE
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                         file to &lt;span class=&#34;nb&#34;&gt;read&lt;/span&gt; the message payloads from. This works only &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; UTF-8 encoded text files. Payloads will be  &lt;span class=&#34;nb&#34;&gt;read&lt;/span&gt;  from  this file and a payload will be randomly selected when sending messages. Note that you must provide
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                         exactly one of --record-size or --payload-file.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;查看 kafka-producer-perf-test.sh 不难发现实际执行 &lt;a class=&#34;link&#34; href=&#34;https://github.com/apache/kafka/blob/trunk/tools/src/main/java/org/apache/kafka/tools/ProducerPerformance.java&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ProducerPerformance&lt;/a&gt; 的方法 main。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% ./bin/kafka-producer-perf-test.sh &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--topic perf_test &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--num-records &lt;span class=&#34;m&#34;&gt;1000000&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--record-size &lt;span class=&#34;m&#34;&gt;1024&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--throughput -1 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--producer-props &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;bootstrap.servers&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;localhost:9092
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;发送 1000000 条大小为 1024 字节的记录到地址为 localhost:9092 的 Kafka Broker 的主题 perf_test，输出包含 records/sec 或 MB/sec 是我们关注的吞吐量。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;m&#34;&gt;498505&lt;/span&gt; records sent, 99701.0 records/sec &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;97.36 MB/sec&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;, 1.4 ms avg latency, 176.0 ms max latency.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;m&#34;&gt;1000000&lt;/span&gt; records sent, 102722.136620 records/sec &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;100.31 MB/sec&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;, 0.92 ms avg latency, 176.00 ms max latency, &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; ms 50th, &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; ms 95th, &lt;span class=&#34;m&#34;&gt;23&lt;/span&gt; ms 99th, &lt;span class=&#34;m&#34;&gt;56&lt;/span&gt; ms 99.9th.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;消费者工具&#34;&gt;消费者工具&lt;/h3&gt;
&lt;p&gt;另一方面，命令行工具 kafka-consumer-perf-test.sh 有助于对消费者进行性能测试。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% ./bin/kafka-consumer-perf-test.sh --help
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;This tool helps in performance &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; the full zookeeper consumer
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Option                                   Description                            
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;------                                   -----------                            
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--bootstrap-server &amp;lt;String: server to    REQUIRED unless --broker-list          
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  connect to&amp;gt;                              &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;deprecated&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; is specified. The server
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;s&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; to connect to.                   
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--broker-list &amp;lt;String: broker-list&amp;gt;      DEPRECATED, use --bootstrap-server     
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           instead&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; ignored &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; --bootstrap-     
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           server is specified.  The broker     
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           list string in the form HOST1:PORT1, 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           HOST2:PORT2.                         
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--consumer.config &amp;lt;String: config file&amp;gt;  Consumer config properties file.       
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--date-format &amp;lt;String: date format&amp;gt;      The date format to use &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; formatting  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           the &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; field. See java.text.       
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           SimpleDateFormat &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; options.        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;default: yyyy-MM-dd HH:mm:ss:SSS&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;   
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--fetch-size &amp;lt;Integer: size&amp;gt;             The amount of data to fetch in a       
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           single request. &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;default: 1048576&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;   
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--from-latest                            If the consumer does not already have  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           an established offset to consume     
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           from, start with the latest message  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           present in the log rather than the   
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           earliest message.                    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--group &amp;lt;String: gid&amp;gt;                    The group id to consume on. &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;default:  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           perf-consumer-20714&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;                 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--help                                   Print usage information.               
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--hide-header                            If set, skips printing the header &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           the stats                            
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--messages &amp;lt;Long: count&amp;gt;                 REQUIRED: The number of messages to    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           send or consume                      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--num-fetch-threads &amp;lt;Integer: count&amp;gt;     DEPRECATED AND IGNORED: Number of      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           fetcher threads. &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;default: 1&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--print-metrics                          Print out the metrics.                 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--reporting-interval &amp;lt;Integer:           Interval in milliseconds at which to   
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  interval_ms&amp;gt;                             print progress info. &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;default: 5000&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--show-detailed-stats                    If set, stats are reported &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; each    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           reporting interval as configured by  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           reporting-interval                   
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--socket-buffer-size &amp;lt;Integer: size&amp;gt;     The size of the tcp RECV size.         
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;default: 2097152&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;                   
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--threads &amp;lt;Integer: count&amp;gt;               DEPRECATED AND IGNORED: Number of      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           processing threads. &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;default: 10&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--timeout &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;Long: milliseconds&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;           The maximum allowed &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; in            
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           milliseconds between returned        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                           records. &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;default: 10000&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;            
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--topic &amp;lt;String: topic&amp;gt;                  REQUIRED: The topic to consume from.   
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--version                                Display Kafka version.  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;查看 kafka-consumer-perf-test.sh 不难发现实际执行 &lt;a class=&#34;link&#34; href=&#34;https://github.com/kafka-dev/kafka/blob/master/core/src/main/scala/kafka/tools/ConsumerPerformance.scala&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ConsumerPerformance&lt;/a&gt; 的方法 main。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;./&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bin&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kafka&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;consumer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;perf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;sh&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;\&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;--&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;broker&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;list&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;localhost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;9092&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;\&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;--&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topic&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;perf_test&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;\&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;--&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;1000000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;从地址是 localhost:9092 的 Kafka Broker 的主题 perf_test 索取 1000000 条记录，输出结果包含列名 nMsg.sec 是我们关注的吞吐量。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;2022-07-02 11:39:47:948, 2022-07-02 11:39:49:374, 976.9287, 685.0832, 1000375, 701525.2454, 187, 1239, 788.4816, 807405.1655
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;理论配置&#34;&gt;理论配置&lt;/h2&gt;
&lt;p&gt;完全受到 &lt;a class=&#34;link&#34; href=&#34;https://docs.confluent.io/cloud/current/client-apps/optimizing/throughput.html#summary-of-configurations-for-optimizing-throughput&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Summary of Configurations for Optimizing Throughput&lt;/a&gt; 的启发。&lt;/p&gt;
&lt;h3 id=&#34;生产者配置&#34;&gt;生产者配置&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;batch.size&lt;/code&gt;。批次大小。批处理时（当多个记录被发送到同一个分区时）累积记录不超过指定字节数，超过时立即发送批量记录。建议增加到 100000 ~ 200000。默认为 16384。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;linger.ms&lt;/code&gt;。逗留时长。批处理时（当多个记录被发送到同一个分区时）累积记录不超过指定毫秒数，超过时立即发送批量记录。属性 linger.ms 优先于属性 batch.size。默认为 0。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;compression.type=lz4&lt;/code&gt;。压缩类型。默认值是 none，表示不压缩。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;acks=1&lt;/code&gt;。生产者要求在 Leader 考虑请求完成之前收到的 ack 数量。默认值是 all，Kafka 3.0 之前的默认值是 1。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;buffer.memory&lt;/code&gt;。缓冲记录的内存总字节数。如果有很多分区就增加它，默认为 33554432。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;消费者配置&#34;&gt;消费者配置&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;fetch.min.bytes&lt;/code&gt;。一个索取请求（fetch request）要求服务端返回的最小字节数。增加到 100000，默认为 1。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;fetch.max.wait.ms=500&lt;/code&gt;。一个索取请求（fetch request）要求服务端未累积到 fetch.min.bytes 的最大阻塞毫秒数。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;验证配置&#34;&gt;验证配置&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% ./bin/kafka-producer-perf-test.sh &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--topic perf_test &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--num-records &lt;span class=&#34;m&#34;&gt;1000000&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--record-size &lt;span class=&#34;m&#34;&gt;1024&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--throughput -1 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--producer-props &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;bootstrap.servers&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;localhost:9092 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;batch.size&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100000&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;linger.ms&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;compression.type&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;lz4 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;acks&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;buffer.memory&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;33554432&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;m&#34;&gt;489179&lt;/span&gt; records sent, 97835.8 records/sec &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;95.54 MB/sec&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;, 3.0 ms avg latency, 421.0 ms max latency.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;m&#34;&gt;1000000&lt;/span&gt; records sent, 102637.791235 records/sec &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;100.23 MB/sec&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;, 2.22 ms avg latency, 421.00 ms max latency, &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; ms 50th, &lt;span class=&#34;m&#34;&gt;5&lt;/span&gt; ms 95th, &lt;span class=&#34;m&#34;&gt;39&lt;/span&gt; ms 99th, &lt;span class=&#34;m&#34;&gt;90&lt;/span&gt; ms 99.9th.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;上面的配置使用 lz4 压缩算法，而下面的配置不使用压缩在某些指标表现得更好。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% % ./bin/kafka-producer-perf-test.sh &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--topic perf_test &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--num-records &lt;span class=&#34;m&#34;&gt;1000000&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--record-size &lt;span class=&#34;m&#34;&gt;1024&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--throughput -1 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--producer-props &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;bootstrap.servers&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;localhost:9092 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;batch.size&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100000&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;linger.ms&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;acks&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;buffer.memory&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;33554432&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;m&#34;&gt;558625&lt;/span&gt; records sent, 111680.3 records/sec &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;109.06 MB/sec&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;, 1.8 ms avg latency, 197.0 ms max latency.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;m&#34;&gt;1000000&lt;/span&gt; records sent, 114207.400640 records/sec &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;111.53 MB/sec&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;, 1.87 ms avg latency, 197.00 ms max latency, &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; ms 50th, &lt;span class=&#34;m&#34;&gt;5&lt;/span&gt; ms 95th, &lt;span class=&#34;m&#34;&gt;20&lt;/span&gt; ms 99th, &lt;span class=&#34;m&#34;&gt;48&lt;/span&gt; ms 99.9th.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;亲自走“调参-测试”循环，方可迭代到更适合自己的最佳实践。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;本文首发于 &lt;a class=&#34;link&#34; href=&#34;https://h2cone.github.io&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://h2cone.github.io&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.confluent.io/platform/current/kafka/design.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kafka Design | Confluent Documentation&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://quarkus.io/blog/kafka-commit-strategies/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kafka - When to commit?&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.confluent.io/cloud/current/client-apps/optimizing/throughput.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Optimizing for Throughput | Confluent Documentation&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Kafka 之于 Elastic Stack</title>
        <link>https://h2cone.github.io/2020/11/22/kafka_in_the_elk/</link>
        <pubDate>Sun, 22 Nov 2020 11:32:08 +0800</pubDate>
        
        <guid>https://h2cone.github.io/2020/11/22/kafka_in_the_elk/</guid>
        <description>&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;刚入行那会，公司产品研发部正如火如荼建设微服务基础设施，其中就包括&lt;strong&gt;日志中心&lt;/strong&gt;。试想一下，包含众多&lt;strong&gt;容器化&lt;/strong&gt;应用程序的系统，一个服务可能会有多个实例，每个实例输出各自的日志记录；假如在客户端收到了来自服务器端的异常响应，例如 &lt;code&gt;500 Internal Server Error&lt;/code&gt;，相应的负责人不可避免地会遇到需要通过查看容器日志来查明哪里发生故障或则什么原因导致性能下降的情景。&lt;/p&gt;
&lt;p&gt;负责人也许走了弯路。登录哪些服务器或跳板机？有没有访问权？需不需要通过“中介”才能获得许可或相关日志文件？查看哪些结点上的哪些服务的日志？&lt;/p&gt;
&lt;p&gt;负责人也以可以走已经铺好的路。直接在日志中心 Web 版搜索所需的一切日志记录；系统中所有服务的日志记录都可以被索引与检索，不仅仅可以用于故障排除，还可以用于监控、告警、数据分析等等。&lt;/p&gt;
&lt;h2 id=&#34;集中式日志管理&#34;&gt;集中式日志管理&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/elastic-stack/centralized_log_management.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;centralized_log_management&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上图来自&lt;a class=&#34;link&#34; href=&#34;https://ops-coffee.cn/elk&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;运维咖啡吧&lt;/a&gt;，这是一类典型的日志处理架构。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/products/beats/filebeat&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Filebeat&lt;/a&gt;，轻量级日志采集器。&lt;/p&gt;
&lt;p&gt;考虑到基于 &lt;a class=&#34;link&#34; href=&#34;https://docs.docker.com/develop/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Docker 开发&lt;/a&gt;服务，应用程序的父镜像应包含 Filebeat，例如 &lt;code&gt;FROM 父镜像&lt;/code&gt; 之后执行一系列下载、安装、设置 Filebeat 的指令。&lt;/p&gt;
&lt;p&gt;Filebeat 作为应用程序的 agent 可以&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-input-log.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;将日志作为输入源（从日志文件读取行）&lt;/a&gt;，再&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/guide/en/beats/filebeat/master/kafka-output.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;将 kafka 作为输出目的地（发送日志记录或事件到 Kafka）&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/products/logstash&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Logstash&lt;/a&gt;，传输和处理日志、事件等数据。&lt;/p&gt;
&lt;p&gt;因为 Logstash 有许多&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/guide/en/logstash/current/input-plugins.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;输入插件&lt;/a&gt;，包括&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/guide/en/logstash/current/input-plugins.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;读取来自 Kafka Topic 的事件&lt;/a&gt;，可以作为 Kafka 的消费者。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/what-is/elk-stack&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ELK&lt;/a&gt; 中的 Logstash 当然支持&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;将 Elasticsearch 作为输出目的地&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/products/elasticsearch&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Elasticsearch&lt;/a&gt;，分布式 RESTful 搜索引擎。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/kibana&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kibana&lt;/a&gt;，可视化 Elasticsearch 数据的用户界面。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有趣的是，&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/cn/elastic-stack&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Elastic Stack&lt;/a&gt; 并不包含 &lt;a class=&#34;link&#34; href=&#34;https://kafka.apache.org&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kafka&lt;/a&gt;，但两者在日志/事件处理领域却是经典组合。&lt;/p&gt;
&lt;h3 id=&#34;何时组合使用-kafka-与-elastic-stack&#34;&gt;何时组合使用 Kafka 与 Elastic Stack&lt;/h3&gt;
&lt;h4 id=&#34;应对突发流量&#34;&gt;应对突发流量&lt;/h4&gt;
&lt;p&gt;在大数据领域，Kafka 以单位时间内&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Throughput&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;吞吐量&lt;/a&gt;极高著称，所谓吞吐量是指代可处理的记录条数，Kafka 非常适用于&lt;strong&gt;流量削峰&lt;/strong&gt;。早在 2014 年，Kafka 已经能达到&lt;a class=&#34;link&#34; href=&#34;https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;每秒 200 万次写入（在三台廉价的机器上）&lt;/a&gt;。为什么 Kafka 如此之快？至少有如下原因：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;基于追加式&lt;a class=&#34;link&#34; href=&#34;https://h2cone.github.io/2020/08/30/log-notes/#%E6%8F%90%E4%BA%A4%E6%97%A5%E5%BF%97&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;提交日志&lt;/a&gt;，顺序 I/O 飞快。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重度使用文件系统缓存。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;复杂性从生产者转移到了消费者。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;高度可水平/横向扩展。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kafka 应对峰值或突发数据的能力远强于 Logstash，可防止单位时间输入过多日志数据导致 Logstash 成为系统的瓶颈；值得注意的是，完成本篇之时，官方的 &lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/guide/en/logstash/current/deploying-and-scaling.html#_scalability&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Logstash 扩展建议&lt;/a&gt;也仅有一小段。&lt;/p&gt;
&lt;h4 id=&#34;当-es-不可访问&#34;&gt;当 ES 不可访问&lt;/h4&gt;
&lt;p&gt;当 Elasticsearch 集群不可访问时（例如升级版本或者其他理由需要暂时下线），Kafka 能够暂时保存 Filebeat 采集的日志数据，直到 Elasticsearch 和 Logstash 再次上线。&lt;/p&gt;
&lt;h3 id=&#34;扩展和容错&#34;&gt;扩展和容错&lt;/h3&gt;
&lt;p&gt;引用一张来自 &lt;a class=&#34;link&#34; href=&#34;https://www.confluent.io/resources/kafka-the-definitive-guide/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kafka: The Definitive Guide&lt;/a&gt; 的插图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/kafka/A_consumer_group_reading_from_a_topic.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;A_consumer_group_reading_from_a _topic&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;消费者群组（Consumer Group）保证同一个主题（Topic）的任意分区（Partition）最多只能被组内的一个消费者使用。增加 Logstash 实例来组成一个消费者群组，它们将并发读取 Kafka Topic 中的日志消息，而不会交叠，因此能够提升单位时间内从 Kafka 到 Logstash 再到 Elasticsearch 的吞吐量；使用多个 Logstash 实例的另外一个好处是是增强系统的容错能力。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/kafka/consumer-groups.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;consumer-groups&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;默认情况下，当消费者加入或离开消费者群组将触发&lt;strong&gt;再平衡（rebalancing）&lt;/strong&gt;，Logstash 消费者的 Kafka Client 库将参与重新分配分区给消费者的过程。当群组中有若干 Logstash 实例失效时，根据再平衡协议，失去消费者的分区将被分配给现有的消费者。&lt;/p&gt;
&lt;h3 id=&#34;一点建议&#34;&gt;一点建议&lt;/h3&gt;
&lt;p&gt;假设 Logstash 实例组成的消费者群组 ID 为 &lt;code&gt;logstash&lt;/code&gt;，存储应用程序日志记录的话题 ID 为 &lt;code&gt;app_logs&lt;/code&gt;，下面是 &lt;code&gt;logstash-*.conf&lt;/code&gt; 的输入源配置：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;input {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    kafka {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        bootstrap_servers =&amp;gt; &amp;#34;kafka_host_1:9092,kafka_host_2:9092&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        group_id =&amp;gt; &amp;#34;logstash&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        topics =&amp;gt; [&amp;#34;app_logs&amp;#34;]
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        consumer_threads =&amp;gt; 8
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        ...
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;其中 &lt;code&gt;consumer_threads&lt;/code&gt; 是消费者线程数（默认值是 1），理想情况下，消费者线程数之和应与分区数相等，以实现完美平衡。如果消费者线程数之和多于分区数，那么某些线程将处于空闲状态；如果消费者线程数之和少于分区数，那么某些线程将消费多个分区。举例来说，&lt;code&gt;app_logs&lt;/code&gt; 话题的分区数为 16，最佳的部署方式很可能是将消费者线程数为 8 的 2 个 Logstash 实例部署到 2 台 CPU 核数为 8 的机器上。&lt;/p&gt;
&lt;p&gt;虽说 Kafka 应对突发数据或流量高峰的能力很强，但是在无法估算日志记录/事件的量级与流速之前应备不时之需。例如，使用一些“突发”主题，当单位时间内应用程序产生过多日志数据时，可以在运行时将其移动到“突发”主题，使其它主题避免不必要的流量。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;本文首发于 &lt;a class=&#34;link&#34; href=&#34;https://h2cone.github.io&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://h2cone.github.io&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/cn/blog/just-enough-kafka-for-the-elastic-stack-part1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Just Enough Kafka for the Elastic Stack, Part 1&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ops-coffee.cn/s/7bygznor_mdcwpf9przcfg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ELK日志系统之通用应用程序日志接入方案&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/swlh/why-kafka-is-so-fast-bde0d987cd03&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Why Kafka Is so Fast&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ops-coffee.cn/s/zlslsqrrlom-8sfwnwcksg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ELK架构下利用Kafka Group实现Logstash的高可用&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/streamthoughts/apache-kafka-rebalance-protocol-or-the-magic-behind-your-streams-applications-e94baf68e4f2&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Apache Kafka Rebalance Protocol, or the magic behind your streams applications&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>日志游记</title>
        <link>https://h2cone.github.io/2020/08/30/log-notes/</link>
        <pubDate>Sun, 30 Aug 2020 15:21:41 +0800</pubDate>
        
        <guid>https://h2cone.github.io/2020/08/30/log-notes/</guid>
        <description>&lt;h2 id=&#34;什么是日志&#34;&gt;什么是日志&lt;/h2&gt;
&lt;p&gt;日志是&lt;strong&gt;追加式&lt;/strong&gt;的，&lt;strong&gt;按时间排序&lt;/strong&gt;的记录（条目）序列。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/log/log%28file%29.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;log(file).png&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;无关记录的格式，日志文件记录操作系统或其它软件运行时发生的&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Event_%28computing%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;事件&lt;/a&gt;及其时间。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;lt;34&amp;gt;1 2003-10-11T22:14:15.003Z mymachine.example.com su - ID47 - BOM&amp;#39;su root&amp;#39; failed for lonvick on /dev/pts/8
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;“应用程序日志”是人类可读的文本，比如 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Syslog&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Syslog&lt;/a&gt; 和 &lt;a class=&#34;link&#34; href=&#34;http://www.slf4j.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SLF4J&lt;/a&gt; 等；如上所示，这是一个来自 &lt;a class=&#34;link&#34; href=&#34;https://tools.ietf.org/html/rfc5424&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;RFC5424&lt;/a&gt; 的 syslog 日志消息例子，从中不难看出主机（mymachine.example.com）上的一个应用程序（su）在 2003-10-11T22:14:15.003Z 发生了 “&amp;lsquo;su root&amp;rsquo; failed for lonvick&amp;hellip;”。&lt;/p&gt;
&lt;p&gt;现代最流行的分布式版本控制系统中的日志记录着所有贡献者的提交&lt;strong&gt;历史&lt;/strong&gt;：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% git log
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;commit 130560a769fe6da64c87f695e4665225de1faec3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Author: Daniel Smith &amp;lt;dbsmith@google.com&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Date:   Fri Jun &lt;span class=&#34;m&#34;&gt;6&lt;/span&gt; 17:31:45 &lt;span class=&#34;m&#34;&gt;2014&lt;/span&gt; -0700
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Proofread guestbook.md
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;commit 2c4b3a562ce34cddc3f8218a2c4d11c7310e6d56
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Author: Joe Beda &amp;lt;joe.github@bedafamily.com&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Date:   Fri Jun &lt;span class=&#34;m&#34;&gt;6&lt;/span&gt; 16:40:48 &lt;span class=&#34;m&#34;&gt;2014&lt;/span&gt; -0700
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    First commit
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;然而，日志并非全都是人类可读的，它可能是二进制格式而只能被程序读取，作为关键抽象普遍存在于数据库系统和分布式系统之中。&lt;/p&gt;
&lt;h2 id=&#34;数据库日志&#34;&gt;数据库日志&lt;/h2&gt;
&lt;p&gt;关系数据库系统中的日志通常用于&lt;a class=&#34;link&#34; href=&#34;http://mlwiki.org/index.php/Crash_Recovery&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;崩溃恢复&lt;/a&gt;、提供一定程度的&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Atomicity_%28database_systems%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;原子性&lt;/a&gt;与&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Durability_%28database_systems%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;持久性&lt;/a&gt;、&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Replication_%28computing%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数据复制&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;预写日志&#34;&gt;预写日志&lt;/h3&gt;
&lt;p&gt;根据经验，我们确信入库数据终将会被写入磁盘。磁盘是一种 I/O 设备（参考&lt;a class=&#34;link&#34; href=&#34;https://h2cone.github.io/2020/03/08/network_nio/#i-o&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;网络·NIO # I/O&lt;/a&gt;），从主存复制数据到 I/O 设备并不是一个原子操作，如果客户端发送请求后，数据库服务端处理请求中，系统&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Crash_%28computing%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;崩溃&lt;/a&gt;或宕机抑或重启，服务端·如何保证不丢失变更或者恢复到正确的数据？&lt;/p&gt;
&lt;p&gt;很久以前，存在着无原子性的非分布式数据库事务。张三账户有 1000 元，李四账户有 2000 元，张三向李四转账 200 元，数据库系统先将张三账户减少 200 元，然后将 800 元写回张三账户，接着将李四账户增加 200 元并且将 2200 元写回李四账户时，服务器突然发生故障；系统重启后，只有一个账户是对的，张三账户是 800 元，但是李四账户还是 2000 元，200 元不翼而飞。&lt;/p&gt;
&lt;p&gt;计算机界明显的坑早已被前人填满。&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Write-ahead_logging&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Write-ahead logging&lt;/a&gt; 是数据库系统中提供原子性与持久性的技术（日志先行技术），简称 &lt;strong&gt;WAL&lt;/strong&gt;，一言蔽之，数据库系统首先将数据变更记录到日志中，然后将日志写入稳定存储（如磁盘），之后才将变更写入数据库。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://mlwiki.org/index.php/Redo_Logging&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Redo log&lt;/a&gt; 和 &lt;a class=&#34;link&#34; href=&#34;http://mlwiki.org/index.php/Undo_Logging&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Undo log&lt;/a&gt; 是运用了 WAL 的磁盘数据结构：&lt;/p&gt;
&lt;p&gt;&lt;del&gt;- Undo log 在崩溃恢复期间用于撤消或回滚未提交的事务。&lt;/del&gt;&lt;/p&gt;
&lt;p&gt;&lt;del&gt;- Redo log 在崩溃恢复期间用于重做已提交但未将数据库对象从缓冲区刷入磁盘的事务。&lt;/del&gt;&lt;/p&gt;
&lt;p&gt;撤消和重做的前提是记录了数据库对象变更前的值和变更后的值。&lt;/p&gt;
&lt;p&gt;假设事务 T[i] 所操作的数据库对象是 X，X 的值从 V[old] 更改为 V[new]，&lt;del&gt;将数据从缓冲区刷入磁盘的操作被称为 flush&lt;/del&gt;，那么 undo/redo log 日志记录形式如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;begin T[i]        //（1）
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;(T[i], X, V)      //（2）
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;commit T[i]       //（3）
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;（1）记录事务开始。&lt;/p&gt;
&lt;p&gt;（2）记录数据库对象的值。Undo log 记录 (T[i], X, V[old]) ，而 Redo log 记录 (T[i], X, V[new])，两者都要求 flush X 之前 flush (T[i], X, V)。&lt;/p&gt;
&lt;p&gt;（3）记录事务提交。Undo log 要求 flush X 之后 flush (commit T[i])，而 Redo log 要求 flush X 之前 flush (commit T[i])。&lt;/p&gt;
&lt;p&gt;在崩溃恢复期间，从数据库系统角度来看：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;若发现 undo log 缺少（3），则无法确定 flush X 是否完成。决定将 X 的值设为 V[old] 后 flush X，因为 X 变更前的值是 V[old]，即使恢复过程中又发生崩溃，重复将 X 的值设为 V[old] 仍然&lt;strong&gt;幂等&lt;/strong&gt;，直到恢复完成后，可以在（3）位置写一条记录：rollback T[i]，下次恢复期间忽略。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;若发现 redo log 缺少（3），则确定 flush X 未执行。决定将 X 的值设为 V[new]，重试 flush X。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;若发现缺少（2），则忽略此事务（无计可施）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;若没有（1），则无此事务。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;逻辑日志&#34;&gt;逻辑日志&lt;/h3&gt;
&lt;p&gt;前文&lt;a class=&#34;link&#34; href=&#34;https://h2cone.github.io/2020/07/11/from-mysql-to-tidb/#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MySQL 窘境 # 主从复制&lt;/a&gt;中提到其数据复制需要数据变更日志，或则数据变更日志记录（事件）。MySQL Server 有&lt;a class=&#34;link&#34; href=&#34;https://dev.mysql.com/doc/refman/5.7/en/server-logs.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;若干种日志&lt;/a&gt;，其中二进制日志（Binary log，简称 binlog）包含描述数据变更的“事件”，例如创建表或对表数据的更改，&lt;strong&gt;MySQL binlog 与存储引擎解耦&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在服务化架构中，组合使用 MySQL 和 &lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/products/elasticsearch&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Elasticsearch&lt;/a&gt; 时常常要求将 MySQL 数据同步到 Elasticsearch；Elastic Stack 的解决方案是使用 &lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/logstash&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Logstash&lt;/a&gt; 的插件：&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Jdbc input plugin&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/elastic-stack/logstash-plugin.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;logstash-plugin&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;Logstash 的 Jdbc input plugin 会根据配置文件定时/定期对 MySQL 进行轮询，可获取上一次询问之后插入或更改的记录。有人误以为 Jdbc input plugin 最快只能每分钟查询一次，实际上也能设置&lt;a class=&#34;link&#34; href=&#34;https://github.com/logstash-plugins/logstash-input-jdbc/issues/265&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;秒级&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;监听 binlog 事件可以实现将 MySQL 数据同步到各种数据源，这种方案非常适合各种消息传递、数据流、实时数据处理。假设有一个中间件，根据 &lt;a class=&#34;link&#34; href=&#34;https://dev.mysql.com/doc/internals/en/client-server-protocol.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MySQL 协议&lt;/a&gt;，它只要向 MySQL master 注册为 MySQL slave，持续接收并解析 binlog 事件，经过处理后又能作为消息传递给各种服务或组件以满足数据同步需求；比如 &lt;a class=&#34;link&#34; href=&#34;https://github.com/alibaba/canal&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;alibaba/canal&lt;/a&gt;，它是一个关于 MySQL binlog 增量订阅&amp;amp;消费的组件。&lt;/p&gt;
&lt;p&gt;诸如此类的设计模式被称为 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Change_data_capture&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CDC（change data capture）&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;分布式系统日志&#34;&gt;分布式系统日志&lt;/h2&gt;
&lt;p&gt;这要从&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/State_machine_replication&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;状态机复制&lt;/a&gt;说起。如下图所示，每个 Server 存储了一个它的&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Finite-state_machine&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;状态机（State Machine）&lt;/a&gt;按顺序执行的一系列命令的日志（Log）；每个日志包含相同顺序的命令集，因此每个状态机将执行相同的命令序列；因为讨论的状态机具有&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Deterministic_algorithm&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;确定性&lt;/a&gt;，所以它们将产生相同的输出并以相同的状态结束。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/distributed-system/replicated-state-machine-architecture.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;replicated-state-machine-architecture&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;什么是确定性？给定特定的输入，将始终产生相同的输出。作为反面，执行类似以下命令的若干状态机（进程）将产生不同的输出并以不同的状态（磁盘和主存中的数据）结束。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;INSERT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;INTO&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;VALUES&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;NOW&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;());&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;状态机复制通常使用 &lt;strong&gt;replicated log&lt;/strong&gt; 实现，保持 replicated log 的一致性是&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Consensus_%28computer_science%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;共识&lt;/a&gt;算法的工作。&lt;/p&gt;
&lt;h2 id=&#34;提交日志&#34;&gt;提交日志&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://kafka.apache.org&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Apache Kafka&lt;/a&gt; 分区（partition）的本质是&lt;strong&gt;提交日志（commit log）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;如果把 Kafka 与&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Relational_database&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;关系型数据库&lt;/a&gt;作类比，那么消息（message）类比行（row），主题（topic）类比表（table）；一个主题分成多个分区，分区是追加式的消息序列，同一个主题的多个分区可以分布在不同机器上。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/kafka/Representation_of_a_topic_with_multiple_partitions.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Representation_of_a_topic_with_multiple_partitions&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;从 Kafka 的角度来看，将消息写入分区就像将日志记录写入提交日志（追加式更新日志文件）。&lt;/p&gt;
&lt;p&gt;在 Kafka 的 &lt;code&gt;server.properties&lt;/code&gt; 中，有一个 &lt;code&gt;log.dirs&lt;/code&gt; 用于指定日志文件目录列表。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# A comma separated list of directories under which to store log files
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;log.dirs=/usr/local/var/lib/kafka-logs
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在磁盘上，一个分区是一个目录，例如主题名为 quickstart-events 的一个分区：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% tree /usr/local/var/lib/kafka-logs/quickstart-events-0/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;/usr/local/var/lib/kafka-logs/quickstart-events-0/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── 00000000000000000000.index
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── 00000000000000000000.log
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── 00000000000000000000.timeindex
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;└── leader-epoch-checkpoint
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;其中 index 文件与 log 文件合称为一个 &lt;strong&gt;segment&lt;/strong&gt;，以人类可读的方式查看 log 文件：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% kafka-run-class kafka.tools.DumpLogSegments --deep-iteration --print-data-log --files /usr/local/var/lib/kafka-logs/quickstart-events-0/00000000000000000000.log
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Dumping /usr/local/var/lib/kafka-logs/quickstart-events-0/00000000000000000000.log
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Starting offset: &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;baseOffset: &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; lastOffset: &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; count: &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; isTransactional: &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt; isControl: &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt; position: &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; CreateTime: &lt;span class=&#34;m&#34;&gt;1604900950169&lt;/span&gt; size: &lt;span class=&#34;m&#34;&gt;90&lt;/span&gt; magic: &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; compresscodec: NONE crc: &lt;span class=&#34;m&#34;&gt;3202290031&lt;/span&gt; isvalid: &lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; offset: &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; CreateTime: &lt;span class=&#34;m&#34;&gt;1604900950169&lt;/span&gt; keysize: -1 valuesize: &lt;span class=&#34;m&#34;&gt;22&lt;/span&gt; sequence: -1 headerKeys: &lt;span class=&#34;o&#34;&gt;[]&lt;/span&gt; payload: This is my first event
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;baseOffset: &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; lastOffset: &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; count: &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; isTransactional: &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt; isControl: &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt; position: &lt;span class=&#34;m&#34;&gt;90&lt;/span&gt; CreateTime: &lt;span class=&#34;m&#34;&gt;1604900955215&lt;/span&gt; size: &lt;span class=&#34;m&#34;&gt;91&lt;/span&gt; magic: &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; compresscodec: NONE crc: &lt;span class=&#34;m&#34;&gt;3852839661&lt;/span&gt; isvalid: &lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; offset: &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; CreateTime: &lt;span class=&#34;m&#34;&gt;1604900955215&lt;/span&gt; keysize: -1 valuesize: &lt;span class=&#34;m&#34;&gt;23&lt;/span&gt; sequence: -1 headerKeys: &lt;span class=&#34;o&#34;&gt;[]&lt;/span&gt; payload: This is my second event
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;从中可以发现，消息编码在 log 文件中；index 文件则包含了偏移量（offset）与消息在 log 文件中的位置（position）的映射，用于查找消息。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://h2cone.github.io/img/kafka/A_consumer_group_reading_from_a_topic.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;A_consumer_group_reading_from_a _topic&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;对于消息消费者组（consumer group）来说，从分区读取消息就像从提交日志读取记录；消费者组通过分区的偏移量区分已读消息和未读消息，消费者组对主题（Topic）的分区的偏移量存储在 &lt;a class=&#34;link&#34; href=&#34;https://elang2.github.io/myblog/posts/2017-09-20-Kafak-And-Zookeeper-Offsets.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Zookeeper 树或 Kafka 内置主题&lt;/a&gt;中。&lt;/p&gt;
&lt;p&gt;毫不夸张地说，Kafka 是一个分布式提交日志系统，只不过官方更愿意称之为分布式事件&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Streaming_data&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;流&lt;/a&gt;平台。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;本文首发于 &lt;a class=&#34;link&#34; href=&#34;https://h2cone.github.io&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://h2cone.github.io&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;The Log: What every software engineer should know about real-time data&amp;rsquo;s unifying abstraction&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Log_file&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Wikipedia # Log file&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Write-ahead_logging&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Wikipedia # Write-ahead logging&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://mlwiki.org/index.php/Undo/Redo_Logging&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML Wiki # Undo/Redo Logging&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://www.mathcs.emory.edu/~cheung/Courses/554/Syllabus/6-logging/overview.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Intro to undo/redo logging&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://www.mathcs.emory.edu/~cheung/Courses/554/Syllabus/6-logging/undo-redo2.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Recovering from a system crash using undo/redo-log&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/35574452&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;undo log 与 redo log 原理分析&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://dev.mysql.com/doc/refman/5.7/en/binary-log.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MySQL 5.7 Reference Manual # The Binary Log&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://dev.mysql.com/doc/refman/5.7/en/mysqlbinlog.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MySQL 5.7 Reference Manual # mysqlbinlog — Utility for Processing Binary Log Files&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://dev.mysql.com/doc/refman/5.7/en/replication-formats.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MySQL 5.7 Reference Manual # Replication Formats&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/blog/how-to-keep-elasticsearch-synchronized-with-a-relational-database-using-logstash&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;How to keep Elasticsearch synchronized with a relational database using Logstash and JDBC&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@siddontang/how-to-sync-your-mysql-data-to-elasticsearch-ddae009243c1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;How to sync your MySQL data to Elasticsearch&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://raft.github.io&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;The Raft Consensus Algorithm&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://thehoard.blog/how-kafkas-storage-internals-work-3a29b02e026&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;How Kafka’s Storage Internals Work&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://presos.jamesward.com/distributed_commit_logs_with_apache_kafka/#/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Distributed Commit Logs with Apache Kafka&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        
    </channel>
</rss>
