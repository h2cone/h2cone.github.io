<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kafka on Huangh&#39;s blog</title>
    <link>https://h2cone.github.io/tags/kafka/</link>
    <description>Recent content in kafka on Huangh&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© Huangh&#39;s blog</copyright>
    <lastBuildDate>Mon, 20 Jun 2022 10:16:16 +0800</lastBuildDate>
    
	<atom:link href="https://h2cone.github.io/tags/kafka/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>高吞吐 Kafka 客户端配置</title>
      <link>https://h2cone.github.io/2022/06/20/high_throughput_kafka_client_config/</link>
      <pubDate>Mon, 20 Jun 2022 10:16:16 +0800</pubDate>
      
      <guid>https://h2cone.github.io/2022/06/20/high_throughput_kafka_client_config/</guid>
      <description>写在前面的话 团队围绕着 Kafka 一系列服务的压力测试的核心指标之一是 Eevents per second，排除其它因素，它与吞吐量正相关。
什么是吞吐量 吞吐量是指通过通信通道成功传递消息的速率。从 Kafka 生产者（Producer）的角度来看，可以用单位时间内交付成功的记录条数或大小来描述吞吐量；从 Kafka 消费者（Consumer）的角度来看，可以用单位时间内读取的记录条数或大小来描述。
生产者准备记录包含业务逻辑，此处只关注单位时间内接收到回执（ack）的记录条数或大小。默认情况下，生产者使用异步发送，且它将尝试在内存中累积记录并在单个请求中发送批量记录。
for (long i = 0; i &amp;lt; numRecords; i++) { producer.send(record, callback); } 调用方法 KafkaProducer.send(ProducerRecord, Callback) 不阻塞在该方法，既传递记录（record）的引用，也传递回调（callback）的引用。
class MyCallback implements Callback { @Override public void onCompletion(RecordMetadata metadata, Exception e) { // handling  } } 生产者接受到发送记录的回执时，将有线程执行方法 onCompletion 的代码，我们可以在回调方法体内实现记录条数或大小的累计。
注意：“提交偏移量”不一定发生在“处理记录”之后。
while (conditions) { ConsumerRecords records = consumer.poll(timeout); processRetrievedRecords(records); } 消费者处理记录包含业务逻辑，此处只关注单位时间内接受到的记录条数或大小。默认情况下，消费者通过轮询拉取（poll）批量的记录，每次调用方法 KafkaConsumer.poll(Duration) 阻塞在该方法，直到超时（timeout）返回，且会有线程定期透明地提交前一批的最后一条记录的偏移量（auto commit）。
测试吞吐量 生产者工具 在 Kafka 安装目录，有助于测试生产者性能的命令行工具是 kafka-producer-perf-test.</description>
    </item>
    
    <item>
      <title>Kafka 之于 Elastic Stack</title>
      <link>https://h2cone.github.io/2020/11/22/kafka_in_the_elk/</link>
      <pubDate>Sun, 22 Nov 2020 11:32:08 +0800</pubDate>
      
      <guid>https://h2cone.github.io/2020/11/22/kafka_in_the_elk/</guid>
      <description>背景 刚入行那会，公司产品研发部正如火如荼建设微服务基础设施，其中就包括日志中心。试想一下，包含众多容器化应用程序的系统，一个服务可能会有多个实例，每个实例输出各自的日志记录；假如在客户端收到了来自服务器端的异常响应，例如 500 Internal Server Error，相应的负责人不可避免地会遇到需要通过查看容器日志来查明哪里发生故障或则什么原因导致性能下降的情景。
负责人也许走了弯路。登录哪些服务器或跳板机？有没有访问权？需不需要通过“中介”才能获得许可或相关日志文件？查看哪些结点上的哪些服务的日志？
负责人也以可以走已经铺好的路。直接在日志中心 Web 版搜索所需的一切日志记录；系统中所有服务的日志记录都可以被索引与检索，不仅仅可以用于故障排除，还可以用于监控、告警、数据分析等等。
集中式日志管理 上图来自运维咖啡吧，这是一类典型的日志处理架构。
 Filebeat，轻量级日志采集器。  考虑到基于 Docker 开发服务，应用程序的父镜像应包含 Filebeat，例如 FROM 父镜像 之后执行一系列下载、安装、设置 Filebeat 的指令。 Filebeat 作为应用程序的 agent 可以将日志作为输入源（从日志文件读取行），再将 kafka 作为输出目的地（发送日志记录或事件到 Kafka）。   Logstash，传输和处理日志、事件等数据。  因为 Logstash 有许多输入插件，包括读取来自 Kafka Topic 的事件，可以作为 Kafka 的消费者。 ELK 中的 Logstash 当然支持将 Elasticsearch 作为输出目的地。   Elasticsearch，分布式 RESTful 搜索引擎。 Kibana，可视化 Elasticsearch 数据的用户界面。  有趣的是，Elastic Stack 并不包含 Kafka，但两者在日志/事件处理领域却是经典组合。
何时组合使用 Kafka 与 Elastic Stack 应对突发流量 在大数据领域，Kafka 以单位时间内吞吐量极高著称，所谓吞吐量是指代可处理的记录条数，Kafka 非常适用于流量削峰。早在 2014 年，Kafka 已经能达到每秒 200 万次写入（在三台廉价的机器上）。为什么 Kafka 如此之快？至少有如下原因：</description>
    </item>
    
    <item>
      <title>日志游记</title>
      <link>https://h2cone.github.io/2020/08/30/log-notes/</link>
      <pubDate>Sun, 30 Aug 2020 15:21:41 +0800</pubDate>
      
      <guid>https://h2cone.github.io/2020/08/30/log-notes/</guid>
      <description>什么是日志 日志是追加式的，按时间排序的记录（条目）序列。
无关记录的格式，日志文件记录操作系统或其它软件运行时发生的事件及其时间。
&amp;lt;34&amp;gt;1 2003-10-11T22:14:15.003Z mymachine.example.com su - ID47 - BOM&amp;#39;su root&amp;#39; failed for lonvick on /dev/pts/8 “应用程序日志”是人类可读的文本，比如 Syslog 和 SLF4J 等；如上所示，这是一个来自 RFC5424 的 syslog 日志消息例子，从中不难看出主机（mymachine.example.com）上的一个应用程序（su）在 2003-10-11T22:14:15.003Z 发生了 “&amp;lsquo;su root&amp;rsquo; failed for lonvick&amp;hellip;”。
现代最流行的分布式版本控制系统中的日志记录着所有贡献者的提交历史：
% git log ... commit 130560a769fe6da64c87f695e4665225de1faec3 Author: Daniel Smith &amp;lt;dbsmith@google.com&amp;gt; Date: Fri Jun 6 17:31:45 2014 -0700 Proofread guestbook.md commit 2c4b3a562ce34cddc3f8218a2c4d11c7310e6d56 Author: Joe Beda &amp;lt;joe.github@bedafamily.com&amp;gt; Date: Fri Jun 6 16:40:48 2014 -0700 First commit 然而，日志并非全都是人类可读的，它可能是二进制格式而只能被程序读取，作为关键抽象普遍存在于数据库系统和分布式系统之中。
数据库日志 关系数据库系统中的日志通常用于崩溃恢复、提供一定程度的原子性与持久性、数据复制。</description>
    </item>
    
  </channel>
</rss>